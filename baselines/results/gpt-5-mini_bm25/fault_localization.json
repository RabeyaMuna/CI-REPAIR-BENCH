[
    {
        "sha_fail": "2c06ffa4c9d2c37846c60ad75899b4d72f214ff9",
        "fault_localization_data": [
            {
                "file_path": "examples/community/ip_adapter_face_id.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/diffusers/examples/community/ip_adapter_face_id.py",
                "faults": [
                    {
                        "file_path": "examples/community/ip_adapter_face_id.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/diffusers/examples/community/ip_adapter_face_id.py",
                        "line_range": [
                            15,
                            43
                        ],
                        "reason": "CI reported a ruff formatting/import-order error at examples/community/ip_adapter_face_id.py:15:1 (I001). The import block spanning lines 15\u201343 is flagged as \"un-sorted or un-formatted\" (I001) and the CI log notes this is fixable with `--fix`. The failure comes from the contiguous import section starting at line 15 \u2014 ruff enforces import ordering/formatting rules and detected the block is not sorted/formatted correctly. The import block scope (lines 15\u201343 per outline) is reported; per import_block expansion include two lines after the import block (up to line 45) to cover surrounding formatting. Evidence: CI message \"I001 Import block is un-sorted or un-formatted\" and \"[*] 1 fixable with the `--fix` option.\"",
                        "issue_type": "formatting",
                        "fault_localization_level": "import_block",
                        "code_snippet": "import inspect\nfrom typing import Any, Callable, Dict, List, Optional, Union\nfrom safetensors import safe_open\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom packaging import version\nfrom transformers import CLIPImageProcessor, CLIPTextModel, CLIPTokenizer, CLIPVisionModelWithProjection\n\nfrom diffusers.configuration_utils import FrozenDict\nfrom diffusers.image_processor import VaeImageProcessor\nfrom diffusers.loaders import FromSingleFileMixin, IPAdapterMixin, LoraLoaderMixin, TextualInversionLoaderMixin\nfrom diffusers.models import AutoencoderKL, UNet2DConditionModel\nfrom diffusers.models.attention_processor import FusedAttnProcessor2_0\nfrom diffusers.models.lora import adjust_lora_scale_text_encoder, LoRALinearLayer\nfrom diffusers.schedulers import KarrasDiffusionSchedulers\nfrom diffusers.utils import (\n    _get_model_file,\n    USE_PEFT_BACKEND,\n    deprecate,\n    logging,\n    scale_lora_layers,\n    unscale_lora_layers,\n)\nfrom diffusers.utils.torch_utils import randn_tensor\nfrom diffusers.pipelines.pipeline_utils import DiffusionPipeline\nfrom diffusers.pipelines.stable_diffusion.pipeline_output import StableDiffusionPipelineOutput\nfrom diffusers.pipelines.stable_diffusion.safety_checker import StableDiffusionSafetyChecker"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "db6550a228941b538f340fb5b65ed16c43a21b88",
        "fault_localization_data": [
            {
                "file_path": "src/diffusers/loaders/ip_adapter.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/diffusers/src/diffusers/loaders/ip_adapter.py",
                "faults": [
                    {
                        "file_path": "src/diffusers/loaders/ip_adapter.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/diffusers/src/diffusers/loaders/ip_adapter.py",
                        "line_range": [
                            14,
                            25
                        ],
                        "reason": "CI lint failure from ruff: F401 Unused import. Log: \"src/diffusers/loaders/ip_adapter.py:15:26: F401 [*] `typing.Optional` imported but unused\". In the import block (lines 14-25) line 15 imports Optional (`from typing import Dict, Optional, Union`) but Optional is not referenced anywhere in the file (type hints use Dict and Union at line 50, but not Optional). ruff reports this as fixable (`--fix`).",
                        "issue_type": "linting",
                        "fault_localization_level": "import_block",
                        "code_snippet": "import os\nfrom typing import Dict, Optional, Union\n\nimport torch\nfrom huggingface_hub.utils import validate_hf_hub_args\nfrom safetensors import safe_open\n\nfrom ..utils import (\n    _get_model_file,\n    is_transformers_available,\n    logging,\n)"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "102f918deb2532bb7b825f00258f2c1414cf94da",
        "fault_localization_data": [
            {
                "file_path": "requirements/requirements.txt",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/mindsdb/requirements/requirements.txt",
                "faults": [
                    {
                        "file_path": "requirements/requirements.txt",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/mindsdb/requirements/requirements.txt",
                        "line_range": [
                            1,
                            39
                        ],
                        "reason": "CI check_requirements failed with DEP002: \"'type_infer' defined as a dependency but not used in the codebase\". The requirements file declares type_infer==0.0.17 on line 27 (line 0027: \"type_infer==0.0.17\"). The tests/scripts/check_requirements.py reported this unused-declared-dependency and exited with code 1, causing the Check main requirements step to fail. Actionable faults: 1) Unused dependency 'type_infer' present in requirements (line 27) per DEP002. 2) The unused dependency causes the requirements check to fail (observed exit code 1 in CI logs).",
                        "issue_type": "dependency_error",
                        "fault_localization_level": "file",
                        "code_snippet": "packaging\nwerkzeug==2.2.2\npandas >=2.0.0, <2.1.0\nflask-restx >= 1.0.1, < 2.0.0\nflask == 2.2.2\npython-multipart >= 0.0.5\npyparsing >= 2.3.1\ncryptography>=35.0\npsycopg[binary]\nwaitress >= 1.4.4\npymongo[srv] >= 4.1.1\npsutil\nsqlalchemy >= 2.0.0, < 3.0.0\npsycopg2-binary  # This is required for using sqlalchemy with postgres\nalembic >= 1.3.3\nredis >=5.0.0, < 6.0.0\nwalrus==0.9.3\nflask-compress >= 1.0.0\nappdirs >= 1.0.0\nmindsdb-sql ~= 0.9.0\nmindsdb-evaluator >= 0.0.7, < 0.1.0\nchecksumdir >= 1.2.0\nduckdb == 0.9.1\nrequests >= 2.30.0\npydateinfer==0.3.0\ndataprep_ml==0.0.21\ntype_infer==0.0.17\ndill == 0.3.6\nnumpy\npytz\nbotocore\nboto3\npython-dateutil\ngunicorn\nscikit-learn==1.3.2\nprotobuf==3.20.3\nhierarchicalforecast~=0.4.0\nlangchain==0.0.347\ngoogle-auth-oauthlib"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "2e41e783672597e2e0c7b2842b5934d879374028",
        "fault_localization_data": [
            {
                "file_path": "tests/test_websockets.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/tests/test_websockets.py",
                "faults": [
                    {
                        "file_path": "tests/test_websockets.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/tests/test_websockets.py",
                        "line_range": [
                            212,
                            223
                        ],
                        "reason": "Test failure reported by CI: AttributeError: 'has_calls' is not a valid assertion. Use a spec for the mock if 'has_calls' is meant to be an attribute. (as shown in CI short summary; failing tests: tests/test_websockets.py::test_ws_frame_put_message_into_queue[0/1/2]). In this test function (lines 212-223) the assertion incorrectly calls assembler.chunks_queue.put.has_calls(... ) at lines 220-223; unittest.mock provides assert_has_calls, not has_calls, so the test raises AttributeError. Additional related CI evidence: a RuntimeWarning 'coroutine ... was never awaited' was emitted from sanic/server/websockets/frame.py:291 in the same test run \u2014 this test also sets assembler.chunks_queue = AsyncMock(spec=Queue) (line 214) and assembler.message_fetched = AsyncMock() (lines 215-216), which interacts with the runtime warning (frame implementation appears to call message_fetched.clear() without awaiting a coroutine). Combined: primary failing cause in this method is the invalid use of has_calls (AttributeError), and the method also exercises AsyncMock-based interactions that produced a runtime coroutine-await warning during CI.",
                        "issue_type": "test_failure",
                        "fault_localization_level": "method",
                        "code_snippet": "async def test_ws_frame_put_message_into_queue(opcode):\n    assembler = WebsocketFrameAssembler(Mock())\n    assembler.chunks_queue = AsyncMock(spec=Queue)\n    assembler.message_fetched = AsyncMock()\n    assembler.message_fetched.is_set = Mock(return_value=False)\n\n    await assembler.put(Frame(opcode, b\"foo\"))\n\n    assembler.chunks_queue.put.has_calls(\n        call(b\"foo\"),\n        call(None),\n    )"
                    },
                    {
                        "file_path": "tests/test_websockets.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/tests/test_websockets.py",
                        "line_range": [
                            186,
                            193
                        ],
                        "reason": "Runtime warning observed in CI: 'coroutine \"AsyncMockMixin._execute_mock_call\" was never awaited' (from sanic/server/websockets/frame.py:291). The test function test_ws_frame_put_fetched (lines 186-193) sets assembler.message_fetched = AsyncMock() (line 188) and assembler.message_fetched.is_set = Mock(return_value=False) (line 189) and then awaits assembler.put(...). CI evidence indicates the frame implementation likely calls message_fetched.clear() (a coroutine when message_fetched is an AsyncMock) without awaiting it, producing the 'coroutine was never awaited' runtime warning. This is a runtime issue triggered by the interaction between the test's AsyncMock and the frame implementation.",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "method",
                        "code_snippet": "async def test_ws_frame_put_fetched(opcode):\n    assembler = WebsocketFrameAssembler(Mock())\n    assembler.message_fetched = AsyncMock()\n    assembler.message_fetched.is_set = Mock(return_value=False)\n\n    await assembler.put(Frame(opcode, b\"\"))\n    assembler.message_fetched.wait.assert_awaited_once()\n    assembler.message_fetched.clear.assert_called_once()"
                    }
                ]
            },
            {
                "file_path": "sanic/server/websockets/frame.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/sanic/server/websockets/frame.py",
                "faults": [
                    {
                        "file_path": "sanic/server/websockets/frame.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/sanic/server/websockets/frame.py",
                        "line_range": [
                            235,
                            292
                        ],
                        "reason": "RuntimeWarning observed in CI: \"/home/runner/work/sanic/sanic/sanic/server/websockets/frame.py:291: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\". The warning points to line 291 where put() calls self.message_fetched.clear() (line 291) without awaiting. If a test or other code replaces self.message_fetched with an AsyncMock (whose .clear attribute is an async mock/coroutine), calling .clear() without await will create an un-awaited coroutine and produce this RuntimeWarning. This explains the coroutine-not-awaited message in the CI logs. (Scope: put method lines 235\u2013292.)",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "method",
                        "code_snippet": "    async def put(self, frame: Frame) -> None:\n        \"\"\"\n        Add ``frame`` to the next message.\n        When ``frame`` is the final frame in a message, :meth:`put` waits\n        until the message is fetched, either by calling :meth:`get` or by\n        iterating the return value of :meth:`get_iter`.\n        :meth:`put` assumes that the stream of frames respects the protocol.\n        If it doesn't, the behavior is undefined.\n        \"\"\"\n\n        async with self.write_mutex:\n            if frame.opcode is Opcode.TEXT:\n                self.decoder = UTF8Decoder(errors=\"strict\")\n            elif frame.opcode is Opcode.BINARY:\n                self.decoder = None\n            elif frame.opcode is Opcode.CONT:\n                pass\n            else:\n                # Ignore control frames.\n                return\n            data: Data\n            if self.decoder is not None:\n                data = self.decoder.decode(frame.data, frame.fin)\n            else:\n                data = frame.data\n            if self.chunks_queue is None:\n                self.chunks.append(data)\n            else:\n                await self.chunks_queue.put(data)\n\n            if not frame.fin:\n                return\n            if not self.get_in_progress:\n                # nobody is waiting for this frame, so try to pause subsequent\n                # frames at the protocol level\n                self.paused = self.protocol.pause_frames()\n            # Message is complete. Wait until it's fetched to return.\n\n            if self.chunks_queue is not None:\n                await self.chunks_queue.put(None)\n            if self.message_complete.is_set():\n                # This should be guarded against with the write_mutex\n                raise ServerError(\n                    \"Websocket put() got a new message when a message was \"\n                    \"already in its chamber.\"\n                )\n            self.message_complete.set()  # Signal to get() it can serve the\n            if self.message_fetched.is_set():\n                # This should be guarded against with the write_mutex\n                raise ServerError(\n                    \"Websocket put() got a new message when the previous \"\n                    \"message was not yet fetched.\"\n                )\n\n            # Allow get() to run and eventually set the event.\n            await self.message_fetched.wait()\n            self.message_fetched.clear()\n            self.decoder = None"
                    },
                    {
                        "file_path": "sanic/server/websockets/frame.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/sanic/sanic/server/websockets/frame.py",
                        "line_range": [
                            88,
                            164
                        ],
                        "reason": "Logical bug in get(): the code assigns completed = await self.message_complete.wait() (line 115) but asyncio.Event.wait() returns None, not a boolean. Immediately after, the code tests `if not completed:` (line 141) which will be True even when the event was set, causing get() to return None incorrectly. This is a code-level mismatch between the expected boolean 'completed' and the actual None return of Event.wait(), leading to incorrect behavior of get(). CI shows failing websocket tests (tests/test_websockets.py::test_ws_frame_put_message_into_queue...) \u2014 while the immediate failing AssertionError in the tests originates in test code, this get() logic bug is a definite observable defect in the get method that can cause message retrieval to fail or time out unexpectedly. (Scope: get method lines 88\u2013164.)",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "method",
                        "code_snippet": "    async def get(self, timeout: Optional[float] = None) -> Optional[Data]:\n        \"\"\"\n        Read the next message.\n        :meth:`get` returns a single :class:`str` or :class:`bytes`.\n        If the :message was fragmented, :meth:`get` waits until the last frame\n        is received, then it reassembles the message.\n        If ``timeout`` is set and elapses before a complete message is\n        received, :meth:`get` returns ``None``.\n        \"\"\"\n        completed: bool\n        async with self.read_mutex:\n            if timeout is not None and timeout <= 0:\n                if not self.message_complete.is_set():\n                    return None\n            if self.get_in_progress:\n                # This should be guarded against with the read_mutex,\n                # exception is only here as a failsafe\n                raise ServerError(\n                    \"Called get() on Websocket frame assembler \"\n                    \"while asynchronous get is already in progress.\"\n                )\n            self.get_in_progress = True\n\n            # If the message_complete event isn't set yet, release the lock to\n            # allow put() to run and eventually set it.\n            # Locking with get_in_progress ensures only one task can get here.\n            if timeout is None:\n                completed = await self.message_complete.wait()\n            elif timeout <= 0:\n                completed = self.message_complete.is_set()\n            else:\n                try:\n                    await asyncio.wait_for(\n                        self.message_complete.wait(), timeout=timeout\n                    )\n                except asyncio.TimeoutError:\n                    ...\n                finally:\n                    completed = self.message_complete.is_set()\n\n            # Unpause the transport, if its paused\n            if self.paused:\n                self.protocol.resume_frames()\n                self.paused = False\n            if not self.get_in_progress:  # no cov\n                # This should be guarded against with the read_mutex,\n                # exception is here as a failsafe\n                raise ServerError(\n                    \"State of Websocket frame assembler was modified while an \"\n                    \"asynchronous get was in progress.\"\n                )\n            self.get_in_progress = False\n\n            # Waiting for a complete message timed out.\n            if not completed:\n                return None\n            if not self.message_complete.is_set():\n                return None\n\n            self.message_complete.clear()\n\n            joiner: Data = b\"\" if self.decoder is None else \"\"\n            # mypy cannot figure out that chunks have the proper type.\n            message: Data = joiner.join(self.chunks)  # type: ignore\n            if self.message_fetched.is_set():\n                # This should be guarded against with the read_mutex,\n                # and get_in_progress check, this exception is here\n                # as a failsafe\n                raise ServerError(\n                    \"Websocket get() found a message when \"\n                    \"state was already fetched.\"\n                )\n            self.message_fetched.set()\n            self.chunks = []\n            # this should already be None, but set it here for safety\n            self.chunks_queue = None\n            return message"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "d1b0280fb92d0d8590cf403ca46af3550507d4d2",
        "fault_localization_data": [
            {
                "file_path": "tornado/tornado/testing.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/testing.py",
                "faults": [
                    {
                        "file_path": "tornado/tornado/testing.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/testing.py",
                        "line_range": [
                            185,
                            201
                        ],
                        "reason": "CI log contains runtime warnings about unawaited coroutines and \"Task was destroyed but it is pending!\" (RuntimeWarning: coroutine 'SelectorThread.__init__.<locals>.thread_manager_anext' was never awaited; log references platform/asyncio.py). In AsyncTestCase.setUp (lines 185-201) the code forcibly calls asyncio.set_event_loop(self.io_loop.asyncio_loop) (line 201). Setting the global asyncio event loop to an IOLoop-wrapped asyncio loop here can create mismatches between the running loop and any background selector thread manager coroutines (leading to unawaited coroutine warnings and destroyed pending tasks). CI evidence: runtime warning text and stack frames referencing asyncio/platform (see error context).",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "method",
                        "code_snippet": "    def setUp(self) -> None:\n        py_ver = sys.version_info\n        if ((3, 10, 0) <= py_ver < (3, 10, 9)) or ((3, 11, 0) <= py_ver <= (3, 11, 1)):\n            # Early releases in the Python 3.10 and 3.1 series had deprecation\n            # warnings that were later reverted; we must suppress them here.\n            setup_with_context_manager(self, warnings.catch_warnings())\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"There is no current event loop\",\n                category=DeprecationWarning,\n                module=r\"tornado\\..*\",\n            )\n        super().setUp()\n        if type(self).get_new_ioloop is not AsyncTestCase.get_new_ioloop:\n            warnings.warn(\"get_new_ioloop is deprecated\", DeprecationWarning)\n        self.io_loop = self.get_new_ioloop()\n        asyncio.set_event_loop(self.io_loop.asyncio_loop)  # type: ignore[attr-defined]"
                    }
                ]
            },
            {
                "file_path": "tornado/tornado/ioloop.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/ioloop.py",
                "faults": [
                    {
                        "file_path": "tornado/tornado/ioloop.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/ioloop.py",
                        "line_range": [
                            465,
                            539
                        ],
                        "reason": "run_sync's timeout handling can leave the executed coroutine/task in a cancelled or pending state without waiting for its cancellation to complete, which can prevent expected error-log messages from being produced and lead to runtime warnings about unawaited coroutines and unclosed resources. CI evidence: the failing test raised Exception(\"did not get expected log message\") (testing.py __exit__), and logs include \"RuntimeWarning: coroutine ... was never awaited\" and multiple \"ResourceWarning: unclosed <socket.socket ...>\" messages. Relevant code: timeout_callback calls future_cell[0].cancel() and, if cancel() returns True, does not wait for the cancellation to finish (lines 0528-0531); the method then proceeds to self.start(), removes the timeout, and immediately checks future_cell[0].cancelled() or not done() to raise TimeoutError (lines 0533-0539). This flow can cause the IOLoop to stop before the canceled coroutine has had a chance to log errors, explaining the missing expected log message and the unawaited/socket warnings.",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "method",
                        "code_snippet": "    def run_sync(self, func: Callable, timeout: Optional[float] = None) -> Any:\n        \"\"\"Starts the `IOLoop`, runs the given function, and stops the loop.\n\n        The function must return either an awaitable object or\n        ``None``. If the function returns an awaitable object, the\n        `IOLoop` will run until the awaitable is resolved (and\n        `run_sync()` will return the awaitable's result). If it raises\n        an exception, the `IOLoop` will stop and the exception will be\n        re-raised to the caller.\n\n        The keyword-only argument ``timeout`` may be used to set\n        a maximum duration for the function.  If the timeout expires,\n        a `asyncio.TimeoutError` is raised.\n\n        This method is useful to allow asynchronous calls in a\n        ``main()`` function::\n\n            async def main():\n                # do stuff...\n\n            if __name__ == '__main__':\n                IOLoop.current().run_sync(main)\n\n        .. versionchanged:: 4.3\n           Returning a non-``None``, non-awaitable value is now an error.\n\n        .. versionchanged:: 5.0\n           If a timeout occurs, the ``func`` coroutine will be cancelled.\n\n        .. versionchanged:: 6.2\n           ``tornado.util.TimeoutError`` is now an alias to ``asyncio.TimeoutError``.\n        \"\"\"\n        future_cell = [None]  # type: List[Optional[Future]]\n\n        def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[0] = fut\n                future_set_exc_info(fut, sys.exc_info())\n            else:\n                if is_future(result):\n                    future_cell[0] = result\n                else:\n                    fut = Future()\n                    future_cell[0] = fut\n                    fut.set_result(result)\n            assert future_cell[0] is not None\n            self.add_future(future_cell[0], lambda future: self.stop())\n\n        self.add_callback(run)\n        if timeout is not None:\n\n            def timeout_callback() -> None:\n                # If we can cancel the future, do so and wait on it. If not,\n                # Just stop the loop and return with the task still pending.\n                # (If we neither cancel nor wait for the task, a warning\n                # will be logged).\n                assert future_cell[0] is not None\n                if not future_cell[0].cancel():\n                    self.stop()\n\n            timeout_handle = self.add_timeout(self.time() + timeout, timeout_callback)\n        self.start()\n        if timeout is not None:\n            self.remove_timeout(timeout_handle)\n        assert future_cell[0] is not None\n        if future_cell[0].cancelled() or not future_cell[0].done():\n            raise TimeoutError(\"Operation timed out after %s seconds\" % timeout)\n        return future_cell[0].result()"
                    }
                ]
            },
            {
                "file_path": "tornado/tornado/test/iostream_test.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/test/iostream_test.py",
                "faults": []
            },
            {
                "file_path": "tornado/tornado/platform/asyncio.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/platform/asyncio.py",
                "faults": [
                    {
                        "file_path": "tornado/tornado/platform/asyncio.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/tornado/tornado/platform/asyncio.py",
                        "line_range": [
                            438,
                            658
                        ],
                        "reason": "Multiple CI runtime warnings and resource leaks point to problems in the SelectorThread class (lines 438\u2013658):\n- Unawaited coroutine / pending Task: CI shows \"RuntimeWarning: coroutine 'SelectorThread.__init__.<locals>.thread_manager_anext' was never awaited\" and a pending Task destroyed with a stack frame at platform/asyncio.py:462. In this file SelectorThread.__init__ defines async def thread_manager_anext (around line 462) and then schedules it via self._real_loop.call_soon(lambda: self._real_loop.create_task(thread_manager_anext())) (around lines 470\u2013472). The CI message directly matches this local coroutine definition and scheduling, indicating the coroutine is not reliably being scheduled/awaited/kept alive which produces the observed RuntimeWarning and the \"Task was destroyed but it is pending\" message.\n- Unclosed sockets / resource leaks: CI produced many \"ResourceWarning: unclosed <socket.socket ...>\" and \"Exception ignored in: <socket.socket ...>\" messages. SelectorThread creates a socket pair (self._waker_r, self._waker_w) at lines 479\u2013481 and attempts to close them in close() (lines 495\u2013497). If the thread manager async generator/task is not started or not shut down correctly (see the unawaited coroutine issue above), close() may never run or may not clean up properly, matching the ResourceWarning evidence.\n- Test failure correlation: The recorded failing test is \"test_no_match ... Exception: did not get expected log message\" (CI test output). The runtime warnings above were printed to stderr during the test run (per CI), and the unawaited coroutine / pending tasks and unclosed sockets originate in this SelectorThread implementation (lines 438\u2013658), so these runtime issues are concrete, local failures that explain the CI log messages and likely contributed to the test-suite instability.\nThese sub-faults all belong to the SelectorThread class (lines 438\u2013658) and should be addressed by correcting how the async generator is advanced/scheduled and ensuring the selector thread and the socketpair are reliably started and deterministically closed/shutdown.",
                        "issue_type": "runtime_error",
                        "fault_localization_level": "class",
                        "code_snippet": "class SelectorThread:\n    \"\"\"Define ``add_reader`` methods to be called in a background select thread.\n\n    Instances of this class start a second thread to run a selector.\n    This thread is completely hidden from the user;\n    all callbacks are run on the wrapped event loop's thread.\n\n    Typically used via ``AddThreadSelectorEventLoop``,\n    but can be attached to a running asyncio loop.\n    \"\"\"\n\n    _closed = False\n\n    def __init__(self, real_loop: asyncio.AbstractEventLoop) -> None:\n        self._real_loop = real_loop\n\n        self._select_cond = threading.Condition()\n        self._select_args: Optional[\n            Tuple[List[_FileDescriptorLike], List[_FileDescriptorLike]]\n        ] = None\n        self._closing_selector = False\n        self._thread: Optional[threading.Thread] = None\n        self._thread_manager_handle = self._thread_manager()\n\n        async def thread_manager_anext() -> None:\n            # the anext builtin wasn't added until 3.10. We just need to iterate\n            # this generator one step.\n            await self._thread_manager_handle.__anext__()\n\n        # When the loop starts, start the thread. Not too soon because we can't\n        # clean up if we get to this point but the event loop is closed without\n        # starting.\n        self._real_loop.call_soon(\n            lambda: self._real_loop.create_task(thread_manager_anext())\n        )\n\n        self._readers: Dict[_FileDescriptorLike, Callable] = {}\n        self._writers: Dict[_FileDescriptorLike, Callable] = {}\n\n        # Writing to _waker_w will wake up the selector thread, which\n        # watches for _waker_r to be readable.\n        self._waker_r, self._waker_w = socket.socketpair()\n        self._waker_r.setblocking(False)\n        self._waker_w.setblocking(False)\n        _selector_loops.add(self)\n        self.add_reader(self._waker_r, self._consume_waker)\n\n    def close(self) -> None:\n        if self._closed:\n            return\n        with self._select_cond:\n            self._closing_selector = True\n            self._select_cond.notify()\n        self._wake_selector()\n        if self._thread is not None:\n            self._thread.join()\n        _selector_loops.discard(self)\n        self.remove_reader(self._waker_r)\n        self._waker_r.close()\n        self._waker_w.close()\n        self._closed = True\n\n    async def _thread_manager(self) -> typing.AsyncGenerator[None, None]:\n        # Create a thread to run the select system call. We manage this thread\n        # manually so we can trigger a clean shutdown from an atexit hook. Note\n        # that due to the order of operations at shutdown, only daemon threads\n        # can be shut down in this way (non-daemon threads would require the\n        # introduction of a new hook: https://bugs.python.org/issue41962)\n        self._thread = threading.Thread(\n            name=\"Tornado selector\",\n            daemon=True,\n            target=self._run_select,\n        )\n        self._thread.start()\n        self._start_select()\n        try:\n            # The presense of this yield statement means that this coroutine\n            # is actually an asynchronous generator, which has a special\n            # shutdown protocol. We wait at this yield point until the\n            # event loop's shutdown_asyncgens method is called, at which point\n            # we will get a GeneratorExit exception and can shut down the\n            # selector thread.\n            yield\n        except GeneratorExit:\n            self.close()\n            raise\n\n    def _wake_selector(self) -> None:\n        if self._closed:\n            return\n        try:\n            self._waker_w.send(b\"a\")\n        except BlockingIOError:\n            pass\n\n    def _consume_waker(self) -> None:\n        try:\n            self._waker_r.recv(1024)\n        except BlockingIOError:\n            pass\n\n    def _start_select(self) -> None:\n        # Capture reader and writer sets here in the event loop\n        # thread to avoid any problems with concurrent\n        # modification while the select loop uses them.\n        with self._select_cond:\n            assert self._select_args is None\n            self._select_args = (list(self._readers.keys()), list(self._writers.keys()))\n            self._select_cond.notify()\n\n    def _run_select(self) -> None:\n        while True:\n            with self._select_cond:\n                while self._select_args is None and not self._closing_selector:\n                    self._select_cond.wait()\n                if self._closing_selector:\n                    return\n                assert self._select_args is not None\n                to_read, to_write = self._select_args\n                self._select_args = None\n\n            # We use the simpler interface of the select module instead of\n            # the more stateful interface in the selectors module because\n            # this class is only intended for use on windows, where\n            # select.select is the only option. The selector interface\n            # does not have well-documented thread-safety semantics that\n            # we can rely on so ensuring proper synchronization would be\n            # tricky.\n            try:\n                # On windows, selecting on a socket for write will not\n                # return the socket when there is an error (but selecting\n                # for reads works). Also select for errors when selecting\n                # for writes, and merge the results.\n                #\n                # This pattern is also used in\n                # https://github.com/python/cpython/blob/v3.8.0/Lib/selectors.py#L312-L317\n                rs, ws, xs = select.select(to_read, to_write, to_write)\n                ws = ws + xs\n            except OSError as e:\n                # After remove_reader or remove_writer is called, the file\n                # descriptor may subsequently be closed on the event loop\n                # thread. It's possible that this select thread hasn't\n                # gotten into the select system call by the time that\n                # happens in which case (at least on macOS), select may\n                # raise a \"bad file descriptor\" error. If we get that\n                # error, check and see if we're also being woken up by\n                # polling the waker alone. If we are, just return to the\n                # event loop and we'll get the updated set of file\n                # descriptors on the next iteration. Otherwise, raise the\n                # original error.\n                if e.errno == getattr(errno, \"WSAENOTSOCK\", errno.EBADF):\n                    rs, _, _ = select.select([self._waker_r.fileno()], [], [], 0)\n                    if rs:\n                        ws = []\n                    else:\n                        raise\n                else:\n                    raise\n\n            try:\n                self._real_loop.call_soon_threadsafe(self._handle_select, rs, ws)\n            except RuntimeError:\n                # \"Event loop is closed\". Swallow the exception for\n                # consistency with PollIOLoop (and logical consistency\n                # with the fact that we can't guarantee that an\n                # add_callback that completes without error will\n                # eventually execute).\n                pass\n            except AttributeError:\n                # ProactorEventLoop may raise this instead of RuntimeError\n                # if call_soon_threadsafe races with a call to close().\n                # Swallow it too for consistency.\n                pass\n\n    def _handle_select(\n        self, rs: List[_FileDescriptorLike], ws: List[_FileDescriptorLike]\n    ) -> None:\n        for r in rs:\n            self._handle_event(r, self._readers)\n        for w in ws:\n            self._handle_event(w, self._writers)\n        self._start_select()\n\n    def _handle_event(\n        self,\n        fd: _FileDescriptorLike,\n        cb_map: Dict[_FileDescriptorLike, Callable],\n    ) -> None:\n        try:\n            callback = cb_map[fd]\n        except KeyError:\n            return\n        callback()\n\n    def add_reader(\n        self, fd: _FileDescriptorLike, callback: Callable[..., None], *args: Any\n    ) -> None:\n        self._readers[fd] = functools.partial(callback, *args)\n        self._wake_selector()\n\n    def add_writer(\n        self, fd: _FileDescriptorLike, callback: Callable[..., None], *args: Any\n    ) -> None:\n        self._writers[fd] = functools.partial(callback, *args)\n        self._wake_selector()\n\n    def remove_reader(self, fd: _FileDescriptorLike) -> bool:\n        try:\n            del self._readers[fd]\n        except KeyError:\n            return False\n        self._wake_selector()\n        return True\n\n    def remove_writer(self, fd: _FileDescriptorLike) -> bool:\n        try:\n            del self._writers[fd]\n        except KeyError:\n            return False\n        self._wake_selector()\n        return True"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "f18f82de3e0270f6dfddf22f1f487104b2428e35",
        "fault_localization_data": [
            {
                "file_path": "tests/unittests/sources/test_wsl.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/tests/unittests/sources/test_wsl.py",
                "faults": [
                    {
                        "file_path": "tests/unittests/sources/test_wsl.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/tests/unittests/sources/test_wsl.py",
                        "line_range": [
                            7,
                            14
                        ],
                        "reason": "CI ruff linter reported an unused-import (F401): \"tests/unittests/sources/test_wsl.py:10:20: F401 `typing.Optional` imported but unused\". The import statement at line 10 is: 'from typing import Optional, cast' (line 10). 'cast' is used in this file (e.g. lines 248, 277, 320), but 'Optional' is not referenced anywhere in lines 1\u2013335, which directly matches the F401 evidence from the CI log. Fix by removing 'Optional' from the import or using it where intended.",
                        "issue_type": "linting",
                        "fault_localization_level": "import_block",
                        "code_snippet": "import os\nfrom copy import deepcopy\nfrom email.mime.multipart import MIMEMultipart\nfrom typing import Optional, cast\n\nfrom cloudinit import helpers, util\nfrom cloudinit.sources import DataSourceWSL as wsl\nfrom tests.unittests.helpers import CiTestCase, mock"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "55d2e8d4abb024997be878797d5625effad65d43",
        "fault_localization_data": [
            {
                "file_path": "tests/unittests/test_net_activators.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/tests/unittests/test_net_activators.py",
                "faults": [
                    {
                        "file_path": "tests/unittests/test_net_activators.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/tests/unittests/test_net_activators.py",
                        "line_range": [
                            329,
                            330
                        ],
                        "reason": "Pylint reported E0213 and E1101 at lines 329-330. The helper 'fake_isfile_no_nmconn' is declared inside class TestNetworkManagerActivatorBringUp (lines 328-419) as 'def fake_isfile_no_nmconn(filename):' (line 329) without a 'self' parameter, causing E0213 (method should have self as first argument). Because pylint treats the first parameter as the instance, the subsequent call to filename.endswith(...) on line 330 triggers E1101 (instance has no 'endswith' member). The root issue is that this function is defined as an instance method but intended to be a standalone or static helper; it should be made a @staticmethod or accept 'self' and use a properly typed parameter.",
                        "issue_type": "linting",
                        "fault_localization_level": "method",
                        "code_snippet": "    def fake_isfile_no_nmconn(filename):\n        return False if filename.endswith(\".nmconnection\") else True"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "385c14d0ae500918cff5565ea836884bfaa2bfa5",
        "fault_localization_data": [
            {
                "file_path": "cloudinit/net/dhcp.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/cloudinit/net/dhcp.py",
                "faults": [
                    {
                        "file_path": "cloudinit/net/dhcp.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/cloudinit/net/dhcp.py",
                        "line_range": [
                            547,
                            595
                        ],
                        "reason": "Pylint reported W0612 (unused-variable) for variables 'out' and 'err' in Dhcpcd.dhcp_discovery (CI log: \"cloudinit/net/dhcp.py:575: [W0612(unused-variable), Dhcpcd.dhcp_discovery] Unused variable 'out'\" and same for 'err'). In Dhcpcd.dhcp_discovery (lines 547-595) the call assigns out, err = subp.subp(...) but those variables are never used afterwards (dhcp_log_func is accepted as a parameter but not invoked), which directly triggers the pylint unused-variable warnings. This is a linting issue (W0612) localized to the method Dhcpcd.dhcp_discovery (lines 547-595).",
                        "issue_type": "linting",
                        "fault_localization_level": "method",
                        "code_snippet": "    def dhcp_discovery(\n        self,\n        interface,\n        dhcp_log_func=None,\n        distro=None,\n    ):\n        \"\"\"Run dhclient on the interface without scripts/filesystem artifacts.\n\n        @param dhclient_cmd_path: Full path to the dhclient used.\n        @param interface: Name of the network interface on which to dhclient.\n        @param dhcp_log_func: A callable accepting the dhclient output and\n            error streams.\n\n        @return: A list of dicts of representing the dhcp leases parsed from\n            the dhclient.lease file or empty list.\n        \"\"\"\n        LOG.debug(\"Performing a dhcp discovery on %s\", interface)\n\n        # ISC dhclient needs the interface up to send initial discovery packets\n        # Generally dhclient relies on dhclient-script PREINIT action to bring\n        # the link up before attempting discovery. Since we are using\n        # -sf /bin/true, we need to do that \"link up\" ourselves first.\n        distro.net_ops.link_up(interface)\n\n        # TODO: disabling hooks means we need to get all of the files in\n        # /lib/dhcpcd/dhcpcd-hooks/ and pass each of those with the --nohook\n        # argument to dhcpcd\n        try:\n            out, err = subp.subp(\n                [\n                    \"dhcpcd\",\n                    \"--oneshot\",  # get lease then exit\n                    \"--nobackground\",  # don't fork\n                    \"--ipv4only\",  # only attempt configuring ipv4\n                    \"--waitip=4\",  # wait for ipv4 to be configured\n                    \"--persistent\",  # don't deconfigure when dhcpcd exits\n                    \"--noarp\",  # don't be slow\n                    interface,\n                ]\n            )\n        except subp.ProcessExecutionError as error:\n            LOG.debug(\n                \"dhclient exited with code: %s stderr: %r stdout: %r\",\n                error.exit_code,\n                error.stderr,\n                error.stdout,\n            )\n            raise NoDHCPLeaseError from error\n        return self.parse_dhcp_lease_file(interface)"
                    }
                ]
            },
            {
                "file_path": "tests/unittests/net/test_dhcp.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/tests/unittests/net/test_dhcp.py",
                "faults": []
            }
        ]
    },
    {
        "sha_fail": "4d5898b8a73c93e1ed4434744c2fa7c3f7fbd501",
        "fault_localization_data": [
            {
                "file_path": "cloudinit/net/dhcp.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/cloudinit/net/dhcp.py",
                "faults": [
                    {
                        "file_path": "cloudinit/net/dhcp.py",
                        "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/cloudinit/net/dhcp.py",
                        "line_range": [
                            538,
                            539
                        ],
                        "reason": "Pylint reported W0235 (useless-super-delegation) for Dhcpcd.__init__ at cloudinit/net/dhcp.py:538: 'Useless super delegation in method \"__init__\"'. The method body (lines 538-539) only calls super().__init__ with no additional logic, which triggers the lint rule and caused the tox run to fail (tox returned InvocationError/exited with code 4) in the CI pylint job. Evidence: CI log message referencing W0235 and the tox InvocationError that made the Test step fail.",
                        "issue_type": "linting",
                        "fault_localization_level": "method",
                        "code_snippet": "    def __init__(self):\n        super().__init__()"
                    }
                ]
            }
        ]
    },
    {
        "sha_fail": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
        "fault_localization_data": [
            {
                "file_path": "cloudinit/distros/__init__.py",
                "full_file_path": "/Users/rabeyakhatunmuna/Documents/CI-REPAIR-BENCH/baselines/repo_cloned/cloud-init/cloudinit/distros/__init__.py",
                "faults": []
            }
        ]
    }
]