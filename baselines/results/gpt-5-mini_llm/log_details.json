[
    {
        "sha_fail": "1afe2c9cb192d3760d59190cc7892e7ac37d5e27",
        "error_context": [
            "The CI run failed during the \"Run linting checks\" step (scripts/check) in all three matrix jobs (Python 3.10, 3.11 and 3.12). The scripts/check job runs ruff then mypy: ruff completed with \"60 files left unchanged\", but mypy returned type-check errors and exited non-zero. Mypy reported 4 errors in httpx/_client.py (lines referenced 1456, 1458, 1459) complaining that keyword arguments 'verify' and 'cert' are unexpected when calling AsyncHTTPTransport and that the names 'verify' and 'cert' are not defined. Mypy notes point to the AsyncHTTPTransport definition at httpx/_transports/default.py:260 as the expected signature. Because mypy failed (\"Found 4 errors in 1 file (checked 60 source files)\"), the scripts/check step exited with code 1 (\"Process completed with exit code 1\"), causing the overall job failure."
        ],
        "relevant_files": [
            {
                "file": "httpx/_client.py",
                "line_number": 1456,
                "reason": "Mypy reported four errors in this file (lines 1456, 1458, 1459) including: \"Unexpected keyword argument 'verify' for 'AsyncHTTPTransport'\" and \"Name 'verify' is not defined\" / \"Name 'cert' is not defined\". These messages are the direct cause of the mypy failure."
            },
            {
                "file": "httpx/_transports/default.py",
                "line_number": 260,
                "reason": "Mypy notes reference this file as the definition site for AsyncHTTPTransport (\"AsyncHTTPTransport defined here\" at line 260), which is relevant because the errors arise from passing unexpected keywords to that type's constructor/signature."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy: unexpected keyword argument",
                "evidence": "httpx/_client.py:1456: error: Unexpected keyword argument \"verify\" for \"AsyncHTTPTransport\" and httpx/_client.py:1456: error: Unexpected keyword argument \"cert\" for \"AsyncHTTPTransport\" (mypy output)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy: name-defined (Name not defined)",
                "evidence": "httpx/_client.py:1458: error: Name \"verify\" is not defined and httpx/_client.py:1459: error: Name \"cert\" is not defined (mypy output)"
            }
        ],
        "failed_job": [
            {
                "job": "tests (Python 3.10)",
                "step": "Run linting checks",
                "command": "scripts/check"
            },
            {
                "job": "tests (Python 3.11)",
                "step": "Run linting checks",
                "command": "scripts/check"
            },
            {
                "job": "tests (Python 3.12)",
                "step": "Run linting checks",
                "command": "scripts/check"
            }
        ]
    },
    {
        "sha_fail": "7f351340260c165e18ccd7c83dc783bb371b3797",
        "error_context": [
            "All failing matrix jobs reached the 'Enforce coverage' step (scripts/coverage) which invoked 'coverage report --show-missing --skip-covered --fail-under=100'. In each of the Python 3.8, 3.9, 3.10 and 3.11 runs the coverage report showed a single missing statement in httpx/_config.py (report line: 'httpx/_config.py     133      1    99%   139'), producing an overall TOTAL coverage of 99%. Because the job enforces --fail-under=100 the coverage check failed with the message 'Coverage failure: total of 99 is less than fail-under=100' and the step exited with code 2. The logs also note '58 files skipped due to complete coverage', indicating the failure was caused solely by the one missed line in httpx/_config.py rather than multiple files or test failures."
        ],
        "relevant_files": [
            {
                "file": "httpx/_config.py",
                "line_number": 139,
                "reason": "Coverage report lists this file with 1 missed statement at line 139 ('httpx/_config.py     133      1    99%   139'), and that single missed line caused the TOTAL coverage to be 99%, which triggered the fail-under=100 enforcement ('Coverage failure: total of 99 is less than fail-under=100')."
            }
        ],
        "error_types": [
            {
                "category": "Configuration Error",
                "subcategory": "Coverage threshold not met",
                "evidence": "'coverage report --fail-under=100' produced 'Coverage failure: total of 99 is less than fail-under=100' and the coverage table shows the single miss in httpx/_config.py (1 missed, 99%)."
            }
        ],
        "failed_job": [
            {
                "job": "tests (Python 3.8)",
                "step": "Enforce coverage",
                "command": "scripts/coverage"
            },
            {
                "job": "tests (Python 3.9)",
                "step": "Enforce coverage",
                "command": "scripts/coverage"
            },
            {
                "job": "tests (Python 3.10)",
                "step": "Enforce coverage",
                "command": "scripts/coverage"
            },
            {
                "job": "tests (Python 3.11)",
                "step": "Enforce coverage",
                "command": "scripts/coverage"
            }
        ]
    },
    {
        "sha_fail": "897a5deb406b53ea2f4675cdf0c2f1fa93fc6238",
        "error_context": [
            "The CI run failed because the linting step (scripts/check -> ruff check) returned a non-zero exit due to a formatting/import-order lint in httpx/__init__.py. Across the Python 3.8, 3.9, 3.10 and 3.11 job logs the sequence shows ./scripts/sync-version, ruff format, and mypy all succeeded (e.g. \"CHANGELOG_VERSION: 0.26.0\", \"60 files left unchanged\", \"Success: no issues found in 60 source files\"). The subsequent command ruff check httpx tests produced the same lint failure in each failing job: \"httpx/__init__.py:1:1: I001 [*] Import block is un-sorted or un-formatted\" and \"Found 1 error.\", causing the step to exit with code 1 (\"##[error]Process completed with exit code 1.\"). The ruff output also indicates the issue is auto-fixable (\"[*] 1 fixable with the `--fix` option.\"), so the root cause is a code formatting / import-order violation detected by the linter rather than a runtime/test/type-check failure."
        ],
        "relevant_files": [
            {
                "file": "httpx/__init__.py",
                "line_number": 1,
                "reason": "Ruff reported a lint error at the start of this file in multiple job logs: \"httpx/__init__.py:1:1: I001 [*] Import block is un-sorted or un-formatted\". The lint error is listed as the single found error and caused ruff check to exit non-zero, making this file the direct cause of the CI failure."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Import order / unsorted import block (ruff I001)",
                "evidence": "\"httpx/__init__.py:1:1: I001 [*] Import block is un-sorted or un-formatted\"; \"Found 1 error.\"; \"[*] 1 fixable with the `--fix` option.\""
            }
        ],
        "failed_job": [
            {
                "job": "Python 3.8",
                "step": "Run linting checks",
                "command": "scripts/check"
            },
            {
                "job": "Python 3.9",
                "step": "Run linting checks",
                "command": "scripts/check"
            },
            {
                "job": "Python 3.10",
                "step": "Run linting checks",
                "command": "scripts/check"
            },
            {
                "job": "Python 3.11",
                "step": "Run linting checks",
                "command": "scripts/check"
            }
        ]
    },
    {
        "sha_fail": "077f6aaac3ebb96626ac747fb126a0b4d752489c",
        "error_context": [
            "The CI run failed in the pre-commit job when the pre-commit action detected and automatically changed files. In the step running pre-commit/action@v3.0.0 (pre-push stage, all files) the action installed pre-commit successfully and restored cache, then executed: `pre-commit run --show-diff-on-failure --color=always --hook-stage pre-push --all-files`. Two hooks modified files: the ruff hook fixed one lint error (\"Found 1 error (1 fixed, 0 remaining)\") and the black-jupyter hook reformatted a file (\"reformatted wandb/integration/ultralytics/callback.py\"). Because hooks made changes, pre-commit exited non-zero and the runner reported `pre-commit hook(s) made changes.` and `##[error]Process completed with exit code 1.` The root cause is not a runtime or dependency failure but code-style/lint hooks making changes that the CI forbids (CI expects no modifications from pre-commit hooks)."
        ],
        "relevant_files": [
            {
                "file": "wandb/integration/ultralytics/bbox_utils.py",
                "line_number": null,
                "reason": "Appears in the unified diff under \"All changes made by hooks:\" with an added blank line in the import area; modified by pre-commit hooks (ruff fixed an issue), which caused the pre-commit step to fail because hooks made changes."
            },
            {
                "file": "wandb/integration/ultralytics/callback.py",
                "line_number": null,
                "reason": "Explicitly reported as reformatted by black-jupyter (log: \"reformatted wandb/integration/ultralytics/callback.py\") and appears in the unified diff; this formatting change caused pre-commit to report that hooks made changes and led to the step failing."
            }
        ],
        "error_types": [
            {
                "category": "Linting",
                "subcategory": "Ruff auto-fix",
                "evidence": "\"ruff...Failed\" with '- files were modified by this hook' and log line: \"Found 1 error (1 fixed, 0 remaining).\""
            },
            {
                "category": "Code Formatting",
                "subcategory": "Black reformat",
                "evidence": "\"black-jupyter...Failed' with '- files were modified by this hook' and log lines: \"reformatted wandb/integration/ultralytics/callback.py\" and \"1 file reformatted, 870 files left unchanged.\""
            },
            {
                "category": "CI Failure",
                "subcategory": "Pre-commit hooks modified files (non-zero exit)",
                "evidence": "Pre-commit summary: \"pre-commit hook(s) made changes.\" and runner error: \"##[error]Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "pre-commit",
                "step": "pre-commit/action@v3.0.0",
                "command": "pre-commit run --show-diff-on-failure --color=always --hook-stage pre-push --all-files"
            }
        ]
    },
    {
        "sha_fail": "c99ead9542bde331497f2456537fdbb0e37706d0",
        "error_context": [
            "The CI run failed because the pre-commit step modified a tracked file, causing the pre-commit action to exit non\u2011zero. In the step 'pre-commit/6_Run pre-commitaction@v3.0.0.txt' (workflow job 'pre-commit' using pre-commit/action@v3.0.0), the black-jupyter hook reformatted wandb/sdk/data_types/image.py. Pre-commit reported \"reformatted wandb/sdk/data_types/image.py\" and \"pre-commit hook(s) made changes.\" The run ended with \"[error]Process completed with exit code 1.\" (No runtime exceptions or test failures were reported; dependency installation and cache restore succeeded earlier in the step.)"
        ],
        "relevant_files": [
            {
                "file": "wandb/sdk/data_types/image.py",
                "line_number": 277,
                "reason": "Pre-commit's black-jupyter hook reformatted this file; log shows: \"reformatted wandb/sdk/data_types/image.py\" and the diff changing util.ensure_matplotlib_figure(data).savefig(buf, format='png') to util.ensure_matplotlib_figure(data).savefig(buf, format=\"png\"). Because the hook modified a tracked file, the pre-commit step failed (exit code 1)."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Pre-commit/Black reformat modified tracked files",
                "evidence": "\"black-jupyter... Failed\" and \"reformatted wandb/sdk/data_types/image.py\"; pre-commit summary: \"pre-commit hook(s) made changes.\" Final message: \"[error]Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "pre-commit",
                "step": "pre-commit/6_Run pre-commitaction@v3.0.0.txt",
                "command": "pre-commit/action@v3.0.0"
            }
        ]
    },
    {
        "sha_fail": "99ad8a351bb884f1e398c1d85c62d6b6e0bdd67e",
        "error_context": [
            "The CI run failed during the docs job when the 'Run docs' step invoked ci/run_conditional_tests.sh (via the workflow step 'Run docs' in job 'docs'). Nox executed a Sphinx build (command: sphinx-build -W -T -N -b html ...) which encountered a Sphinx parsing warning: \"Inline emphasis start-string without end-string\" in the docstring of class Document in packages/google-ai-generativelanguage/google/ai/generativelanguage_v1beta/types/retriever.py (docstring line 6). Because sphinx-build was run with -W (treat warnings as errors), that warning was escalated to an error (log: \"Warning, treated as error: ... Inline emphasis start-string without end-string.\"), causing sphinx-build to exit with code 2 and the nox docs session to fail (\"nox > Session docs failed.\"). The failed docs session caused the job to fail and the runner to report \"Process completed with exit code 1.\" The subsequent git-diff checks across other packages were skipped or reported no changes because only packages/google-ai-generativelanguage/ had changes."
        ],
        "relevant_files": [
            {
                "file": "packages/google-ai-generativelanguage/google/ai/generativelanguage_v1beta/types/retriever.py",
                "line_number": 6,
                "reason": "Docstring in class Document contains an unterminated inline emphasis causing SphinxWarning: \"...Document:6:Inline emphasis start-string without end-string.\" This is the direct cause of the Sphinx failure (warnings treated as errors)."
            },
            {
                "file": "packages/google-ai-generativelanguage/.nox/docs/lib/python3.10/site-packages/sphinx/cmd/build.py",
                "line_number": null,
                "reason": "Top frame of the traceback during the failing sphinx-build; indicates where the Sphinx CLI invoked the build that raised the warning/error."
            },
            {
                "file": "packages/google-ai-generativelanguage/.nox/docs/lib/python3.10/site-packages/sphinx/application.py",
                "line_number": null,
                "reason": "Appears in the traceback while Sphinx was performing the build (app.build) when warnings were flushed and the SphinxWarning was raised."
            },
            {
                "file": "packages/google-ai-generativelanguage/.nox/docs/lib/python3.10/site-packages/sphinx/builders/__init__.py",
                "line_number": null,
                "reason": "Appears multiple times in the traceback (build_update/build) as Sphinx processed documents and prepared to flush pending warnings."
            },
            {
                "file": "packages/google-ai-generativelanguage/.nox/docs/lib/python3.10/site-packages/sphinx/util/logging.py",
                "line_number": null,
                "reason": "Sphinx logging utility flushed pending warnings and raised the SphinxWarning (the final 'raise exc' originates here) when the inline emphasis warning was treated as an error."
            },
            {
                "file": "lib/python3.10/logging/__init__.py",
                "line_number": null,
                "reason": "Standard library logging frames appear in the traceback while Sphinx flushed pending warnings; involved in propagation of the SphinxWarning."
            },
            {
                "file": "lib/python3.10/contextlib.py",
                "line_number": null,
                "reason": "Standard library context manager frame appears in the traceback during exit from the logging context used to flush pending warnings."
            }
        ],
        "error_types": [
            {
                "category": "Documentation Build Error",
                "subcategory": "Sphinx parsing warning (Inline emphasis start-string without end-string)",
                "evidence": "\"sphinx.errors.SphinxWarning: ... retriever.py:docstring of google.ai.generativelanguage_v1beta.types.retriever.Document:6:Inline emphasis start-string without end-string.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Warnings treated as errors (-W passed to sphinx-build)",
                "evidence": "sphinx-build was run with the -W flag and the log shows \"Warning, treated as error:\" and the sphinx-build command printed in the log: \"sphinx-build -W -T -N -b html ...\""
            },
            {
                "category": "Tooling / Test Failure",
                "subcategory": "nox session failed (sphinx-build exit code propagated)",
                "evidence": "Log: \"nox > Command sphinx-build -W ... failed with exit code 2\" and \"nox > Session docs failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "docs",
                "step": "docs/5_Run docs.txt",
                "command": "ci/run_conditional_tests.sh"
            }
        ]
    },
    {
        "sha_fail": "44b56e01683771fb4ca583f9ea57c67dcee8e779",
        "error_context": [
            "The CI run failed in the 'Run Quality check' step when the Make target 'quality' (invoked by the workflow command 'make quality') executed a documentation style check that raised an exception. Black completed successfully and ruff was invoked, but the doc-builder style command raised a ValueError: \"1 files should be restyled!\", which caused make to fail ('make: *** [Makefile:17: quality] Error 1') and the step to exit with code 2 ('Process completed with exit code 2'). In short: the documentation/style checker detected one file needing restyling and returned a non\u2011zero error, causing the quality job to fail."
        ],
        "relevant_files": [
            {
                "file": "bin/doc-builder",
                "line_number": 8,
                "reason": "Entry-point script shown at top of traceback: invoked doc-builder which called into the CLI and ultimately triggered the style command failure."
            },
            {
                "file": "lib/python3.8/site-packages/doc_builder/commands/doc_builder_cli.py",
                "line_number": 47,
                "reason": "CLI dispatch location in the traceback ('args.func(args)') where the doc-builder command delegated to the style command that raised the error."
            },
            {
                "file": "lib/python3.8/site-packages/doc_builder/commands/style.py",
                "line_number": 28,
                "reason": "Direct location that raised the ValueError ('raise ValueError(f\"{len(changed)} files should be restyled!\")'), producing the message '1 files should be restyled!'."
            },
            {
                "file": "Makefile",
                "line_number": 17,
                "reason": "Make reported the failing target and location: 'make: *** [Makefile:17: quality] Error 1' showing the quality target failed as a result of the style check error."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Documentation style / restyling required",
                "evidence": "ValueError in doc-builder style: \"1 files should be restyled!\" (traceback from doc-builder -> doc_builder_cli.py -> style.py)."
            },
            {
                "category": "Build/CI Failure",
                "subcategory": "Make target failed",
                "evidence": "Make failed the 'quality' target: 'make: *** [Makefile:17: quality] Error 1' and the step exited with code 2 ('Process completed with exit code 2')."
            }
        ],
        "failed_job": [
            {
                "job": "quality",
                "step": "Run Quality check",
                "command": "make quality"
            }
        ]
    },
    {
        "sha_fail": "3dd8e4404a0ce2e29db4911dc2cd7e94755be631",
        "error_context": [
            "The CI run failed because the quality-check step reported linting errors. In the step 'quality/5_Run Quality check.txt' (workflow step 'Run Quality check') the Makefile target 'quality' executed 'make quality' which ran two linters: black and ruff. Black succeeded ('All done! \u2728 \ud83c\udf70 \u2728' / '118 files would be left unchanged'), but ruff reported two issues: 'tests/deepspeed/test_deepspeed.py:15:1: I001 [*] Import block is un-sorted or un-formatted' and 'tests/fsdp/test_fsdp.py:16:1: I001 [*] Import block is un-sorted or un-formatted'. Ruff summarized 'Found 2 errors.' and indicated they are fixable ('[*] 2 fixable with the `--fix` option'). Because ruff returned a non-zero exit status, the Makefile target failed ('make: *** [Makefile:16: quality] Error 1') and the job exited with an error ('Process completed with exit code 2'). No runtime/test failures or dependency installation errors are reported in the logs; the failure is limited to code-format/import-order lint violations detected by ruff in the two test files."
        ],
        "relevant_files": [
            {
                "file": "tests/deepspeed/test_deepspeed.py",
                "line_number": 15,
                "reason": "Ruff reported an import-block ordering/formatting error at tests/deepspeed/test_deepspeed.py:15:1 ('I001 [*] Import block is un-sorted or un-formatted'), which contributed to 'Found 2 errors.' and caused the 'make quality' target to fail."
            },
            {
                "file": "tests/fsdp/test_fsdp.py",
                "line_number": 16,
                "reason": "Ruff reported an import-block ordering/formatting error at tests/fsdp/test_fsdp.py:16:1 ('I001 [*] Import block is un-sorted or un-formatted'), which contributed to 'Found 2 errors.' and caused the 'make quality' target to fail."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Import block ordering / formatting (ruff I001)",
                "evidence": "Ruff output: 'tests/deepspeed/test_deepspeed.py:15:1: I001 [*] Import block is un-sorted or un-formatted' and 'tests/fsdp/test_fsdp.py:16:1: I001 [*] Import block is un-sorted or un-formatted' followed by 'Found 2 errors.' and '[*] 2 fixable with the `--fix` option.'"
            }
        ],
        "failed_job": [
            {
                "job": "quality",
                "step": "quality/5_Run Quality check.txt",
                "command": "make quality"
            }
        ]
    },
    {
        "sha_fail": "028ad1efee2c41691d78e5a4de90ebd6f8236cad",
        "error_context": [
            "The CI run failed in the 'Run Quality check' step (workflow step name: 'Run Quality check') when executing the command 'make quality'. The quality target ran two linters: Black (which passed: 'All done! ... 118 files would be left unchanged.') and ruff (which failed). Ruff reported two import-block ordering/formatting violations (I001) in src/accelerate/utils/__init__.py and src/accelerate/utils/modeling.py and indicated both are fixable with '--fix'. Because ruff returned a non-zero exit code, make reported 'make: *** [Makefile:16: quality] Error 1' and the job terminated with 'Process completed with exit code 2.' In short: linter formatting errors (ruff I001) caused the 'quality' Make target to fail, causing the entire CI job to fail."
        ],
        "relevant_files": [
            {
                "file": "src/accelerate/utils/__init__.py",
                "line_number": 1,
                "reason": "Ruff reported an import-block ordering/formatting error at src/accelerate/utils/__init__.py:1:1 ('I001 Import block is un-sorted or un-formatted'), which contributed to the 'Found 2 errors.' result from ruff and caused the quality target to fail."
            },
            {
                "file": "src/accelerate/utils/modeling.py",
                "line_number": 15,
                "reason": "Ruff reported an import-block ordering/formatting error at src/accelerate/utils/modeling.py:15:1 ('I001 Import block is un-sorted or un-formatted'), which was one of the two fixable errors ruff reported and caused the quality target to fail."
            },
            {
                "file": "Makefile",
                "line_number": 16,
                "reason": "Make reported the quality target failure at 'Makefile:16: quality' ('make: *** [Makefile:16: quality] Error 1'), indicating the non-zero exit from the linters caused make to stop and the CI job to fail."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Import block ordering/formatting (ruff I001)",
                "evidence": "ruff output: 'src/accelerate/utils/__init__.py:1:1: I001 [*] Import block is un-sorted or un-formatted' and 'src/accelerate/utils/modeling.py:15:1: I001 [*] Import block is un-sorted or un-formatted' and 'Found 2 errors. [*] 2 fixable with the `--fix` option.'"
            },
            {
                "category": "Build Failure",
                "subcategory": "Make target failed due to linter non-zero exit",
                "evidence": "'make: *** [Makefile:16: quality] Error 1' followed by '##[error]Process completed with exit code 2.' showing the make 'quality' target failed because a linter returned a non-zero status."
            }
        ],
        "failed_job": [
            {
                "job": "quality",
                "step": "Run Quality check",
                "command": "make quality"
            }
        ]
    },
    {
        "sha_fail": "c9991372b81edabb86965638db110ab930f8e165",
        "error_context": [
            "The CI run failed in the quality check job when running the 'Run Quality check' step (log step: 'quality/5_Run Quality check.txt'). The step executed 'make quality', which runs code formatters/linters: black then ruff. Black completed successfully ('All done! \u2728 \ud83c\udf70 \u2728' \u2014 118 files unchanged), but ruff returned an error: \"src/accelerate/utils/fsdp_utils.py:14:1: I001 [*] Import block is un-sorted or un-formatted\" and summarized \"Found 1 error.\" Ruff also noted the issue is fixable with '--fix'. Because ruff exited non\u2011zero, make aborted with \"make: *** [Makefile:16: quality] Error 1\" and the runner reported \"Process completed with exit code 2.\" No unit tests or other steps reported failures; the root cause is a code-format/linting issue (unsorted import block) in src/accelerate/utils/fsdp_utils.py that caused the quality target to fail."
        ],
        "relevant_files": [
            {
                "file": "src/accelerate/utils/fsdp_utils.py",
                "line_number": 14,
                "reason": "Ruff reported a lint error at this file and exact location: 'src/accelerate/utils/fsdp_utils.py:14:1: I001 [*] Import block is un-sorted or un-formatted' \u2014 this lint failure is the direct cause of the quality check failing."
            },
            {
                "file": "Makefile",
                "line_number": 16,
                "reason": "Make aborted the 'quality' target with 'make: *** [Makefile:16: quality] Error 1' after ruff returned a non-zero exit code; this line references the failing make target that caused the CI step to exit with code 2."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Unsorted / misformatted import block",
                "evidence": "Ruff output: 'src/accelerate/utils/fsdp_utils.py:14:1: I001 [*] Import block is un-sorted or un-formatted' and 'Found 1 error. [*] 1 fixable with the `--fix` option.'"
            },
            {
                "category": "Build/CI Failure",
                "subcategory": "Make target failed due to linter non-zero exit",
                "evidence": "Make failure: 'make: *** [Makefile:16: quality] Error 1' and runner message '##[error]Process completed with exit code 2.' caused by ruff returning non-zero."
            }
        ],
        "failed_job": [
            {
                "job": "quality",
                "step": "Run Quality check",
                "command": "make quality"
            }
        ]
    },
    {
        "sha_fail": "16a0c04d06205527ec5e379df2596b399ee5dadc",
        "error_context": [
            "The CI run failed in the pre-commit hooks step 'pre-commit hooks/4_Run pre-commitaction@v3.0.0.txt' inside the 'pre-commit hooks' job. The pre-commit action ran black and mypy across the repository. Black reformatted a source file (dask/utils.py), causing pre-commit to report \"files were modified by this hook\" and stop with changes to commit. After formatting, the mypy hook returned an error (exit code 1) reporting two type-checking errors in dask/utils.py: \"Unsupported operand types for + (\\\"str\\\" and \\\"None\\\")\" at lines 231 and 257. Because hooks both modified files (black) and mypy found type errors, pre-commit exited with code 1 and the job failed (log: \"pre-commit hook(s) made changes.\" and \"[error]Process completed with exit code 1.\")."
        ],
        "relevant_files": [
            {
                "file": "dask/utils.py",
                "line_number": 231,
                "reason": "Black reformatted this file (log: \"reformatted dask/utils.py\" and diff showing a signature change) and mypy reported two type errors in this file: \"dask/utils.py:231: error: Unsupported operand types for + (\"str\" and \"None\")\" and similarly at line 257. The file is therefore directly responsible for both the formatting change and the type-check failures."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Black reformat",
                "evidence": "\"reformatted dask/utils.py\" and pre-commit output: \"- hook id: black - files were modified by this hook\" (pre-commit reported changes/diff)."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch",
                "evidence": "mypy errors: \"dask/utils.py:231: error: Unsupported operand types for + (\\\"str\\\" and \\\"None\\\")\" and \"dask/utils.py:257: error: Unsupported operand types for + (\\\"str\\\" and \\\"None\\\")\"; summary: \"Found 2 errors in 1 file\"."
            },
            {
                "category": "CI / Pre-commit",
                "subcategory": "Pre-commit hook failure (hooks made changes / nonzero exit)",
                "evidence": "Pre-commit reported: \"pre-commit hook(s) made changes.\" and the job ended: \"[error]Process completed with exit code 1.\"; mypy hook had \"- exit code: 1\"."
            }
        ],
        "failed_job": [
            {
                "job": "pre-commit hooks",
                "step": "pre-commit hooks/4_Run pre-commitaction@v3.0.0.txt",
                "command": "uses: pre-commit/action@v3.0.0"
            }
        ]
    },
    {
        "sha_fail": "e21f666b44b5c2ddf22f9a9d057787811dc92a30",
        "error_context": [
            "The CI run failed during the \"Run linting checks\" step (scripts/check) across multiple Python matrix jobs. In each of the logged steps (Python 3.8, 3.9, 3.10 and 3.11 runs) the scripts/check step executed ruff format (which succeeded: \"67 files already formatted\") and then ran mypy on the starlette package. Mypy returned a non-zero exit due to seven type-checking errors across three files and caused the step to fail (logs end with \"Found 7 errors in 3 files (checked 35 source files)\" and \"##[error]Process completed with exit code 1.\"). The reported mypy problems include: (1) usage of Python 3.10 union syntax (\"X | Y\") flagged as a syntax/version issue in starlette/_utils.py and starlette/exceptions.py; (2) use of built-in generics subscripting (\"dict[...]\" and \"list[...]\"), which mypy complained about in starlette/exceptions.py (suggesting typing.Dict/typing.List); and (3) a misc/unpacking type error in starlette/concurrency.py (\"Need more than 1 value to unpack (2 expected)\"). These mypy errors are present in the logs for each failing matrix step and are the direct cause of the CI failures."
        ],
        "relevant_files": [
            {
                "file": "starlette/concurrency.py",
                "line_number": 32,
                "reason": "Mypy reported: \"starlette/concurrency.py:32: error: Need more than 1 value to unpack (2 expected)  [misc]\" \u2014 this specific error is one of the seven mypy failures that caused the linting step to exit non-zero."
            },
            {
                "file": "starlette/_utils.py",
                "line_number": 77,
                "reason": "Mypy reported: \"starlette/_utils.py:77: error: X | Y syntax for unions requires Python 3.10  [syntax]\" \u2014 this syntax/version error was flagged by mypy and contributed to the failure."
            },
            {
                "file": "starlette/exceptions.py",
                "line_number": 12,
                "reason": "Mypy reported multiple errors in this file, e.g. \"starlette/exceptions.py:12: error: X | Y syntax for unions requires Python 3.10\", \"starlette/exceptions.py:13: error: \\\"dict\\\" is not subscriptable, use \\\"typing.Dict\\\" instead\", and \"starlette/exceptions.py:59: error: \\\"list\\\" is not subscriptable, use \\\"typing.List\\\" instead\" \u2014 these combined issues are a primary source of the mypy failures."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy syntax/version incompatibility (X | Y union)",
                "evidence": "\"error: X | Y syntax for unions requires Python 3.10\" reported for starlette/_utils.py:77 and starlette/exceptions.py:12,13,30 (mypy output)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy builtin-generic subscripting disallowed (use typing.Dict/List)",
                "evidence": "\"\\\"dict\\\" is not subscriptable, use \\\"typing.Dict\\\" instead\" and \"\\\"list\\\" is not subscriptable, use \\\"typing.List\\\" instead\" reported for starlette/exceptions.py (mypy output)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy misc/type error (unpacking)",
                "evidence": "\"starlette/concurrency.py:32: error: Need more than 1 value to unpack (2 expected)  [misc]\" (mypy output)"
            }
        ],
        "failed_job": [
            {
                "job": "tests (Python 3.8)",
                "step": "Python 3.8/5_Run linting checks.txt",
                "command": "scripts/check"
            },
            {
                "job": "tests (Python 3.9)",
                "step": "Python 3.9/5_Run linting checks.txt",
                "command": "scripts/check"
            },
            {
                "job": "tests (Python 3.10)",
                "step": "Python 3.10/5_Run linting checks.txt",
                "command": "scripts/check"
            },
            {
                "job": "tests (Python 3.11)",
                "step": "Python 3.11/5_Run linting checks.txt",
                "command": "scripts/check"
            }
        ]
    },
    {
        "sha_fail": "cc0b066c05947c2a356d063d0137685205709c3e",
        "error_context": [
            "The CI failed during the 'Run tests' step (scripts/test) for multiple Python matrix jobs (observed in the Python 3.9 and Python 3.11 test runs). Pytest reported 24 failed tests caused primarily by route resolution / mounting regressions: many requests to mounted or root_path routes returned HTTP 404 Not Found where tests expected 200 OK (e.g. tests/test_applications.py:163, tests/test_routing.py:188, 854, 1009, 1041, 1104, 1281; tests/middleware/test_session.py:134).",
            "These 404 responses then produced secondary failures: tests expecting JSON bodies failed with json.decoder.JSONDecodeError when httpx attempted response.json() on the plain 'Not Found' body (evidence: \"json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\" from httpx/_models.py -> json), websocket tests failed because websocket_connect returned an immediate close causing starlette.websockets.WebSocketDisconnect (evidence: \"WebSocketDisconnect: (1000, '')\" from starlette/testclient.py), and one test using pytest.raises() failed because the expected Exception was not raised (evidence: \"Failed: DID NOT RAISE <class 'Exception'>\").",
            "Failures were consistent across async backends (asyncio and trio variants) and repeated in both Python 3.9 and 3.11 runs, indicating a behavioral/regression issue in routing/mounting or request dispatch rather than an environment-specific dependency error. Pytest summary: 24 failed, many passed; overall job exit was non-zero (Process completed with exit code 1)."
        ],
        "relevant_files": [
            {
                "file": "tests/test_applications.py",
                "line_number": 163,
                "reason": "Multiple failing assertions for mounted routes (e.g. test_mounted_route and test_mounted_route_path_params) show client.get('/users/') and client.get('/users/tomchristie') returned 404 instead of expected 200 (log evidence: tests/test_applications.py:163 and :169 assertion failures)."
            },
            {
                "file": "tests/test_routing.py",
                "line_number": 188,
                "reason": "Many routing-related failures originate here (GET /users -> 404, root_path and submount handling causing JSONDecodeError, partial endpoint and websocket path failures, mount/middleware behavior). Representative failing lines include 188, 572, 854, 864, 1009, 1041, 1052, 1104, and 1281."
            },
            {
                "file": "tests/middleware/test_session.py",
                "line_number": 134,
                "reason": "Session cookie subpath test of a mounted app returned 404 for POST /update_session instead of 200 in both backends (tests/middleware/test_session.py:134), linking session/mount behavior to the routing failures."
            },
            {
                "file": "starlette/testclient.py",
                "line_number": 135,
                "reason": "WebSocket connect failures surface here: WebSocketTestSession._raise_on_close raised starlette.websockets.WebSocketDisconnect when websocket_connect received an immediate close message (log evidence: starlette/testclient.py:94 and :135 leading to WebSocketDisconnect)."
            },
            {
                "file": "site-packages/httpx/_models.py",
                "line_number": 761,
                "reason": "httpx.Response.json() attempted to parse a response body that was 'Not Found', delegating to json.loads and triggering a JSONDecodeError (log evidence: httpx/_models.py:761 in the json() call chain)."
            },
            {
                "file": "lib/python3.9/json/__init__.py",
                "line_number": 346,
                "reason": "The stdlib JSON loader was invoked on 'Not Found' content and forwarded to the decoder, appearing in the traceback for the JSONDecodeError (log evidence: json.__init__.py:346)."
            },
            {
                "file": "lib/python3.9/json/decoder.py",
                "line_number": 355,
                "reason": "The JSON decoder raised JSONDecodeError: 'Expecting value: line 1 column 1 (char 0)' when given 'Not Found' instead of JSON (traceback evidence: json/decoder.py:337/355)."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Multiple assertions failed where response.status_code was 404 but tests expected 200 (log examples: 'E       assert 404 == 200' at tests/test_applications.py:163; tests/test_routing.py:188, 854, 1009, 1041, 1104, 1281)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "JSONDecodeError",
                "evidence": "httpx attempted to parse a non-JSON 'Not Found' response and raised json.decoder.JSONDecodeError: 'Expecting value: line 1 column 1 (char 0)' (traceback through site-packages/httpx/_models.py:761 -> json)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "WebSocketDisconnect",
                "evidence": "WebSocket tests failed because websocket_connect returned an immediate close causing starlette.websockets.WebSocketDisconnect with code 1000 (evidence: 'starlette.websockets.WebSocketDisconnect: (1000, '')' from starlette/testclient.py)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Failed: DID NOT RAISE",
                "evidence": "A pytest context manager expecting an Exception did not receive one, shown as 'Failed: DID NOT RAISE <class 'Exception'>' in tests/test_routing.py:1052/1053."
            }
        ],
        "failed_job": [
            {
                "job": "Python 3.9",
                "step": "Run tests",
                "command": "scripts/test"
            },
            {
                "job": "Python 3.11",
                "step": "Run tests",
                "command": "scripts/test"
            }
        ]
    },
    {
        "sha_fail": "58c7cde15084b1c07373c00028dbd19b85fd5e1b",
        "error_context": [
            "In the test run step for Python 3.9 ('Python 3.9/7_Run tests.txt'), the repository's test runner (invoked by the workflow step 'Run tests' -> command 'scripts/test') executed pytest and reported 2 failing tests. Both failing tests are test_file_response_with_pathsend for the asyncio and trio backends in tests/test_responses.py. Each failure is caused by a TypeError: \"unhashable type: 'dict'\" raised when the test awaits the ASGI app with a scope that includes an extensions value written as {\"http.response.pathsend\", {}}. The inner dict literal ({}) placed inside a set makes the set construction invalid (dicts are unhashable), causing the TypeError at tests/test_responses.py:358, which in turn makes pytest exit with code 1 (summary: 2 failed, 777 passed, 4 xfailed)."
        ],
        "relevant_files": [
            {
                "file": "tests/test_responses.py",
                "line_number": 358,
                "reason": "Traceback and failing await call are at tests/test_responses.py:358; pytest shows 'E       TypeError: unhashable type: 'dict'' raised when calling await app(...) with scope containing \"extensions\": {\"http.response.pathsend\", {}}."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "Exception raised during test (TypeError)",
                "evidence": "Pytest reported 2 failed tests and the log shows 'E       TypeError: unhashable type: 'dict'' at tests/test_responses.py:358; failures occur during await app(scope, receive, send) where scope.extensions is {\"http.response.pathsend\", {}}."
            }
        ],
        "failed_job": [
            {
                "job": "Python 3.9",
                "step": "Run tests",
                "command": "scripts/test"
            }
        ]
    },
    {
        "sha_fail": "0b93d2da3b721c80dcb6a2993a23876a97498dd5",
        "error_context": [
            "In the 'Run tests' steps for multiple Python versions (logged as \"Python 3.9 ubuntu-latest/7_Run tests.txt\", \"Python 3.10 ubuntu-latest/7_Run tests.txt\", and \"Python 3.11 ubuntu-latest/7_Run tests.txt\") the CI ran scripts/test (coverage + pytest) and pytest collected 565 tests. The run failed because 6 tests in tests/protocols/test_websocket.py failed (summary: \"6 failed, 559 passed\"), causing the step to exit with code 1.",
            "Two of the failing parameterizations (test_server_reject_connection_with_body_nolength with websockets + httptools/h11 variants) failed because the HTTP client observed the server close the connection while the client was still expecting response headers. httpcore raised RemoteProtocolError(\"Server disconnected without sending a response.\"), which was mapped and re-raised as httpx.RemoteProtocolError by httpx. Log evidence: httpcore/_async/http11.py:226 'Server disconnected without sending a response.' and httpx/_transports/default.py:84 'httpx.RemoteProtocolError: Server disconnected without sending a response.'; captured stderr shows the Uvicorn server logged a WebSocket request and then 'connection rejected (403 Forbidden)' followed by 'connection closed'.",
            "The other four failing parameterizations (missing-body and multiple-response-start-event variants across httptools/h11) failed because the websockets client saw an EOF / malformed HTTP status line while reading the server's handshake response. websockets raised EOFError('line without CRLF') -> EOFError('connection closed while reading HTTP status line') -> websockets.exceptions.InvalidMessage('did not receive a valid HTTP response'). Log evidence: websockets/legacy/http.py:200 'EOFError: line without CRLF' and websockets/legacy/client.py:141 'InvalidMessage: did not receive a valid HTTP response'; captured stderr again shows the Uvicorn server logged a WebSocket request and then 'connection rejected (404 Not Found)' and 'connection closed'.",
            "Across all failures the client-side libraries (httpcore/httpx and websockets) interpreted the server-side connection close as a protocol error or malformed HTTP response. The server (uvicorn) logs show it intentionally rejected the WebSocket upgrade (403 or 404) and closed the connection, and that close is the proximate cause of the client exceptions that made the tests fail."
        ],
        "relevant_files": [
            {
                "file": "tests/protocols/test_websocket.py",
                "line_number": 1219,
                "reason": "Contains the failing tests and test helpers invoked by pytest; stack traces point here for the failing awaits (e.g. tests/protocols/test_websocket.py:1219, :1298, :1348) where websocket_session/wsresponse are used and the client observed protocol/EOF errors."
            },
            {
                "file": "httpcore/_async/http11.py",
                "line_number": 226,
                "reason": "Raised the initial httpcore.RemoteProtocolError('Server disconnected without sending a response.') when a network read returned EOF while h11 was in SEND_RESPONSE state; this is the root of the httpx-mapped exception seen in two failures."
            },
            {
                "file": "httpx/_transports/default.py",
                "line_number": 84,
                "reason": "Maps httpcore exceptions to httpx exceptions; the log shows httpx.RemoteProtocolError was raised here from the httpcore.RemoteProtocolError during the failing httpx GET requests used by the wsresponse helper."
            },
            {
                "file": "httpx/_client.py",
                "line_number": 1748,
                "reason": "Client call path (client.get/request/send) appears in traces leading into the transport that raised the mapped httpx exception while attempting to GET the ws:// URL in the test helper."
            },
            {
                "file": "httpcore/_async/connection_pool.py",
                "line_number": 268,
                "reason": "Appears in the exception propagation path where exceptions from the connection are re-raised by the connection pool (seen in the stack traces for the httpx/httpcore failures)."
            },
            {
                "file": "httpcore/_async/connection.py",
                "line_number": 103,
                "reason": "Part of the httpcore stack forwarding the request to the underlying HTTP/1.1 implementation before the RemoteProtocolError was raised."
            },
            {
                "file": "websockets/legacy/http.py",
                "line_number": 200,
                "reason": "Raised EOFError('line without CRLF') when read_line found a line not ending with CRLF; this led to EOFError('connection closed while reading HTTP status line') used as evidence that the client saw a truncated/malformed handshake response."
            },
            {
                "file": "websockets/legacy/client.py",
                "line_number": 141,
                "reason": "Converted the lower-level EOFError into websockets.exceptions.InvalidMessage('did not receive a valid HTTP response'), which is the exception observed by the tests in four failures."
            },
            {
                "file": "uvicorn/server.py",
                "line_number": 219,
                "reason": "Captured logs reference uvicorn.server lifecycle lines (Started server process, Uvicorn running, connection rejected, connection closed, Shutting down) that show the server returned 403/404 and closed the connection\u2014action correlated with client-side protocol errors."
            },
            {
                "file": "uvicorn/protocols/websockets/websockets_impl.py",
                "line_number": 317,
                "reason": "Log site for '('<client ip>', <port>) - \"WebSocket /\" <status>' entries; indicates the server's websockets implementation performed the rejection that preceded the client EOF/protocol errors."
            },
            {
                "file": "uvicorn/protocols/http/httptools_impl.py",
                "line_number": null,
                "reason": "Referenced in test parameterization for the httptools variants; implicated as the server-side http protocol implementation used in failing httptools tests."
            },
            {
                "file": "uvicorn/protocols/http/h11_impl.py",
                "line_number": null,
                "reason": "Referenced in test parameterization for the h11 variants; implicated as the server-side http protocol implementation used in failing h11 tests."
            },
            {
                "file": "pyproject.toml",
                "line_number": null,
                "reason": "Coverage debug output shows this config file was used for pytest/coverage configuration (printed at step start), establishing the test run configuration context."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "Unexpected client exceptions during websocket handshake",
                "evidence": "Pytest summary: '6 failed, 559 passed' and failing frames point into tests/protocols/test_websocket.py where websocket_session awaited wsresponse/connect and observed exceptions."
            },
            {
                "category": "Runtime Error",
                "subcategory": "httpcore.RemoteProtocolError -> httpx.RemoteProtocolError (server closed connection without response)",
                "evidence": "\"httpcore.RemoteProtocolError: Server disconnected without sending a response.\" (httpcore/_async/http11.py:226) and later 'httpx.RemoteProtocolError: Server disconnected without sending a response.' (httpx/_transports/default.py:84)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "websockets.exceptions.InvalidMessage due to EOFError on status line (line without CRLF)",
                "evidence": "\"EOFError: line without CRLF\" (websockets/legacy/http.py:200) -> \"EOFError: connection closed while reading HTTP status line\" (websockets/legacy/http.py:122) -> \"websockets.exceptions.InvalidMessage: did not receive a valid HTTP response\" (websockets/legacy/client.py:141)."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Python 3.9 ubuntu-latest/7_Run tests.txt",
                "command": "scripts/test"
            },
            {
                "job": "tests",
                "step": "Python 3.10 ubuntu-latest/7_Run tests.txt",
                "command": "scripts/test"
            },
            {
                "job": "tests",
                "step": "Python 3.11 ubuntu-latest/7_Run tests.txt",
                "command": "scripts/test"
            }
        ]
    },
    {
        "sha_fail": "e5b5fcb646e6fa9cab60fb4fff930888149b88fe",
        "error_context": [
            "The CI job failed because the requirements-check script found an unused dependency and returned a non-zero exit code. In the check_requirements job (workflow job 'check_requirements'), the step that ran the commands 'pip install -r requirements/requirements-dev.txt' followed by 'python tests/scripts/check_requirements.py' completed package installation successfully but the check_requirements.py script reported DEP002 for a single requirements file and then the job exited with code 1. Log evidence: \"- mindsdb/integrations/handlers/rag_handler/requirements.txt    None:None: DEP002 'sentence-transformers' defined as a dependency but not used in the codebase\" and \"##[error]Process completed with exit code 1.\""
        ],
        "relevant_files": [
            {
                "file": "mindsdb/integrations/handlers/rag_handler/requirements.txt",
                "line_number": null,
                "reason": "The requirements checker reported DEP002 for this file: \"DEP002 'sentence-transformers' defined as a dependency but not used in the codebase\", which directly caused the check_requirements script to fail and return exit code 1."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Unused dependency (listed but not imported)",
                "evidence": "Log: \"DEP002 'sentence-transformers' defined as a dependency but not used in the codebase\" and the check script exited with a non-zero status causing the job to fail."
            }
        ],
        "failed_job": [
            {
                "job": "check_requirements",
                "step": "Check main requirements",
                "command": "pip install -r requirements/requirements-dev.txt\n\npython tests/scripts/check_requirements.py"
            }
        ]
    },
    {
        "sha_fail": "6cbb12e47665eda2c687b4431d6ce789e74ea4a4",
        "error_context": [
            "In the run-tests job, step 'Run tests' (log: 'run-tests (3.8, full, pinned)/5_Run tests.txt') running the command 'make test' executed the test suite with pytest and produced a single failing test. The failing test was tests/test_categorical.py::TestBarPlot::test_datetime_native_scale_axis, which executed pd.date_range(\"2010-01-01\", periods=20, freq=\"ME\") and triggered an exception inside pandas. The pandas internals first raised KeyError: 'ME' in pandas/_libs/tslibs/offsets.pyx and then a propagated ValueError: \"Invalid frequency: ME\", causing the test failure. Because pytest returned a non-zero exit code, make reported 'make: *** [Makefile:4: test] Error 1' and the CI job failed (Process completed with exit code 2)."
        ],
        "relevant_files": [
            {
                "file": "tests/test_categorical.py",
                "line_number": 2081,
                "reason": "This is the test that failed; the log shows the failing line: 'x = pd.date_range(\"2010-01-01\", periods=20, freq=\"ME\")' (tests/test_categorical.py:2081)."
            },
            {
                "file": "pandas/_libs/tslibs/offsets.pyx",
                "line_number": 3508,
                "reason": "Traceback shows the initial KeyError for 'ME' and the subsequent ValueError originated in this compiled pandas offsets module (KeyError at offsets.pyx:3502 and ValueError: Invalid frequency: ME at offsets.pyx:3508 / 3612)."
            },
            {
                "file": "pandas/core/indexes/datetimes.py",
                "line_number": 1069,
                "reason": "The call to pd.date_range delegated to DatetimeArray._generate_range in this file, as shown in the traceback: '/.../site-packages/pandas/core/indexes/datetimes.py:1069: in date_range'."
            },
            {
                "file": "pandas/core/arrays/datetimes.py",
                "line_number": 377,
                "reason": "The traceback shows DatetimeArray._generate_range called to_offset here ('/.../site-packages/pandas/core/arrays/datetimes.py:377: in _generate_range'), which then raised the ValueError when resolving freq='ME'."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "Failing test due to uncaught exception",
                "evidence": "Pytest reported: 'FAILED tests/test_categorical.py::TestBarPlot::test_datetime_native_scale_axis - ValueError: Invalid frequency: ME' and final counts '1 failed, 2350 passed...'."
            },
            {
                "category": "Runtime Error",
                "subcategory": "ValueError from third-party library (pandas) - invalid input",
                "evidence": "Traceback shows pandas raised 'KeyError: \"ME\"' followed by 'ValueError: Invalid frequency: ME' in pandas/_libs/tslibs/offsets.pyx."
            },
            {
                "category": "Build/CI Failure",
                "subcategory": "Make/command exit non-zero due to test failure",
                "evidence": "Make reported 'make: *** [Makefile:4: test] Error 1' and the runner logged 'Process completed with exit code 2' after pytest failed."
            }
        ],
        "failed_job": [
            {
                "job": "run-tests",
                "step": "Run tests",
                "command": "make test"
            }
        ]
    },
    {
        "sha_fail": "2201be21886bb82201f3c3487f5f1468f6e6ac81",
        "error_context": [
            "Multiple CI jobs failed due to the same root cause: the name get_layout_engine is referenced but not defined in seaborn/_core/plot.py. Evidence: flake8 reported \"seaborn/_core/plot.py:1815:22: F821 undefined name 'get_layout_engine'\" in the 'lint' step, and pytest runs in the 'run-tests' job raised NameError exceptions during test execution (three tests failed with \"NameError: name 'get_layout_engine' is not defined\"). The undefined name also caused the documentation build to fail: in the 'build-docs' job the notebook conversion step (doc/tools/nb_to_doc.py ep.preprocess) produced a nbclient.exceptions.CellExecutionError when executing a cell that calls p.layout(...).show(), with the underlying traceback showing the same NameError from seaborn/_core/plot.py. The logs also contain repeated environment warnings (nbconvert/pandoc version too old and debugger \"frozen modules\" warnings) that are notable but secondary; the primary blocking failures are the lint error, the test failures, and the notebook execution error all triggered by the undefined get_layout_engine reference."
        ],
        "relevant_files": [
            {
                "file": "seaborn/_core/plot.py",
                "line_number": 1815,
                "reason": "Direct source of the runtime error: code at line 1815 calls get_layout_engine(self._figure) but get_layout_engine is not defined, causing NameError observed by flake8 (F821) and at runtime in tests and notebook execution."
            },
            {
                "file": "tests/_core/test_plot.py",
                "line_number": 1100,
                "reason": "Contains the failing tests that exercise Plot().layout(...).plot(); tests at lines ~1100, 1109, 1114 triggered the NameError in seaborn/_core/plot.py (pytest reported three failures originating from this test file)."
            },
            {
                "file": "doc/tools/nb_to_doc.py",
                "line_number": 126,
                "reason": "Script used to execute and convert notebooks; traceback shows ep.preprocess(...) on line 126 raised nbclient.exceptions.CellExecutionError when executing a notebook cell that invoked plotting code which then raised the NameError."
            },
            {
                "file": "doc/docstrings/objects.Plot.on.ipynb",
                "line_number": null,
                "reason": "The notebook whose cell (p.layout(...).show()) failed during nbconvert/nbclient execution, triggering the documentation build error."
            },
            {
                "file": "doc/docstrings/objects.Plot.layout.rst",
                "line_number": null,
                "reason": "Make attempted to generate this rst file from the failing notebook and the conversion failed (make reported Error 1 for this target)."
            },
            {
                "file": "doc/Makefile",
                "line_number": 60,
                "reason": "Top-level doc Makefile target 'docstrings' failed after notebook conversion errors (make: *** [Makefile:60: docstrings] Error 2)."
            },
            {
                "file": "Makefile",
                "line_number": null,
                "reason": "Root Makefile lint and test targets failed: 'make lint' failed when flake8 reported F821 and 'make test' failed when pytest returned non-zero (Makefile references observed in logs: Makefile:7 for lint and Makefile:4 for test)."
            },
            {
                "file": "nbclient/client.py",
                "line_number": null,
                "reason": "Appears in the traceback raising nbclient.exceptions.CellExecutionError that wrapped the exception raised while executing the notebook cell."
            },
            {
                "file": "nbconvert/preprocessors/execute.py",
                "line_number": null,
                "reason": "Executor orchestrates notebook cell execution; its preprocess_cell call is in the traceback for the failing cell execution."
            },
            {
                "file": "nbconvert/utils/pandoc.py",
                "line_number": 51,
                "reason": "Emitted repeated RuntimeWarning that the installed pandoc (2.9.2.1) is unsupported for nbconvert (requires >=2.14.2), a documented environment warning present during many notebook conversions."
            },
            {
                "file": "jupyter_core/utils/__init__.py",
                "line_number": null,
                "reason": "Appears in async wrapper frames in the notebook execution traceback (run_until_complete) leading to the CellExecutionError."
            },
            {
                "file": "asyncio/base_events.py",
                "line_number": null,
                "reason": "Appears in traceback (run_until_complete/future.result()) for notebook execution; part of the call stack that surfaced the CellExecutionError."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "NameError: undefined name 'get_layout_engine'",
                "evidence": "Traceback and exception: \"NameError: name 'get_layout_engine' is not defined\" at seaborn/_core/plot.py:1815 (shown in pytest and nbclient tracebacks)."
            },
            {
                "category": "Test Failure",
                "subcategory": "pytest failures caused by runtime exception",
                "evidence": "Pytest summary: \"3 failed, 2299 passed...\" with each failure showing NameError in seaborn/_core/plot.py (tests/_core/test_plot.py::TestPlotting::test_layout_extent etc.)."
            },
            {
                "category": "Linting",
                "subcategory": "Undefined name (flake8 F821)",
                "evidence": "Flake8 output: \"seaborn/_core/plot.py:1815:22: F821 undefined name 'get_layout_engine'\" causing the 'lint' target to fail."
            },
            {
                "category": "Documentation build",
                "subcategory": "Notebook execution error (nbclient.exceptions.CellExecutionError)",
                "evidence": "nbclient raised CellExecutionError while executing cell \"p.layout(extent=[0, 0, .8, 1]).show()\" invoked by doc/tools/nb_to_doc.py, causing make to fail generating docstrings."
            },
            {
                "category": "Environment Warning",
                "subcategory": "Unsupported pandoc version",
                "evidence": "Repeated RuntimeWarning from nbconvert: \"You are using an unsupported version of pandoc (2.9.2.1). Your version must be at least (2.14.2) but less than (4.0.0).\""
            },
            {
                "category": "Debugger Warning",
                "subcategory": "Frozen modules / file validation warnings",
                "evidence": "Repeated messages: \"Debugger warning: It seems that frozen modules are being used... pass -Xfrozen_modules=off to python... Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\""
            }
        ],
        "failed_job": [
            {
                "job": "build-docs",
                "step": "Build docs",
                "command": "cd doc\nmake -j `nproc` notebooks\nmake html"
            },
            {
                "job": "lint",
                "step": "Flake8",
                "command": "make lint"
            },
            {
                "job": "run-tests",
                "step": "Run tests",
                "command": "make test"
            }
        ]
    },
    {
        "sha_fail": "785242b646b54a33547ff1298cb945a05c24aa4c",
        "error_context": [
            "In the run-tests job, step 'Run tests' (matrix python=3.8, install=full, deps=pinned) the test suite was executed with `make test` and pytest reported a single test failure. The failing test is TestLinePlotter.test_weights in tests/test_relational.py, which calls `expected = np.average(pos_df[\"y\"], weights=pos_df[\"x\"])`. NumPy raised a ZeroDivisionError: \"Weights sum to zero, can't be normalized\" when computing a weighted average for a group whose weights sum to zero. Because the test suite returned a non-zero exit, `make test` failed and the CI job exited with a non-zero status (`make: *** [Makefile:4: test] Error 1` / `Process completed with exit code 2`).",
            "The logs also show many deprecation and Matplotlib-related warnings (collected but not fatal) originating from seaborn core modules and tests; these warnings did not cause the failure but are present in the run."
        ],
        "relevant_files": [
            {
                "file": "tests/test_relational.py",
                "line_number": 1077,
                "reason": "Location of the failing test (TestLinePlotter.test_weights). The test invokes np.average on pos_df['y'] with weights pos_df['x'], and the traceback shows the exception was raised from this call at tests/test_relational.py:1077."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/numpy/lib/function_base.py",
                "line_number": 409,
                "reason": "NumPy's average implementation raised the ZeroDivisionError ('Weights sum to zero, can't be normalized') when the sum of the provided weights was zero; the traceback points to this file/line as the source of the exception."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "Unhandled exception (ZeroDivisionError) during test",
                "evidence": "Failing test TestLinePlotter.test_weights called np.average(...) and raised ZeroDivisionError: \"Weights sum to zero, can't be normalized\" (traceback into numpy/lib/function_base.py:409)."
            },
            {
                "category": "Build Failure",
                "subcategory": "Make target returned non-zero exit due to test failure",
                "evidence": "Make failed after pytest returned non-zero: \"make: *** [Makefile:4: test] Error 1\" and the runner: \"Process completed with exit code 2\"."
            },
            {
                "category": "Warnings",
                "subcategory": "Deprecation / Matplotlib warnings collected (non-fatal)",
                "evidence": "Warnings summary: many MatplotlibDeprecationWarning and DeprecationWarning entries (e.g., from seaborn/_core/plot.py and seaborn/_core/rules.py) were collected but did not cause the job to fail."
            }
        ],
        "failed_job": [
            {
                "job": "run-tests",
                "step": "Run tests",
                "command": "make test"
            }
        ]
    },
    {
        "sha_fail": "3ed7a88e343c89b7153efea25db1b6287b2f0823",
        "error_context": [
            "The CI run failed during the lint phase of the matrixed 'ci' job (the step that runs './script/cibuild'). Across all tested Python versions (3.8, 3.9, 3.10, 3.11, 3.12) the environment and dependency installation completed successfully, but the linter reported the same error and the build exited non\u2011zero. The specific lint message reported in each CI Build step was: \"tests/test_octodns_processor_filter.py:199:13: local variable 'filter_private' is assigned to but never used\", and immediately afterwards the process exited with code 1 (\"Process completed with exit code 1\"). Therefore the root cause is a lint/flake8/pyflakes code-quality failure (an unused local variable) in tests/test_octodns_processor_filter.py that caused ./script/cibuild to return a non-zero exit and mark the job as failed in every matrix run."
        ],
        "relevant_files": [
            {
                "file": "tests/test_octodns_processor_filter.py",
                "line_number": 199,
                "reason": "The lint step explicitly points to this file and line: \"tests/test_octodns_processor_filter.py:199:13: local variable 'filter_private' is assigned to but never used\" \u2014 this unused local variable caused the linter to fail and the CI to exit with code 1 across all python-version matrix runs."
            }
        ],
        "error_types": [
            {
                "category": "Code Quality",
                "subcategory": "Linting - unused local variable (pyflakes/flake8)",
                "evidence": "\"local variable 'filter_private' is assigned to but never used\" reported by the lint step and followed by \"Process completed with exit code 1\" in each CI Build log."
            }
        ],
        "failed_job": [
            {
                "job": "ci",
                "step": "CI Build (python 3.8)",
                "command": "./script/cibuild"
            },
            {
                "job": "ci",
                "step": "CI Build (python 3.9)",
                "command": "./script/cibuild"
            },
            {
                "job": "ci",
                "step": "CI Build (python 3.10)",
                "command": "./script/cibuild"
            },
            {
                "job": "ci",
                "step": "CI Build (python 3.11)",
                "command": "./script/cibuild"
            },
            {
                "job": "ci",
                "step": "CI Build (python 3.12)",
                "command": "./script/cibuild"
            }
        ]
    },
    {
        "sha_fail": "9e1aa7b8edfb723656f41f97bab57f9a653d5e1b",
        "error_context": [
            "The CI run failed because a unit test failed while running the test suite during the build steps. Across multiple jobs/variants the test run invoked pytest and reported 294 collected tests with 293 passed and 1 failed. The single failing test is tests/test_octodns_manager.py::TestManager::test_missing_zone. The test calls Manager(get_config_filename('dynamic-config.yaml')).sync(['missing.zones.']) and expects a ManagerException whose string contains the substring 'Requested zone:'. The assertion self.assertTrue('Requested zone:' in str(ctx.exception)) evaluated to False, producing an AssertionError (log evidence: \"E       AssertionError: False is not true\" and \"FAILED tests/test_octodns_manager.py::TestManager::test_missing_zone - AssertionError: False is not true\").",
            "The failure happened during the CI Build step(s) that run the project's build and tests: in the matrix job 'ci' step named 'CI Build' (runs ./script/cibuild) for multiple Python versions (3.8, 3.9, 3.10, 3.11, 3.12) and also in the 'setup-py' job step 'CI setup.py' (runs ./script/cibuild-setup-py) \u2014 logs from those steps show the same failing test. Each affected step ends with the pytest failure summary and the runner reporting \"Process completed with exit code 1.\"",
            "The run also printed non-fatal deprecation warnings during package install via setup.py (originating from setuptools/_distutils/cmd.py:66): SetuptoolsDeprecationWarning \"setup.py install is deprecated\" and EasyInstallDeprecationWarning \"easy_install command is deprecated.\" These are warnings only and not the direct cause of the CI failure, but they are present in the logs and may be relevant to packaging workflows (log evidence quoting the origin and admonition blocks in the install logs)."
        ],
        "relevant_files": [
            {
                "file": "tests/test_octodns_manager.py",
                "line_number": 87,
                "reason": "This test file contains the failing test. Log evidence: the failure block shows TestManager.test_missing_zone and the assertion at tests/test_octodns_manager.py:87 (self.assertTrue('Requested zone:' in str(ctx.exception))) which raised \"AssertionError: False is not true\" and is reported as the single failing test."
            },
            {
                "file": "dynamic-config.yaml",
                "line_number": null,
                "reason": "Referenced directly by the failing test via Manager(get_config_filename('dynamic-config.yaml')).sync([...]) \u2014 the configuration file is the input used in the test that produced the ManagerException whose message did not match the test's expectation."
            },
            {
                "file": "/tmp/ci-9dr3sWv5MQ/lib/python3.12/site-packages/setuptools/_distutils/cmd.py",
                "line_number": 66,
                "reason": "This file is the origin of deprecation warnings emitted during the setup.py install phase in the setup-py job. Logs show SetuptoolsDeprecationWarning and EasyInstallDeprecationWarning emitted from this path at line 66."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest failure: \"self.assertTrue('Requested zone:' in str(ctx.exception))\" -> \"E       AssertionError: False is not true\" and \"FAILED tests/test_octodns_manager.py::TestManager::test_missing_zone - AssertionError: False is not true\""
            },
            {
                "category": "Deprecation Warning",
                "subcategory": "SetuptoolsDeprecationWarning / EasyInstallDeprecationWarning",
                "evidence": "\"/tmp/.../site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\" and similar EasyInstallDeprecationWarning printed during install"
            }
        ],
        "failed_job": [
            {
                "job": "ci",
                "step": "CI Build",
                "command": "./script/cibuild"
            },
            {
                "job": "setup-py",
                "step": "CI setup.py",
                "command": "./script/cibuild-setup-py"
            }
        ]
    },
    {
        "sha_fail": "f2f8b63c3d579f9e8f1d4319592e44e39591ee38",
        "error_context": [
            "The CI run failed during the \"Run tests\" step(s) because two distinct problems caused test runs to abort/fail: (1) On the ubuntu-22.04 test run several parameterizations of tests/test_context_commands.py::test_empty_context_sections asserted that pwndbg.gdblib.config.context_sections.value equals the expected default but instead contained an extra token \"heap-tracker\", producing AssertionError failures (5 failed tests). Logs show the assertion at tests/test_context_commands.py:85 and the diff: actual '... threads heap-tracker' vs expected '... threads'. The failing step name in the logs is \"tests (ubuntu-22.04)/6_Run tests.txt\" and the job's test step invoked: mkdir .cov; sudo sysctl -w kernel.yama.ptrace_scope=0; ./tests.sh --cov. (2) On another test run (ubuntu-20.04 log) pytest failed during collection because importing pwndbg triggered an import-time TypeError caused by use of the Python 3.10+ union type operator '|' in a function annotation (def resolve_address(...) -> int | None:) in pwndbg/gdblib/heap_tracking.py. The traceback shows pwndbg/__init__.py -> load_commands() -> pwndbg.commands.ai -> pwndbg.commands.context -> import pwndbg.gdblib.heap_tracking, where the TypeError \"unsupported operand type(s) for |: 'type' and 'NoneType'\" is raised. This import-time error caused many collection errors (\"collected 59 items / 27 errors\") and aborted the test collection. Both failures are tied to the test-run step(s) that run ./tests.sh --cov in the workflow's \"Run tests\" step(s)."
        ],
        "relevant_files": [
            {
                "file": "tests/test_context_commands.py",
                "line_number": 85,
                "reason": "Assertion failure originates here: test_empty_context_sections asserts pwndbg.gdblib.config.context_sections.value equals a hard-coded default but actual value contains an extra token 'heap-tracker', producing AssertionError as shown in the logs."
            },
            {
                "file": "pwndbg/gdblib/heap_tracking.py",
                "line_number": 88,
                "reason": "Import-time TypeError occurs at the function annotation 'def resolve_address(name: str) -> int | None:' (line 88). The logs show 'TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'' which prevents pwndbg from being imported during pytest collection."
            },
            {
                "file": "pwndbg/commands/context.py",
                "line_number": 24,
                "reason": "This module imports pwndbg.gdblib.heap_tracking (the module that raises the TypeError). The traceback in the logs shows this import as part of the chain that triggers the collection-time failures."
            },
            {
                "file": "pwndbg/commands/ai.py",
                "line_number": 21,
                "reason": "This module imports pwndbg.commands.context and so participates in the import chain (pwndbg.commands.ai -> context -> gdblib.heap_tracking) that leads to the TypeError during test collection."
            },
            {
                "file": "pwndbg/commands/__init__.py",
                "line_number": 633,
                "reason": "load_commands() at this location imports pwndbg.commands.ai (and thus context and heap_tracking). The logs show this line in the traceback for every collection error."
            },
            {
                "file": "pwndbg/__init__.py",
                "line_number": 14,
                "reason": "Importing pwndbg executes load_commands() (line 14) during test collection; this is the initial entrypoint in the traceback that leads into the failing import chain."
            },
            {
                "file": "/lib64/ld-linux-x86-64.so.2",
                "line_number": null,
                "reason": "Appears in the GDB frame printed when the test target immediately stopped: 'Program stopped. 0x00007ffff7fe3290 in _start () from /lib64/ld-linux-x86-64.so.2'. Shown repeatedly for the failing parameterized tests in tests/test_context_commands.py."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "tests/test_context_commands.py:85 AssertionError: actual 'regs disasm code ... threads heap-tracker' != expected 'regs disasm code ... threads' (log shows the diff and 5 failing parameterizations; Tests failed: 5)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "GDB program stop / unexpected process stop",
                "evidence": "Log lines: 'Program stopped. 0x00007ffff7fe3290 in _start () from /lib64/ld-linux-x86-64.so.2' printed immediately before the failing assertions in the context-tests."
            },
            {
                "category": "Import / Compatibility Error",
                "subcategory": "TypeError from use of '|' union type in annotation (Python runtime incompatibility)",
                "evidence": "Traceback: '.../pwndbg/gdblib/heap_tracking.py:88 def resolve_address(name: str) -> int | None:' then 'TypeError: unsupported operand type(s) for |: 'type' and 'NoneType''. Appears repeatedly during pytest collection (27 errors)."
            },
            {
                "category": "Test Collection Error",
                "subcategory": "Interrupted collection due to import errors",
                "evidence": "Pytest summary: 'collected 59 items / 27 errors' and '!!!!!!!!!!!!!!!!!!! Interrupted: 27 errors during collection !!!!!!!!!!!!!!!!!!!' (caused by the TypeError during imports)."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "tests (ubuntu-22.04)/6_Run tests.txt",
                "command": "mkdir .cov\nsudo sysctl -w kernel.yama.ptrace_scope=0\n./tests.sh --cov"
            },
            {
                "job": "tests",
                "step": "tests (ubuntu-20.04)/6_Run tests.txt",
                "command": "mkdir .cov\nsudo sysctl -w kernel.yama.ptrace_scope=0\n./tests.sh --cov"
            }
        ]
    },
    {
        "sha_fail": "fc6215f93ad9e2be8a32dc18b75a3f5bf6381a16",
        "error_context": [
            "The CI run failed because the pre-commit pylint hook detected a spelling error in a code comment and exited non-zero, causing the 'Run pylint checks' step to fail. The log shows the environment and installation completed successfully (virtualenv activated, pip built and installed pylint 3.1.0.dev0), but the pre-commit hook failed: \"pylint...................................................................Failed\" with \"- hook id: pylint\" and \"- exit code: 16\". Pylint reported a spelling problem in pylint/checkers/nested_min_max.py at line 70: \"C0401: Wrong spelling of a word 'redunant' in a comment\" (the commented line: \"# Meaning, redunant call only if parent max call has more than 1 arg.\"). The pre-commit failure returned exit code 16 which caused the job step to terminate and the workflow to report \"Process completed with exit code 1.\""
        ],
        "relevant_files": [
            {
                "file": "pylint/checkers/nested_min_max.py",
                "line_number": 70,
                "reason": "Pylint reported a spelling issue at this file/line: \"pylint/checkers/nested_min_max.py:70:0: C0401: Wrong spelling of a word 'redunant' in a comment\" (the comment: \"# Meaning, redunant call only if parent max call has more than 1 arg.\") which triggered the pre-commit pylint hook failure."
            }
        ],
        "error_types": [
            {
                "category": "Code Quality",
                "subcategory": "Linting - wrong spelling in comment",
                "evidence": "pylint output: \"pylint/checkers/nested_min_max.py:70:0: C0401: Wrong spelling of a word 'redunant' in a comment\" (wrong-spelling-in-comment)."
            },
            {
                "category": "CI",
                "subcategory": "Pre-commit hook failure (non-zero exit)",
                "evidence": "Pre-commit summary: \"pylint...................................................................Failed\", \"- hook id: pylint\", \"- exit code: 16\" and \"##[error]Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "pylint",
                "step": "Run pylint checks",
                "command": ". venv/bin/activate\npip install .\npip list | grep 'astroid\\|pylint'\npre-commit run --hook-stage manual pylint-with-spelling --all-files"
            }
        ]
    },
    {
        "sha_fail": "a14be35a9de01a87991618a5dbd6b96470d0f799",
        "error_context": [
            "The CI run failed because the codestyle check detected a formatting violation. In the step 'build (3.9)/7_Codestyle.txt' (workflow step 'Codestyle' in job 'build'), the command 'black --check errbot/ tests/ tools/' reported: \"would reformat /home/runner/work/errbot/errbot/errbot/core_plugins/vcheck.py\" and returned a nonzero exit status. Tox captured this as \"codestyle: exit 1\" which caused the codestyle tox environment to fail (\"codestyle: FAIL code 1\") and the GitHub Actions job to finish with exit code 1. The workflow runs 'tox -e codestyle' only for python-version == '3.9', so the failing matrix entry was the 3.9 build."
        ],
        "relevant_files": [
            {
                "file": "errbot/core_plugins/vcheck.py",
                "line_number": null,
                "reason": "Black reported it \"would reformat .../errbot/core_plugins/vcheck.py\", which directly caused 'black --check' to exit with status 1 and the codestyle tox environment to fail."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Black check failure (file would be reformatted)",
                "evidence": "\"would reformat /home/runner/work/errbot/errbot/errbot/core_plugins/vcheck.py\" and \"codestyle: exit 1\" (black --check returned nonzero because a file needs reformatting)."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "build (3.9)/7_Codestyle.txt",
                "command": "tox -e codestyle"
            }
        ]
    },
    {
        "sha_fail": "8a04007d606de7a355f904407294f8ad5d2b7374",
        "error_context": [
            "The CI run failed because the codestyle check returned a non-zero exit code: in the build job's 'Codestyle' step (matrix python-version == '3.9') the workflow ran 'tox -e codestyle', which invoked 'black --check errbot/ tests/ tools/'. Black reported a formatting mismatch for a test file: 'would reformat /home/runner/work/errbot/errbot/tests/commands_test.py' and exited with status 1, causing the codestyle tox environment to fail ('codestyle: exit 1' and 'codestyle: FAIL code 1'). The tox setup and dependency installs completed successfully (black==23.10.1 was present), so the root cause is a code-formatting mismatch detected by black, not an installation or runtime error."
        ],
        "relevant_files": [
            {
                "file": "tests/commands_test.py",
                "line_number": null,
                "reason": "Black reported this file 'would reformat /home/runner/work/errbot/errbot/tests/commands_test.py', which directly caused 'black --check' to return non-zero and the 'codestyle' tox environment to fail."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Black formatting check failure",
                "evidence": "From log: 'would reformat /home/runner/work/errbot/errbot/tests/commands_test.py' and '1 file would be reformatted' followed by 'codestyle: exit 1' and 'Process completed with exit code 1.'"
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Codestyle",
                "command": "tox -e codestyle"
            }
        ]
    },
    {
        "sha_fail": "ce191b811e255722bfb4f5c2c7c30bcb7a4a3d59",
        "error_context": [
            "All failing steps are the 'Pip install and run pylint' lint step in the accuracy_checker job (multiple matrix variants). In each logged variant pylint was installed and run; pylint reported a single code-style violation: openvino/tools/accuracy_checker/annotation_converters/amazon.py:42:0: C0301: Line too long (125/120) (line-too-long). The pylint invocation was followed by the runner reporting a non-zero termination: 'Process completed with exit code 16' (or '##[error]Process completed with exit code 16'), which caused the CI step to be marked as failed. The logs also show repeated FutureWarning messages emitted by the third-party astroid package (e.g. '/opt/.../site-packages/astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.') \u2014 these are dependency warnings produced while importing astroid during pylint analysis and are diagnostic but not the direct cause of the non-zero exit. In short: the lint step failed across multiple runners because pylint emitted a line-length violation on amazon.py (line 42) and the step exited with code 16, causing the workflow failure."
        ],
        "relevant_files": [
            {
                "file": "openvino/tools/accuracy_checker/annotation_converters/amazon.py",
                "line_number": 42,
                "reason": "Pylint reported a C0301 line-too-long violation referencing this file and line: 'openvino/tools/accuracy_checker/annotation_converters/amazon.py:42:0: C0301: Line too long (125/120) (line-too-long)'. This is the repository source file that triggered the lint complaint."
            },
            {
                "file": "/opt/hostedtoolcache/.../site-packages/astroid/raw_building.py",
                "line_number": 416,
                "reason": "Repeated FutureWarning entries in the logs originate from this astroid file and line: '/opt/.../site-packages/astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.' \u2014 a dependency warning emitted while pylint/astroid imported repository modules."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Line Length Exceeded",
                "evidence": "openvino/tools/accuracy_checker/annotation_converters/amazon.py:42:0: C0301: Line too long (125/120) (line-too-long)"
            },
            {
                "category": "Dependency Warning",
                "subcategory": "Third-party FutureWarning (astroid)",
                "evidence": "/opt/.../site-packages/astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar."
            },
            {
                "category": "CI / Process Failure",
                "subcategory": "Non-zero exit code from lint step",
                "evidence": "[error]Process completed with exit code 16. (also shown as '##[error]Process completed with exit code 16.')"
            }
        ],
        "failed_job": [
            {
                "job": "accuracy_checker",
                "step": "accuracy_checker (ubuntu-20.04, 3.8)/6_Pip install and run pylint.txt",
                "command": "python -m pip install pylint==2.10.2\n        PYTHONPATH=. python -m pylint --rcfile=.pylintrc `find -wholename '?*/**/*.py' -not -path \"./tests/*\" -not -path \"./build/*\"`"
            },
            {
                "job": "accuracy_checker",
                "step": "accuracy_checker (ubuntu-20.04, 3.9)/6_Pip install and run pylint.txt",
                "command": "python -m pip install pylint==2.10.2\n        PYTHONPATH=. python -m pylint --rcfile=.pylintrc `find -wholename '?*/**/*.py' -not -path \"./tests/*\" -not -path \"./build/*\"`"
            },
            {
                "job": "accuracy_checker",
                "step": "accuracy_checker (ubuntu-20.04, 3.10)/6_Pip install and run pylint.txt",
                "command": "python -m pip install pylint==2.10.2\n        PYTHONPATH=. python -m pylint --rcfile=.pylintrc `find -wholename '?*/**/*.py' -not -path \"./tests/*\" -not -path \"./build/*\"`"
            },
            {
                "job": "accuracy_checker",
                "step": "accuracy_checker (ubuntu-22.04, 3.8)/6_Pip install and run pylint.txt",
                "command": "python -m pip install pylint==2.10.2\n        PYTHONPATH=. python -m pylint --rcfile=.pylintrc `find -wholename '?*/**/*.py' -not -path \"./tests/*\" -not -path \"./build/*\"`"
            }
        ]
    },
    {
        "sha_fail": "07bc10c0e7858b22e9345812af8e6bb6c4ef18be",
        "error_context": [
            "The CI run failed during the \"Pip install and run pylint\" step of the accuracy_checker job. In that step the workflow installed pylint (python -m pip install pylint==2.10.2) successfully, but running pylint produced repeated FutureWarning messages emitted by astroid during import (originating from astroid/raw_building.py:416) and reported a single lint error: a trailing whitespace (C0303) in openvino/tools/accuracy_checker/evaluators/model_evaluator.py at line 805. Immediately after, the job runner reported a non-zero termination: \"Process completed with exit code 16\", causing the job to fail. Log evidence: repeated lines of \"/.../astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\" and the pylint message \"openvino/tools/accuracy_checker/evaluators/model_evaluator.py:805:0: C0303: Trailing whitespace (trailing-whitespace)\", followed by \"##[error]Process completed with exit code 16.\""
        ],
        "relevant_files": [
            {
                "file": "openvino/tools/accuracy_checker/evaluators/model_evaluator.py",
                "line_number": 805,
                "reason": "Pylint reported a trailing-whitespace lint error at this file and line: \"openvino/tools/accuracy_checker/evaluators/model_evaluator.py:805:0: C0303: Trailing whitespace (trailing-whitespace)\"."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.8.18/x64/lib/python3.8/site-packages/astroid/raw_building.py",
                "line_number": 416,
                "reason": "Repeated FutureWarning messages originated from this file/line during pylint/astroid import: \"/.../astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\"."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Trailing whitespace",
                "evidence": "pylint output: \"openvino/tools/accuracy_checker/evaluators/model_evaluator.py:805:0: C0303: Trailing whitespace (trailing-whitespace)\"."
            },
            {
                "category": "Runtime Warning",
                "subcategory": "Library FutureWarning from astroid",
                "evidence": "Multiple occurrences of: \"/opt/hostedtoolcache/.../astroid/raw_building.py:416: FutureWarning: In the future `np.long` will be defined as the corresponding NumPy scalar.\" printed during pylint/astroid import."
            },
            {
                "category": "CI Runner",
                "subcategory": "Non-zero exit code",
                "evidence": "Runner reported: \"##[error]Process completed with exit code 16.\" immediately after pylint finished."
            }
        ],
        "failed_job": [
            {
                "job": "accuracy_checker",
                "step": "Pip install and run pylint",
                "command": "python -m pip install pylint==2.10.2\nPYTHONPATH=. python -m pylint --rcfile=.pylintrc `find -wholename '?*/**/*.py' -not -path \"./tests/*\" -not -path \"./build/*\"`"
            }
        ]
    },
    {
        "sha_fail": "55f8e6684499eb6abe5b1c1dba01ca4c90d2c949",
        "error_context": [
            "The CI run failed because the tox 'lint' environment returned a non-zero exit code, causing the overall job to fail. In the 'build (3.10)/5_Test with tox.txt' step the lint command executed 'ruff /home/runner/work/cowrie/cowrie/src' and ruff found 6 errors in src/cowrie/output/oraclecloud.py (unused imports, redefinition, quoting style, and print statements) and exited with code 1 (\"Found 6 errors... lint: exit 1\"). Several typing tools also reported serious issues during the same tox run: mypyc crashed with an AssertionError pointing at src/cowrie/shell/protocol.py (\"AssertionError: unexpected type <class 'mypy.types.DeletedType'>\"), pytype failed with a usage error (\"pytype: error: Need an input.\"), pyre reported a taint configuration error (\"No `.config` was found in the taint directories\"), and pyright produced a large bulk of type errors (\"385 errors, 50 warnings...\"). However, most typing failures were configured as non-blocking within tox (logs show \"command failed but is marked ignore outcome so handling it as success\"), so they did not by themselves stop the tox run. Unit tests (py310 unittest discover) passed (\"Ran 117 tests... OK\"). Final runner error is \"Process completed with exit code 255.\" In summary: the immediate blocking cause is the lint step failing due to ruff errors (notably oraclecloud.py), while multiple type-checking and static-analysis tools reported many additional issues (mypy/mypyc assertion, pytype usage, pyre taint config, pyright missing imports and many type problems) that indicate broader problems but were non-blocking in this run."
        ],
        "relevant_files": [
            {
                "file": "src/cowrie/output/oraclecloud.py",
                "line_number": null,
                "reason": "Ruff reported 6 lint errors in this file (unused imports, redefinition, quoting preference, and `print` usage) which caused the lint environment to exit non-zero and fail the CI: \"src/cowrie/output/oraclecloud.py:3:26: F401 ... F811 ... F401 ... Q000 ... T201 ... T201\"."
            },
            {
                "file": "src/cowrie/shell/protocol.py",
                "line_number": null,
                "reason": "mypyc crashed with an AssertionError referencing this file (\"src/cowrie/shell/protocol.py:25: AssertionError: unexpected type <class 'mypy.types.DeletedType'>\"), indicating an internal type/IR mapping problem during compilation."
            },
            {
                "file": "src/backend_pool/nat.py",
                "line_number": null,
                "reason": "Pyright reported multiple type/member issues here (optional member access, reactor API usage, and write binding mismatches), e.g. \"'loseConnection' is not a known member of 'None'\", \"'connectTCP' is not a known member of module 'twisted.internet.reactor'\"."
            },
            {
                "file": "src/backend_pool/pool_server.py",
                "line_number": null,
                "reason": "Pyright reported a write binding/type mismatch for transport.write: \"Could not bind method 'write' because 'ITransport' is not assignable to parameter 'data'\"."
            },
            {
                "file": "src/backend_pool/pool_service.py",
                "line_number": null,
                "reason": "Pyright reported missing import resolution for libvirt and other type errors (\"Import 'libvirt' could not be resolved\" and iteration over None)."
            },
            {
                "file": "src/backend_pool/ssh_exec.py",
                "line_number": null,
                "reason": "Pyright flagged optional member and reactor usage errors (e.g. 'sendRequest'/'transport' not known on None; 'connectTCP' not known on twisted.internet.reactor)."
            },
            {
                "file": "src/backend_pool/telnet_exec.py",
                "line_number": null,
                "reason": "Pyright reported unknown/optional members on transport/factory and reactor usage errors (factory/loseConnection/connectTCP issues)."
            },
            {
                "file": "src/backend_pool/libvirt/backend_service.py",
                "line_number": null,
                "reason": "Pyright reported missing import: \"Import 'libvirt' could not be resolved\"."
            },
            {
                "file": "src/backend_pool/libvirt/guest_handler.py",
                "line_number": null,
                "reason": "Pyright reported missing import for libvirt: \"Import 'libvirt' could not be resolved\"."
            },
            {
                "file": "src/backend_pool/libvirt/network_handler.py",
                "line_number": null,
                "reason": "Pyright reported missing import errors for libvirt at multiple lines: \"Import 'libvirt' could not be resolved\"."
            },
            {
                "file": "src/cowrie/commands/__init__.py",
                "line_number": null,
                "reason": "Pyright warned many names listed in __all__ are not present (reportUnsupportedDunderAll), indicating module export inconsistencies."
            },
            {
                "file": "src/cowrie/commands/chmod.py",
                "line_number": null,
                "reason": "Pyright reported type/signature mismatches for regex.fullmatch usage and argument type issues (no matching overloads; None may be passed where str required)."
            },
            {
                "file": "src/cowrie/commands/curl.py",
                "line_number": null,
                "reason": "Pyright reported many possibly-unbound variables and operator/type issues (e.g. 'url' possibly unbound, operator 'not in' unsupported between types)."
            },
            {
                "file": "src/cowrie/commands/finger.py",
                "line_number": null,
                "reason": "Pyright flagged possibly-unbound 'args' usage in several locations."
            },
            {
                "file": "src/cowrie/commands/fs.py",
                "line_number": null,
                "reason": "Pyright reported many possibly-unbound variable errors across this file (multiple lines flagged)."
            },
            {
                "file": "src/cowrie/commands/perl.py",
                "line_number": null,
                "reason": "Pyright reported 'Unbound' is not iterable and possibly-unbound opts/args errors."
            },
            {
                "file": "src/cowrie/commands/ssh.py",
                "line_number": null,
                "reason": "Pyright reported 'Unbound' iterable errors and possibly-unbound variables in SSH command handling."
            },
            {
                "file": "src/cowrie/commands/tftp.py",
                "line_number": null,
                "reason": "Pyright reported len() called on bytes|None and optional member access errors (e.g. 'metrics' unknown on None)."
            },
            {
                "file": "src/cowrie/commands/wc.py",
                "line_number": null,
                "reason": "Pyright flagged possibly-unbound 'args' variables in multiple places."
            },
            {
                "file": "src/cowrie/commands/wget.py",
                "line_number": null,
                "reason": "Pyright reported 'errormsg' possibly unbound in an error-handling path."
            },
            {
                "file": "src/cowrie/core/auth.py",
                "line_number": null,
                "reason": "Pyright reported invalid member access for bytearray/memoryview ('search' member unknown)."
            },
            {
                "file": "src/cowrie/core/output.py",
                "line_number": null,
                "reason": "Pyright reported many possibly-unbound 'sessionno' usages across the file indicating potential uninitialized variable access."
            },
            {
                "file": "src/cowrie/core/realm.py",
                "line_number": null,
                "reason": "Pyright reported type/interface incompatibilities: HoneyPotRealm incompatible with IRealm and CowrieUser incompatible with IConchUser (missing 'logout' member)."
            },
            {
                "file": "src/cowrie/output/abuseipdb.py",
                "line_number": null,
                "reason": "Pyright reported reactor API usage issues (e.g. 'callLater' not known on twisted.internet.reactor)."
            },
            {
                "file": "src/cowrie/output/csirtg.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'csirtgsdk' could not be resolved."
            },
            {
                "file": "src/cowrie/output/datadog.py",
                "line_number": null,
                "reason": "Pyright reported type incompatibility for contextFactory parameter (WebClientContextFactory vs BrowserLikePolicyForHTTPS)."
            },
            {
                "file": "src/cowrie/output/discord.py",
                "line_number": null,
                "reason": "Pyright reported type incompatibility for contextFactory argument similar to other output plugins."
            },
            {
                "file": "src/cowrie/output/dshield.py",
                "line_number": null,
                "reason": "Pyright reported missing reactor method 'callFromThread' on twisted.internet.reactor."
            },
            {
                "file": "src/cowrie/output/elasticsearch.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'elasticsearch' could not be resolved."
            },
            {
                "file": "src/cowrie/output/graylog.py",
                "line_number": null,
                "reason": "Pyright reported contextFactory type incompatibility similar to other outputs."
            },
            {
                "file": "src/cowrie/output/hpfeeds3.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'hpfeeds.twisted' could not be resolved."
            },
            {
                "file": "src/cowrie/output/influx.py",
                "line_number": null,
                "reason": "Pyright reported missing imports for 'influxdb' and 'influxdb.exceptions'."
            },
            {
                "file": "src/cowrie/output/misp.py",
                "line_number": null,
                "reason": "Pyright reported missing import errors for 'pymisp' across multiple lines."
            },
            {
                "file": "src/cowrie/output/mongodb.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'pymongo' could not be resolved."
            },
            {
                "file": "src/cowrie/output/mysql.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'mysql.connector' could not be resolved."
            },
            {
                "file": "src/cowrie/output/redis.py",
                "line_number": null,
                "reason": "Pyright warned that 'redis' could not be resolved from source (missing module source/stub)."
            },
            {
                "file": "src/cowrie/output/rethinkdblog.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'rethinkdb' could not be resolved."
            },
            {
                "file": "src/cowrie/output/s3.py",
                "line_number": null,
                "reason": "Pyright reported missing botocore imports: 'botocore.exceptions' and 'botocore.session' could not be resolved."
            },
            {
                "file": "src/cowrie/output/slack.py",
                "line_number": null,
                "reason": "Pyright reported missing import: 'slack' could not be resolved."
            },
            {
                "file": "src/cowrie/output/splunk.py",
                "line_number": null,
                "reason": "Pyright reported contextFactory type incompatibility similar to other outputs (WebClientContextFactory vs BrowserLikePolicyForHTTPS)."
            },
            {
                "file": "src/cowrie/output/virustotal.py",
                "line_number": null,
                "reason": "Pyright reported contextFactory type incompatibility for Virustotal output plugin."
            },
            {
                "file": "src/cowrie/output/xmpp.py",
                "line_number": null,
                "reason": "Pyright reported missing 'wokkel' imports and additional operator/None handling issues in XMPP plugin."
            },
            {
                "file": "src/cowrie/pool_interface/client.py",
                "line_number": null,
                "reason": "Pyright reported binding errors for transport.write (ITransport vs bytes) and optional member access problems."
            },
            {
                "file": "src/cowrie/python/logfile.py",
                "line_number": null,
                "reason": "Pyright reported incompatible argument type for textFileLogObserver (CowrieDailyLogFile not assignable to IO[Any])."
            },
            {
                "file": "src/cowrie/scripts/createfs.py",
                "line_number": null,
                "reason": "Pyright reported unbound/iteration errors (e.g. 'Unbound' is not iterable; optlist possibly unbound)."
            },
            {
                "file": "src/cowrie/scripts/playlog.py",
                "line_number": null,
                "reason": "Pyright reported multiple possibly-unbound variable errors (including 'logfile' possibly unbound)."
            },
            {
                "file": "src/cowrie/shell/honeypot.py",
                "line_number": null,
                "reason": "Pyright flagged many possibly-unbound variables and operator incompatibilities (cmd_expr, pos, result, basedir)."
            },
            {
                "file": "src/cowrie/ssh/channel.py",
                "line_number": null,
                "reason": "Pyright reported optional member access errors (transport not known on None)."
            },
            {
                "file": "src/cowrie/ssh/connection.py",
                "line_number": null,
                "reason": "Pyright reported missing member access on None (sendPacket not known on None)."
            },
            {
                "file": "src/cowrie/ssh/factory.py",
                "line_number": null,
                "reason": "Pyright reported unknown member 'tac' on CowrieSSHFactory."
            },
            {
                "file": "src/cowrie/ssh/forwarding.py",
                "line_number": null,
                "reason": "Pyright reported possibly-unbound 'res_code' variables."
            },
            {
                "file": "src/cowrie/ssh/session.py",
                "line_number": null,
                "reason": "Pyright reported missing/unknown members on ISession (e.g. 'environ') and optional sendEOF/sendClose issues."
            },
            {
                "file": "src/cowrie/ssh/userauth.py",
                "line_number": null,
                "reason": "Pyright reported type assignment and optional sendPacket errors (type mismatches and 'sendPacket' unknown on None)."
            },
            {
                "file": "src/cowrie/ssh_proxy/client_transport.py",
                "line_number": null,
                "reason": "Pyright reported many optional member and unknown-member errors (getPeer/getHost unknown on None, connectionLost/loseConnection optional access)."
            },
            {
                "file": "src/cowrie/ssh_proxy/server_transport.py",
                "line_number": null,
                "reason": "Pyright reported widespread interface/member and write-binding issues (getPeer/getHost unknown, write binding mismatches, loseConnection optional access)."
            },
            {
                "file": "src/cowrie/ssh_proxy/userauth.py",
                "line_number": null,
                "reason": "Pyright reported missing sendPacket and other unknown-member errors on objects that may be None."
            },
            {
                "file": "src/cowrie/telnet/factory.py",
                "line_number": null,
                "reason": "Pyright reported unknown plugin members and optional call errors (output_plugins unknown; object of type None cannot be called)."
            },
            {
                "file": "src/cowrie/telnet/session.py",
                "line_number": null,
                "reason": "Pyright reported many ITransport/IOptional member issues (options, willChain, write, loseConnection, transport optional access)."
            },
            {
                "file": "src/cowrie/telnet/transport.py",
                "line_number": null,
                "reason": "Pyright reported missing/unknown transport members (sessionno) and write binding/type mismatches."
            },
            {
                "file": "src/cowrie/telnet/userauth.py",
                "line_number": null,
                "reason": "Pyright reported numerous write binding and missing-member errors and optional-member access issues across the file."
            },
            {
                "file": "src/cowrie/telnet_proxy/client_transport.py",
                "line_number": null,
                "reason": "Pyright reported getPeer/getHost unknown on None, write binding mismatches, and other member-access errors."
            },
            {
                "file": "src/cowrie/telnet_proxy/server_transport.py",
                "line_number": null,
                "reason": "Pyright reported sessionno/getPeer/getHost unknown, write binding mismatches, and optional member access problems."
            },
            {
                "file": "src/cowrie/test/fake_transport.py",
                "line_number": null,
                "reason": "Pyright reported test helper type/assignment issues (literal assignment and ClassVar assignment errors)."
            },
            {
                "file": "src/cowrie/test/test_base_commands.py",
                "line_number": null,
                "reason": "Pyright reported optional member access and possibly-unbound variable errors in tests (e.g. 'file_contents' not a known member of None)."
            },
            {
                "file": "src/cowrie/test/test_proxy.py",
                "line_number": null,
                "reason": "Pyright reported type/interface incompatibilities in tests (HoneyPotRealm incompatible with IRealm and other registerChecker/listenTCP issues)."
            },
            {
                "file": "src/twisted/plugins/cowrie_plugin.py",
                "line_number": null,
                "reason": "Pyright reported incompatible observer type for addObserver and missing/unknown cowrie.core members (realm, checkers) in the plugin."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Linter errors (ruff)",
                "evidence": "Ruff found 6 errors and exited non-zero: \"Found 6 errors... src/cowrie/output/oraclecloud.py:3:26: F401 ... F811 ... F401 ... Q000 ... T201 ... T201\"; lint: exit 1."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypyc internal assertion / IR mapping error",
                "evidence": "mypyc crashed with an AssertionError: \"src/cowrie/shell/protocol.py:25: AssertionError: unexpected type <class 'mypy.types.DeletedType'>\"."
            },
            {
                "category": "Type Checking",
                "subcategory": "Pyright type errors / missing stubs",
                "evidence": "Pyright reported 385 errors and 50 warnings across the codebase, including many 'Import \"X\" could not be resolved' and optional-member/unbound-variable issues (e.g. 'Import \"libvirt\" could not be resolved', many reportOptionalMemberAccess and reportUnboundVariable errors)."
            },
            {
                "category": "Type Checking",
                "subcategory": "Pytype usage/config error",
                "evidence": "pytype failed with: \"pytype: error: Need an input.\" (usage error); exit 2."
            },
            {
                "category": "Type Checking",
                "subcategory": "Pyre taint configuration error",
                "evidence": "Pyre reported: \"ERROR Found 1 taint configuration error! ? No `.config` was found in the taint directories\"; pyre exited with code 9."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing third-party modules / unresolved imports",
                "evidence": "Multiple files flagged 'Import \"X\" could not be resolved' (examples: 'libvirt', 'elasticsearch', 'pymongo', 'pymisp', 'influxdb', 'wokkel', 'hpfeeds.twisted', 'botocore', 'slack', 'rethinkdb')."
            },
            {
                "category": "CI / Process Error",
                "subcategory": "Job failed due to non-zero exit from lint step",
                "evidence": "Final summary shows 'lint: FAIL code 1' and runner ended with 'Process completed with exit code 255.'"
            },
            {
                "category": "Test Result",
                "subcategory": "Unit tests passed",
                "evidence": "Unit tests run under py310 reported: 'Ran 117 tests... OK' and 'py310: OK'."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Test with tox",
                "command": "tox"
            },
            {
                "job": null,
                "step": "build (3.10)/5_Test with tox.txt -> lint",
                "command": "ruff /home/runner/work/cowrie/cowrie/src"
            }
        ]
    },
    {
        "sha_fail": "386bf6f0815368b78261be43bf90e203dfe9c13f",
        "error_context": [
            "The CI run failed while executing the step 'build/7_Run all examples.txt' (mapped to the workflow step 'Run all examples' in job 'build'). The Python invocation that runs all example scripts aborted due to a source-level string literal error: the log reports \"('Line terminator characters must be escaped inside string literals', 'U+000A')\", meaning a raw line terminator (newline) appeared inside a string literal and was not escaped. This caused the Python interpreter to fail while running one of the example .py files enumerated by the step's shell loop (examples/node_prediction/*.py, examples/graph_prediction/*.py, or examples/other/*.py), so the step stopped early with a syntax/parse error."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Syntax Error",
                "subcategory": "Unescaped line terminator in string literal",
                "evidence": "('Line terminator characters must be escaped inside string literals', 'U+000A') \u2014 indicates an unescaped newline inside a string literal caused the interpreter to fail while running example scripts."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "build/7_Run all examples.txt",
                "command": "cd examples/node_prediction/\nfor f in *.py; do\n  echo \"##### $f #####\"\n  python $f\ndone\ncd ..\ncd graph_prediction/\nfor f in *.py; do\n  echo \"##### $f #####\"\n  python $f\ndone\ncd ..\ncd other/\nfor f in *.py; do\n  echo \"##### $f #####\"\n  python $f\ndone\ncd .."
            }
        ]
    },
    {
        "sha_fail": "f46396889b66799df97d97d6bf05335bb02989e5",
        "error_context": [
            "The CI job failed during the 'Run tests' step because pytest encountered a repeated runtime exception when many tests attempted to construct an InputOutput object. The immediate cause (shown in many tracebacks) is InputOutput.__init__ calling Path(self.input_history_file).parent.mkdir(...) while self.input_history_file is None, which results in Python's pathlib raising TypeError: \"expected str, bytes or os.PathLike object, not NoneType\" (trace: aider/io.py:311 -> lib/python3.10/pathlib.py:_parse_args -> os.fspath(None)).",
            "Earlier workflow steps (checkout, setup-python, apt-get install, pip install .) completed successfully and installed dependencies; the failure is not an install or dependency error but a runtime error occurring when tests run. Evidence: log shows successful checkout, Python setup, apt-get and pip install output, then pytest collected 486 items and produced many ERRORS/FAILURES all with the same TypeError originating at aider/io.py:311.",
            "Because InputOutput initialization is exercised widely in tests (directly and indirectly via GitRepo, Coder.create, RepoMap, etc.), the single runtime error in aider/io.py cascaded to hundreds of failing tests across many test modules (examples: tests/basic/test_coder.py, tests/basic/test_commands.py, tests/basic/test_io.py, tests/basic/test_repo.py, tests/basic/test_repomap.py, tests/help/test_help.py, tests/scrape/test_scrape.py). The root-code fix is to avoid passing None to pathlib.Path (guard or provide a default for input_history_file) or change tests to supply a valid path."
        ],
        "relevant_files": [
            {
                "file": "aider/io.py",
                "line_number": 311,
                "reason": "Direct failure site: InputOutput.__init__ executes Path(self.input_history_file).parent.mkdir(...). Logs show repeated tracebacks pointing to 'aider/io.py:311' as the call that passes None into pathlib.Path and triggers the TypeError."
            },
            {
                "file": "lib/python3.10/pathlib.py",
                "line_number": 578,
                "reason": "Standard-library failure point: pathlib._parse_args calls os.fspath(a) on the Path constructor argument; logs show 'TypeError: expected str, bytes or os.PathLike object, not NoneType' at pathlib.py:578 when Path(None) is attempted."
            },
            {
                "file": "tests/help/test_help.py",
                "line_number": 52,
                "reason": "Test setup that triggers the error: TestHelp.setUpClass calls InputOutput(pretty=False, yes=True) and errors during InputOutput construction (traceback shows tests/help/test_help.py:52 -> aider/io.py:311 -> pathlib TypeError)."
            },
            {
                "file": "tests/basic/test_coder.py",
                "line_number": null,
                "reason": "Many failing tests in this module instantiate InputOutput(...) and fail at aider/io.py:311; the log contains dozens of failing test cases from this file showing the same TypeError pattern."
            },
            {
                "file": "tests/basic/test_commands.py",
                "line_number": null,
                "reason": "Numerous tests in this module call InputOutput(...) in their setup/test bodies and fail with the same Path(None) TypeError (tracebacks in the log reference this test file frequently)."
            },
            {
                "file": "tests/basic/test_io.py",
                "line_number": null,
                "reason": "This module directly tests InputOutput behavior; multiple tests (color initialization, confirm_ask, multiline mode, format files) attempt InputOutput(...) and hit the same aider/io.py:311 -> pathlib TypeError."
            },
            {
                "file": "tests/basic/test_repo.py",
                "line_number": null,
                "reason": "Repository-related tests create GitRepo(InputOutput(), ...) or call InputOutput() and repeatedly fail at InputOutput.__init__, per the log traces referencing this file."
            },
            {
                "file": "tests/basic/test_repomap.py",
                "line_number": null,
                "reason": "Many RepoMap tests call InputOutput() (or pass it into RepoMap) and fail during InputOutput initialization; the log shows repeated failures originating from tests in this file."
            },
            {
                "file": "tests/basic/test_editblock.py",
                "line_number": null,
                "reason": "Tests in this file create Coder objects with io=InputOutput(...) and fail at aider/io.py:311 when InputOutput() is constructed."
            },
            {
                "file": "tests/basic/test_wholefile.py",
                "line_number": null,
                "reason": "Whole-file coder tests instantiate InputOutput(...) and fail repeatedly at the same call site; the log contains many failing entries from this module tied to the same TypeError."
            },
            {
                "file": "tests/scrape/test_scrape.py",
                "line_number": 38,
                "reason": "SetUp in these tests does self.io = InputOutput(yes=True) and the log shows the same traceback from that line to aider/io.py:311 and pathlib TypeError."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "TypeError from pathlib.Path when passed None",
                "evidence": "Log: \"TypeError: expected str, bytes or os.PathLike object, not NoneType\" originating from lib/python3.10/pathlib.py when Path(self.input_history_file) is called (aider/io.py:311)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Pytest errors/failures due to exception in test setup",
                "evidence": "Pytest collected 486 items and reported many ERRORS/FAILURES; multiple tests error in setUp or at the start of the test when constructing InputOutput (examples: tests/help/test_help.py:52, tests/basic/test_coder.py tests call sites shown in logs)."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "1ba9d437f8843d49e509353d51871b4c14f0f509",
        "error_context": [
            "The CI job 'Test and lint' on windows-latest with Python 3.12 completed setup and dependency installation successfully, but failed while running the test suite. In the 'Run PyTest' step (pytest) a single test failed: tests/test_per_worker_seed.py::test_dataloader_epoch_diversity. The failure occurs when constructing a torch DataLoader with num_workers>0 (worker processes are spawned). Python's multiprocessing spawn path attempts to pickle the Process object and fails with an AttributeError raised by multiprocessing.reduction.ForkingPickler: \"Can't get local object 'test_dataloader_epoch_diversity.<locals>.SimpleDataset'\". The root cause is that the test defines SimpleDataset as a local (nested) class inside the test function, which is not picklable by the spawn-based multiprocessing implementation on Windows; this causes worker start to fail and the child spawn process to subsequently raise EOFError: \"Ran out of input\" while trying to unpickle parent data. Many tests emitted UserWarning messages about invalid transform arguments (from tests/test_transforms.py and tests/transforms3d/test_transforms.py), but these were warnings and did not cause the job failure. The single failing test and the multiprocessing pickling error caused pytest to exit nonzero and the job to fail."
        ],
        "relevant_files": [
            {
                "file": "tests/test_per_worker_seed.py",
                "line_number": 166,
                "reason": "Location of the failing test and the locally defined dataset class (SimpleDataset) that cannot be pickled by multiprocessing; failure traceback points to the for-loop iterating the DataLoader at this file and line."
            },
            {
                "file": "Lib/site-packages/torch/utils/data/dataloader.py",
                "line_number": 1146,
                "reason": "Dataloader initiates multiprocessing workers; stack frames show __iter__ -> _get_iterator -> _MultiProcessingDataLoaderIter.__init__ -> w.start(), which triggers the multiprocessing pickling that fails."
            },
            {
                "file": "Lib/multiprocessing/reduction.py",
                "line_number": 60,
                "reason": "ForkingPickler.dump raised AttributeError: \"Can't get local object 'test_dataloader_epoch_diversity.<locals>.SimpleDataset'\" while trying to serialize the Process object for spawn \u2014 the immediate cause of failure."
            },
            {
                "file": "Lib/multiprocessing/popen_spawn_win32.py",
                "line_number": 95,
                "reason": "Platform-specific Popen calls reduction.dump(process_obj, to_child); this is where the pickling call is invoked on Windows and triggers the AttributeError."
            },
            {
                "file": "Lib/multiprocessing/spawn.py",
                "line_number": 132,
                "reason": "Child spawn process attempted to unpickle data from the parent and failed with EOFError: \"Ran out of input\" after the parent's pickling failed, as shown in the captured stderr."
            },
            {
                "file": "tests/test_transforms.py",
                "line_number": null,
                "reason": "Many UserWarning messages originate here (invalid transform arguments in many parametrized tests). Warnings are numerous but did not cause the job to fail."
            },
            {
                "file": "tests/transforms3d/test_transforms.py",
                "line_number": null,
                "reason": "Numerous UserWarning messages for 3D transforms (invalid argument names) were emitted during testing; these are warnings present in the log but not the cause of the failure."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "Multiprocessing pickling error (AttributeError)",
                "evidence": "E AttributeError: Can't get local object 'test_dataloader_epoch_diversity.<locals>.SimpleDataset' (multiprocessing.reduction.ForkingPickler.dump) - shown in failure traceback originating from Lib/multiprocessing/reduction.py:60"
            },
            {
                "category": "Runtime Error",
                "subcategory": "EOFError during multiprocessing spawn",
                "evidence": "Captured stderr teardown shows multiprocessing.spawn child error: \"EOFError: Ran out of input\" while executing spawn_main/_main after parent pickling failed (Lib/multiprocessing/spawn.py:132)."
            },
            {
                "category": "Test Warnings",
                "subcategory": "UserWarning: invalid transform arguments",
                "evidence": "Many lines like \"UserWarning: Argument(s) 'mask_interpolation' are not valid for transform RandomCrop\" originating from tests/test_transforms.py and tests/transforms3d/test_transforms.py \u2014 logged as warnings (1132 warnings total) in the pytest summary."
            }
        ],
        "failed_job": [
            {
                "job": "test_and_lint (Test and lint)",
                "step": "Run PyTest",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "86c980e4482dc3853ab635d1cf2c814ff6287899",
        "error_context": [
            "Two separate jobs failed in this run. In job 'tests' (step 'Run tests for Agno') pytest collection failed with an ImportError: project code agno.tools.zep attempted \"from zep_cloud.types import MemorySearchResult\" but the installed package at .venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py does not expose that name, causing pytest to abort during collection (log: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\" and the module then raised: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud\"). This indicates a missing or incompatible dependency/version (zep-cloud) or an unexpected API change. Warnings from pydub (SyntaxWarning/DeprecationWarning/RuntimeWarning) were emitted but did not cause the job to fail.",
            "In job 'style-check' (step 'Ruff check') the linter failed: ruff reported multiple \"invalid-syntax\" errors because the code uses newer Python syntax (walrus operator ':=' and parentheses in a with-statement) while ruff is checking against Python 3.7 rules (log: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\"). Ruff also reported F821 undefined-name errors for missing imports (e.g. Dict, Any). The style-check step exited non\u2011zero with \"Found 38 errors.\""
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Pytest collection failed importing this test module (traceback: \"ERROR collecting tests/unit/tools/test_zep.py\" and import at line 5: \"from agno.tools.zep import ZepAsyncTools, ZepTools\")."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This module attempted \"from zep_cloud.types import MemorySearchResult\" and then raised an ImportError instructing to install zep-cloud (traceback shows failure at lines 12 and 15)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "The ImportError cites this installed package file as the source of the missing symbol: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (/.../.venv/lib/.../zep_cloud/types/__init__.py)\" \u2014 indicating the installed zep_cloud package does not expose the expected API."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Multiple pytest warnings reference this file (SyntaxWarning, DeprecationWarning, RuntimeWarning) during test run, e.g. \"SyntaxWarning: invalid escape sequence\" and \"DeprecationWarning: 'audioop' is deprecated\" and ffmpeg warning at line 170."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff reported invalid-syntax here for use of the walrus operator and parentheses-in-with: log shows \"invalid-syntax ... Cannot use named assignment expression (`:=`)\" and \"Cannot use parentheses within a `with` statement\" pointing to lines 66-74."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged use of the walrus operator here: \"invalid-syntax: Cannot use named assignment expression (`:=`) ... --> agno/knowledge/website.py:90:16\"."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5028,
                "reason": "Many invalid-syntax occurrences reported for this file using ':=' across multiple locations (first listed at line 5028 in the log)."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported several invalid-syntax occurrences using ':=' in this file (first shown at agno/tools/apify.py:281)."
            },
            {
                "file": "agno/tools/firecrawl.py",
                "line_number": 95,
                "reason": "Ruff reported F821 undefined-name errors here: \"F821 Undefined name `Dict`\" and \"F821 Undefined name `Any`\" at line 95: \"params: Dict[str, Any] = {}\"."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff reported invalid-syntax for use of the walrus operator here (log: \"--> agno/tools/function.py:119:16 ... if docstring := getdoc(c):\")."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: cannot import name X / missing or incompatible package",
                "evidence": "\"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (/.../.venv/lib/.../zep_cloud/types/__init__.py)\" and module then raised: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"."
            },
            {
                "category": "Code Formatting / Static Analysis",
                "subcategory": "Invalid-syntax due to target Python version (walrus operator / parentheses-in-with)",
                "evidence": "Ruff messages: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" pointing to multiple files (e.g. agno/api/playground.py:66, agno/tools/apify.py:281)."
            },
            {
                "category": "Lint Error",
                "subcategory": "Undefined name (F821)",
                "evidence": "Ruff reported \"F821 Undefined name `Dict`\" and \"F821 Undefined name `Any`\" in agno/tools/firecrawl.py:95 (\"params: Dict[str, Any] = {}\")."
            },
            {
                "category": "Warnings",
                "subcategory": "Deprecation / Syntax / Runtime warnings from third-party package",
                "evidence": "Pytest warnings: \".venv/lib/.../pydub/utils.py:300: SyntaxWarning: invalid escape sequence...\", \":14: DeprecationWarning: 'audioop' is deprecated...\", \":170: RuntimeWarning: Couldn't find ffmpeg or avconv...\"."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "96aae9a5b1a9f5b50b553e5e6e8084d330bf8bec",
        "error_context": [
            "The CI run failed for two distinct reasons in two jobs. In the style-check job (style-check, Python 3.9) the ruff linter reported 38 errors and exited non-zero: many files use Python 3.8+ language constructs (named assignment operator ':=' and parentheses in with-statements) that ruff flagged as Python-3.7-incompatible (e.g. \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" for files such as agno/api/playground.py, agno/team/team.py, agno/tools/apify.py, agno/tools/function.py, agno/knowledge/website.py). Ruff also reported unused-import errors (F401) in agno/models/meta/llama.py and agno/models/perplexity/perplexity.py. Because the workflow runs the step \"ruff check .\" (which returned exit code 1), the style-check job failed. \n\nSeparately, in the tests job (tests, Python 3.12) pytest aborted collection with an ImportError: the test module libs/agno/tests/unit/tools/test_zep.py imports agno.tools.zep, which attempted \"from zep_cloud.types import MemorySearchResult\" but failed (ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'), and agno.tools.zep raises a user-facing ImportError instructing to install 'zep-cloud'. This caused pytest to stop collection (1 error) and the tests job to exit non-zero. Warnings from pydub were printed but non-fatal. Overall the run contained a linter failure (style-check) and a test-collection failure due to a missing or incompatible zep_cloud API/installation (tests)."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged Python-version-incompatible syntax: named assignment expression at line 66 and parentheses in a with-statement at line 72 (messages: \"Cannot use named assignment expression (`:=`) on Python 3.7\"; \"Cannot use parentheses within a `with` statement on Python 3.7\")."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff reported a named-assignment expression at line 90 (\"if document_list := self.reader.read(url=url):\") which it marks as Python-3.7-incompatible."
            },
            {
                "file": "agno/models/meta/llama.py",
                "line_number": 7,
                "reason": "Ruff emitted an unused-import error F401: \"`pydantic.BaseModel` imported but unused\" at line 7 and suggested removing the import."
            },
            {
                "file": "agno/models/perplexity/perplexity.py",
                "line_number": 5,
                "reason": "Ruff emitted an unused-import error F401: \"`pydantic.BaseModel` imported but unused\" at line 5 and suggested removing the import."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5067,
                "reason": "Ruff reported many occurrences of the named-assignment operator (':=') across this file (first reported at line 5067: \"if context_images := self.memory.get_team_context_images():\"), marking them as Python-3.7-incompatible."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged multiple named-assignment usages (earliest reported at line 281: \"if http_client := getattr(...):\" and several other `:=` occurrences) as Python-3.7-incompatible."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff reported named-assignment usage at line 119 (\"if docstring := getdoc(c):\") as Python-3.7-incompatible."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Test collection traceback shows this module attempted \"from zep_cloud.types import MemorySearchResult\" (line 12) which raised ImportError; the module then re-raises an ImportError instructing to install 'zep-cloud', causing pytest collection to fail."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Pytest could not import this test module because it imports agno.tools.zep (the import at line 5 triggers the ImportError originating from zep.py)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "The ImportError message points to this installed package file as the source of the failed name import: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\", indicating either the package is missing that symbol or an incompatible version is installed."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Syntax Compatibility (Python version incompatibility)",
                "evidence": "\"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" reported by ruff across multiple files (e.g. agno/api/playground.py, agno/team/team.py)."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Unused Import",
                "evidence": "Ruff F401 messages: \"`pydantic.BaseModel` imported but unused\" in agno/models/meta/llama.py and agno/models/perplexity/perplexity.py."
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError: Missing or incompatible dependency (zep-cloud)",
                "evidence": "Pytest collection error: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" and agno.tools.zep raised: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"."
            },
            {
                "category": "Runtime Warning",
                "subcategory": "Deprecation / Syntax warnings from third-party libs",
                "evidence": "Pytest warnings: SyntaxWarning and DeprecationWarning from pydub utils (invalid escape sequences and 'audioop' deprecated) were printed during the tests job (non-fatal)."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "28e82b172246b8b3ff5f03211f19391133cd058a",
        "error_context": [
            "Two independent CI failures occurred in this run. In job 'style-check' (Python 3.9) the step 'Ruff check' exited non\u2011zero because ruff reported multiple \"invalid-syntax\" diagnostics treating newer Python syntax as incompatible with Python 3.7 (e.g. uses of the walrus operator ':=' and parentheses in a with-statement). Evidence: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7...\" across many files and final summary \"Found 24 errors.\" This caused the style-check job to fail (exit code 1).",
            "Separately, in job 'tests' (Python 3.12) the step 'Run tests for Agno' failed during pytest collection because an import in libs/agno/agno/tools/firecrawl.py could not find the expected symbol in the installed dependency 'firecrawl'. Evidence: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\" and the module then raising: \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", producing \"collected 1198 items / 1 error\" and aborting collection (exit code 2).",
            "Additional non-blocking warnings from installed packages were emitted during the tests job (pydub SyntaxWarnings and Deprecation/Runtime warnings; Pydantic deprecation warnings in crawl4ai), but the blocking failure was the ImportError during test collection. The two failures are independent: linting (ruff) failed due to configured/target Python compatibility settings, and tests failed due to a dependency/API mismatch in the installed 'firecrawl' package."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged a walrus operator here: \"if token := read_auth_token():\" with message \"Cannot use named assignment expression (`:=`) on Python 3.7\"."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged a walrus operator here: \"if document_list := self.reader.read(url=url):\" with compatibility error for Python 3.7."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5412,
                "reason": "Multiple ruff diagnostics flagged named-assignment expressions (walrus operator) across this file (e.g. \"if context_images := self.memory.get_team_context_images():\"), counted among the \"Found 24 errors.\""
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 284,
                "reason": "Ruff flagged walrus operator usage here: \"if http_client := getattr(client.http_client, 'httpx_client', None):\" as invalid under Python 3.7 compatibility rules."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged a named-assignment expression here: \"if docstring := getdoc(c):\" as incompatible with Python 3.7."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest collection failed on this test module with an ImportError while importing it, causing the test job to abort: \"ERROR collecting tests/unit/tools/test_firecrawl.py\"."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "This module attempted \"from firecrawl import FirecrawlApp, ScrapeOptions\" and then raised an ImportError when ScrapeOptions was not present in the installed package, triggering test collection failure."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Installed package does not provide the expected symbol: log shows \"cannot import name 'ScrapeOptions'... Did you mean: 'V1ScrapeOptions'?\", indicating an API mismatch between installed 'firecrawl' and project code."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Multiple SyntaxWarning/Deprecation/RuntimeWarning messages were emitted from this dependency during test collection (invalid escape sequences, deprecated 'audioop', missing ffmpeg), visible in pytest warnings summary."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/crawl4ai/models.py",
                "line_number": 129,
                "reason": "Pydantic deprecation warnings were emitted here (class-based `config` deprecated), appearing in pytest warnings summary."
            }
        ],
        "error_types": [
            {
                "category": "Linting",
                "subcategory": "Invalid-syntax due to Python version compatibility (ruff)",
                "evidence": "\"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" across multiple files; final ruff summary: \"Found 24 errors.\""
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError / Upstream API mismatch",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\" and the project raising \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"."
            },
            {
                "category": "Test Failure",
                "subcategory": "Pytest collection error (import-time failure)",
                "evidence": "\"collected 1198 items / 1 error\" and \"ERROR libs/agno/tests/unit/tools/test_firecrawl.py\" with traceback showing import-time ImportError in libs/agno/agno/tools/firecrawl.py."
            },
            {
                "category": "Runtime/Dependency Warnings",
                "subcategory": "SyntaxWarning / Deprecation / Runtime warnings in third-party packages",
                "evidence": "Pytest warnings: pydub SyntaxWarning invalid escape sequences, DeprecationWarning: 'audioop' deprecated, RuntimeWarning: Couldn't find ffmpeg; PydanticDeprecatedSince20 warnings in crawl4ai/models.py."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "4a801c301c146b1a6e643ae0819baf2a1e045de1",
        "error_context": [
            "Two CI jobs failed in this run. In job 'tests (3.12)', the \"Run tests for Agno\" step executed pytest but test collection failed with ImportError(s): libs/agno/agno/tools/firecrawl.py could not import ScrapeOptions from the installed firecrawl package (pytest shows: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\"), and libs/agno/agno/tools/zep.py could not import MemorySearchResult from zep_cloud.types (\"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"). Both modules then raised ImportError advising to install specific packages, indicating either missing packages or incompatible package versions/interfaces in the created virtual environment. The dev_setup step did install many dependencies, but the installed package APIs do not match the code's expectations, causing pytest to abort during collection with exit code 2. \n\nSeparately, in job 'style-check (3.9)' the \"Ruff check\" step failed: ruff reported 36 \"invalid-syntax\" errors (e.g., use of the named assignment expression := and parenthesized with-statements). The ruff messages state these constructs are not allowed for Python 3.7 (\"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7 (syntax was added in Python 3.9)\"), indicating the linter was checking for compatibility with an older Python target (py37) while the code uses Python 3.8+/3.9+ syntax. This caused ruff to exit non-zero (Found 36 errors) and the job to fail with exit code 1. \n\nAdditional non-fatal environment warnings were emitted during test collection from pydub (SyntaxWarning invalid escape sequences, DeprecationWarning about audioop, and a RuntimeWarning: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg\"), and pip emitted a warning about pymongo extras; these did not directly cause the failures but are environment issues worth reviewing."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Import attempted: \"from firecrawl import FirecrawlApp, ScrapeOptions\" and traceback shows ImportError at this file (libs/agno/agno/tools/firecrawl.py:9) which then raises \"`firecrawl-py` not installed...\" \u2014 directly triggered pytest collection failure."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest reported \"ERROR collecting tests/unit/tools/test_firecrawl.py\" because importing this test caused the ImportError originating in agno/tools/firecrawl.py."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Pytest ImportError references this installed package file: \"cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" \u2014 indicates installed firecrawl package API differs from code expectations."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Import attempted: \"from zep_cloud.types import MemorySearchResult\" and traceback shows ImportError at this file (libs/agno/agno/tools/zep.py:12) which then raises \"`zep-cloud` package not found...\" \u2014 directly triggered pytest collection failure."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest reported \"ERROR collecting tests/unit/tools/test_zep.py\" because importing this test caused the ImportError originating in agno/tools/zep.py."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Pytest ImportError references this installed package file: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...site-packages/zep_cloud/types/__init__.py)\" \u2014 indicates installed zep_cloud package API differs from code expectations."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Warnings emitted during test collection reference this file: multiple SyntaxWarning invalid escape sequences (lines 300,301,310,314), DeprecationWarning for audioop (line 14) and RuntimeWarning about missing ffmpeg/avconv (line 170). These are environment warnings observed during collection."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged invalid-syntax here: use of named assignment expression (\"if token := read_auth_token():\") and a parenthesized with-statement \u2014 one of the errors that caused the style-check job to fail."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged invalid-syntax at \"if document_list := self.reader.read(url=url):\" (walrus operator) \u2014 included in the linter's errors."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5132,
                "reason": "Repeated ruff invalid-syntax errors across this file for named assignment expressions (multiple occurrences like \"if context_images := ...\") \u2014 contributed many of the 36 ruff errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged named assignment usage (e.g., \"if http_client := getattr(...)\") at several lines in this file \u2014 part of the compatibility errors reported by ruff."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged named assignment usage (\"if docstring := getdoc(c):\") causing invalid-syntax under the targeted Python version in the linter configuration."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: Missing or incompatible third-party package",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py)\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...site-packages/zep_cloud/types/__init__.py)\"; modules then raised messages advising to install 'firecrawl-py' and 'zep-cloud'."
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError during pytest collection",
                "evidence": "Pytest output: \"collected 1089 items / 2 errors\" and \"Interrupted: 2 errors during collection\" showing ImportErrors for libs/agno/tests/unit/tools/test_firecrawl.py and test_zep.py causing collection to abort (exit code 2)."
            },
            {
                "category": "Static Analysis / Linting",
                "subcategory": "Invalid-syntax detected by ruff due to Python version compatibility (named assignment / parenthesized with)",
                "evidence": "Ruff reported multiple errors: \"Cannot use named assignment expression (`:=`) on Python 3.7 (syntax was added in Python 3.8)\" and \"Cannot use parentheses within a `with` statement on Python 3.7 (syntax was added in Python 3.9)\"; final line: \"Found 36 errors.\""
            },
            {
                "category": "Environment Warning",
                "subcategory": "Missing runtime binary / Deprecation / Syntax warnings from dependencies",
                "evidence": "Warnings from pydub: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg\" (RuntimeWarning), SyntaxWarning invalid escape sequences, and DeprecationWarning: 'audioop' is deprecated and slated for removal in Python 3.13."
            },
            {
                "category": "Dependency Warning",
                "subcategory": "pip package extras/metadata warning",
                "evidence": "Pip emitted: \"warning: The package `pymongo==4.15.5` does not have an extra named `srv`\" during installation in dev_setup."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            },
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "71293243e535a75399f632e0ea5f57398e991e30",
        "error_context": [
            "The CI run failed for two independent reasons in different jobs. In the tests job (tests / python 3.12) collection failed: pytest raised an ImportError while importing libs/agno/tests/unit/tools/test_zep.py because libs/agno/agno/tools/zep.py attempted \"from zep_cloud.types import MemorySearchResult\" and the installed zep_cloud package in the virtualenv does not export that name (log: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\"), and the module then raised an explicit ImportError suggesting to install zep-cloud. This blocked test collection and caused pytest to exit with code 2. Separately, in the style-check job (style-check / python 3.9) the Ruff check step failed: ruff reported syntax-compatibility errors for code that uses newer Python syntax (named assignment / walrus operator and parenthesized multiple with-contexts) while the style job is running under Python 3.9 but ruff targeted compatibility with Python 3.7, producing many \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" messages (evidence: multiple ruff errors across agno/api/playground.py, agno/team/team.py, etc.). Additionally, the tests run emitted non-fatal warnings from pydub about invalid escape sequences, deprecated 'audioop', and missing ffmpeg/avconv, but these were warnings and did not cause the failing exit codes."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest failed while importing this test module (collection error). The traceback shows the import of agno.tools.zep triggered the ImportError that stopped test collection."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Contains the failing import \"from zep_cloud.types import MemorySearchResult\" (traceback shows this line) and raises the explicit ImportError when the import fails."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Log shows the ImportError originates from this installed package: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\", indicating the installed zep_cloud lacks the expected symbol/API."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Pytest warnings reference this file multiple times (SyntaxWarning invalid escape sequences, DeprecationWarning for 'audioop', RuntimeWarning about missing ffmpeg/avconv). These are non-fatal warnings emitted during test collection/run."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff reported invalid-syntax here (walrus operator and grouped with-contexts) e.g. \"if token := read_auth_token():\" and a parenthesized with statement; these syntax usages were flagged as incompatible with target Python 3.7."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff reported a named-assignment (walrus) usage here: \"if document_list := self.reader.read(url=url):\", which contributed to the style-check failure."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5068,
                "reason": "Multiple ruff errors reference this file at many locations for walrus operator usage (e.g. \"if context_images := self.memory.get_team_context_images()\"), making it a primary source of the 30 syntax errors."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged named-assignment usage here (\"if docstring := getdoc(c):\") and again later, contributing to the style-check failure."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "ImportError during test collection",
                "evidence": "Pytest collection aborted: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\" and module raised: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`.\""
            },
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible/changed API in installed dependency",
                "evidence": "Installed zep_cloud package does not expose the expected name: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" (indicates dependency API mismatch or missing version)."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Syntax compatibility / Use of newer Python syntax (walrus, parenthesized with) vs. target",
                "evidence": "Ruff reported \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" across multiple files (e.g. agno/api/playground.py, agno/team/team.py)."
            },
            {
                "category": "Runtime Warning",
                "subcategory": "Missing external tool & deprecated stdlib usage",
                "evidence": "Warnings from pydub: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\" and \"'audioop' is deprecated and slated for removal in Python 3.13\" (logged during test run)."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\necho \"AGNO_COVERAGE=$(python -c 'import json; print(json.load(open(\"coverage-agno.json\"))[\"totals\"][\"percent_covered_display\"])')\" >> $GITHUB_ENV"
            },
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "e70b6e2bec5437f0ddd45583fb259b337b8c7797",
        "error_context": [
            "Two jobs in the workflow failed for different reasons. In the 'tests' job (tests (3.12) -> step 'Run tests for Agno'), pytest test collection aborted with an ImportError: the project module libs/agno/agno/tools/firecrawl.py attempted to import FirecrawlApp and ScrapeOptions from the installed 'firecrawl' package, but the installed package does not export ScrapeOptions (log: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\") and the module then raises an ImportError with the message \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", causing pytest to report an error for libs/agno/tests/unit/tools/test_firecrawl.py and terminate collection. Separately, in the 'style-check' job (style-check (3.9) -> step 'Mypy'), mypy failed type checking: agno/agent/agent.py produced a type error reported as \"Value of type \"Coroutine[Any, Any, None]\" must be used  [unused-coroutine]\" with the note \"Are you missing an await?\" at line 6551, causing the style-check job to exit with code 1. Several non-fatal warnings (pydub syntax/deprecation, missing ffmpeg, Pydantic deprecation from crawl4ai) were also emitted during test setup but did not cause the run to fail."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 11,
                "reason": "Project module that attempted to import FirecrawlApp and ScrapeOptions and then raised an ImportError instructing to install firecrawl-py; traceback shows import at line 9 and the explicit raise at line 11: \"raise ImportError(\"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\")\"."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Test module that failed to import due to the ImportError from agno.tools.firecrawl; pytest reports: \"ERROR collecting tests/unit/tools/test_firecrawl.py\" and shows the import at this file's line 10."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Installed third-party package that did not expose the expected symbol \u2014 log evidence: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (.../site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" indicating an incompatible or different package API/version."
            },
            {
                "file": "agno/agent/agent.py",
                "line_number": 6551,
                "reason": "File that triggered mypy failure: \"agno/agent/agent.py:6551: error: Value of type \\\"Coroutine[Any, Any, None]\\\" must be used  [unused-coroutine]\" with the note \"Are you missing an await?\", which caused the style-check job to fail."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Source of multiple runtime/warning messages captured during test setup (SyntaxWarning invalid escape sequences, DeprecationWarning for 'audioop', and RuntimeWarning about missing ffmpeg); these warnings were printed during test collection but did not directly cause failure."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/crawl4ai/models.py",
                "line_number": 129,
                "reason": "Raised Pydantic deprecation warnings during setup: \"Support for class-based `config` is deprecated, use ConfigDict instead.\" (also reported at line 310); shown in pytest warnings summary."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "ImportError: incompatible/missing dependency symbol",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (.../site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" and the project fallback: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" causing pytest collection to error for libs/agno/tests/unit/tools/test_firecrawl.py."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy unused-coroutine (missing await)",
                "evidence": "\"agno/agent/agent.py:6551: error: Value of type \\\"Coroutine[Any, Any, None]\\\" must be used  [unused-coroutine]\" and \"note: Are you missing an await?\" \u2014 mypy returned 1 error and exited non-zero."
            },
            {
                "category": "Dependency / Compatibility Warning",
                "subcategory": "Third-party package deprecations and runtime warnings",
                "evidence": "Pytest warnings: SyntaxWarning and DeprecationWarning from pydub (invalid escape sequences, 'audioop' deprecated), RuntimeWarning about missing ffmpeg, and PydanticDeprecatedSince20 warnings from crawl4ai/models.py (\"Support for class-based `config` is deprecated\")."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            },
            {
                "job": "style-check",
                "step": "Mypy",
                "command": "mypy ."
            }
        ]
    },
    {
        "sha_fail": "cd8c651cb11b85f465cd1432d9695eff5ec2b8d3",
        "error_context": [
            "The CI run failed in the tests job during test collection. The workflow executed dev setup successfully (./scripts/dev_setup.sh installed many packages and created the virtualenv), but the 'Run tests for Agno' step (pytest) aborted during collection with an ImportError. Pytest reported \"collected 1470 items / 1 error\" and failed while importing libs/agno/tests/unit/tools/test_firecrawl.py. The traceback shows agno/agno/tools/firecrawl.py attempted \"from firecrawl import FirecrawlApp, ScrapeOptions\" and the installed site-packages firecrawl does not expose ScrapeOptions (error: \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\"). The project module then raises an explicit ImportError: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", which stops pytest collection and causes the job to exit with code 2. In short: a dependency/API mismatch (installed firecrawl package lacks the expected ScrapeOptions symbol / correct package) caused ImportError during test collection in the tests job."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Pytest failed while importing this test module: \"ERROR collecting ... test_firecrawl.py\" and the traceback shows the test imports agno.tools.firecrawl which triggered the ImportError (log: \"libs/agno/tests/unit/tools/test_firecrawl.py:10: in <module>     from agno.tools.firecrawl import FirecrawlTools\")."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "This module attempts the failing import: \"from firecrawl import FirecrawlApp, ScrapeOptions\" and then raises the explicit ImportError: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" (log lines show failure at line 9 and raise at line 11)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Installed firecrawl package does not provide the expected symbol: pytest traceback shows \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (.../site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\", implicating this installed package as incompatible with the project's expectations."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/importlib/__init__.py",
                "line_number": 90,
                "reason": "Standard import machinery appears in the traceback while handling the failing import: importlib invoked during import resolution (log: importlib line 90 in the stack trace)."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible package API / wrong package version",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" and the project's fallback message: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"."
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError during test collection",
                "evidence": "Pytest output: \"collected 1470 items / 1 error\" and \"ERROR collecting tests/unit/tools/test_firecrawl.py\" with traceback showing the ImportError raised during collection."
            },
            {
                "category": "Warnings",
                "subcategory": "Deprecation / Syntax / Runtime warnings during test runtime",
                "evidence": "Warnings printed by pytest: SyntaxWarning invalid escape sequences in pydub/utils.py; DeprecationWarning for 'audioop' and websockets.legacy; RuntimeWarning about missing ffmpeg; PydanticDeprecatedSince20 warnings in crawl4ai/models.py (see warnings summary in logs)."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "tests (3.12)",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "2b4a06142018cef143149ec1540002ad651f365d",
        "error_context": [
            "Two independent failures caused the CI run to fail. In job 'tests (3.12)' the test collection aborted with an ImportError: the project's module libs/agno/agno/tools/firecrawl.py attempts \"from firecrawl import FirecrawlApp, ScrapeOptions\" but the installed firecrawl package in the venv does not expose ScrapeOptions (log: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (.../.venv/lib/python3.12/site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\"). The project's module then raises an explicit fallback ImportError advising to install firecrawl-py (log: \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py`\") which caused pytest to report \"1 error\" during collection and exit with code 2. Separately, in job 'style-check (3.9)' the mypy static type check failed: mypy reported 22 type errors all in agno/knowledge/document.py (example: \"Item 'dict[str, Any]' of 'Union[Document, dict[str, Any]]' has no attribute 'name'\"), and mypy exited with code 1 causing that job to fail. Both failures are evidenced in the logs and are independent (one is a runtime/import error encountered during pytest collection, the other is a static type-check failure)."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Traceback shows this file performed the failing import: \"from firecrawl import FirecrawlApp, ScrapeOptions\" (libs/agno/agno/tools/firecrawl.py:9) and later raises the fallback ImportError instructing to install firecrawl-py (libs/agno/agno/tools/firecrawl.py:11)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "The ImportError message references this installed package file as the source of the failed import and indicates the package exposes 'V1ScrapeOptions' instead of the expected 'ScrapeOptions', i.e. incompatible API in the installed dependency."
            },
            {
                "file": "libs/agno/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Pytest reported an ImportError while importing this test module (log: \"ImportError while importing test module '/.../libs/agno/tests/unit/tools/test_firecrawl.py'\"), and the test imports agno.tools.firecrawl which triggers the failing import."
            },
            {
                "file": "agno/knowledge/document.py",
                "line_number": 29,
                "reason": "Mypy produced 22 errors all referencing this file (first reported error at line 29: \"Item 'dict[str, Any]' of 'Union[Document, dict[str, Any]]' has no attribute 'name'\") and mypy reported \"Found 22 errors in 1 file\" causing the style-check job to fail."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "ImportError during test collection",
                "evidence": "Pytest: \"ERROR collecting tests/unit/tools/test_firecrawl.py\" and \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py'\"; collection aborted with \"collected 1355 items / 1 error\" and exit code 2."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible package API / missing symbol",
                "evidence": "ImportError: \"cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" \u2014 indicates installed 'firecrawl' provides a different symbol name than the project expects."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch",
                "evidence": "Mypy output: \"agno/knowledge/document.py:29: error: Item 'dict[str, Any]' of 'Union[Document, dict[str, Any]]' has no attribute 'name' ... Found 22 errors in 1 file (checked 523 source files)\" causing exit code 1."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\necho \"AGNO_COVERAGE=$(python -c 'import json; print(json.load(open(\"coverage-agno.json\")[\"totals\"][\"percent_covered_display\"])')\" >> $GITHUB_ENV"
            },
            {
                "job": "style-check",
                "step": "Mypy",
                "command": "mypy ."
            }
        ]
    },
    {
        "sha_fail": "9afa34c7ee5870da5b18d824a482ac1e4f7161e7",
        "error_context": [
            "The run failed for two independent reasons in two jobs. In job 'style-check' the failure occurred in the Mypy step when running `mypy .`; mypy reported two argument-type errors in agno/workflow/v2/workflow.py (lines 3220 and 3226) \u2014 specifically: \"Argument 1 to \\\"merge_dictionaries\\\" has incompatible type \\\"Optional[dict[str, Any]]\\\"; expected \\\"dict[str, Any]\\\"\" \u2014 and mypy exited with code 1, causing that job to fail.",
            "In job 'tests' the failure occurred during the 'Run tests for Agno' step while running pytest inside the created virtual environment. Collection aborted with an ImportError raised when importing the test module libs/agno/tests/unit/tools/test_firecrawl.py. The traceback shows libs/agno/agno/tools/firecrawl.py attempted `from firecrawl import FirecrawlApp, ScrapeOptions` but the installed package (`.venv/lib/python3.12/site-packages/firecrawl/__init__.py`) does not expose `ScrapeOptions` (log: \"ImportError: cannot import name 'ScrapeOptions' ... Did you mean: 'V1ScrapeOptions'?\"). The module then explicitly raises: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", and pytest exited with code 2, causing the tests job to fail.",
            "Ruff formatting and linting passed in the style-check job, and dependency installation completed in both jobs; the failures are a type-checking error (mypy) and an import/dependency compatibility error observed during test collection (pytest ImportError)."
        ],
        "relevant_files": [
            {
                "file": "agno/workflow/v2/workflow.py",
                "line_number": 3220,
                "reason": "Mypy reported two argument-type errors in this file (lines 3220 and 3226) where an Optional[dict[str, Any]] is passed to merge_dictionaries which expects dict[str, Any]; log: \"agno/workflow/v2/workflow.py:3220: error: Argument 1 to \\\"merge_dictionaries\\\" has incompatible type \\\"Optional[dict[str, Any]]\\\"; expected \\\"dict[str, Any]\\\"\"."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Import in this module fails during test collection: it tries `from firecrawl import FirecrawlApp, ScrapeOptions` and, on ImportError, raises a helpful error: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\". The traceback points to this file (lines 9 and 11) as the source of the import failure."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "The installed firecrawl package in the virtualenv does not export the expected symbol `ScrapeOptions` (log: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\"), causing the ImportError during pytest collection."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch",
                "evidence": "\"agno/workflow/v2/workflow.py:3220: error: Argument 1 to \\\"merge_dictionaries\\\" has incompatible type \\\"Optional[dict[str, Any]]\\\"; expected \\\"dict[str, Any]\\\"\" and \"Found 2 errors in 1 file (checked 551 source files)\"; mypy exited with code 1."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError / incompatible package API",
                "evidence": "Pytest collection error: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" and code in libs/agno/agno/tools/firecrawl.py raises: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"; pytest exited with code 2."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Mypy",
                "command": "mypy ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "5bc251ad971b80a0717f241ae0afc1d70aca803a",
        "error_context": [
            "Step \"style-check (3.9)\" failed when the Ruff linter reported 36 \"invalid-syntax\" errors because the code uses newer Python syntax (named assignment operator ':=' introduced in Python 3.8 and parentheses in with-statements introduced in Python 3.9) while Ruff was enforcing compatibility with Python 3.7. Evidence: ruff output lines such as \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7 ... --> agno/api/playground.py:66:8\" and \"Found 36 errors.\"",
            "Step \"tests (3.12)\" failed during pytest collection with two ImportErrors that prevented tests from running. Evidence: pytest collected \"1135 items / 2 errors\" and then aborted with \"Interrupted: 2 errors during collection\". The two collection errors were: (1) an ImportError in libs/agno/agno/tools/firecrawl.py where \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" and the module raising \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"; (2) a ModuleNotFoundError in libs/agno/agno/reranker/infinity.py: \"No module named 'infinity_client'\" followed by a raised ImportError asking to \"please run `pip install infinity_client`\".",
            "The dev setup step installed many packages successfully (editable installs and a large dependency set), but the test-run step still failed due to either missing third-party packages or API changes in installed packages (firecrawl API mismatch). Warnings about third-party packages (pydub syntax warnings, pydantic deprecation) appeared but are non-blocking; the blocking issues are Ruff syntax checks and missing/incompatible dependencies preventing test collection."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged Python 3.8/3.9 syntax in this file: \"if token := read_auth_token():\" (walrus) and a parenthesized with-statement; log shows \"invalid-syntax ... --> agno/api/playground.py:66:8\" and also an invalid-syntax at :72 for parentheses in a with-statement."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged a named assignment (walrus) here: log shows \"invalid-syntax ... --> agno/knowledge/website.py:90:16\" with source context \"if document_list := self.reader.read(url=url):\"."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5136,
                "reason": "Many repeated Ruff errors point to walrus operator usage in this file (several locations). Example: \"invalid-syntax ... --> agno/team/team.py:5136:24\" for \"if context_images := self.memory.get_team_context_images():\"; this file accounts for numerous of the 36 ruff errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged walrus operator usages in this file (e.g. \"if http_client := getattr(client.http_client, \\\"httpx_client\\\", None):\"); log shows \"invalid-syntax ... --> agno/tools/apify.py:281:8\"."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged walrus usage here: \"invalid-syntax ... --> agno/tools/function.py:160:16\" for \"if docstring := getdoc(c):\"."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Import failure during pytest collection: traceback shows \"from firecrawl import FirecrawlApp, ScrapeOptions\" raised ImportError (expected name 'ScrapeOptions' not present) and the module then raises \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module during collection because the module under test (agno.tools.firecrawl) raised an ImportError; header: \"ERROR collecting tests/unit/tools/test_firecrawl.py\"."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "The installed firecrawl package does not expose the expected symbol; log shows \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\", indicating an API mismatch between code and installed package."
            },
            {
                "file": "libs/agno/agno/reranker/infinity.py",
                "line_number": 9,
                "reason": "Import failure during pytest collection: traceback shows \"from infinity_client import AuthenticatedClient, Client\" raised ModuleNotFoundError and the file raises \"infinity_client not installed, please run `pip install infinity_client`\"."
            },
            {
                "file": "libs/agno/tests/unit/vectordb/test_chromadb.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module during collection because importing agno.vectordb.chroma triggered the reranker infinity import that failed with a missing dependency; header: \"ERROR collecting tests/unit/vectordb/test_chromadb.py\"."
            },
            {
                "file": "libs/agno/agno/vectordb/chroma/__init__.py",
                "line_number": 1,
                "reason": "This package's import leads into chromadb and then into the reranker import chain that fails due to missing infinity_client (traceback includes this file in the chain)."
            },
            {
                "file": "libs/agno/agno/vectordb/chroma/chromadb.py",
                "line_number": 17,
                "reason": "This module imports agno.reranker.base (traceback shows chromadb.py:17), which causes agno.reranker.infinity to be imported and fail due to missing infinity_client."
            },
            {
                "file": "libs/agno/agno/reranker/__init__.py",
                "line_number": 3,
                "reason": "This package imports InfinityReranker (traceback shows __init__.py:3), which triggers agno.reranker.infinity and the subsequent ImportError for infinity_client."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Multiple warnings surfaced during test collection referencing this file (SyntaxWarning invalid escape sequences at lines ~300-314 and a RuntimeWarning about missing ffmpeg); these are non-blocking warnings shown in the log."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydantic/_internal/_config.py",
                "line_number": 323,
                "reason": "A deprecation warning from pydantic was emitted during collection: \"PydanticDeprecatedSince20: Support for class-based `config` is deprecated...\" as logged at this file/line."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Linter syntax compatibility (invalid-syntax due to newer Python features)",
                "evidence": "Ruff reported \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" and concluded \"Found 36 errors.\" (style-check step)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible package API / missing symbol (firecrawl)",
                "evidence": "ImportError: \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" and code raised \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" (tests collection)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing dependency (infinity_client)",
                "evidence": "ModuleNotFoundError: \"No module named 'infinity_client'\" and subsequent raised ImportError: \"infinity_client not installed, please run `pip install infinity_client`\" (tests collection)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Pytest collection error (ImportError during collection)",
                "evidence": "Pytest output shows \"collected 1135 items / 2 errors\" and \"!!!!!!!!!!!!!!!!!!! Interrupted: 2 errors during collection !!!!!!!!!!!!!!!!!!!!\" with two ImportError tracebacks preventing test execution."
            },
            {
                "category": "Warnings",
                "subcategory": "Third-party library warnings (SyntaxWarning/DeprecationWarning/RuntimeWarning)",
                "evidence": "Warnings emitted during collection: pydub utils SyntaxWarning invalid escape sequences, pydub RuntimeWarning about ffmpeg, and pydantic deprecation warning (logs show .venv/.../pydub/utils.py and pydantic/_internal/_config.py lines)."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "a85e1bd5dafc21ebfa7bca57cc4ba87a28bade52",
        "error_context": [
            "Two independent failures caused the CI run to fail. In the tests (3.12) job, pytest test collection aborted with an ImportError: libs/agno/agno/tools/zep.py attempted \"from zep_cloud.types import MemorySearchResult\" which raised \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" and the module then raised the fallback: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\". Pytest reported \"collected 836 items / 1 error\" and the run ended with exit code 2. In the style-check (3.9) job, ruff reported syntax errors across the codebase (36 errors) \u2014 primarily use of the named assignment (walrus) operator (\":=\") and parenthesized with-statements that ruff flagged as \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\". Ruff printed per-file line numbers and stopped the job with exit code 1. The logs also show non-fatal warnings from pydub (SyntaxWarning/DeprecationWarning/RuntimeWarning), but these warnings did not cause the job failures. Together, the ImportError in tests and the ruff invalid-syntax failures in style-check are the immediate root causes."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This module attempted \"from zep_cloud.types import MemorySearchResult\" (traceback shows libs/agno/agno/tools/zep.py:12) and then raised the fallback ImportError at line 15: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\", directly causing pytest collection to fail."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Pytest failed while importing this test module (traceback: libs/agno/tests/unit/tools/test_zep.py:5) because importing agno.tools.zep triggers the ImportError described above."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "The ImportError message points to this installed package file as the source: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (.../.venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py)\", indicating the installed zep_cloud package API does not provide the expected symbol."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff reported invalid-syntax here (e.g. \"if token := read_auth_token():\") \u2014 one of the occurrences of the walrus operator flagged in the style-check failure (log shows error at agno/api/playground.py:66 and 68, and a parenthesized with-statement at line 72)."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged use of the walrus operator at line 90: \"if document_list := self.reader.read(url=url):\", contributing to the 36 ruff 'invalid-syntax' errors that caused style-check to fail."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5134,
                "reason": "Multiple occurrences of the walrus operator were flagged across this file (first reported at agno/team/team.py:5134), contributing many of the ruff invalid-syntax errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported several invalid-syntax occurrences here (first at agno/tools/apify.py:281: \"if http_client := ...\"), included in the 36 errors that made ruff exit non-zero."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged walrus operator usage here (agno/tools/function.py:119: \"if docstring := getdoc(c):\"), part of the style-check failure."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: missing or mismatched package symbol",
                "evidence": "\"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" and fallback \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\" (pytest traceback in tests (3.12) job)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test collection error due to ImportError",
                "evidence": "\"collected 836 items / 1 error\" and \"ERROR collecting tests/unit/tools/test_zep.py\" with traceback showing the ImportError in agno.tools.zep."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Ruff invalid-syntax (walrus operator / parenthesized with-statement)",
                "evidence": "Ruff output: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7 ...\" and \"Found 36 errors.\" (style-check (3.9) job)."
            },
            {
                "category": "Warnings",
                "subcategory": "Syntax/Deprecation/Runtime warnings from third-party package",
                "evidence": "Pytest warnings summary shows SyntaxWarning and DeprecationWarning in .venv/lib/.../pydub/utils.py and a RuntimeWarning: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\" (6 warnings total)."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            },
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "ff05ec31ea5bb7789ba6485f75fd336de635749c",
        "error_context": [
            "Two CI jobs failed independently: (1) style-check (3.9) failed during the \"Ruff check\" step because the linter reported 39 errors and exited with code 1. Ruff reported many \"invalid-syntax\" errors (uses of the walrus operator ':=' and parentheses in with-statements) which the linter described as Python-3.8/3.9 syntax being invalid for Python 3.7 (e.g. \"Cannot use named assignment expression (`:=`) on Python 3.7\"). Ruff also reported F821 undefined-name errors in agno/eval/performance.py. Evidence: \"Found 39 errors.\" and \"##[error]Process completed with exit code 1.\" (step 'Ruff check' ran command \"ruff check .\").\n\n(2) tests (3.12) failed during test collection in the \"Run tests for Agno\" step because an ImportError occurred while importing libs/agno/tests/unit/tools/test_zep.py. Importing agno.tools.zep attempted \"from zep_cloud.types import MemorySearchResult\" which raised \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"; agno.tools.zep then raises an ImportError instructing to install `zep-cloud`. Pytest aborted collection with \"1 error\" and the job exited with code 2. Evidence: \"E   ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" and \"E   ImportError: `zep-cloud` package not found. Please install it with `pip install zep-cloud`\" (step ran command \"python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\").\n\nTogether these indicate two root causes: a linting/configuration mismatch (ruff is checking files as if targeting an older Python version or otherwise configured to disallow newer syntax used in the code), and a dependency/import failure during tests (zep_cloud API mismatch or missing/incorrectly installed zep-cloud package leading to ImportError). Additional runtime warnings (pydub SyntaxWarnings/Deprecation/RuntimeWarning about ffmpeg) were emitted during test setup but are warnings, not the primary failure."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged invalid-syntax at line 66 for the walrus operator (\"if token := read_auth_token():\") and additional syntax at lines 68 and 72; these caused lint failure messages (part of the 39 ruff errors)."
            },
            {
                "file": "agno/eval/performance.py",
                "line_number": 329,
                "reason": "Ruff reported F821 undefined-name errors at line 329+ for names such as log_eval_run, asdict and EvalType (\"F821 Undefined name `log_eval_run`\" and \"F821 Undefined name `asdict`\")."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged invalid-syntax at line 90 for use of the walrus operator (\"if document_list := self.reader.read(url=url):\"), contributing to the lint failure."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5099,
                "reason": "Multiple occurrences of the walrus operator across many locations (examples at 5099, 5101, 5103, 5114, etc.) were reported as invalid-syntax by ruff, contributing heavily to the 39 reported errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported invalid-syntax where named assignment expressions are used (e.g. \"if http_client := getattr(...):\" at line 281), included in lint errors."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff reported invalid-syntax for walrus operator use in this file (e.g. \"if docstring := getdoc(c):\" at line 119), included in lint errors."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Import in this file triggers the test failure: \"from zep_cloud.types import MemorySearchResult\" raised ImportError; the file then raises an ImportError advising to install zep-cloud (lines 12\u201315)."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Pytest failed collecting this test module because importing it imports agno.tools.zep which raised the ImportError that aborted test collection."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "The installed package module was the immediate source of the import failure: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" (pytest traceback points here)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Multiple warnings emitted during test run (SyntaxWarning invalid escape sequences at lines 300/301/310/314, DeprecationWarning for audioop, and a RuntimeWarning about missing ffmpeg) \u2014 these are warnings surfaced during collection/execution."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/importlib/__init__.py",
                "line_number": 90,
                "reason": "Appears in pytest traceback during import machinery when the ImportError was raised (context for the failed import)."
            }
        ],
        "error_types": [
            {
                "category": "Linting Error",
                "subcategory": "Invalid syntax due to newer Python syntax (named assignment ':=' and with-parentheses) vs linter target",
                "evidence": "Ruff: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7 ...\" and many locations listed (e.g. agno/api/playground.py:66, agno/team/team.py:5099); ruff exited with \"Found 39 errors.\""
            },
            {
                "category": "Linting Error",
                "subcategory": "Undefined name (F821)",
                "evidence": "Ruff reported \"F821 Undefined name `log_eval_run`\" and \"F821 Undefined name `asdict`\" in agno/eval/performance.py (lines 329\u2013332)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError / Missing or incompatible package symbol",
                "evidence": "Pytest import traceback: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" and agno.tools.zep raised \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test collection aborted due to ImportError",
                "evidence": "Pytest: \"collected 836 items / 1 error\" and \"ERROR collecting tests/unit/tools/test_zep.py\" followed by the ImportError that interrupted collection; job exited with code 2."
            },
            {
                "category": "Runtime Warning",
                "subcategory": "Library warnings (SyntaxWarning/Deprecation/RuntimeWarning)",
                "evidence": "Pytest warnings: multiple SyntaxWarning lines in pydub/utils.py (invalid escape sequences), DeprecationWarning for 'audioop', and RuntimeWarning \"Couldn't find ffmpeg or avconv\" were printed during test setup."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "376f2e4f9366f5f0461b26011fb82c80625d907e",
        "error_context": [
            "Two independent failures caused the CI run to fail. In the tests (3.12) job, pytest collection errored with ImportErrors for two test modules: importing libs/agno/tests/unit/tools/test_firecrawl.py failed because libs/agno/agno/tools/firecrawl.py attempted \"from firecrawl import FirecrawlApp, ScrapeOptions\" but the installed package exported a different symbol (log: \"cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\") and the module raised a fallback ImportError (\"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"). Similarly, importing tests/unit/tools/test_zep.py failed because libs/agno/agno/tools/zep.py attempted \"from zep_cloud.types import MemorySearchResult\" but the installed zep_cloud.types did not export that name (log: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\") and raised a fallback ImportError (\"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"). These are dependency/import compatibility issues discovered during test collection after dev_setup installed packages into .venv. \n\nSeparately, in the style-check (3.9) job, ruff check exited with syntax errors because the code uses newer-Python syntax (walrus operator ':=' and parentheses in a with-statement) while ruff flagged those as invalid for Python 3.7 (multiple messages: \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\"). The workflow set up Python 3.9 for the style-check job, but ruff reported errors specifically referencing Python 3.7 grammar, indicating a mismatch between the code's Python usage and the style-checker's configured/targeted Python version. \n\nWarnings about pydub (SyntaxWarning invalid escape sequences and RuntimeWarning: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg\") appeared in the tests job but are non-blocking; they indicate missing runtime tooling (ffmpeg) and deprecation warnings, not the immediate cause of the failing jobs."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Traceback shows this file imports \"from firecrawl import FirecrawlApp, ScrapeOptions\" and then raises the fallback ImportError; it's the source of the test collection failure for test_firecrawl.py."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Import of this test module triggered the failure rooted in agno.tools.firecrawl (pytest collection error references this test file)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Log shows the installed firecrawl package does not export 'ScrapeOptions' (error: \"cannot import name 'ScrapeOptions'... Did you mean: 'V1ScrapeOptions'?\") causing the ImportError during test collection."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This file attempts \"from zep_cloud.types import MemorySearchResult\" and raises a fallback ImportError when the symbol is missing; it is the root of the test_zep collection error."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Import of this test module triggered the failure rooted in agno.tools.zep (pytest collection error references this test file)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Log shows this installed module does not export 'MemorySearchResult' (\"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"), causing the ImportError during test collection."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff reported invalid-syntax at this line for using the walrus operator (\"if token := read_auth_token():\") and parentheses in a with-statement, which ruff flagged as invalid for Python 3.7."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged use of the walrus operator here (\"if document_list := self.reader.read(url=url):\") as invalid under Python 3.7."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5042,
                "reason": "This large file contains many occurrences of the walrus operator (first reported at line 5042) that ruff flagged as invalid for Python 3.7; these contributed to the 'Found 36 errors.' ruff failure."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged walrus operator usage at this line (\"if http_client := getattr(...):\") as invalid for Python 3.7; multiple other occurrences in this file were also reported."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged walrus operator usage at this line (\"if docstring := getdoc(c):\") as invalid for Python 3.7; another occurrence was reported at line 252."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Pytest warnings reference this file (SyntaxWarning invalid escape sequences at lines 300/301/310/314 and RuntimeWarning about missing ffmpeg); indicates environment/tooling warnings present during tests."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: missing or incompatible symbol",
                "evidence": "Tests failed during collection: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"; fallback messages asked to install specific packages."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Invalid-syntax flagged by style checker (newer-Python syntax)",
                "evidence": "Ruff reported multiple \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" errors (e.g., \"--> agno/api/playground.py:66:8\", \"Found 36 errors.\")."
            },
            {
                "category": "Configuration Error",
                "subcategory": "Style checker / target-Python mismatch",
                "evidence": "Despite running under Python 3.9, ruff's errors explicitly reference Python 3.7 grammar (logs: \"Cannot use named assignment expression ... on Python 3.7\"), indicating a mismatch between code syntax and ruff's configured target."
            },
            {
                "category": "Tooling Warning",
                "subcategory": "Missing runtime tool & SyntaxWarnings in dependency",
                "evidence": "Pytest printed warnings: SyntaxWarning invalid escape sequences in pydub/utils.py and RuntimeWarning: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\"."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\necho \"AGNO_COVERAGE=$(python -c 'import json; print(json.load(open(\"coverage-agno.json\"))[\"totals\"][\"percent_covered_display\"])')\" >> $GITHUB_ENV"
            },
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "5c9eb5a8d40eac63b1621e74419779620acd95b9",
        "error_context": [
            "The CI run failed due to two independent classes of errors in two jobs. In job 'tests (3.12)' the test collection step aborted because pytest encountered ImportError during collection: agno/tools/firecrawl.py attempted to import 'ScrapeOptions' from the installed 'firecrawl' package which raised \"ImportError: cannot import name 'ScrapeOptions'... Did you mean: 'V1ScrapeOptions'?\", and agno/tools/zep.py attempted to import 'MemorySearchResult' from 'zep_cloud.types' which raised \"ImportError: cannot import name 'MemorySearchResult'...\"; each project module then raised a fallback ImportError recommending installing the expected package, causing pytest to stop with \"2 errors during collection\" and exit code 2. In job 'style-check (3.9)' the ruff check step failed (exit code 1) because ruff reported many \"invalid-syntax\" diagnostics: the codebase uses newer Python syntax (named assignment expression ':=' and parentheses in with-statements) which ruff flagged as incompatible with Python 3.7 (e.g. \"Cannot use named assignment expression (`:=`) on Python 3.7\" for multiple files). The two failing jobs therefore are: (1) tests failing at Pytest collection due to ImportError/API mismatch in installed dependencies, and (2) style-check failing because ruff flagged modern syntax as invalid (Python version/ruff-target mismatch or configuration) across multiple files."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module because importing agno.tools.firecrawl raised an ImportError; log: \"ImportError while importing test module '.../libs/agno/tests/unit/tools/test_firecrawl.py'.\""
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "This module attempted \"from firecrawl import FirecrawlApp, ScrapeOptions\" and when that import failed the module raised a fallback ImportError: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", causing test collection to error."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Installed package raised the import error: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (.../.venv/.../site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" \u2014 evidence of API/version mismatch in the dependency."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module because importing agno.tools.zep raised an ImportError; log: \"ImportError while importing test module '.../libs/agno/tests/unit/tools/test_zep.py'.\""
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This module attempted \"from zep_cloud.types import MemorySearchResult\" and when that import failed the module raised a fallback ImportError: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\", causing test collection to error."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Installed package raised the import error: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (.../.venv/.../site-packages/zep_cloud/types/__init__.py)\", indicating the expected symbol is missing (API/version mismatch)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Test collection emitted multiple warnings from pydub: SyntaxWarning about invalid escape sequences (lines ~300, 301, 310, 314), DeprecationWarning about 'audioop', and RuntimeWarning about missing ffmpeg \u2014 present in the collection output but not the primary exit cause."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff reported \"invalid-syntax\" for use of the walrus operator and parentheses in a with-statement (e.g. \"if token := read_auth_token()\" at line 66), contributing to the ruff 'Found 36 errors.' failure."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff reported \"invalid-syntax\" for a named assignment expression (\"if document_list := self.reader.read(url=url):\" at line 90), included in the ruff error set that caused the style-check job to fail."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5042,
                "reason": "Multiple ruff \"invalid-syntax\" diagnostics point to repeated uses of ':=' across this file (first reported at line 5042), making it a major contributor to the 'Found 36 errors.' ruff failure."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged several instances of the named assignment expression in this file (e.g. \"if http_client := getattr(...):\" at line 281), part of the style-check failure."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 161,
                "reason": "Ruff flagged named assignment expressions here (e.g. \"if docstring := getdoc(c):\" at line 161), included in the invalid-syntax diagnostics that caused ruff to exit with errors."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: missing symbol / API mismatch",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...site-packages/zep_cloud/types/__init__.py)\" (pytest collection errors)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing dependency / fallback ImportError raised by project",
                "evidence": "Project modules raised fallback ImportError messages: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" and \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\", shown during pytest collection."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Linting/ruff invalid-syntax (Python version incompatibility)",
                "evidence": "Ruff reported many \"invalid-syntax\" diagnostics stating e.g. \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\", resulting in \"Found 36 errors.\" and exit code 1."
            },
            {
                "category": "Warnings",
                "subcategory": "Runtime/Deprecation/Syntax warnings from third-party package",
                "evidence": "Pytest emitted warnings from pydub: SyntaxWarning for invalid escape sequences and DeprecationWarning about 'audioop', plus RuntimeWarning \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\" during collection."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\necho \"AGNO_COVERAGE=$(python -c 'import json; print(json.load(open(\"coverage-agno.json\")[\"totals\"][\"percent_covered_display\"])')\" >> $GITHUB_ENV"
            }
        ]
    },
    {
        "sha_fail": "8e35a02d3f456cc04e683028082c4fdc3daa5856",
        "error_context": [
            "Two separate failures caused the overall CI run to fail. First, in the style-check job (style-check (3.9)), the 'Ruff check' step failed because ruff reported 36 \"invalid-syntax\" errors: the codebase uses Python >=3.8/3.9 syntax (named assignment operator ':=' and parentheses across multiple context managers in a with-statement) while ruff was checking compatibility with Python 3.7. Evidence: ruff messages such as \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7 ... --> agno/api/playground.py:66:8\" and the summary \"Found 36 errors.\" This caused the style-check job to exit with code 1. Second, in the tests job (tests (3.12)), pytest aborted collection with an ImportError originating from libs/agno/agno/tools/zep.py which attempted \"from zep_cloud.types import MemorySearchResult\" and failed: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\". The module then raises a fallback ImportError: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\" and pytest reports \"collected 828 items / 1 error\" and exits with code 2. That indicates a dependency mismatch or missing symbol in the installed zep-cloud package (version mismatch or missing API). Both failures are independent: linting/syntax-compatibility errors in the style-check job and an import/dependency error causing test collection to fail in the tests job."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged named-assignment (walrus) usage at line 66: \"if token := read_auth_token()\" \u2014 reported as invalid-syntax for Python 3.7."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged named-assignment (walrus) usage at line 90: \"if document_list := self.reader.read(url=url):\" reported as Python 3.7-incompatible syntax."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5067,
                "reason": "Multiple ruff invalid-syntax entries (many line numbers) showing repeated walrus operator uses (first listed at 5067) causing a large portion of the 36 lint errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged walrus operator usage at line 281: \"if http_client := getattr(...)\" \u2014 marked as Python 3.7-incompatible syntax."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged walrus operator usage at line 119: \"if docstring := getdoc(c):\" \u2014 reported as invalid for Python 3.7."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "Pytest failed to import this test module during collection; import triggers the failing import of agno.tools.zep."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Module import attempts \"from zep_cloud.types import MemorySearchResult\" and, on failure, raises an ImportError instructing to install 'zep-cloud' \u2014 this import failure aborts test collection."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Identified in traceback as the installed package module that does not provide 'MemorySearchResult' (\"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\")."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Syntax compatibility (invalid-syntax for Python 3.7: walrus operator, with-parentheses)",
                "evidence": "Ruff output: multiple \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" messages (e.g. agno/api/playground.py:66:8) and \"Found 36 errors.\" (style-check job)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: cannot import name X (version/missing-symbol mismatch)",
                "evidence": "Pytest traceback: \"E   ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\" and module raised \"`zep-cloud` package not found. Please install it with `pip install zep-cloud\" (tests job)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test collection error due to ImportError",
                "evidence": "Pytest summary: \"collected 828 items / 1 error\" and \"ERROR collecting tests/unit/tools/test_zep.py\" with the ImportError during import/collection."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "705b89c43639bca0f651c5d1219216c2531e23e8",
        "error_context": [
            "The CI run failed for two distinct reasons in two jobs. In job 'style-check' (matrix python-version 3.9) the step 'Ruff check' exited with code 1 because ruff reported 36 \"invalid-syntax\" errors: the linter flagged use of Python 3.8+/3.9+ syntax (named assignment operator ':=' and parentheses in a with statement) while reporting these constructs as invalid on Python 3.7 (evidence: repeated messages like \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" with file/line references). Installation and ruff format completed, but the compatibility checks failed at 'ruff check .', causing the job to fail.\n\nIn job 'tests' (matrix python-version 3.12) the step 'Run tests for Agno' failed during pytest collection (pytest aborted with 2 import errors). Two test modules failed to import because code attempted to import symbols that are absent or differently named in installed third-party packages. Evidence: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" (libs/agno/agno/tools/firecrawl.py) and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" (libs/agno/agno/tools/zep.py). Both modules then explicitly raised ImportError instructing to install 'firecrawl-py' and 'zep-cloud'. Dependency installation steps earlier completed without fatal pip errors, so the failures are due to missing/incompatible third-party package API (or wrong package variant) rather than pip install failing.\n\nAdditionally, pytest emitted several environment/runtime warnings (pydub SyntaxWarning and DeprecationWarning and a RuntimeWarning about missing ffmpeg) which are non-blocking but indicate environment/tooling issues that may affect runtime behavior."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged use of the walrus operator and parentheses-in-with: log shows \"agno/api/playground.py:66:8\" with snippet \"if token := read_auth_token():\" and also parentheses-in-with flagged at line 72; these syntax uses caused ruff's \"invalid-syntax\" errors."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged a walrus operator here: log shows \"agno/knowledge/website.py:90:16\" with snippet \"if document_list := self.reader.read(url=url):\" cited in the invalid-syntax errors."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5059,
                "reason": "Multiple occurrences of the walrus operator in this large file were flagged (many ruff entries point to lines in the 5059\u20135571 range); example: \"if context_images := self.memory.get_team_context_images():\" at line 5059 contributed to the 36 lint errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged several walrus usages in this module (e.g. \"if http_client := getattr(...)\" at line 281, plus additional occurrences at 313, 316, 326, 347, 352), producing invalid-syntax lint errors."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged walrus usage in docstring parsing (\"if docstring := getdoc(c):\" at line 160 and similarly at line 252) as invalid under Python 3.7 compatibility checks."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Pytest collection failed importing this module: traceback shows \"from firecrawl import FirecrawlApp, ScrapeOptions\" raised ImportError (ScrapeOptions not present) and the module then raised an ImportError instructing to install 'firecrawl-py'."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest reported \"ERROR collecting tests/unit/tools/test_firecrawl.py\" because importing the test module failed due to the ImportError raised in agno.tools.firecrawl (missing ScrapeOptions / package mismatch)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Python import machinery reported the missing symbol location here: \"cannot import name 'ScrapeOptions' from 'firecrawl' (/.../.venv/lib/python3.12/site-packages/firecrawl/__init__.py)\", indicating the installed package API differs from the import expectation."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Pytest collection failed importing this module: traceback shows \"from zep_cloud.types import MemorySearchResult\" raised ImportError (symbol not found) and the module then raised an ImportError instructing to install 'zep-cloud'."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest reported \"ERROR collecting tests/unit/tools/test_zep.py\" because importing the test module failed due to the ImportError raised in agno.tools.zep (missing MemorySearchResult / package mismatch)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Python import machinery reported \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (/.../.venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py)\", showing the installed zep_cloud package API is not compatible with the import."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": null,
                "reason": "Pytest emitted multiple warnings pointing to this file: SyntaxWarning for invalid escape sequences, DeprecationWarning about 'audioop', and RuntimeWarning about missing ffmpeg/avconv; these are non-fatal but indicate environment/tooling issues."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Linting error: Syntax compatibility (Python version mismatch)",
                "evidence": "Ruff output: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" across multiple files; ruff check exited with \"Found 36 errors.\""
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError during collection (missing/incompatible API)",
                "evidence": "Pytest errors: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" caused test collection to abort (2 errors during collection)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing or incompatible third-party package / wrong package variant",
                "evidence": "Modules raised explicit messages instructing package installation: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" and \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"; import traces show installed packages do not expose the expected symbols (suggesting API or package mismatch)."
            },
            {
                "category": "Runtime/Environment Warning",
                "subcategory": "Warnings about system dependencies and deprecations",
                "evidence": "Pytest warnings reference pydub: SyntaxWarning for invalid escape sequences and DeprecationWarning ('audioop' is deprecated) and RuntimeWarning: \"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\"."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "61335e0ea23b38c00d159f51173337a1507ea88e",
        "error_context": [
            "Two independent failures caused the CI run to fail. In the style-check job (style-check (3.9)) the Ruff lint step (`Ruff check`) failed: ruff reported 36 \"invalid-syntax\" compatibility errors (e.g. \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\"), and the job exited with code 1 (log: \"Found 36 errors.\" and \"##[error]Process completed with exit code 1.\"). Those errors point to Python-syntax features (walrus operator, parenthesized with) that ruff flagged as incompatible with Python 3.7 in files such as agno/api/playground.py, agno/team/team.py, agno/tools/apify.py, etc. Separately, in the tests job (tests (3.12)) the pytest collection failed during the Run tests for Agno step because of import errors: an ImportError \"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\" occurred and the project module libs/agno/agno/tools/zep.py raised an ImportError instructing to install `zep-cloud` (log: \"E   ImportError: cannot import name 'MemorySearchResult'...\" and \"E   ImportError: `zep-cloud` package not found. Please install it with `pip install zep-cloud`\"). This caused pytest to abort collection and the job to exit with code 2. Both failures are evidenced in the logs and are independent: the style-check failure is a lint/syntax-compatibility issue; the tests failure is a missing/incompatible dependency or symbol in the installed zep-cloud package."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged invalid-syntax here for using the walrus operator and parenthesized with: e.g. \"if token := read_auth_token():\" and a parenthesized `with` (log shows errors at agno/api/playground.py:66:8 and :72:14) which contributed to the ruff check failure."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff reported a compatibility-syntax error at line 90 for a walrus operator usage (\"if document_list := self.reader.read(url=url):\"), included in the ruff 'Found 36 errors' output."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 4916,
                "reason": "Multiple ruff invalid-syntax errors reference this file at many locations (first shown at 4916:24) for named assignment (walrus operator) uses (e.g. \"if context_images := self.memory.get_team_context_images():\"), part of the 36 ruff errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported invalid-syntax errors for multiple walrus usages in this file (first shown at agno/tools/apify.py:281:8, \"if http_client := getattr(...):\"), contributing to ruff check failure."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged walrus operator usage here (\"if docstring := getdoc(c):\") reported as invalid-syntax for Python 3.7 in the ruff output."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module during collection; the traceback shows the import error originated when importing agno.tools.zep from this test file (ERROR collecting tests/unit/tools/test_zep.py)."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Import in this module failed: \"from zep_cloud.types import MemorySearchResult\" raised ImportError and the module then raised an ImportError instructing to install `zep-cloud` (lines referenced in log: libs/agno/agno/tools/zep.py:12 and :15)."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Pytest traceback shows the installed package file failed to provide the symbol: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...site-packages/zep_cloud/types/__init__.py)\" indicating a missing or incompatible symbol in the installed zep_cloud package."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Syntax compatibility (walrus operator / named assignment)",
                "evidence": "Ruff errors: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7 (syntax was added in Python 3.8)\" reported across multiple files (e.g. agno/team/team.py:4916, agno/tools/apify.py:281)."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Syntax compatibility (parenthesized with statement)",
                "evidence": "Ruff error: \"invalid-syntax: Cannot use parentheses within a `with` statement on Python 3.7 (syntax was added in Python 3.9)\" at agno/api/playground.py:72:14."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: missing symbol / incompatible installed package",
                "evidence": "Pytest traceback: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (.../.venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py)\"."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing package (zep-cloud)",
                "evidence": "Project-level ImportError raised by libs/agno/agno/tools/zep.py: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test collection aborted due to ImportError",
                "evidence": "Pytest summary: \"collected 844 items / 1 error\" and \"ERROR collecting tests/unit/tools/test_zep.py\" followed by the ImportError trace; pytest aborted collection (\"Interrupted: 1 error during collection\")."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "a09ab3751b226f765986a5e756204ceb78b185b8",
        "error_context": [
            "Two independent failures caused the run to fail. In the style-check job (step 'Mypy') the mypy type checker found a type error in agno/tools/bitbucket.py which produced an exit code 1 and failed the job: \"agno/tools/bitbucket.py:266: error: Incompatible return value type (got \\\"Union[str, dict[str, Any]]\\\", expected \\\"str\\\")\". Separately, in the tests job (step 'Run tests for Agno') pytest aborted collection with an ImportError: agno.tools.firecrawl attempted to import ScrapeOptions from the installed 'firecrawl' package but that symbol is not present (the package exposes 'V1ScrapeOptions' instead). The firecrawl import failure caused agno.tools.firecrawl to raise a hard ImportError instructing to install firecrawl-py and pytest to exit with code 2: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" and \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py`\". Additional captured warnings (SyntaxWarning/DeprecationWarning/RuntimeWarning and Pydantic deprecation warnings) were reported during test collection but did not directly cause the run to stop."
        ],
        "relevant_files": [
            {
                "file": "agno/tools/bitbucket.py",
                "line_number": 266,
                "reason": "Mypy reported a type-check error at this exact location: \"agno/tools/bitbucket.py:266: error: Incompatible return value type (got \\\"Union[str, dict[str, Any]]\\\", expected \\\"str\\\")\"; this mypy error caused the style-check job to exit with code 1."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "The module attempted to import ScrapeOptions from 'firecrawl' (log: \"from firecrawl import FirecrawlApp, ScrapeOptions\") and then raised an ImportError when that import failed (log shows it raises: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"). This import chain aborted pytest collection."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Pytest failed importing this test module; traceback shows the failure originates from this file at the import of FirecrawlTools which triggers the failing import in agno.tools.firecrawl."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "The installed firecrawl package (site-packages/firecrawl/__init__.py) does not expose the expected name ScrapeOptions; pytest reported: \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\", indicating an API/version mismatch in the installed dependency."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": null,
                "reason": "Multiple SyntaxWarning/Deprecation/RuntimeWarning entries were captured from this file during test collection (e.g. \"SyntaxWarning: invalid escape sequence\" and \"'audioop' is deprecated\"), contributing to the warnings summary."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/crawl4ai/models.py",
                "line_number": null,
                "reason": "Pydantic deprecation warnings were emitted from this file during test collection (e.g. \"Support for class-based `config` is deprecated\"), and were included in pytest's warnings summary."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch",
                "evidence": "\"agno/tools/bitbucket.py:266: error: Incompatible return value type (got \\\"Union[str, dict[str, Any]]\\\", expected \\\"str\\\")\" and \"Found 1 error in 1 file (checked 544 source files)\""
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError: missing symbol / API mismatch",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" and pytest collection aborted: \"Interrupted: 1 error during collection\""
            },
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible/incorrect dependency API version",
                "evidence": "The installed package 'firecrawl' lacks the expected ScrapeOptions symbol and the module raises: \"`firecrawl-py` not installed. Please install using `pip install firecrawl-py`\", indicating a dependency version or packaging mismatch."
            },
            {
                "category": "Warnings",
                "subcategory": "Runtime/Deprecation/Syntax warnings",
                "evidence": "Pytest captured multiple warnings during collection, e.g. \"SyntaxWarning: invalid escape sequence\" from pydub/utils.py, \"DeprecationWarning: 'audioop' is deprecated\", and Pydantic deprecation warnings in crawl4ai/models.py; summary: \"8 warnings, 1 error\""
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Mypy",
                "command": "mypy ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "502523d32fda4231bfecaea5ca5d8072087c0d2a",
        "error_context": [
            "Two independent failures caused the CI run to fail. In job 'style-check' (matrix python-version 3.9) the step 'Mypy' ran the command `mypy .` and exited with code 1 after reporting 5 static type errors in agno/app/discord/client.py (examples: \"Argument 1 to \\\"_handle_response_in_thread\\\" ... incompatible type \\\"TeamRunResponse\\\"; expected \\\"RunResponse\\\"\" and \"X | Y syntax for unions requires Python 3.10\"). These mypy errors are static type-check failures and caused the style-check job to fail. Separately, in job 'tests' (python-version 3.12) the step 'Run tests for Agno' executed pytest via `python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit` and test collection aborted with an ImportError: the project code imported `ScrapeOptions` from the installed firecrawl package but the installed package exposes `V1ScrapeOptions` instead. The import failure originates in libs/agno/agno/tools/firecrawl.py (it attempts `from firecrawl import FirecrawlApp, ScrapeOptions`) and the test imports that module, causing pytest to report \"ERROR collecting ... test_firecrawl.py\" and exit with code 2. In short: (1) style-check job failed due to mypy type/syntax errors in agno/app/discord/client.py; (2) tests job failed during collection due to a missing/incompatible symbol in the installed firecrawl package (dependency/API mismatch) which the code treats as a missing dependency and raises an ImportError."
        ],
        "relevant_files": [
            {
                "file": "agno/app/discord/client.py",
                "line_number": 144,
                "reason": "Mypy reported five type-checking errors in this file (lines 144, 146, 147, 153, 178). Example evidence: \"agno/app/discord/client.py:144: error: Argument 1 to \\\"_handle_response_in_thread\\\" ... incompatible type \\\"TeamRunResponse\\\"; expected \\\"RunResponse\\\"\" and \"Found 5 errors in 1 file (checked 520 source files)\"."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Import that triggers the test-collection failure: log shows \"from firecrawl import FirecrawlApp, ScrapeOptions\" at this file and then the module raises: \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py`\" which aborts pytest collection."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": 10,
                "reason": "Pytest failed to collect this test module because importing agno.tools.firecrawl raised an ImportError. Log: \"ERROR collecting tests/unit/tools/test_firecrawl.py\" and traceback shows this test's import at line 10."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Installed package is the immediate source of the ImportError: \"cannot import name 'ScrapeOptions' from 'firecrawl' ... Did you mean: 'V1ScrapeOptions'?\" \u2014 indicates an API/version mismatch of the firecrawl package installed in the virtualenv."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch",
                "evidence": "\"agno/app/discord/client.py:144: error: Argument 1 to \\\"_handle_response_in_thread\\\" of \\\"DiscordClient\\\" has incompatible type \\\"TeamRunResponse\\\"; expected \\\"RunResponse\\\"\" and \"Found 5 errors in 1 file (checked 520 source files)\"."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy syntax / Python-version incompatibility",
                "evidence": "\"agno/app/discord/client.py:146: error: X | Y syntax for unions requires Python 3.10  [syntax]\" \u2014 mypy reports code using 3.10 union syntax while the style-check job used Python 3.9."
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy union attribute access error",
                "evidence": "\"agno/app/discord/client.py:147: error: Item \\\"TeamRunResponse\\\" of \\\"Union[RunResponse, TeamRunResponse]\\\" has no attribute \\\"tools_requiring_confirmation\\\"\" and similar union-attr errors at lines 153 and 178."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: incompatible/missing package API",
                "evidence": "\"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl' (...site-packages/firecrawl/__init__.py). Did you mean: 'V1ScrapeOptions'?\" and the project's module then raising: \"ImportError: `firecrawl-py` not installed. Please install using `pip install firecrawl-py`\"."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test collection error due to ImportError",
                "evidence": "\"ERROR collecting tests/unit/tools/test_firecrawl.py\" and \"Interrupted: 1 error during collection\" with the ImportError traceback shown in the log."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Mypy",
                "command": "mypy ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "06aa9f8af2c3992435ae6ce8a8bf4391d61d8d80",
        "error_context": [
            "Two independent CI jobs failed. In job 'tests' (step 'Run tests for Agno') pytest failed during test collection because importing the test module libs/agno/tests/unit/tools/test_zep.py raised an ImportError: the code attempted `from zep_cloud.types import MemorySearchResult` but that symbol was not found in the installed zep_cloud package, and agno.tools.zep then raised a secondary ImportError instructing to install `zep-cloud`. Evidence: \"E   ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\" and \"E   ImportError: `zep-cloud` package not found. Please install it with `pip install zep-cloud`\". This import error interrupted pytest collection (\"Interrupted: 1 error during collection\") and caused exit code 2.\n\nSeparately, in job 'style-check' (step 'Ruff check') ruff reported syntax/compatibility errors and failed the style check. Ruff flagged multiple uses of the named assignment expression (walrus operator `:=`) and one use of parentheses in a with-statement that are incompatible with Python 3.7, which ruff was configured to check against. Evidence: many messages like \"Cannot use named assignment expression (`:=`) on Python 3.7 (syntax was added in Python 3.8)\" referencing files such as agno/api/playground.py, agno/knowledge/website.py, agno/team/team.py, agno/tools/apify.py, and agno/tools/function.py; and one message \"Cannot use parentheses within a `with` statement on Python 3.7 (syntax was added in Python 3.9)\" for agno/api/playground.py. Ruff reported \"Found 36 errors.\" and the job exited with code 1.\n\nAdditionally, the tests run emitted non-fatal warnings from third-party packages (pydub) including SyntaxWarning, DeprecationWarning, and a RuntimeWarning about missing ffmpeg/avconv; these did not cause the job to fail but are present in the pytest output."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module during collection; log shows \"ERROR collecting tests/unit/tools/test_zep.py\" and the traceback originates from importing this file which triggered the zep import error."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This module attempts the failing import `from zep_cloud.types import MemorySearchResult` (traceback shows this at line 12) and then raises a fallback ImportError instructing to install `zep-cloud`, directly causing test import failure."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "The ImportError cites this site-packages file as the location where `MemorySearchResult` could not be found: \"cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...site-packages/zep_cloud/types/__init__.py)\" \u2014 implicating the installed package contents/version."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": null,
                "reason": "Pytest emitted multiple warnings referencing this file (SyntaxWarning for invalid escape sequences, DeprecationWarning for 'audioop', and RuntimeWarning about ffmpeg/avconv). These are warnings present during test run but did not directly fail the job."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged invalid-syntax at this file (e.g., `if token := read_auth_token():` at line 66) and also a parentheses-in-with usage at line 72; these compatibility errors were part of the 36 ruff errors that caused the style-check job to fail."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged the use of the walrus operator (`if document_list := ...`) at line 90 as incompatible with Python 3.7; included among style-check failures."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5067,
                "reason": "Multiple repeated ruff invalid-syntax findings point to uses of `:=` throughout this large file (first reported at line 5067); these occurrences contributed to the total of 36 ruff errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported several walrus-operator usages in this file (first shown at line 281: `if http_client := ...`) flagged as incompatible with Python 3.7 and counted toward the ruff failure."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged `if docstring := getdoc(c):` at line 119 (and another at line 206) as invalid for Python 3.7; this contributed to the style-check failure."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "ImportError: missing symbol in installed package / missing dependency",
                "evidence": "\"E   ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (...)\" and \"E   ImportError: `zep-cloud` package not found. Please install it with `pip install zep-cloud`\" (pytest collection error for tests/unit/tools/test_zep.py)."
            },
            {
                "category": "Code Formatting",
                "subcategory": "Syntax / Python-version compatibility (ruff)",
                "evidence": "Multiple ruff messages: \"Cannot use named assignment expression (`:=`) on Python 3.7 (syntax was added in Python 3.8)\" and \"Cannot use parentheses within a `with` statement on Python 3.7 (syntax was added in Python 3.9)\" \u2014 \"Found 36 errors.\""
            },
            {
                "category": "Warnings",
                "subcategory": "Third-party package warnings (SyntaxWarning/Deprecation/RuntimeWarning)",
                "evidence": "Pytest warnings: \".venv/.../pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\", \":14: DeprecationWarning: 'audioop' is deprecated...\", \":170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\"."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\n          python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "ec6a461a2f8330858876ee6ddd33fa3087dc0645",
        "error_context": [
            "Step 'style-check (3.9)' failed during the 'Ruff check' step because ruff reported 38 linting/syntax errors and exited with code 1. The primary root cause is use of Python syntax features not supported under the configured compatibility target (reports: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" for many files and \"Cannot use parentheses within a `with` statement on Python 3.7\"). Additional lint issues (F841, F401) were reported (e.g. \"Local variable `e` is assigned to but never used\" and \"`typing.Optional` imported but unused\").",
            "Step 'tests (3.12)' failed during the 'Run tests for Agno' step because pytest aborted collection with import errors for two test modules. During collection imports in libs/agno/agno/tools/firecrawl.py and libs/agno/agno/tools/zep.py failed: the installed third-party packages lack the expected names/versions (logs: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"). The project modules then raised explicit ImportError messages instructing to install optional packages (\"`firecrawl-py` not installed...\", \"`zep-cloud` package not found...\") which caused pytest to exit with code 2. Several non-fatal warnings from site-packages (pydub) were also emitted but did not cause the job to fail."
        ],
        "relevant_files": [
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged use of the walrus operator (':=') at line 66 (e.g. \"if token := read_auth_token():\"), reported as invalid-syntax under Python 3.7 and contributing to the ruff failure."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff flagged walrus operator usage at line 90 (\"if document_list := self.reader.read(url=url):\"), reported as invalid-syntax for Python 3.7."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5059,
                "reason": "Multiple ruff invalid-syntax reports across this file for walrus operator uses (first reported at line 5059: \"if context_images := self.memory.get_team_context_images():\"). These repeated occurrences contributed to the total of 38 ruff errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff flagged walrus operator usage at line 281 (\"if http_client := getattr(...)\") as invalid-syntax under Python 3.7."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 160,
                "reason": "Ruff flagged walrus operator usage at line 160 (\"if docstring := getdoc(c):\") as invalid-syntax under Python 3.7."
            },
            {
                "file": "agno/utils/functions.py",
                "line_number": 33,
                "reason": "Ruff F841: a local variable `e` is assigned in an except block but not used (\"except Exception as e:\"), reported as a linter error."
            },
            {
                "file": "tests/unit/utils/test_functions.py",
                "line_number": 3,
                "reason": "Ruff F401: `typing.Optional` imported but unused on the test import line (\"from typing import Dict, Optional\"), reported as a linter error."
            },
            {
                "file": "libs/agno/agno/tools/firecrawl.py",
                "line_number": 9,
                "reason": "Import in this module failed during pytest collection: it attempts \"from firecrawl import FirecrawlApp, ScrapeOptions\" and the installed package does not export ScrapeOptions, causing an ImportError and the module to raise a subsequent ImportError instructing to install `firecrawl-py`."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_firecrawl.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module due to the ImportError originating from libs/agno/agno/tools/firecrawl.py; collection aborted for this test file."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "Import in this module failed during pytest collection: it attempts \"from zep_cloud.types import MemorySearchResult\" and the installed zep_cloud package does not provide that name, causing an ImportError and the module to raise a subsequent ImportError instructing to install `zep-cloud`."
            },
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": null,
                "reason": "Pytest failed to import this test module due to the ImportError originating from libs/agno/agno/tools/zep.py; collection aborted for this test file."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/firecrawl/__init__.py",
                "line_number": null,
                "reason": "Traceback shows the installed firecrawl package (site-packages) is where the missing name 'ScrapeOptions' originates (\"cannot import name 'ScrapeOptions' from 'firecrawl'\")."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Traceback shows the installed zep_cloud.types package is missing 'MemorySearchResult' (\"cannot import name 'MemorySearchResult' from 'zep_cloud.types'\")."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": 300,
                "reason": "Pytest emitted multiple warnings from this third-party file (SyntaxWarning for invalid escape sequences, DeprecationWarning for 'audioop', and RuntimeWarning for missing ffmpeg), visible during test collection but not the primary cause of the failure."
            }
        ],
        "error_types": [
            {
                "category": "Linting",
                "subcategory": "Syntax incompatible with configured Python target (named-assignment ':=' and `with` parentheses)",
                "evidence": "Ruff messages: \"invalid-syntax: Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\"; ruff check exited with \"Found 38 errors.\""
            },
            {
                "category": "Linting",
                "subcategory": "Unused variable / unused import (F841, F401)",
                "evidence": "Ruff reported \"F841 Local variable `e` is assigned to but never used\" (agno/utils/functions.py:33) and \"F401 `typing.Optional` imported but unused\" (tests/unit/utils/test_functions.py:3)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing or incompatible third-party package / symbol (ImportError / API mismatch)",
                "evidence": "Pytest collection errors: \"ImportError: cannot import name 'ScrapeOptions' from 'firecrawl'... Did you mean: 'V1ScrapeOptions'?\" and \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\"; project modules then raised \"`firecrawl-py` not installed...\" and \"`zep-cloud` package not found...\""
            },
            {
                "category": "Test Failure",
                "subcategory": "ImportError during collection",
                "evidence": "Pytest output: \"collected 951 items / 2 errors\" and \"Interrupted: 2 errors during collection\" with both errors being ImportError while importing test modules."
            },
            {
                "category": "Warning",
                "subcategory": "Third-party package warnings (SyntaxWarning / DeprecationWarning / RuntimeWarning)",
                "evidence": "Pytest warnings: multiple SyntaxWarning lines from pydub/utils.py (invalid escape sequences), DeprecationWarning: 'audioop' is deprecated, and RuntimeWarning about missing ffmpeg."
            }
        ],
        "failed_job": [
            {
                "job": "style-check",
                "step": "Ruff check",
                "command": "ruff check ."
            },
            {
                "job": "tests",
                "step": "Run tests for Agno",
                "command": "source .venv/bin/activate\npython -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit"
            }
        ]
    },
    {
        "sha_fail": "acf89337c1f84439dd15445415dd91da91f78645",
        "error_context": [
            "The CI run completed dependency installation successfully but failed during the test run step. In the 'build (3.10)' job the 'Run tests' step (pytest) reported a single failing test: tests/basic/test_openrouter.py::test_openrouter_get_model_info_from_cache. The test constructed a fake OpenRouter JSON payload with pricing values as strings (\"pricing\": {\"prompt\": \"100\", \"completion\": \"200\"}) and asserted that manager.get_model_info(...) should return input_cost_per_token == 0.0001, but the returned value was 100.0. Pytest shows the failing assertion E       assert 100.0 == 0.0001, causing pytest to exit with code 1 and the job to fail (Process completed with exit code 1). The failure is isolated to the test assertion in 'Run tests' rather than package installation or environment setup, both of which completed successfully according to the logs."
        ],
        "relevant_files": [
            {
                "file": "tests/basic/test_openrouter.py",
                "line_number": 42,
                "reason": "This test file contains the failing assertion: tests/basic/test_openrouter.py:42 shows the assertion that expected input_cost_per_token == 0.0001 but observed 100.0, and pytest short summary lists the failed test in this file."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest failure: 'E       assert 100.0 == 0.0001' and 'FAILED tests/basic/test_openrouter.py::test_openrouter_get_model_info_from_cache - assert 100.0 == 0.0001'."
            }
        ],
        "failed_job": [
            {
                "job": "build (3.10)",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "23a4718350a29510ae9f74ef35a93bbae88f7c80",
        "error_context": [
            "The CI job checked out commit 23a4718 and installed system packages and the repository successfully, but the run failed during the \"Run tests\" step when pytest reported 5 errors in tests/help/test_help.py. The immediate test failures are AssertionError(s) from TestHelp.setUpClass where the test expected commands.cmd_help(\"hi\") to raise aider.commands.SwitchCoder but it did not (assertion at tests/help/test_help.py:69).",
            "Captured stdout from the failing test setup shows a runtime ImportError coming from SciPy: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\". That import error occurred while the test harness attempted to install the optional help extras (aider-chat[help]) at test time and is likely to have prevented interactive help from initializing, causing commands.cmd_help to behave differently and not raise the expected SwitchCoder.",
            "During the test-time remediation the environment attempted to (re)install/upgrade many packages (aider-chat[help] and many pinned deps). The pip logs show mass uninstall/install and then an \"Install failed, try running this command manually:\" message for the same pip install command used to install the help extras. This indicates dependency resolution / upgrade attempts were performed but did not complete cleanly in the test context, leaving the runtime in a state where SciPy import failed and interactive help could not initialize.",
            "There was also an earlier pip warning during initial install about a yanked configargparse candidate (yanked version for incorrect metadata), which reflects dependency/version fragility in the environment but is secondary to the SciPy import error that correlates directly with the tests' inability to initialize help."
        ],
        "relevant_files": [
            {
                "file": "tests/help/test_help.py",
                "line_number": 69,
                "reason": "Multiple pytest ERROR traces point to setUpClass and the assertion at line 69: \"AssertionError: SwitchCoder exception was not raised\". The failing setUpClass calls cls.retry_with_backoff(run_help_command) (line 72) and the test harness output shows five errors all originating from this file."
            },
            {
                "file": "scipy/_lib/_array_api.py",
                "line_number": null,
                "reason": "Captured stdout during test setup includes: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (.../site-packages/scipy/_lib/_array_api.py)\", indicating a runtime import failure inside SciPy that prevented help initialization and is directly tied to the test failures."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "AssertionError: SwitchCoder exception was not raised (tests/help/test_help.py:69). Short test summary: 460 passed, 1 skipped, 5 errors."
            },
            {
                "category": "Runtime Error",
                "subcategory": "ImportError: cannot import name 'scipy_namespace_for'",
                "evidence": "\"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (/.../site-packages/scipy/_lib/_array_api.py)\" captured in test setup stdout."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Package install/upgrade failed or conflicting versions",
                "evidence": "\"Install failed, try running this command manually: /opt/hostedtoolcache/.../python -m pip install --upgrade --upgrade-strategy only-if-needed 'aider-chat[help]' --extra-index-url https://download.pytorch.org/whl/cpu\" and logs showing many uninstalls/installs (version churn)."
            },
            {
                "category": "Dependency Warning",
                "subcategory": "Yanked package candidate",
                "evidence": "WARNING: The candidate selected for download or install is a yanked version: 'configargparse' candidate ... Reason: incorrect metadata related to supported python versions (logged during initial pip install)."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "f87820b744b6ace98a621980130d6f3599893fff",
        "error_context": [
            "The CI job (build matrix python-version=3.12) completed checkout, Python setup, system package installation, and pip install of the repository and dependencies successfully, but failed during the test execution step. In the 'Run tests' step (pytest) a single unit test failed: TestRepo.test_commit_with_custom_committer_name in tests/basic/test_repo.py. The test patches aider.repo.GitRepo.get_commit_message and creates a temporary git repo with user.name set to \"Test User\"; it expects that calling GitRepo.commit(..., aider_edits=True) will produce a commit whose author name is \"Test User (aider)\". Instead the recorded commit author.name was \"Test User\", causing an AssertionError: \"'Test User' != 'Test User (aider)'\". Pytest summary shows 1 failed, 483 passed, 1 skipped and pytest returned a non-zero exit code, which made the job fail (runner reported \"Process completed with exit code 1\"). Captured stdout confirms the commit occurred (\"Commit d5b8b04 \\\"a good commit message\\\"\"), but the expected committer-name transformation did not happen."
        ],
        "relevant_files": [
            {
                "file": "tests/basic/test_repo.py",
                "line_number": 217,
                "reason": "This is the exact test that failed: assertion at line 217 expected commit.author.name == \"Test User (aider)\" but actual value was \"Test User\", as shown by the failure trace and AssertionError in the test output."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest failure: \"E           AssertionError: 'Test User' != 'Test User (aider)'\" and pytest summary \"1 failed, 483 passed, 1 skipped\"; captured stdout: \"Commit d5b8b04 \\\"a good commit message\\\"\"."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "73f1acb9539c928be57de3ecb4e9d2b49da62d9f",
        "error_context": [
            "The CI run failed in the build matrix entry 'build (3.12)' (job 'build') due to a Python parsing/syntax issue: the log reports \"Line terminator characters must be escaped inside string literals\" with codepoint U+000A. This indicates an unescaped newline character inside a string literal in the repository code, which causes the Python parser to error when that file is read/parsed. The error surfaced during the build job (matrix python-version 3.12), preventing the job from completing; it likely occurred at the point the code was parsed or executed (for example during import, test collection, or packaging), but the exact step/command within the job is not identified in the provided logs."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Syntax Error",
                "subcategory": "Unescaped line terminator in string literal",
                "evidence": "('Line terminator characters must be escaped inside string literals', 'U+000A')"
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "build (3.12)",
                "command": null
            }
        ]
    },
    {
        "sha_fail": "d33d8edb6b0af87364ef0b107e42ac987d959ac7",
        "error_context": [
            "The CI run completed repository checkout and dependency installation successfully, but failed during the test execution step. In the job 'build' (matrix variant python 3.10) the 'Run tests' step executed 'pytest' and reported 1 failing unit test. Pytest collected 479 items and produced the failure: \"FAILED tests/basic/test_models.py::TestModels::test_model_aliases - AssertionError: 'anthropic/claude-sonnet-4-20250514' != 'anthropic/claude-3-7-sonnet-20250219'\". The failing assertion is in tests/basic/test_models.py where Model(\"sonnet\") returned \"anthropic/claude-sonnet-4-20250514\" but the test expected \"anthropic/claude-3-7-sonnet-20250219\". Because pytest exited non-zero (1 failed), the job ended with \"Process completed with exit code 1.\""
        ],
        "relevant_files": [
            {
                "file": "tests/basic/test_models.py",
                "line_number": 141,
                "reason": "Direct test failure: the assertion self.assertEqual(model.name, \"anthropic/claude-3-7-sonnet-20250219\") failed when Model(\"sonnet\") produced \"anthropic/claude-sonnet-4-20250514\" (pytest failure printed and short summary references this file and line)."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest output: \"FAILED tests/basic/test_models.py::TestModels::test_model_aliases - AssertionError: 'anthropic/claude-sonnet-4-20250514' != 'anthropic/claude-3-7-sonnet-20250219'\" and failure trace at tests/basic/test_models.py:141."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "31a771ee95643ec96e1aa6d9648015f56057c675",
        "error_context": [
            "The CI run failed because tests that exercise the interactive /help flow could not initialize interactive help after a dependency/install issue, causing multiple test setups to fail with assertion errors. In the 'Install dependencies' step (workflow step name: \"Install dependencies\" in job 'build'), pip performed an additional install attempt for the help extras (aider-chat[help]) and the log shows both a large install/uninstall sequence and a subsequent message: \"Install failed, try running this command manually: /opt/hostedtoolcache/.../python -m pip install --upgrade --upgrade-strategy only-if-needed 'aider-chat[help]' --extra-index-url https://download.pytorch.org/whl/cpu\". Captured stdout during test setup shows that interactive help installation completed but then an import-time error occurred: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\". That ImportError prevented initialization of interactive help (log: \"Unable to initialize interactive help.\"), which changed runtime behavior of commands.cmd_help so it did not raise the expected aider.commands.SwitchCoder exception. As a result, in the 'Run tests' step (workflow step name: \"Run tests\") pytest reported setup-time AssertionErrors in tests/help/test_help.py because the test expected a SwitchCoder exception but none was raised (assertion: \"SwitchCoder exception was not raised\" at tests/help/test_help.py:69). The cascade: dependency/install problem -> SciPy import error at runtime -> interactive help initialization failure -> commands.cmd_help did not behave as tests expect -> multiple test setup assertion errors -> overall job exit code 1."
        ],
        "relevant_files": [
            {
                "file": "tests/help/test_help.py",
                "line_number": 69,
                "reason": "Test setup assertion failed here: the traceback shows the assertion at tests/help/test_help.py:69 ('SwitchCoder exception was not raised') and setup invoked retry_with_backoff at line 72. Multiple ERROR stack traces reference this file as the direct failing test code."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/scipy/_lib/_array_api.py",
                "line_number": null,
                "reason": "Captured stdout contains the runtime ImportError referencing this SciPy internal file: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\". That import failure is tied to the inability to initialize interactive help and is upstream of the test failures."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError (SciPy internal API mismatch)",
                "evidence": "\"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (/opt/hostedtoolcache/.../site-packages/scipy/_lib/_array_api.py)\" (captured stdout during test setup)"
            },
            {
                "category": "Dependency Error",
                "subcategory": "Install/Resolver Failure / Inconsistent state",
                "evidence": "\"Install failed, try running this command manually: /opt/hostedtoolcache/.../python -m pip install --upgrade --upgrade-strategy only-if-needed 'aider-chat[help]' --extra-index-url https://download.pytorch.org/whl/cpu\" (pip output immediately after large install/uninstall sequence)"
            },
            {
                "category": "Runtime Error",
                "subcategory": "Initialization Failure",
                "evidence": "Log line: \"Unable to initialize interactive help.\" (occurs after the pip/install activity and before pytest setup failures)"
            },
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest error: \"AssertionError: SwitchCoder exception was not raised\" at tests/help/test_help.py:69 and short summary: \"ERROR tests/help/test_help.py::TestHelp::test_ask_without_mock - AssertionError: SwitchCoder exception was not raised\""
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Install dependencies",
                "command": "python -m pip install --upgrade pip\npip install pytest\npip install ."
            },
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "46a2733f8a7bc2cd18d7c902cd60a1b0573cdea8",
        "error_context": [
            "The CI run fails during the build job's test phase. In the 'Install dependencies' step the job installed project and extras (pip install . and later an on-demand install of aider-chat[help]) and printed both a successful-install list and then \"Install failed, try running this command manually:\" which preceded the test failures. During the 'Run tests' step pytest reported 8 test failures and 5 errors (exit code 1).",
            "Two distinct root causes appear in the test run: (1) a runtime UnboundLocalError in the InputOutput decorator in aider/io.py: the wrapper's finally block references orig_buf_append when it was never bound, raising UnboundLocalError (log: \"UnboundLocalError: cannot access local variable 'orig_buf_append' where it is not associated with a value\", aider/io.py:92). This caused multiple failing tests in tests/basic/test_commands.py and tests/basic/test_io.py (8 failed tests).",
            "(2) several TestHelp setup errors where code expected an aider.commands.SwitchCoder to be raised but it was not, causing AssertionError in tests/help/test_help.py (evidence: \"AssertionError: SwitchCoder exception was not raised\" at tests/help/test_help.py:69-72). The TestHelp setup attempted to ensure interactive help extras were installed; captured stdout shows pip tried to install/upgrade aider-chat[help] and reported an ImportError while importing SciPy: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api'\", which indicates a dependency/import problem during help-extra initialization and may explain the interactive help initialization failure (log: \"Unable to initialize interactive help.\").",
            "Overall: the test failures are primarily caused by code-level runtime bugs (UnboundLocalError in aider/io.py and missing expected exception behavior in help-related code) and were compounded by dependency/import instability during on-demand installation of help extras (scipy import error and pip manual-install prompt)."
        ],
        "relevant_files": [
            {
                "file": "aider/io.py",
                "line_number": 92,
                "reason": "Multiple failing traces show the UnboundLocalError originates from the decorator wrapper finally block referencing 'orig_buf_append' when it was never assigned: \"UnboundLocalError: cannot access local variable 'orig_buf_append' ...\" (aider/io.py:92). This directly caused 8 failing tests in test_commands and test_io."
            },
            {
                "file": "aider/commands.py",
                "line_number": 823,
                "reason": "Failing tests call commands that invoke InputOutput.confirm_ask and flow into the failing decorator. Stack traces show calls from aider/commands.py:823 into the decorated wrapper in aider/io.py, linking this command code path to the UnboundLocalError failures."
            },
            {
                "file": "tests/basic/test_commands.py",
                "line_number": 44,
                "reason": "Several failing tests exercise cmd_add and related commands that trigger the UnboundLocalError via InputOutput.confirm_ask; log shows failures referenced to this test file (e.g., \"FAILED tests/basic/test_commands.py::TestCommands::test_cmd_add - UnboundLocalError ...\")."
            },
            {
                "file": "tests/basic/test_io.py",
                "line_number": 181,
                "reason": "Multiple failing tests exercising confirm_ask are located here (e.g., test_confirm_ask_explicit_yes_required) and their traces show the UnboundLocalError propagation from aider/io.py into these tests."
            },
            {
                "file": "tests/help/test_help.py",
                "line_number": 69,
                "reason": "Several ERROR entries come from TestHelp setup where an assertion expected a SwitchCoder exception but it was not raised (\"AssertionError: SwitchCoder exception was not raised\" at tests/help/test_help.py:69-72). Captured stdout for these errors includes the pip/help-extra install attempts and SciPy import error."
            },
            {
                "file": "scipy/_lib/_array_api.py",
                "line_number": null,
                "reason": "Captured stdout contains an ImportError referencing this SciPy internal module: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\" which occurred while installing or initializing the help extras and likely contributed to 'Unable to initialize interactive help.'"
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "UnboundLocalError",
                "evidence": "\"UnboundLocalError: cannot access local variable 'orig_buf_append' where it is not associated with a value\" (trace pointing to aider/io.py:92) \u2014 multiple tests failed with this error."
            },
            {
                "category": "Test Failure",
                "subcategory": "AssertionError (expected exception not raised)",
                "evidence": "\"AssertionError: SwitchCoder exception was not raised\" in tests/help/test_help.py (setup), causing ERROR in multiple TestHelp tests."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError / failed extras installation",
                "evidence": "Captured stdout shows pip attempted to install aider-chat[help], then printed \"Install failed, try running this command manually:\" and an ImportError: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api'\", and the log shows \"Unable to initialize interactive help.\""
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Install dependencies",
                "command": "python -m pip install --upgrade pip\npip install pytest\npip install ."
            },
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "546d402f0498ef545ec4ad4ce23ec5d1463d1798",
        "error_context": [
            "The CI run checked out commit 546d402f0... and installed system dependencies and Python packages (step 'Install dependencies' ran python -m pip install --upgrade pip; pip install pytest; pip install .). The package installation completed but tests failed during the 'Run tests' step (command: pytest).",
            "During the pytest run the suite encountered two classes of runtime problems: (1) multiple unit tests failed with an AttributeError originating in the InputOutput wrapper (aider/io.py) because prompt_session was None (log: \"AttributeError: 'NoneType' object has no attribute 'default_buffer'\" at aider/io.py:79). These failures appear in tests/basic/test_commands.py and tests/basic/test_io.py and caused many test failures.",
            "(2) Several help-related tests errored during TestHelp.setUpClass because the expected SwitchCoder exception was not raised (AssertionError: \"SwitchCoder exception was not raised\" at tests/help/test_help.py:69). The test setup attempted to auto-install the interactive help extras and encountered a SciPy import failure during that process: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\". The log shows pip attempting to collect/install aider-chat[help] extras during test setup, many packages were downloaded and replaced, and pip emitted both a warning about a yanked configargparse wheel and an \"Install failed, try running this command manually\" hint for the extras.",
            "Taken together the evidence shows: tests depending on interactive help path hit dependency/import issues (SciPy import error and an installer warning/partial install), and separately many tests that exercise InputOutput failed because prompt_session was not initialized (None) leading to AttributeError. The primary failing workflow step is 'Run tests' (pytest) which returned a non-zero exit code because of these test failures/errors."
        ],
        "relevant_files": [
            {
                "file": "aider/io.py",
                "line_number": 79,
                "reason": "Multiple test failures originate here: the InputOutput wrapper attempts to access self.prompt_session.default_buffer.append_to_history and raises \"AttributeError: 'NoneType' object has no attribute 'default_buffer'\" (stack traces show aider/io.py:65 wrapper and aider/io.py:79 failing)."
            },
            {
                "file": "aider/commands.py",
                "line_number": 823,
                "reason": "Commands.cmd_add calls self.io.confirm_ask which triggers the InputOutput wrapper that fails; stack traces show aider/commands.py:823 calling into aider/io.py and leading to the AttributeError."
            },
            {
                "file": "tests/basic/test_commands.py",
                "line_number": 44,
                "reason": "This test file contains several failing tests that triggered the InputOutput AttributeError (example failure begins at tests/basic/test_commands.py:44 calling commands.cmd_add)."
            },
            {
                "file": "tests/basic/test_io.py",
                "line_number": 308,
                "reason": "This test file contains multiple failing TestInputOutput tests that hit the same InputOutput.prompt_session None issue (failures referenced at tests/basic/test_io.py:181, :214, :255, and :308)."
            },
            {
                "file": "tests/help/test_help.py",
                "line_number": 69,
                "reason": "Help-related tests errored during setUpClass with an AssertionError \"SwitchCoder exception was not raised\" (stack shows tests/help/test_help.py:69 and :72 and retry_with_backoff at :39). The setup attempted to install aide-chat[help] extras which triggered additional dependency activity."
            },
            {
                "file": "scipy/_lib/_array_api.py",
                "line_number": null,
                "reason": "Runtime import error references this SciPy file: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...)\" \u2014 indicating an incompatible or mismatched SciPy installation encountered while attempting to initialize interactive help extras during tests."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "AttributeError",
                "evidence": "Multiple traces: \"AttributeError: 'NoneType' object has no attribute 'default_buffer'\" originating in aider/io.py (wrapper accessing self.prompt_session.default_buffer.append_to_history)."
            },
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Help tests raised AssertionError: \"SwitchCoder exception was not raised\" during TestHelp.setUpClass (tests/help/test_help.py:69)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError / Incompatible dependency",
                "evidence": "Captured stdout: \"cannot import name 'scipy_namespace_for' from 'scipy._lib._array_api' (...site-packages/scipy/_lib/_array_api.py)\" while installing/initializing help extras."
            },
            {
                "category": "Dependency / Installation",
                "subcategory": "Pip extras installation failed / partial install",
                "evidence": "Log shows pip collecting many aider-chat[help] packages, many uninstall/reinstall attempts, then the message: \"Install failed, try running this command manually: ... 'aider-chat[help]' --extra-index-url https://download.pytorch.org/whl/cpu\" and \"Unable to initialize interactive help.\""
            },
            {
                "category": "Dependency Warning",
                "subcategory": "Yanked package candidate",
                "evidence": "Pip warning: \"The candidate selected for download or install is a yanked version: 'configargparse' candidate (version 1.7) ... Reason for being yanked: incorrect metadata related to supported python versions\"."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            }
        ]
    },
    {
        "sha_fail": "8c0707ba9879994f0106a79126e917559b0b0bb9",
        "error_context": [
            "The CI run completed dependency installation successfully but failed during the test execution phase. In the build job (logged as \"build (3.10, ubuntu-latest)\"), tests were executed (tests/testall.sh in the log) and multiple tests (#511.py, #588.py, #655.py) crashed with the same runtime error originating in the model code. The immediate cause is a RuntimeError raised in ChatTTS/model/gpt.py::_prepare_generation_inputs when calling attention_mask.narrow(...): \"RuntimeError: narrow(): length must be non-negative.\" This error was triggered while tests invoked chat.infer(...) through ChatTTS/core.py (infer/_infer/_refine_text), causing each test to exit with a non-zero status and the job to finish with exit code 1. The logs also include non-fatal warnings that no GPU/NPU was found and one test reporting invalid characters, but the blocking failure is the negative-length narrow() call in the model code that prevents generation and causes test failures."
        ],
        "relevant_files": [
            {
                "file": "tests/#511.py",
                "line_number": 41,
                "reason": "Test file shown in the stack trace where chat.infer(...) triggered the failure: trace shows 'File \".../tests/#511.py\", line 41' before the RuntimeError was raised."
            },
            {
                "file": "tests/#588.py",
                "line_number": 28,
                "reason": "Test file shown in the stack trace where chat.infer(...) triggered the failure: trace shows 'File \".../tests/#588.py\", line 28' before the RuntimeError was raised."
            },
            {
                "file": "tests/#655.py",
                "line_number": 34,
                "reason": "Test file shown in the stack trace where chat.infer(...) triggered the failure: trace shows 'File \".../tests/#655.py\", line 34' before the RuntimeError was raised; this test also logged a normalization warning about invalid characters."
            },
            {
                "file": "ChatTTS/core.py",
                "line_number": 474,
                "reason": "Core API functions (infer/_infer/_refine_text) appear repeatedly in the traces as the callers into the model generation code (e.g. 'File \".../ChatTTS/core.py\", line 474, in _infer'), showing this module coordinates calls that lead to the failing model call."
            },
            {
                "file": "ChatTTS/model/gpt.py",
                "line_number": 230,
                "reason": "Primary location of the runtime failure: stack traces point to '_prepare_generation_inputs' and the line 'attention_mask = attention_mask.narrow(' at line ~230, followed by 'RuntimeError: narrow(): length must be non-negative.'"
            },
            {
                "file": "torch/utils/_contextlib.py",
                "line_number": 38,
                "reason": "Torch context-manager frames appear directly around the generator call sites in the traces (e.g. 'File \".../torch/utils/_contextlib.py\", line 38, in generator_context'), showing the model generation was executed under torch contexts when the error occurred."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "RuntimeError during tensor operation (negative length for narrow)",
                "evidence": "\"RuntimeError: narrow(): length must be non-negative.\" raised in ChatTTS/model/gpt.py::_prepare_generation_inputs (stack traces from tests #511, #588, #655)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test exited with non-zero status",
                "evidence": "Test harness lines: 'Error: tests/#511.py exited with a non-zero status.' (also reported for #588.py and #655.py) and overall 'Process completed with exit code 1.'"
            },
            {
                "category": "Configuration / Environment Warning",
                "subcategory": "No GPU available (fallback to CPU)",
                "evidence": "Repeated warning in logs: '[WARN] Test | gpu | no GPU or NPU found, use CPU instead' (appears before failing traces)."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run tests",
                "command": "pytest"
            },
            {
                "job": "build (3.10, ubuntu-latest)",
                "step": "build (3.10, ubuntu-latest)",
                "command": "tests/testall.sh"
            }
        ]
    },
    {
        "sha_fail": "895cf8e9e87f5a32d8ef2095a91a524eb1380d26",
        "error_context": [
            "The CI run completed environment setup and package installation (steps 'Test Install' and 'Install Dependencies') successfully, but the failure occurs during the 'Run Test' step when executing tests/testall.sh. Multiple tests (tests/#511.py, tests/#588.py, tests/#655.py) invoked ChatTTS.chat.infer which enters ChatTTS/model/gpt.py::_prepare_generation_inputs and attempts to call attention_mask.narrow(...). Each test raised the same runtime exception: \"RuntimeError: narrow(): length must be non-negative.\", causing the test processes to exit with non-zero status and the job to fail. Logs also show the runner detected no GPU/NPU and fell back to CPU (\"no GPU or NPU found, use CPU instead\"), which is a configuration observation but the immediate root cause is the code passing a negative length to torch.Tensor.narrow (attention_mask.narrow)."
        ],
        "relevant_files": [
            {
                "file": "ChatTTS/model/gpt.py",
                "line_number": 230,
                "reason": "Immediate source of the exception: stack traces show _prepare_generation_inputs executing attention_mask = attention_mask.narrow(...) and the RuntimeError: \"narrow(): length must be non-negative.\" (log references ChatTTS/model/gpt.py line 230)."
            },
            {
                "file": "ChatTTS/core.py",
                "line_number": 263,
                "reason": "Entry point in the package used by the tests: tracebacks show tests calling chat.infer which enters ChatTTS/core.py (multiple lines referenced, e.g. line 263) before reaching model/gpt.py; this file orchestrates the call-path that triggers the failing narrow() call."
            },
            {
                "file": "tests/#511.py",
                "line_number": 41,
                "reason": "Test that first triggered the failure in the run: traceback starts at tests/#511.py line 41 where wavs = chat.infer(...) and the process exited non-zero per the log."
            },
            {
                "file": "tests/#588.py",
                "line_number": 28,
                "reason": "Another test that reproduced the same failure: traceback shows tests/#588.py line 28 calling chat.infer(...) and then raising the same RuntimeError."
            },
            {
                "file": "tests/#655.py",
                "line_number": 34,
                "reason": "A third failing test calling chat.infer(...) (tests/#655.py line 34) that raised the identical RuntimeError; log also includes a normalization warning for this test but the error is the narrow() exception."
            },
            {
                "file": "torch/utils/_contextlib.py",
                "line_number": 38,
                "reason": "Appears in each stack trace as context-manager/generator wrappers (lines 38 and 120 shown) used while calling into model/gpt.py; present in tracebacks but not the root failing file."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "Tensor operation error (torch.Tensor.narrow negative length)",
                "evidence": "Exception message in logs: \"RuntimeError: narrow(): length must be non-negative.\" shown repeatedly from ChatTTS/model/gpt.py::_prepare_generation_inputs."
            },
            {
                "category": "Test Failure",
                "subcategory": "Test process exited with non-zero status",
                "evidence": "Test harness messages: \"Error: tests/#511.py exited with a non-zero status.\", \"Error: tests/#588.py exited with a non-zero status.\", \"Error: tests/#655.py exited with a non-zero status.\" and final \"Process completed with exit code 1.\""
            },
            {
                "category": "Configuration Warning",
                "subcategory": "No GPU/NPU detected (fallback to CPU)",
                "evidence": "Log warning printed before each failure: \"[WARN] Test | gpu | no GPU or NPU found, use CPU instead\" (indicates tests ran on CPU)."
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "Run Test",
                "command": "tests/testall.sh"
            }
        ]
    },
    {
        "sha_fail": "003204a02c6d56533005d3c855176631606e1887",
        "error_context": [
            "The CI run failed during the dependency installation step because Poetry's dependency resolver detected a Python-version incompatibility. In the test_core job running Python 3.9 (matrix entry \"Python 3.9\"), the workflow ran the step 'Install dependencies (mandatory only)' which executed: \"cd framework; python -m poetry install --all-extras\". Poetry reported that the project's supported Python range is \">=3.9.2,<4.0.0\" but one required package, docstrfmt (git+https://github.com/charlesbvll/docstrfmt.git@patch-2, version 1.11.2.dev0), requires Python >=3.10, causing version solving to fail (log: \"docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\"). The resolver error caused the process to exit with code 1 (\"##[error]Process completed with exit code 1.\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution / Python version incompatibility",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.9)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "16fde6a6ec000283f317b57aa46bf207ba64c6f3",
        "error_context": [
            "The CI run failed during the 'Install dependencies (mandatory only)' step when running in the framework directory: 'cd framework && python -m poetry install --all-extras'. Poetry's dependency resolver aborted with a version-solving error because a pinned dependency (docstrfmt 1.11.2.dev0 from git+https://github.com/charlesbvll/docstrfmt.git@patch-2) requires Python >=3.10 while the project's declared supported Python range is '>=3.9.2,<4.0.0'.",
            "Poetry reports that docstrfmt 'requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10' and concludes 'Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.' The bootstrap/setup steps (checkout, setup-python, pip/setuptools/poetry installation) completed successfully, so the failure is confined to dependency resolution in the Install dependencies step. Poetry suggests restricting the project's python constraint to '>=3.10,<4.0.0' for docstrfmt or using environment markers to make the dependency conditional."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version resolution / incompatible Python requirement",
                "evidence": "Poetry error: 'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.'"
            }
        ],
        "failed_job": [
            {
                "job": "test_core (matrix: Python 3.12)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "92628807690605b728916ce835112ec02aa0bcad",
        "error_context": [
            "The CI run failed during dependency installation in the test_core job running Python 3.12. The 'Bootstrap' step (actions/setup-python and the repository's bootstrap action) completed and installed Python 3.12.12 and Poetry 2.1.3, but the 'Install dependencies (mandatory only)' step (command: `cd framework && python -m poetry install --all-extras`) failed when Poetry could not resolve dependencies. Poetry reported that the project's declared Python range (\">=3.9.2,<4.0.0\") is incompatible with a required package: \"docstrfmt requires Python >=3.10\". Because flwr depends on a git-sourced docstrfmt revision (1.11.2.dev0 at git+https://github.com/charlesbvll/docstrfmt.git@patch-2) that requires Python >=3.10, version solving failed and the step exited with code 1 (\"##[error]Process completed with exit code 1\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Project / dependency Python requirement mismatch",
                "evidence": "Poetry suggests adjusting the dependency's `python` property (e.g. set docstrfmt to \">=3.10,<4.0.0\"); log shows project's python range (>=3.9.2,<4.0.0) conflicts with docstrfmt requiring >=3.10."
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.12)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework\npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "138d14a2aaa2888e4174c20410a63871ebf9dd31",
        "error_context": [
            "The run failed during the test_core job for Python 3.11 while executing the step 'Install dependencies (mandatory only)'. The step ran the command `cd framework` then `python -m poetry install --all-extras` and Poetry was unable to solve dependencies. Poetry reported that the project's declared Python range (\">=3.9.2,<4.0.0\") is incompatible with a required package: docstrfmt (pointed at git+https://github.com/charlesbvll/docstrfmt.git@patch-2) requires Python >=3.10. Because the project's allowed range includes 3.9.x where docstrfmt is not supported, dependency version solving failed and Poetry exited with code 1. The job was terminated with \"##[error]Process completed with exit code 1.\""
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution / version conflict",
                "evidence": "Poetry output: \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python version constraint mismatch",
                "evidence": "Poetry output: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10... For docstrfmt, a possible solution would be to set the `python` property to \">=3.10,<4.0.0\".\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.11)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "9ac1cc529e19ea05d81b64846b42bc3fed4fc750",
        "error_context": [
            "The CI run failed during dependency installation in the framework directory when running 'python -m poetry install --all-extras' under the test_core job for Python 3.9. The bootstrap step successfully set up CPython 3.9.25 and installed poetry, but poetry's dependency resolver failed because the project declares a supported Python range of >=3.9.2,<4.0.0 while one required package (docstrfmt from a git URL) requires Python >=3.10. The resolver reports: \"docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\" and: \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" Poetry's hints about changing the dependency's python property are also present in the logs. No tests were run because the install step exited with code 1."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python requirement / Version conflict",
                "evidence": "Poetry resolver output: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.9)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "2749440127f2afea34b896cd3dee76c978e95568",
        "error_context": [
            "The CI job failed during dependency installation in the framework directory. In the 'Python 3.12' job (matrix python=3.12) the bootstrap step successfully installed tooling (poetry 2.1.3), but the subsequent step 'Install dependencies (mandatory only)' ran `cd framework` and `python -m poetry install --all-extras` and Poetry's resolver failed. Poetry reports that the project's declared Python constraint (\"The current project's supported Python range (>=3.9.2,<4.0.0)\") is incompatible with a required package: \"docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\". Because flwr depends on docstrfmt from a git URL which requires Python >=3.10, version solving failed and the step exited with \"Process completed with exit code 1.\" The root cause is a dependency resolution / project metadata mismatch: the project's declared python range allows <3.10 while a required dependency declares >=3.10, so Poetry cannot produce a compatible lock/install even though the runner's actual Python is 3.12.12."
        ],
        "relevant_files": [
            {
                "file": "framework",
                "line_number": null,
                "reason": "The failing command was executed from the framework directory: `cd framework` then `python -m poetry install --all-extras`. Poetry's resolver failed while resolving dependencies declared in that directory (error: docstrfmt requires Python >=3.10)."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution / Python version incompatibility",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.12)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "53c0bd76f41454129620c887a45c904236b00ca8",
        "error_context": [
            "The CI run failed during dependency installation in the framework directory. In the 'Python 3.9' job the bootstrap step completed (Python 3.9.25, pip/setuptools/poetry installed), but the subsequent 'Install dependencies (mandatory only)' step ran \"cd framework && python -m poetry install --all-extras\" and Poetry aborted dependency resolution because of a Python version conflict. Poetry reported: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt (...) which requires Python >=3.10, version solving failed.\" As a result the step exited with code 1 and the job failed before any tests ran.",
            "Steps involved: actions/checkout@v4 (repository checkout) and the custom bootstrap action (set up Python and Poetry) succeeded, but the 'Install dependencies (mandatory only)' run step failed due to dependency resolution in Poetry caused by docstrfmt requiring Python >=3.10 while the job used Python 3.9."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Poetry dependency resolution failure",
                "evidence": "Poetry error: \"Because flwr depends on docstrfmt (...) which requires Python >=3.10, version solving failed.\" and \"Resolving dependencies...\" followed by the incompatibility message."
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python version constraint mismatch",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "b2e2825119544ad876f4e49438c0f0d9824789e4",
        "error_context": [
            "The run failed during dependency installation in the 'Install dependencies (mandatory only)' step (logged as the runtime step group 'Run cd framework'). The job used Python 3.12 but Poetry's resolver failed because the project's declared Python requirement (reported by Poetry as \"The current project's supported Python range (>=3.9.2,<4.0.0)\") is not compatible with a required package's Python requirement: \"docstrfmt requires Python >=3.10\". Poetry reports: \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" As a result the command \"python -m poetry install --all-extras\" exited with code 1 and terminated the job.",
            "The failure is a dependency resolution / configuration issue (not a network, package-download, or test failure). The resolver indicates the project-wide python constraint includes versions older than 3.10 (>=3.9.2,<4.0.0), which makes the pinned/linked docstrfmt package impossible to satisfy for the whole declared range; Poetry therefore stops with a version solving error and the CI step fails (\"##[error]Process completed with exit code 1\")."
        ],
        "relevant_files": [
            {
                "file": "framework/pyproject.toml",
                "line_number": null,
                "reason": "Poetry reads the project's supported Python range from pyproject.toml (Poetry reported: \"The current project's supported Python range (>=3.9.2,<4.0.0)\"), which conflicts with the docstrfmt dependency that requires Python >=3.10."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version solving / Python requirement mismatch",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "CI Failure",
                "subcategory": "Non-zero exit from install step",
                "evidence": "\"python -m poetry install --all-extras\" terminated with \"##[error]Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "d8f4fd29f25b46b1ab525d6870d43c90289629ef",
        "error_context": [
            "The CI run failed during dependency installation in the test_core job for Python 3.11. The bootstrap step (which installed pip, setuptools, and poetry) completed successfully, but the subsequent Install dependencies step (running `cd framework && python -m poetry install --all-extras`) aborted during Poetry's dependency resolution. Poetry reported that the project's Python constraint (>=3.9.2,<4.0.0) is incompatible with a required package: docstrfmt requires Python >=3.10. The log shows: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" The failure caused the job to exit with code 1 (\"##[error]Process completed with exit code 1.\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version resolution / Python requirement incompatibility",
                "evidence": "Poetry: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Project Python constraint mismatch",
                "evidence": "Poetry suggestion: \"For docstrfmt, a possible solution would be to set the `python` property to \">=3.10,<4.0.0\"\" (log advises adjusting the project's python constraint)."
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.11)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "a6071a929cf0092f4ebcca388e63a0f4c4d1a007",
        "error_context": [
            "The run failed during the 'Install dependencies (mandatory only)' step when running 'cd framework; python -m poetry install --all-extras'. Poetry's dependency resolution failed because the project's Python requirement (>=3.9.2,<4.0.0) is incompatible with a required package: docstrfmt (pulled from git) requires Python >=3.10. The log shows: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt (...) which requires Python >=3.10, version solving failed.\"",
            "Earlier steps that prepared the environment (actions/setup-python, pip/setuptools/poetry installation performed in the Bootstrap step) completed successfully (e.g. \"Successfully set up CPython (3.9.25)\" and poetry-2.1.3 installed). The failure is restricted to dependency resolution inside the framework directory and not to environment setup or test execution."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility / Version conflict",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt (...) which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.9)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "41c0bc8397ad3d3b4dc123b1a2c6ff24cb61922f",
        "error_context": [
            "The CI run failed during dependency installation in the 'Install dependencies (mandatory only)' step (logged as 'Run cd framework'). Bootstrap succeeded (Python 3.12 and poetry 2.1.3 were installed), but running `python -m poetry install --all-extras` inside the framework directory triggered Poetry's dependency resolver to fail. Poetry reported that the project's declared Python range (>=3.9.2,<4.0.0) is incompatible with a required package: docstrfmt requires Python >=3.10. The log shows the concrete cause: \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" Poetry then recommends adjusting the project's `python` property (for example to \">=3.10,<4.0.0\") or using environment markers. The job exited immediately afterwards with exit code 1."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible Python requirement",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.12)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework\npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "1663f627bead754eeae979123ff5616dbd003d36",
        "error_context": [
            "The run failed during the Install dependencies step: the workflow ran the command `cd framework; python -m poetry install --all-extras` (step name: \"Install dependencies (mandatory only)\" in the Python 3.11 job) and Poetry's dependency resolver aborted with a version/compatibility conflict. Poetry reported that the project's declared Python range (\">=3.9.2,<4.0.0\") is not compatible with a required dependency (docstrfmt) which requires Python \">=3.10\". The solver explicitly states: \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" Poetry suggests narrowing the project's `python` property (for example to \">=3.10,<4.0.0\"). This dependency resolution failure caused the step to exit with a non-zero status and terminate the job."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version Conflict / Solver Failure",
                "evidence": "The log: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Project Python version specification incompatible with dependency",
                "evidence": "Poetry output recommends changing the project's `python` property: \"For docstrfmt, a possible solution would be to set the `python` property to \">=3.10,<4.0.0\"\" and earlier shows the project's current supported range as \">=3.9.2,<4.0.0\"."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "11b937395748c25a1d22656299644d4492b282ed",
        "error_context": [
            "The CI run failed during the 'Install dependencies (mandatory only)' step when running 'cd framework' then 'python -m poetry install --all-extras'. The job was running Python 3.9 (setup reported \"Successfully set up CPython (3.9.25)\"). Poetry's dependency resolution failed because the repository's declared Python support (\">=3.9.2,<4.0.0\") is incompatible with a required package: docstrfmt requires Python >=3.10. The log shows: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" The failure caused Poetry to exit with code 1 (\"##[error]Process completed with exit code 1\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version conflict (Python requirement)",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... version solving failed.\""
            },
            {
                "category": "Tooling Error",
                "subcategory": "Poetry dependency resolution failure",
                "evidence": "\"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" and the step ended with \"Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "84e31bc056e9eaa0c1becdfe54b83a286e8f7f60",
        "error_context": [
            "The run failed during dependency installation in the test_core job for Python 3.11. The workflow executed the step 'Install dependencies (mandatory only)' which runs `cd framework && python -m poetry install --all-extras`. Poetry's dependency resolver failed because a dependency (docstrfmt from a git requirement) requires Python >=3.10 while the project's declared python range is >=3.9.2,<4.0.0, causing an incompatibility. The log shows: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" As a result poetry exited with a non-zero status and the job stopped (\"##[error]Process completed with exit code 1\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version conflict / solver failure",
                "evidence": "Poetry resolver failed: \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python version constraint mismatch",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with... docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only) [matrix python=3.11] (log step: 'Python 3.11')",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "86db86b098312d07dab695eaa4b4271db680bdde",
        "error_context": [
            "The CI run failed during dependency installation for the framework package. In the job matrix entry for Python 3.9 (job test_core, displayed as \"Python 3.9\") the step that runs the install command (workflow step: \"Install dependencies (mandatory only)\"; logged as the grouped step \"Run cd framework\") executed: `cd framework` then `python -m poetry install --all-extras`. Tooling setup completed successfully (Python 3.9.25, pip/setuptools/poetry installed), but Poetry's dependency resolver failed because the repository's declared Python range (\"The current project's supported Python range (>=3.9.2,<4.0.0)\") is incompatible with a required dependency: docstrfmt (referenced as docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2) which \"requires Python >=3.10\". The resolver therefore aborted and the step exited with code 1. Evidence: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution failure (unsupported Python requirement)",
                "evidence": "\"Because flwr depends on docstrfmt (1.11.2.dev0) ... which requires Python >=3.10, version solving failed.\" and \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python version mismatch (CI matrix vs. dependency requirements)",
                "evidence": "Bootstrapped environment uses Python 3.9.25 (matrix entry python: '3.9'); Poetry reports project range >=3.9.2,<4.0.0 but a dependency requires >=3.10 (\"docstrfmt requires Python >=3.10\")."
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.9)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework\npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "8a8959d836d95b54695e0f2b4132556e688872e9",
        "error_context": [
            "The CI run failed during dependency installation in the test_core matrix job for Python 3.9. In the 'Bootstrap' step the runner set up CPython 3.9.25 and installed Poetry, then the 'Install dependencies (mandatory only)' step executed: cd framework && python -m poetry install --all-extras. Poetry's resolver failed because one required dependency (docstrfmt from a git URL) requires Python >=3.10 while the project's declared Python compatibility is >=3.9.2,<4.0.0. Log evidence: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" As a result poetry install exited with code 1 and the job terminated."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version solving failed / incompatible dependency Python requirement",
                "evidence": "\"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" and \"docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python interpreter version mismatch with dependency requirements",
                "evidence": "Runner set up CPython 3.9.25 (\"Successfully set up CPython (3.9.25)\") but dependency docstrfmt requires Python >=3.10, causing the resolver to fail."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "ea55aa9f13ecb43c792a378936eb48a225e8330d",
        "error_context": [
            "The CI run failed during dependency installation: in the job 'test_core' (matrix variant 'Python 3.11'), the step 'Install dependencies (mandatory only)' executed the command 'cd framework' followed by 'python -m poetry install --all-extras' and Poetry's dependency resolver aborted with exit code 1. Poetry reported a Python-version compatibility problem: the project's declared Python range (>=3.9.2,<4.0.0) is not compatible with a required package (docstrfmt) that requires Python >=3.10, causing version solving to fail. Relevant log evidence: 'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10 ... Because flwr depends on docstrfmt ... version solving failed.'"
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version mismatch / Dependency resolution failure",
                "evidence": "'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible ... - docstrfmt requires Python >=3.10 ... Because flwr depends on docstrfmt ... version solving failed.' (poetry install output)"
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework\npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "400210e75eb50de8e943cb5977feac67f11f19ee",
        "error_context": [
            "The run failed during the dependency installation step: in the test_core job (matrix variant Python 3.12) the workflow ran the step 'Install dependencies (mandatory only)' which executes: 'cd framework' and 'python -m poetry install --all-extras'. Poetry's dependency resolver reported a Python-compatibility conflict: the project declares a supported Python range of \">=3.9.2,<4.0.0\" while the required dependency docstrfmt (1.11.2.dev0 from git+https://github.com/charlesbvll/docstrfmt.git@patch-2) requires Python \">=3.10\". Poetry treats this as a constraint conflict (the project range includes versions <3.10), and the solver failed with 'version solving failed' and the job exited with code 1. Log evidence: 'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible ... - docstrfmt requires Python >=3.10 ... Because flwr depends on docstrfmt ... version solving failed.'"
        ],
        "relevant_files": [
            {
                "file": "framework",
                "line_number": null,
                "reason": "The failing command ('python -m poetry install --all-extras') was executed in the 'framework' directory and the dependency resolution failure arises from the project's dependency configuration located in that directory (poetry/pyproject configuration)."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible Python requirement / Version solving failed",
                "evidence": "'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10' and 'Because flwr depends on docstrfmt ... version solving failed.'"
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "c630d0834851b8fe85418f81832cd882fd1935e6",
        "error_context": [
            "The CI run failed during dependency installation: in the test_core job (matrix Python 3.11) the step 'Install dependencies (mandatory only)' ran `cd framework && python -m poetry install --all-extras` and Poetry's dependency resolver failed. Poetry reported a Python-version incompatibility between the project's declared Python range and a required package: the project supports Python >=3.9.2,<4.0.0 while the required dependency docstrfmt (1.11.2.dev0 from a git URL) requires Python >=3.10. Because the project's declared range includes <3.10, the solver refused to select docstrfmt and terminated with a non-zero exit (\"Process completed with exit code 1\"). The failure originates from dependency resolution (Poetry) rather than a test or runtime error."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility / resolver failure",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n        python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "9a33917c9a45784ad93afd7f6e37f611da9c99c8",
        "error_context": [
            "The CI run failed during dependency installation: in the job 'test_core' (matrix Python 3.10 / step name shown as 'Python 3.10') the workflow ran the 'Install dependencies (mandatory only)' step which executes `cd framework` and `python -m poetry install --all-extras`. Poetry's dependency resolver failed because the project's declared Python compatibility (\"The current project's supported Python range (>=3.9.2,<4.0.0)\") is incompatible with a required dependency: flwr depends on docstrfmt (from git+https://github.com/charlesbvll/docstrfmt.git@patch-2) which requires Python >=3.10. Poetry reports: \"docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\" and therefore \"version solving failed.\" The bootstrap step prepared Python and installed Poetry successfully, but the failure occurs when resolving project dependencies in the 'Install dependencies' step, causing the process to exit with code 1 (\"##[error]Process completed with exit code 1.\")."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution failure",
                "evidence": "\"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" (poetry resolver output) and \"Process completed with exit code 1.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Python version constraint mismatch",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible ... docstrfmt requires Python >=3.10\" (poetry suggests setting the `python` property to \">=3.10,<4.0.0\")."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "8d4c6c02bc23f0dd035e3c418354483209c2fdd5",
        "error_context": [
            "The CI run failed during the 'Install dependencies (mandatory only)' step when executing 'cd framework' and 'python -m poetry install --all-extras'. Poetry's dependency resolver aborted with a Python-version constraint conflict: the project's declared Python range is \">=3.9.2,<4.0.0\" while a required dependency (docstrfmt from a git URL) requires Python >=3.10. Poetry reports that docstrfmt \"requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\" and therefore \"version solving failed.\" This prevented dependency installation and caused the job to exit with code 1.",
            "The failure is rooted in dependency metadata/constraints, not an interpreter runtime error: the job did set up Python 3.12.12 successfully, but Poetry enforces compatibility between the project's declared python constraint and each dependency's python requirement (so a dependency requiring >=3.10 conflicts with a project constraint that allows <3.10). The log suggests fixing either the project's or the dependency's python markers (for example, setting docstrfmt's 'python' property to \">=3.10,<4.0.0\" or adjusting the project's python constraint)."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility / dependency constraint conflict",
                "evidence": "Poetry output: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt (...) which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "920aee334a4ef0aa9a6f18b7e8bc24eb8a2935ab",
        "error_context": [
            "The job prepared the runner, checked out commit 920aee3 and successfully set up Python (3.10.19), pip, setuptools and Poetry, but failed when installing project dependencies. In the test_core job (matrix Python 3.10) the step 'Install dependencies (mandatory only)' ran the command 'cd framework && python -m poetry install --all-extras' and Poetry failed during dependency resolution. Poetry reported a Python version constraint conflict: the project declares a supported Python range (>=3.9.2,<4.0.0) that is incompatible with the pinned docstrfmt dependency (docstrfmt @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2) which requires Python >=3.10, resulting in 'version solving failed' and exit code 1. The log suggests adjusting the dependency's python property (for example to \">=3.10,<4.0.0\") as a possible fix."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version constraint / version solving failure",
                "evidence": "Poetry output: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "9b84fef89d4e9699ab11407f416734ff9888d369",
        "error_context": [
            "The CI run failed during dependency installation in the test_core job (matrix Python 3.12). The bootstrap step succeeded: actions/setup-python set up CPython 3.12.12 and poetry 2.1.3 was installed. Failure occurred in the step named \"Install dependencies (mandatory only)\" which runs: \"cd framework; python -m poetry install --all-extras\". Poetry's resolver aborted with a Python version compatibility error: the log shows \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement\" and specifically \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" As a result poetry exited with code 1 and the job failed. In short: dependency resolution failed because a required package (docstrfmt from a git dependency) requires Python >=3.10 which is incompatible with the project's declared Python constraint as evaluated by Poetry, causing \"version solving failed.\""
        ],
        "relevant_files": [
            {
                "file": "framework",
                "line_number": null,
                "reason": "The failing command was executed in this directory: the CI ran \"cd framework && python -m poetry install --all-extras\" and the poetry resolver error originated while resolving dependencies declared for the project in this directory; the log references the git dependency URL for docstrfmt (git+https://github.com/charlesbvll/docstrfmt.git@patch-2) which caused the failure."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Dependency resolution / Python version mismatch",
                "evidence": "\"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\" and \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement\" (poetry dependency resolver output)."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n        python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "621a90505d9c13df181bad537161fbc09e4eeb8e",
        "error_context": [
            "The CI run failed because the 'Install dependencies (mandatory only)' step (executed in the 'Python 3.12' job) ran `python -m poetry install --all-extras` inside the framework directory and the Poetry dependency resolver reported a Python-version incompatibility. The resolver output states the project's supported Python range as \">=3.9.2,<4.0.0\" and indicates that the dependency docstrfmt (referenced as git+https://github.com/charlesbvll/docstrfmt.git@patch-2, version 1.11.2.dev0) \"requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\"; consequently, version solving failed and the step exited with code 1 (\"##[error]Process completed with exit code 1.\"). The failure is a dependency-resolution/configuration error (Poetry) triggered during the 'Install dependencies' step; no later steps ran because the job terminated on this non-zero exit."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility (poetry dependency resolution)",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.\""
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.12)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "c0e5991e35d5158e3c0e2c99433bd3657cf8ef72",
        "error_context": [
            "The CI run failed during the 'Install dependencies (mandatory only)' step of the test_core job running Python 3.9. The step executed poetry install in the framework directory (cd framework; python -m poetry install --all-extras). Poetry's dependency resolver failed because the project metadata restricts the project's Python range to \">=3.9.2,<4.0.0\" while one required package, docstrfmt (pulled from git+https://github.com/charlesbvll/docstrfmt.git@patch-2 and required by flwr), declares Python requirement \">=3.10\". As the log states: \"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\" The failing resolver caused Poetry to exit with code 1 and the job to fail."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Incompatible Python version requirement",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... - docstrfmt requires Python >=3.10\" and \"Because flwr depends on docstrfmt (1.11.2.dev0) @ git+https://github.com/charlesbvll/docstrfmt.git@patch-2 which requires Python >=3.10, version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "CI/runtime Python version incompatible with dependency",
                "evidence": "Job used Python 3.9 (actions/setup-python set up CPython 3.9.25) while a required dependency requires Python >=3.10, causing the resolver failure: see \"docstrfmt requires Python >=3.10\"."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \npython -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "b869aa8f51e9ad6d0cfe1f20ca04fdb6da899d3d",
        "error_context": [
            "The CI run failed during dependency installation in the test_core job for Python 3.11. In the step 'Install dependencies (mandatory only)' (run: `cd framework && python -m poetry install --all-extras`) Poetry's dependency resolver failed because of a Python-version requirement mismatch: the project declares a supported Python range of \">=3.9.2,<4.0.0\" while the dependency docstrfmt (referenced as 1.11.2.dev0 from git+https://github.com/charlesbvll/docstrfmt.git@patch-2) requires Python \">=3.10\". Poetry reports that \"docstrfmt requires Python >=3.10, so it will not be installable for Python >=3.9.2,<3.10\" and therefore \"version solving failed\", causing the step to exit with code 1. The earlier bootstrap/setup steps completed (Python 3.11 was installed and pip/setuptools/poetry were upgraded), so the failure is limited to dependency resolution/configuration rather than environment setup or test execution."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Version solver failure (Python requirement incompatibility)",
                "evidence": "\"The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible... docstrfmt requires Python >=3.10... Because flwr depends on docstrfmt ... version solving failed.\""
            },
            {
                "category": "Configuration Error",
                "subcategory": "Declared Python requirement mismatch in project metadata",
                "evidence": "Poetry suggests adjusting the project's `python` property (e.g. set to \">=3.10,<4.0.0\") because the project's declared range (>=3.9.2,<4.0.0) prevents installing docstrfmt which requires >=3.10."
            }
        ],
        "failed_job": [
            {
                "job": "test_core",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n        python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "126b95a3fee30cc2a6ee70466a83b772e4bf2379",
        "error_context": [
            "In the 'Install dependencies (mandatory only)' step of the test_core job (Python 3.11), the command 'cd framework && python -m poetry install --all-extras' failed because Poetry's dependency resolver encountered a Python-version compatibility conflict. The project's declared Python range is \">=3.9.2,<4.0.0\" while a required dependency, docstrfmt (1.11.2.dev0 from git+https://github.com/charlesbvll/docstrfmt.git@patch-2), requires Python >=3.10. The resolver output states: 'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible ... docstrfmt requires Python >=3.10' and 'Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.' Poetry aborted and the step exited with code 1, causing the job to fail."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "Python version incompatibility / resolver conflict",
                "evidence": "'The current project's supported Python range (>=3.9.2,<4.0.0) is not compatible with some of the required packages Python requirement: - docstrfmt requires Python >=3.10' and 'Because flwr depends on docstrfmt ... which requires Python >=3.10, version solving failed.'"
            }
        ],
        "failed_job": [
            {
                "job": "test_core (Python 3.11)",
                "step": "Install dependencies (mandatory only)",
                "command": "cd framework \n          python -m poetry install --all-extras"
            }
        ]
    },
    {
        "sha_fail": "d4983e10a38431417a7f4a3fb9848a9b46c291d4",
        "error_context": [
            "Two separate jobs failed in this run. In the tests (3.12) job, the test-collection step failed because importing the project's zep integration raised ImportError(s): libs/agno/agno/tools/zep.py attempted \"from zep_cloud.types import MemorySearchResult\" and the installed zep_cloud package did not expose that symbol (log: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' ...\"). While zep.py also raises an explicit helper ImportError recommending to install zep-cloud (log: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\"), the underlying cause is a mismatch or missing API in the installed zep_cloud package in the virtualenv, which aborts pytest collection (1 error during collection). Separately, in the style-check (3.9) job the linter step failed: ruff reported 36 \"invalid-syntax\" errors because code uses newer Python syntax (named assignment expression ':=' and parentheses in with) while ruff was checking for compatibility with older Python (log messages: \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Found 36 errors.\"). Both failures caused their jobs to exit non-zero (tests exited with code 2; style-check exited with code 1). Additionally, test collection produced several non-fatal warnings from a dependency (pydub) including SyntaxWarning, DeprecationWarning and a RuntimeWarning about missing ffmpeg \u2014 these do not appear to be the primary failure but indicate dependency warnings in the test environment."
        ],
        "relevant_files": [
            {
                "file": "libs/agno/tests/unit/tools/test_zep.py",
                "line_number": 5,
                "reason": "This test module failed to import during pytest collection (traceback shows import at line 5: \"from agno.tools.zep import ZepAsyncTools, ZepTools\"), and the import failed because agno.tools.zep raised ImportError due to zep_cloud issues."
            },
            {
                "file": "libs/agno/agno/tools/zep.py",
                "line_number": 12,
                "reason": "This module attempted \"from zep_cloud.types import MemorySearchResult\" (log: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types'\") and then raised an explicit ImportError instructing to install zep-cloud; it is the immediate source of the test import failure."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py",
                "line_number": null,
                "reason": "Log evidence explicitly references this installed file in the ImportError: the installed package's types/__init__.py does not provide MemorySearchResult (\"cannot import name 'MemorySearchResult' from 'zep_cloud.types' .../site-packages/zep_cloud/types/__init__.py\")."
            },
            {
                "file": ".venv/lib/python3.12/site-packages/pydub/utils.py",
                "line_number": null,
                "reason": "Multiple warnings during test collection originated here (SyntaxWarning for invalid escape sequences, DeprecationWarning for audioop, and RuntimeWarning about missing ffmpeg), indicating dependency warnings in the test environment though not the primary failure."
            },
            {
                "file": "agno/api/playground.py",
                "line_number": 66,
                "reason": "Ruff flagged invalid-syntax here: uses named assignment expression (walrus) and parentheses-in-with constructs not allowed under the checked Python compatibility (log: \"Cannot use named assignment expression (`:=`) on Python 3.7\" at line 66 and additional messages for lines 68 and 72)."
            },
            {
                "file": "agno/knowledge/website.py",
                "line_number": 90,
                "reason": "Ruff reported a walrus operator usage at line 90 (\"if document_list := self.reader.read(url=url):\") causing an invalid-syntax error under the configured compatibility target."
            },
            {
                "file": "agno/team/team.py",
                "line_number": 5078,
                "reason": "This file contains many occurrences of the walrus operator flagged by ruff across multiple locations (first reported at line 5078), contributing to the 36 linting errors."
            },
            {
                "file": "agno/tools/apify.py",
                "line_number": 281,
                "reason": "Ruff reported several walrus operator usages in this module (first flagged at line 281: \"if http_client := getattr(...)\") as invalid-syntax under the enforced Python compatibility."
            },
            {
                "file": "agno/tools/function.py",
                "line_number": 119,
                "reason": "Ruff flagged walrus usage here (line 119: \"if docstring := getdoc(c):\") and again at line 206, contributing to the style-check failure."
            }
        ],
        "error_types": [
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: missing symbol / wrong package version",
                "evidence": "pytest collection failed with: \"ImportError: cannot import name 'MemorySearchResult' from 'zep_cloud.types' (/.../.venv/lib/python3.12/site-packages/zep_cloud/types/__init__.py)\" indicating installed zep_cloud lacks the expected symbol or API."
            },
            {
                "category": "Dependency Error",
                "subcategory": "Missing dependency (install suggestion)",
                "evidence": "agno/tools/zep.py raised: \"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\" which was shown in the pytest traceback and caused test collection to abort."
            },
            {
                "category": "Code Formatting / Linting",
                "subcategory": "Ruff: invalid-syntax due to newer Python syntax (walrus, with-parens)",
                "evidence": "Ruff reported many errors like: \"Cannot use named assignment expression (`:=`) on Python 3.7\" and \"Cannot use parentheses within a `with` statement on Python 3.7\" and concluded with \"Found 36 errors.\""
            },
            {
                "category": "Runtime Warning / Dependency Warning",
                "subcategory": "SyntaxWarning / DeprecationWarning / RuntimeWarning from dependency",
                "evidence": "During pytest collection pydub emitted warnings: \"SyntaxWarning: invalid escape sequence '\\('\" (multiple lines), \"DeprecationWarning: 'audioop' is deprecated...\" and \"RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg\"."
            }
        ],
        "failed_job": [
            {
                "job": "tests",
                "step": "tests (3.12) / Run tests for Agno",
                "command": "source .venv/bin/activate\n          python -m pytest --cov=agno --cov-report=json:coverage-agno.json ./libs/agno/tests/unit\n          echo \"AGNO_COVERAGE=$(python -c 'import json; print(json.load(open(\"coverage-agno.json\"))[\"totals\"][\"percent_covered_display\"])')\" >> $GITHUB_ENV"
            },
            {
                "job": "style-check",
                "step": "style-check (3.9) / Ruff check",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "00dff2ac803dca7ae44435c5dea311c633926b87",
        "error_context": [
            "The run failed in the Codespell job named \"Check for spelling errors\". The Codespell step (uses: codespell-project/actions-codespell@v2) terminated with the error \"Line terminator characters must be escaped inside string literals', 'U+000A'\", indicating the spelling-check action encountered an unescaped line terminator (U+000A, newline) inside a string literal while scanning repository files. No other steps are reported as failing in the provided logs."
        ],
        "relevant_files": [],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "Parse error: unescaped line terminator in string literal",
                "evidence": "\"Line terminator characters must be escaped inside string literals', 'U+000A'\" (error reported by the Codespell step)"
            }
        ],
        "failed_job": [
            {
                "job": "codespell",
                "step": "Codespell",
                "command": "uses: codespell-project/actions-codespell@v2"
            }
        ]
    },
    {
        "sha_fail": "3d7d985ce91cc390e39f97e000b2a9f1b2e62bfc",
        "error_context": [
            "The CI run failed because the ruff linter (step 'Run Ruff' in job 'ruff') found undefined-name linting errors in webui.py and exited with a non-zero status. The workflow successfully checked out the repository and set up Python (actions/checkout@v4 and actions/setup-python@v5) and the 'Install Ruff' step completed (pip installed ruff==0.3.3). Immediately after, the 'Run Ruff' step executed the command 'ruff check .' and ruff reported 13 F821 Undefined name `cmd_opts` errors in webui.py (e.g. \"webui.py:28:12: F821 Undefined name `cmd_opts`\", ... , \"webui.py:67:8: F821 Undefined name `cmd_opts`\") and the process finished with exit code 1, causing the job to fail."
        ],
        "relevant_files": [
            {
                "file": "webui.py",
                "line_number": 28,
                "reason": "Ruff reported 13 F821 'Undefined name `cmd_opts`' errors pointing to webui.py at multiple locations (first reported at webui.py:28:12 through webui.py:67:8), which directly caused the ruff step to exit with code 1."
            }
        ],
        "error_types": [
            {
                "category": "Code Quality",
                "subcategory": "Undefined name (linting) - F821",
                "evidence": "\"webui.py:28:12: F821 Undefined name `cmd_opts`\" (and 12 additional F821 messages); ruff summary: \"Found 13 errors.\" and the step ended with \"Process completed with exit code 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "ruff",
                "step": "Run Ruff",
                "command": "ruff check ."
            }
        ]
    },
    {
        "sha_fail": "ddaf3580c46184c957e4dc3a8e54e15808e67397",
        "error_context": [
            "The CI run failed in the 'linter' job when the jpetrucciani/mypy-check action executed mypy over the repository and returned type-checking errors. Docker image build and pip installation completed successfully, but mypy reported three type errors and exited with code 1, causing the job to fail. The three mypy errors are: (1) taipy/gui/page.py:82:24 \u2014 argument passed to Page.set_style is \"Any | None\" but mypy expects \"dict[str, dict[str, Any]]\"; (2) taipy/core/data/_file_datanode_mixin.py:50:27 \u2014 incompatible assignment where expression is \"Any | None\" assigned to a variable annotated as \"str\"; (3) taipy/core/data/excel.py:228:31 \u2014 attempting to index a value of type \"tuple[Any] | list[Any] | set[Any]\" which mypy reports as not indexable. Pip warnings about running as root were printed but are informational; the decisive failure is the mypy type-check failures reported by the action and summarized as \"Found 3 errors in 3 files (checked 1022 source files)\"."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 82,
                "reason": "mypy reported: \"taipy/gui/page.py:82:24: error: Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\" \u2014 this type mismatch caused the linter to fail."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 50,
                "reason": "mypy reported: \"taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\" \u2014 an assignment type error that contributed to the mypy failure."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 228,
                "reason": "mypy reported: \"taipy/core/data/excel.py:228:31: error: Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\" \u2014 an indexing/type error flagged by mypy that caused the linter to exit non-zero."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy arg-type mismatch",
                "evidence": "taipy/gui/page.py:82:24: error: Argument 1 to \"set_style\" of \"Page\" has incompatible type \"Any | None\"; expected \"dict[str, dict[str, Any]]\"  [arg-type]"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy assignment type mismatch",
                "evidence": "taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \"Any | None\", variable has type \"str\")  [assignment]"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy indexability error",
                "evidence": "taipy/core/data/excel.py:228:31: error: Value of type \"tuple[Any] | list[Any] | set[Any]\" is not indexable  [index]"
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "jpetrucciani/mypy-check@master",
                "command": "jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "3fd84eecb194505c88ae1d60e7c5c87ec24cea4c",
        "error_context": [
            "The CI run failed in the linter job when the jpetrucciani/mypy-check action ran mypy inside a Docker container and mypy returned type errors. The Docker image build and pip installs completed, but the mypy invocation produced three type-checking errors and the wrapper exited with code 1, failing the job. Evidence: the mypy run produced \"Found 3 errors in 3 files (checked 1021 source files)\" and the runner logged the three mypy error lines before exiting with \"Process completed with exit code 1.\" The failing step corresponds to the workflow step that uses jpetrucciani/mypy-check@master (the project's linter step)."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 82,
                "reason": "mypy reported: \"taipy/gui/page.py:82:24: error: Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\" \u2014 this type error was one of the three that caused the linter to fail."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 50,
                "reason": "mypy reported: \"taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\" \u2014 this assignment type mismatch contributed to the mypy failure."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 228,
                "reason": "mypy reported: \"taipy/core/data/excel.py:228:31: error: Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\" \u2014 this indexing/type error was included in the mypy errors that caused exit code 1."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy arg-type mismatch",
                "evidence": "\"Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\" (taipy/gui/page.py:82:24)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy assignment type mismatch",
                "evidence": "\"Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\" (taipy/core/data/_file_datanode_mixin.py:50:27)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy indexability/type error",
                "evidence": "\"Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\" (taipy/core/data/excel.py:228:31)"
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "linter",
                "command": "jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "a3ca770a503dde53f12bcbcaf6d3ef251e2c7b5a",
        "error_context": [
            "The CI run failed primarily because pytest aborted during collection due to missing Python modules in the test environment. In multiple 'overall-tests' and 'coverage' jobs pytest raised ModuleNotFoundError while importing tests/gui/e2e/renderers/test_html_rendering.py: \"E   ModuleNotFoundError: No module named 'taipy.gui.servers.fastapi'\" (tests/gui/e2e/renderers/test_html_rendering.py:25). This missing package/module caused pytest to report \"1 error during collection\" and exit with code 2 in those jobs (observed in coverage and overall-tests logs).",
            "A second, separate blocking failure appeared in several 'intermittent-tests' jobs: pytest failed to load tests/conftest.py because a third-party package attempted to import pkg_resources and pkg_resources was not available in the environment, producing: \"E   ModuleNotFoundError: No module named 'pkg_resources'\" (site-packages apispec_webframeworks/__init__.py). That caused a ConftestImportFailure and the job to exit (exit code 4).",
            "Other build output shows non-fatal but notable warnings: frontend/npm produced deprecation and vulnerability warnings and webpack emitted repeated \"WARNING in asset size limit\" messages about very large bundles (e.g., taipy-gui-deps.dll.js 4.89 MiB). Those frontend warnings did not cause the CI to fail but are recorded in the logs and may warrant attention."
        ],
        "relevant_files": [
            {
                "file": "tests/gui/e2e/renderers/test_html_rendering.py",
                "line_number": 25,
                "reason": "Test module that triggered the fatal import error during pytest collection; log shows the failing import at this file/line: \"tests/gui/e2e/renderers/test_html_rendering.py:25: in <module>     from taipy.gui.servers.fastapi import _FastAPIServer\" and pytest reported ERROR collecting this file."
            },
            {
                "file": "taipy/gui/servers/fastapi.py",
                "line_number": null,
                "reason": "Module path referenced by the failing import; Python raised \"ModuleNotFoundError: No module named 'taipy.gui.servers.fastapi'\", indicating this module/file is missing or not importable in the test environment."
            },
            {
                "file": "tests/conftest.py",
                "line_number": 17,
                "reason": "Conftest import that failed in intermittent-tests jobs; log shows \"ImportError while loading conftest '/home/runner/work/taipy/taipy/tests/conftest.py'\" and the traceback begins at tests/conftest.py:17 which triggers the taipy import chain that ends in the missing 'pkg_resources'."
            },
            {
                "file": ".local/share/virtualenvs/taipy-SKi803WO/lib/python3.12/site-packages/apispec_webframeworks/__init__.py",
                "line_number": 1,
                "reason": "Site-packages module that attempted to import pkg_resources and raised the ModuleNotFoundError: logs show \"...site-packages/apispec_webframeworks/__init__.py:1: in <module> import pkg_resources\" followed by \"E   ModuleNotFoundError: No module named 'pkg_resources'\"."
            },
            {
                "file": "taipy/rest/commons/apispec.py",
                "line_number": 15,
                "reason": "Repository module that imports apispec_webframeworks (the site-package that tried to import pkg_resources). The traceback shows this file's import: \"taipy/rest/commons/apispec.py:15: in <module>     from apispec_webframeworks.flask import FlaskPlugin\" \u2014 linking project imports to the failing third-party import."
            },
            {
                "file": "taipy/rest/api/schemas/datanode.py",
                "line_number": 99,
                "reason": "Emitted a Marshmallow deprecation warning during test collection: log shows \"/home/runner/work/taipy/taipy/taipy/rest/api/schemas/datanode.py:99: RemovedInMarshmallow4Warning: The 'default' argument to fields is deprecated. Use 'dump_default' instead.\" \u2014 a notable warning observed in the pytest warnings summary."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "ImportError: No module named 'taipy.gui.servers.fastapi'",
                "evidence": "\"E   ModuleNotFoundError: No module named 'taipy.gui.servers.fastapi'\" (traceback from tests/gui/e2e/renderers/test_html_rendering.py:25); pytest reported \"ERROR collecting tests/gui/e2e/renderers/test_html_rendering.py\" and \"Interrupted: 1 error during collection\"."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ImportError: No module named 'pkg_resources'",
                "evidence": "\"E   ModuleNotFoundError: No module named 'pkg_resources'\" from site-packages apispec_webframeworks/__init__.py during conftest import, recorded as ConftestImportFailure and causing exit code 4."
            },
            {
                "category": "Test Failure",
                "subcategory": "Pytest collection aborted due to import error",
                "evidence": "Pytest summary lines: \"collected 2682 items / 1 error\" and \"!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\" (also ConftestImportFailure entries in intermittent-tests)."
            },
            {
                "category": "Configuration/Build Warning",
                "subcategory": "Webpack asset size limit / large frontend bundles",
                "evidence": "\"WARNING in asset size limit: The following asset(s) exceed the recommended size limit (244 KiB) ... taipy-gui-deps.dll.js (4.89 MiB)\" and similar warnings for taipy-gui.js (1.23 MiB) and taipy-gui-core.js (901 KiB)."
            },
            {
                "category": "Dependency Warning",
                "subcategory": "Marshmallow deprecation (RemovedInMarshmallow4Warning)",
                "evidence": "\"taipy/rest/api/schemas/datanode.py:99: RemovedInMarshmallow4Warning: The 'default' argument to fields is deprecated. Use 'dump_default' instead.\" in pytest warnings summary."
            },
            {
                "category": "Dependency Warning",
                "subcategory": "npm package deprecations / vulnerabilities",
                "evidence": "npm logs: multiple deprecation warnings (e.g., \"npm WARN deprecated inflight@1.0.6\") and \"7 vulnerabilities (2 low, 2 moderate, 2 high, 1 critical)\" reported by npm audit during frontend install."
            }
        ],
        "failed_job": [
            {
                "job": "coverage",
                "step": "Pytest with coverage",
                "command": "python -m pip install xmltodict\npipenv run pytest \\\n  --cov=taipy \\\n  --cov-report=xml:${{ github.workspace }}/coverage.xml \\\n  --cov-config=.coveragerc"
            },
            {
                "job": "overall-tests",
                "step": "Pytest",
                "command": "pipenv run pytest -m \"not orchestrator_dispatcher and not standalone and not teste2e\" tests"
            },
            {
                "job": "intermittent-tests",
                "step": "Pytest Core orchestrator/standalone",
                "command": "pipenv run pytest -m \"${{ matrix.orchestrator }}\" tests/core"
            }
        ]
    },
    {
        "sha_fail": "c273eb3e3940b427136144b6ce5e20dbc2d0c61c",
        "error_context": [
            "The CI run failed in the 'linter' job when the jpetrucciani/mypy-check action executed mypy inside a Docker container and returned a non-zero exit code. Mypy reported three static type errors in three source files and the action exited with code 1 ('+ exit 1' and 'Process completed with exit code 1'), which caused the linter job to fail. The workflow is configured so other jobs (e.g., tests and coverage) depend on the linter ('needs: linter'), so those downstream jobs would not proceed until the linter errors are resolved. The Docker image build emitted only warnings about running pip as root (non-fatal), but the explicit failure reason in the logs is the mypy errors: (1) taipy/gui/page.py:79:24 argument type mismatch, (2) taipy/core/data/_file_datanode_mixin.py:50:27 incompatible assignment, and (3) taipy/core/data/excel.py:228:31 non-indexable type; mypy summary: 'Found 3 errors in 3 files (checked 1019 source files)'."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 79,
                "reason": "Mypy reported: 'taipy/gui/page.py:79:24: error: Argument 1 to \"set_style\" of \"Page\" has incompatible type \"Any | None\"; expected \"dict[str, dict[str, Any]]\"' \u2014 this type mismatch caused the linter to fail."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 50,
                "reason": "Mypy reported: 'taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \"Any | None\", variable has type \"str\")' \u2014 this incompatible assignment contributed to the mypy failure."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 228,
                "reason": "Mypy reported: 'taipy/core/data/excel.py:228:31: error: Value of type \"tuple[Any] | list[Any] | set[Any]\" is not indexable' \u2014 this indexing error caused the linter to exit non-zero."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy: arg-type mismatch",
                "evidence": "taipy/gui/page.py:79:24: 'Argument 1 to \"set_style\" of \"Page\" has incompatible type \"Any | None\"; expected \"dict[str, dict[str, Any]]\"' (mypy output)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy: incompatible assignment",
                "evidence": "taipy/core/data/_file_datanode_mixin.py:50:27: 'Incompatible types in assignment (expression has type \"Any | None\", variable has type \"str\")' (mypy output)"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy: not indexable (index)",
                "evidence": "taipy/core/data/excel.py:228:31: 'Value of type \"tuple[Any] | list[Any] | set[Any]\" is not indexable' (mypy output)"
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "linter",
                "command": "uses: jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "cdf9f086ec5f4d14cffb2531a64d3361b995afa3",
        "error_context": [
            "The CI run failed because the ruff linter step returned a non-zero exit code due to linting errors in taipy/gui/gui.py. In the linter job, the mypy step (jpetrucciani/mypy-check@master) completed successfully ('Success: no issues found in 1030 source files'), but the subsequent ruff action (astral-sh/ruff-action@v3) reported two I001 errors: 'taipy/gui/gui.py:12:1: I001 Import block is un-sorted or un-formatted' and 'taipy/gui/gui.py:44:1: I001 Import block is un-sorted or un-formatted'. Because the ruff process exited with code 1 ('The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1'), the overall linter job failed and blocked downstream jobs that have 'needs: linter'. Warnings from docker/pip about running pip as root were present during the mypy container build but did not cause the job to fail."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/gui.py",
                "line_number": 12,
                "reason": "Ruff lint reported import-block formatting/sorting errors in this file at lines 12 and 44: 'taipy/gui/gui.py:12:1: I001 Import block is un-sorted or un-formatted' and 'taipy/gui/gui.py:44:1: I001 Import block is un-sorted or un-formatted', which caused the ruff action to exit with code 1 and fail the linter job."
            }
        ],
        "error_types": [
            {
                "category": "Code Formatting",
                "subcategory": "Import block unsorted / unformatted (ruff I001)",
                "evidence": "'taipy/gui/gui.py:12:1: I001 Import block is un-sorted or un-formatted' and 'taipy/gui/gui.py:44:1: I001 Import block is un-sorted or un-formatted' \u2014 ruff returned these errors and exited with code 1."
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "astral-sh/ruff-action@v3",
                "command": "uses: astral-sh/ruff-action@v3"
            }
        ]
    },
    {
        "sha_fail": "4899d129d4d129f0036cde2591068fe0be05940c",
        "error_context": [
            "The CI run failed in the 'linter' job when the mypy static type-checker (jpetrucciani/mypy-check@master) reported type errors and returned a non-zero exit code. The docker image build and dependency installation succeeded (pip installed mypy 1.19.0), but the mypy invocation produced three errors and the wrapper exited with code 1. Evidence: \"mypy 1.19.0... Found 3 errors in 3 files (checked 1020 source files)\" and the job ended with \"Process completed with exit code 1.\" The three failing locations are taipy/gui/page.py:79:24, taipy/core/data/_file_datanode_mixin.py:50:27, and taipy/core/data/excel.py:228:31 (mypy messages shown in the log). No runtime exceptions were reported \u2014 the failure is solely due to static type-checking errors raised by mypy."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 79,
                "reason": "Mypy reported an argument type mismatch: \"Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\" (log: \"taipy/gui/page.py:79:24: error: Argument 1 to \\\"set_style\\\" ... expected \\\"dict[str, dict[str, Any]]\\\"\")."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 50,
                "reason": "Mypy reported an incompatible assignment where the expression has type \"Any | None\" but the variable is typed as \"str\": \"Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\" (log: \"taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment...\")."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 228,
                "reason": "Mypy reported an indexing error: value has type \"tuple[Any] | list[Any] | set[Any]\" which is not indexable (log: \"taipy/core/data/excel.py:228:31: error: Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\")."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy arg-type",
                "evidence": "\"taipy/gui/page.py:79:24: error: Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"  [arg-type]\""
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy assignment",
                "evidence": "\"taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")  [assignment]\""
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy index",
                "evidence": "\"taipy/core/data/excel.py:228:31: error: Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable  [index]\""
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "linter",
                "command": "uses: jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "20818c9421971770b2427059b1abb47fa1139dd8",
        "error_context": [
            "The CI run failed in the 'linter' job. The mypy-check step (jpetrucciani/mypy-check@master) completed successfully ('Success: no issues found in 1023 source files'), but the ruff lint step (astral-sh/ruff-action@v3) reported a lint error and exited non\u2011zero. Specifically, ruff found an unused import (F401) in tests/gui/config/test_filename.py at line 14: 'tests/gui/config/test_filename.py:14:8: F401 `pytest` imported but unused', and the ruff process then exited with code 1 ('The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1'), causing the linter job to fail. Pip warnings printed during the mypy Docker image build ('WARNING: Running pip as the 'root' user ...') are non-fatal warnings and did not cause the failure."
        ],
        "relevant_files": [
            {
                "file": "tests/gui/config/test_filename.py",
                "line_number": 14,
                "reason": "Ruff reported an unused import at this location: 'tests/gui/config/test_filename.py:14:8: F401 `pytest` imported but unused' \u2014 this lint error directly caused the ruff step to exit with code 1."
            },
            {
                "file": "opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff",
                "line_number": null,
                "reason": "The ruff binary invocation is the process that failed according to the log: 'The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1' \u2014 indicating the linter run terminated non-zero."
            }
        ],
        "error_types": [
            {
                "category": "Linting",
                "subcategory": "Unused Import (F401)",
                "evidence": "'tests/gui/config/test_filename.py:14:8: F401 `pytest` imported but unused' and subsequent 'The process ... ruff ... failed with exit code 1' in the linter logs."
            },
            {
                "category": "Configuration Warning",
                "subcategory": "Pip running as root warning",
                "evidence": "During the Docker image build: 'WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager.' (non-fatal warning logged twice)."
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "astral-sh/ruff-action@v3",
                "command": "/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff check /home/runner/work/taipy/taipy"
            }
        ]
    },
    {
        "sha_fail": "b5b54cbf726cd33c340b07aa946441330211adf7",
        "error_context": [
            "The CI run failed in the 'linter' job when the mypy-check action reported type-checking errors and exited with a non-zero status. The workflow ran the jpetrucciani/mypy-check action (Docker image built successfully), then invoked mypy which returned three errors and caused the action to exit 1 (log: \"Found 3 errors in 3 files ...\" and \"Process completed with exit code 1\"). The failing mypy invocation produced GitHub Actions annotations for three issues: an argument-type mismatch in taipy/gui/page.py, an assignment type mismatch in taipy/core/data/_file_datanode_mixin.py, and an indexing error in taipy/core/data/excel.py. Because the linter job failed at the mypy step, subsequent linter steps (the ruff action) did not complete within this job."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 77,
                "reason": "Mypy reported an argument type error at taipy/gui/page.py:77:24: \"Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\", which is one of the three errors that caused the linter job to fail."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 42,
                "reason": "Mypy reported an assignment type mismatch at taipy/core/data/_file_datanode_mixin.py:42:27: \"Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\", included in the mypy failure summary."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 226,
                "reason": "Mypy reported an indexing error at taipy/core/data/excel.py:226:31: \"Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\", which contributed to the mypy exit code 1."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy arg-type",
                "evidence": "taipy/gui/page.py:77:24: error: Argument 1 to \"set_style\" of \"Page\" has incompatible type \"Any | None\"; expected \"dict[str, dict[str, Any]]\"  [arg-type]"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy assignment",
                "evidence": "taipy/core/data/_file_datanode_mixin.py:42:27: error: Incompatible types in assignment (expression has type \"Any | None\", variable has type \"str\")  [assignment]"
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy index",
                "evidence": "taipy/core/data/excel.py:226:31: error: Value of type \"tuple[Any] | list[Any] | set[Any]\" is not indexable  [index]"
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "linter",
                "command": "jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "8a61f4402a4fd7090ef45c3937b1ad8e272bac42",
        "error_context": [
            "The CI run failed in the linter job when the jpetrucciani/mypy-check action executed mypy and reported type-checking errors. Docker image build and dependency installation succeeded, but the mypy invocation returned exit code 1 after reporting three errors across three files, causing the job to fail. Evidence: the mypy output shows \"Found 3 errors in 3 files (checked 1023 source files)\" and the workflow emitted error lines matching the mypy messages, followed by \"Process completed with exit code 1.\" The failing step was the mypy-check action run inside the 'linter' job (mypy flagged argument type mismatch, incompatible assignment, and non-indexable value errors in taipy/gui/page.py, taipy/core/data/_file_datanode_mixin.py, and taipy/core/data/excel.py)."
        ],
        "relevant_files": [
            {
                "file": "taipy/gui/page.py",
                "line_number": 82,
                "reason": "Mypy reported an argument type mismatch at this line: \"Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"\" \u2014 this directly caused the linter failure."
            },
            {
                "file": "taipy/core/data/_file_datanode_mixin.py",
                "line_number": 50,
                "reason": "Mypy reported an incompatible assignment at this line: \"Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")\" \u2014 this type error contributed to the mypy failure."
            },
            {
                "file": "taipy/core/data/excel.py",
                "line_number": 228,
                "reason": "Mypy reported an indexing error at this line: \"Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable\" \u2014 this error was included in the mypy summary that caused the job to exit nonzero."
            }
        ],
        "error_types": [
            {
                "category": "Type Checking",
                "subcategory": "Mypy type mismatch (arg-type)",
                "evidence": "\"taipy/gui/page.py:82:24: error: Argument 1 to \\\"set_style\\\" of \\\"Page\\\" has incompatible type \\\"Any | None\\\"; expected \\\"dict[str, dict[str, Any]]\\\"  [arg-type]\""
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy incompatible assignment",
                "evidence": "\"taipy/core/data/_file_datanode_mixin.py:50:27: error: Incompatible types in assignment (expression has type \\\"Any | None\\\", variable has type \\\"str\\\")  [assignment]\""
            },
            {
                "category": "Type Checking",
                "subcategory": "Mypy indexing error (non-indexable value)",
                "evidence": "\"taipy/core/data/excel.py:228:31: error: Value of type \\\"tuple[Any] | list[Any] | set[Any]\\\" is not indexable  [index]\""
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "linter",
                "command": "jpetrucciani/mypy-check@master"
            }
        ]
    },
    {
        "sha_fail": "549382b1baf446a2e789444f0dce626d9f13b4d1",
        "error_context": [
            "The CI 'linter' job failed during the ruff linting step. Mypy completed successfully (\"Success: no issues found in 944 source files\"), but the astral-sh/ruff-action@v3 run returned a lint violation and exited non-zero. Ruff reported a T201 violation (use of print) in tools/frontend/bundle_build.py at line 45 column 9 (\"##[error]tools/frontend/bundle_build.py:45:9: T201 `print` found\"), and the ruff process exited with code 1 (\"##[error]The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1\"). Because the ruff action returned a non-zero exit code, the linter job failed and blocked downstream jobs that depend on linter."
        ],
        "relevant_files": [
            {
                "file": "tools/frontend/bundle_build.py",
                "line_number": 45,
                "reason": "Ruff reported a T201 lint error at this exact location: \"tools/frontend/bundle_build.py:45:9: T201 `print` found\", identifying the offending print call that caused the linter to fail."
            },
            {
                "file": "/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff",
                "line_number": null,
                "reason": "The ruff binary executed the failing command and exited with a non-zero code: \"The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1\", which caused the linter job to fail."
            }
        ],
        "error_types": [
            {
                "category": "Code Linting",
                "subcategory": "T201 `print` found (ruff rule)",
                "evidence": "\"##[error]tools/frontend/bundle_build.py:45:9: T201 `print` found\""
            },
            {
                "category": "Tool / Action Failure",
                "subcategory": "Linter returned non-zero exit code",
                "evidence": "\"##[error]The process '/opt/hostedtoolcache/ruff/0.6.4/x86_64/ruff' failed with exit code 1\""
            }
        ],
        "failed_job": [
            {
                "job": "linter",
                "step": "astral-sh/ruff-action@v3",
                "command": "astral-sh/ruff-action@v3"
            }
        ]
    },
    {
        "sha_fail": "de825fa299b6673c2a06f342a85fb0a99ca17803",
        "error_context": [
            "Primary test failures: Several CI jobs ran pytest and two template-related tests repeatedly failed: tests/templates/test_scenario_mgt_template.py::test_scenario_management_with_toml_config and ::test_scenario_management_without_toml_config. In those failures the test helper executed the cookiecutter-generated application main.py and the run aborted with ImportError: \"attempted relative import with no known parent package\". Log evidence: captured traceback shows \"File \\\"/tmp/pytest-of-runner/.../foo_app/main.py\\\", line 15, in <module\\n    from .config.config import configure\\nImportError: attempted relative import with no known parent package\" causing stdout to be empty and assertions expecting Taipy INFO messages to fail.",
            "Dependency / collection failures in some runs: In other job variants (notably python 3.12 partial and intermittent runs) pytest failed early during collection because a third-party package attempted to import pkg_resources and that import raised ModuleNotFoundError: No module named 'pkg_resources'. Log evidence: import chain from tests/conftest.py into taipy/rest/... -> apispec_webframeworks.__init__.py which does \"import pkg_resources\" and raised \"ModuleNotFoundError: No module named 'pkg_resources'\", aborting pytest (exit code 4).",
            "Warnings and ancillary issues: The logs show many non-fatal warnings that were recorded during the runs and may be maintenance items: CoverageWarning due to a non-Python file under templates (couldn't parse taipy/templates/default/{{cookiecutter.__root_folder}}/.gitignore), marshmallow deprecation (taipy/rest/api/schemas/datanode.py:99 warns about 'default' argument), many TaipyGuiWarnings (e.g. AttributeError in WebSocket broadcast: \"'Gui' object has no attribute '_server'\"), and webpack frontend build performance warnings (large bundle sizes). These are present in the logs but are not the direct cause of the failing assertions; they are recorded as evidence for follow-up fixes.",
            "Steps involved: In the workflow the failing commands are test runs executed by several steps: coverage -> step 'Pytest with coverage' (runs pipenv run pytest with --cov), partial-tests -> conditional step(s) e.g. 'Pytest Templates' (runs pipenv run pytest tests/templates) and 'Pytest Common' (runs pipenv run pytest tests/common), overall-tests -> step 'Pytest' (runs pipenv run pytest -m \"not orchestrator_dispatcher and not standalone and not teste2e\" tests), and intermittent-tests -> step 'Pytest Core orchestrator/standalone' (runs pipenv run pytest -m \"${{ matrix.orchestrator }}\" tests/core). The template ImportError failures appear when those steps run the templates tests; the pkg_resources ModuleNotFoundError appears during pytest collection in some jobs when the test import chain pulls in apispec_webframeworks which imports pkg_resources."
        ],
        "relevant_files": [
            {
                "file": "tests/templates/test_scenario_mgt_template.py",
                "line_number": 47,
                "reason": "This test file contains the two failing assertions. Logs show two failures referencing this file (AssertionError at lines 47 and 79) and captured stdout blocks from the test runs."
            },
            {
                "file": "tmp/pytest-of-runner/.../foo_app/main.py",
                "line_number": 15,
                "reason": "Generated application main.py executed by the tests raised the runtime ImportError: the traceback points to line 15 where the file does \"from .config.config import configure\" and fails with \"attempted relative import with no known parent package\", preventing expected startup output."
            },
            {
                "file": "tests/conftest.py",
                "line_number": 17,
                "reason": "Test collection/import entry point that triggered the failing import chain in some jobs. Logs show \"ImportError while loading conftest '/home/runner/.../tests/conftest.py'\" and the import at line 17 started the chain leading to ModuleNotFoundError for pkg_resources."
            },
            {
                "file": "home/runner/.local/share/virtualenvs/taipy-SKi803WO/lib/python3.12/site-packages/apispec_webframeworks/__init__.py",
                "line_number": 1,
                "reason": "Third-party package that attempts \"import pkg_resources\" during pytest collection. Logs show this file raising ModuleNotFoundError: No module named 'pkg_resources', which aborted pytest in some runs."
            },
            {
                "file": "taipy/rest/api/schemas/datanode.py",
                "line_number": 99,
                "reason": "Repeated warnings originate here: log shows \"taipy/rest/api/schemas/datanode.py:99: RemovedInMarshmallow4Warning: The 'default' argument to fields is deprecated. Use 'dump_default' instead.'\", a maintenance/deprecation issue captured during many test runs."
            },
            {
                "file": "taipy/templates/default/{{cookiecutter.__root_folder}}/.gitignore",
                "line_number": null,
                "reason": "Coverage produced a CoverageWarning: \"Couldn't parse Python file .../.gitignore (couldnt-parse)\". The non-Python file inside templates caused coverage to emit a parsing warning."
            },
            {
                "file": "taipy/gui/gui.py",
                "line_number": 1326,
                "reason": "Multiple TaipyGuiWarning entries show a traceback into this file where WebSocket broadcast code raised AttributeError: \"'Gui' object has no attribute '_server'\" during tests; recorded repeatedly in logs and indicates runtime GUI warnings during test runs."
            },
            {
                "file": "taipy/core/sequence/_sequence_manager.py",
                "line_number": 149,
                "reason": "Stack traces for Taipy sequence access failures reference this file and show a raised NonExistingTask from __get_sequence_tasks; logs include \"raise NonExistingTask(task)\" originating here, recorded as warnings in test output."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest reported: \"E       assert \"[Taipy][INFO] Configuration 'config/config.toml' successfully loaded.\" in ''\" and \"E       AssertionError: assert '[Taipy][INFO]  * Server starting on' in ''\" (failures in tests/templates/test_scenario_mgt_template.py)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "ImportError: attempted relative import with no known parent package",
                "evidence": "Captured traceback: \"File \\\"/tmp/pytest-of-runner/.../foo_app/main.py\\\", line 15, in <module\\n    from .config.config import configure\\nImportError: attempted relative import with no known parent package\" (this prevented the generated app from starting during tests)."
            },
            {
                "category": "Dependency Error",
                "subcategory": "ModuleNotFoundError: No module named 'pkg_resources'",
                "evidence": "Pytest collection aborted with: \"E   ModuleNotFoundError: No module named 'pkg_resources'\" after apispec_webframeworks.__init__.py attempted \"import pkg_resources\" (seen in several python 3.12 / intermittent runs)."
            },
            {
                "category": "Coverage / Tooling Warning",
                "subcategory": "CoverageWarning: couldnt-parse",
                "evidence": "Coverage reported: \"CoverageWarning: Couldn't parse Python file '.../taipy/templates/default/{{cookiecutter.__root_folder}}/.gitignore' (couldnt-parse)\" during coverage run."
            },
            {
                "category": "Deprecation / Lint Warning",
                "subcategory": "RemovedInMarshmallow4Warning",
                "evidence": "Log shows: \"taipy/rest/api/schemas/datanode.py:99: RemovedInMarshmallow4Warning: The 'default' argument to fields is deprecated. Use 'dump_default' instead.\" repeated in warnings summaries."
            },
            {
                "category": "Runtime Warning",
                "subcategory": "TaipyGuiWarning: AttributeError in WebSocket broadcast",
                "evidence": "Multiple warnings in logs: \"TaipyGuiWarning: Exception raised in WebSocket communication ... AttributeError: 'Gui' object has no attribute '_server'\" pointing to taipy/gui/gui.py:1326."
            },
            {
                "category": "Runtime Error (logic)",
                "subcategory": "NonExistingTask (sequence building)",
                "evidence": "Warning stack shows: \"taipy.core.exceptions.exceptions.NonExistingTask: TASK_task1_...\" raised from taipy/core/sequence/_sequence_manager.py during sequence access attempts."
            }
        ],
        "failed_job": [
            {
                "job": "coverage",
                "step": "Pytest with coverage",
                "command": "pipenv run pytest --cov=taipy --cov-report=xml:${{ github.workspace }}/coverage.xml --cov-config=.coveragerc"
            },
            {
                "job": "partial-tests",
                "step": "Pytest Templates",
                "command": "pipenv run pytest tests/templates"
            },
            {
                "job": "partial-tests",
                "step": "Pytest Common",
                "command": "pipenv run pytest tests/common"
            },
            {
                "job": "overall-tests",
                "step": "Pytest",
                "command": "pipenv run pytest -m \"not orchestrator_dispatcher and not standalone and not teste2e\" tests"
            },
            {
                "job": "intermittent-tests",
                "step": "Pytest Core orchestrator/standalone",
                "command": "pipenv run pytest -m \"${{ matrix.orchestrator }}\" tests/core"
            }
        ]
    },
    {
        "sha_fail": "ed4b25df54e0b8b1f074b3ea71bfebd33545da2b",
        "error_context": [
            "The CI job 'build' (both python 3.13 and 3.12 matrix runs) failed during the 'Run build-system tests' step. Pytest reported multiple test setup ERRORS caused by SyntaxError while evaluating pytest skipif conditions in backends/build_system/functional/test_aws_cli_venv.py (log: \"invalid syntax (<skipif condition>, line 1)\" and \"Error evaluating 'skipif' condition ... SyntaxError: invalid syntax\"). Those skipif conditions appear to be plain text strings (e.g. \"Posix virtualenv\", \"No bin dir on windows\") which produced invalid Python syntax when pytest tried to evaluate them, causing the tests to error at setup.",
            "Separately, several integration tests failed due to subprocess commands returning non-zero exit codes while invoking the project's build helper and Makefile. pytest fixtures call helpers in backends/build_system/integration/__init__.py which use subprocess.check_output; those subprocess calls raised subprocess.CalledProcessError when the internal 'backends/build_system build ...' command returned exit status 1 or when 'make' returned exit status 2 (log evidence: \"subprocess.CalledProcessError: Command ... returned non-zero exit status 1.\" and \"Command '['make']' returned non-zero exit status 2.\").",
            "One test assertion also failed because the test expected a particular error message (substring 'pyinstaller') but received a different error output from the failing build helper, producing an AssertionError (log: \"assert 'pyinstaller' in 'ERROR: Exception:...'\").",
            "The CI wrapper scripts (scripts/ci/run-tests and scripts/ci/run-build-system-tests) propagated pytest's non-zero exit status via subprocess.CalledProcessError and caused the job to exit with code 1 (log shows these scripts raising CalledProcessError and final message 'Process completed with exit code 1').",
            "Install-dependencies steps completed (many packages downloaded/built) and produced informational pip notices, but there is no direct evidence that package installation itself caused the skipif SyntaxErrors; the primary failures are malformed/unevaluatable pytest skipif conditions and failed subprocess builds invoked by tests."
        ],
        "relevant_files": [
            {
                "file": "backends/build_system/functional/test_aws_cli_venv.py",
                "line_number": null,
                "reason": "Pytest setup errors originate here: multiple tests in this file errored with \"invalid syntax (<skipif condition>, line 1)\" and \"Error evaluating 'skipif' condition\" (the skipif text like 'Posix virtualenv' caused a SyntaxError when pytest attempted to evaluate it)."
            },
            {
                "file": "backends/build_system/integration/conftest.py",
                "line_number": 23,
                "reason": "Pytest fixture setup in this file calls workspace.call_build_system and appears in tracebacks that propagate subprocess.CalledProcessError (stack traces reference backends/build_system/integration/conftest.py:23 and :38 as fixture invocation points)."
            },
            {
                "file": "backends/build_system/integration/__init__.py",
                "line_number": 189,
                "reason": "Integration helper that runs subprocesses; stack traces show call sites (e.g. call_build_system -> subprocess) at lines ~189/210/224 where subprocess.check_output is used and where CalledProcessError is raised when build commands fail."
            },
            {
                "file": "backends/build_system/integration/test_build_system.py",
                "line_number": 44,
                "reason": "Contains the failing assertion expecting 'pyinstaller' in error output; log shows an AssertionError at this file/line when the build helper produced a different error message."
            },
            {
                "file": "backends/build_system/integration/test_makefile.py",
                "line_number": 135,
                "reason": "Tests here invoke workspace.make(), which calls make; logs show CalledProcessError raised from a failing Make invocation (Command '['make']' returned non-zero exit status 2) with tracebacks pointing to this file (lines ~135 and ~157)."
            },
            {
                "file": "scripts/ci/run-tests",
                "line_number": 129,
                "reason": "CI test runner script invoked pytest and propagated the non-zero exit code; traceback shows run-tests raised subprocess.CalledProcessError when pytest returned exit status 1."
            },
            {
                "file": "scripts/ci/run-build-system-tests",
                "line_number": 43,
                "reason": "Top-level CI script that called run-tests; logs show this script raised CalledProcessError after run-tests returned non-zero, causing the job to fail."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.13.9/x64/lib/python3.13/subprocess.py",
                "line_number": 577,
                "reason": "Standard-library subprocess.check_output/check_call raised CalledProcessError in the recorded trace (this is the exact function and line that raised the exception propagating failing subprocess exit codes)."
            }
        ],
        "error_types": [
            {
                "category": "Configuration Error",
                "subcategory": "Invalid pytest skipif expression / SyntaxError",
                "evidence": "\"invalid syntax (<skipif condition>, line 1)\" and \"Error evaluating 'skipif' condition ... SyntaxError: invalid syntax\" reported for tests in backends/build_system/functional/test_aws_cli_venv.py."
            },
            {
                "category": "Runtime Error",
                "subcategory": "Subprocess.CalledProcessError (external command returned non-zero)",
                "evidence": "Multiple traces show: \"subprocess.CalledProcessError: Command '[.../venv/bin/python', 'backends/build_system', 'build', ...]' returned non-zero exit status 1.\" and \"Command '['make']' returned non-zero exit status 2.\""
            },
            {
                "category": "Test Failure",
                "subcategory": "AssertionError (unexpected error output)",
                "evidence": "Test assertion failed: \"assert 'pyinstaller' in 'ERROR: Exception:...'\", indicating the test expected 'pyinstaller' in the build error output but received a different message."
            }
        ],
        "failed_job": [
            {
                "job": "build (ubuntu-latest, python=3.13)",
                "step": "Run build-system tests",
                "command": "python scripts/ci/run-build-system-tests"
            },
            {
                "job": "build (ubuntu-latest, python=3.12)",
                "step": "Run build-system tests",
                "command": "python scripts/ci/run-build-system-tests"
            }
        ]
    },
    {
        "sha_fail": "2c55286dcbe108a7a41c81d5da97e3d73d1712ce",
        "error_context": [
            "The CI run failed because the test suite reported a single failing functional test which caused pytest to exit non-zero and the test runner script to raise an exception. In each matrix job the installation step (python scripts/ci/install) completed successfully and the failure occurred in the subsequent \"Run tests\" step (command: python scripts/ci/run-tests --with-cov).",
            "The immediate root cause is a failed assertion in functional/botocore/test_s3.py::test_retries_reuse_request_checksum: the test expected the mocked urllib3 send method to be called twice (indicating a retry) but observed only one call (AssertionError: assert 1 == 2 at functional/botocore/test_s3.py:2216).",
            "Because pytest returned a non-zero exit status, the scripts/ci/run-tests wrapper invoked by the workflow propagated this as a subprocess.CalledProcessError (\"Command 'pytest ...' returned non-zero exit status 1\"), which caused the GitHub Actions step to fail with exit code 1.",
            "Related non-fatal issues appeared in the logs (coverage warnings and RuntimeWarnings about coroutines not awaited and an xdist DeprecationWarning) but these are warnings that did not directly cause the job to fail; the failing test assertion is the blocking error."
        ],
        "relevant_files": [
            {
                "file": "functional/botocore/test_s3.py",
                "line_number": 2216,
                "reason": "Direct failing test location and assertion: log shows the failure in test_retries_reuse_request_checksum and the assertion \"assert mock_urllib3_session_send.call_count == 2\" failed with \"AssertionError: assert 1 == 2\" (functional/botocore/test_s3.py:2216)."
            },
            {
                "file": "scripts/ci/run-tests",
                "line_number": null,
                "reason": "Test harness wrapper that invoked pytest and propagated the non-zero exit. Traceback shows scripts/ci/run-tests called subprocess.check_call and raised subprocess.CalledProcessError after pytest returned non-zero."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/coverage/inorout.py",
                "line_number": 536,
                "reason": "Coverage produced a CoverageWarning during the test run: \"Module s3transfer was previously imported, but not measured (module-not-measured)\" as recorded in the logs; present in multiple matrix jobs."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/inspect.py",
                "line_number": 3063,
                "reason": "RuntimeWarning referencing this stdlib file was emitted during tests: \"RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" (appears in the warnings summary)."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/unittest/mock.py",
                "line_number": 2181,
                "reason": "RuntimeWarning referencing unittest.mock was emitted: \"RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" (part of warnings summary across test workers)."
            },
            {
                "file": "/opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/json/decoder.py",
                "line_number": 353,
                "reason": "RuntimeWarning referencing json.decoder was emitted: \"RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" (included in test warnings)."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Pytest failure shows: \"E       AssertionError: assert 1 == 2\" from functional/botocore/test_s3.py:2216 and the failing test is test_retries_reuse_request_checksum."
            },
            {
                "category": "Test Harness Failure",
                "subcategory": "Subprocess non-zero exit",
                "evidence": "scripts/ci/run-tests raised CalledProcessError: \"Command 'pytest ...' returned non-zero exit status 1.\""
            },
            {
                "category": "Runtime Warning",
                "subcategory": "coroutine never awaited",
                "evidence": "Warnings summary contains lines like: \"/opt/.../inspect.py:3063: RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" and similar references in unittest/mock.py and json/decoder.py."
            },
            {
                "category": "Coverage Warning",
                "subcategory": "module not measured",
                "evidence": "CoverageWarning in logs: \"/opt/.../site-packages/coverage/inorout.py:536: CoverageWarning: Module s3transfer was previously imported, but not measured (module-not-measured)\"."
            },
            {
                "category": "Deprecation Warning",
                "subcategory": "pytest-xdist --rsyncdir deprecated",
                "evidence": "DeprecationWarning from xdist plugin: \"/opt/.../site-packages/xdist/plugin.py:227: DeprecationWarning: The --rsyncdir command line argument and rsyncdirs config variable are deprecated.\""
            }
        ],
        "failed_job": [
            {
                "job": "build (3.10, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            },
            {
                "job": "build (3.11, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            },
            {
                "job": "build (3.12, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            }
        ]
    },
    {
        "sha_fail": "9615d6f209311a94cc3bcbd0ebc5716aac9d4b08",
        "error_context": [
            "Both matrix build jobs failed during the \"Install dependencies\" step when the CI ran the project build (python -m build) from scripts/ci/install. The packaging/build backend (pep517) attempted to generate an auto-complete index by importing the project's modules; while importing awscli.customizations.s3.subcommands the Python parser raised a SyntaxError on an invalid f-string. The log shows the exact offending source: \"f'The user-provided path {params['src']} does not exist.'\" and the interpreter message \"SyntaxError: f-string: unmatched '['\" (awscli/customizations/s3/subcommands.py:1638). That SyntaxError aborted the pep517 build_wheel backend (log: \"ERROR Backend subproccess exited when trying to invoke build_wheel\"), which caused scripts/ci/install to fail with subprocess.CalledProcessError: \"Command 'python -m build' returned non-zero exit status 1.\" The failure occurred during packaging/installation (before test steps) and is rooted in a source-code syntax error in the project's S3 subcommands module."
        ],
        "relevant_files": [
            {
                "file": "awscli/customizations/s3/subcommands.py",
                "line_number": 1638,
                "reason": "Contains the invalid f-string that triggered the parse error: the log shows the exact source line \"f'The user-provided path {params['src']} does not exist.'\" and Python reported \"SyntaxError: f-string: unmatched '['\"."
            },
            {
                "file": "awscli/customizations/s3/s3.py",
                "line_number": 15,
                "reason": "Imports the subcommands module that contains the SyntaxError; log traceback shows this import (from awscli.customizations.s3.subcommands) immediately before the parse failure."
            },
            {
                "file": "awscli/handlers.py",
                "line_number": 113,
                "reason": "Imported during plugin loading and triggers the S3 customization import chain; the traceback shows this file's import frame just prior to s3.s3 importing subcommands."
            },
            {
                "file": "awscli/plugin.py",
                "line_number": 48,
                "reason": "Plugin-loading code invoked __import__ which started the import chain that eventually parsed the faulty subcommands.py; traceback includes frames in this module during the failure."
            },
            {
                "file": "awscli/clidriver.py",
                "line_number": 117,
                "reason": "create_clidriver() is called by the autocomplete generator and calls load_plugins, which leads to the import chain that encounters the SyntaxError."
            },
            {
                "file": "awscli/autocomplete/generator.py",
                "line_number": 35,
                "reason": "generate_index() invoked the code path that creates the CLI driver and triggered plugin/module imports which exposed the SyntaxError while building the auto-complete index."
            },
            {
                "file": "awscli/backends/pep517.py",
                "line_number": 65,
                "reason": "Build backend invoked by pep517 to build/inject wheel extras and to build the auto-complete index; traceback shows calls in this file (_inject_wheel_extras/_build_ac_index) that led to generate_index."
            },
            {
                "file": "pep517/in_process/_in_process.py",
                "line_number": 351,
                "reason": "In-process pep517 runner invoked the project's build_wheel backend; appears as the top frames in the traceback that propagated the SyntaxError out of the build subprocess."
            },
            {
                "file": "scripts/ci/install",
                "line_number": 32,
                "reason": "CI script that invoked 'python -m build' and surfaced the non-zero exit; the script's subprocess.check_call raised the CalledProcessError when the build backend exited."
            },
            {
                "file": "subprocess.py",
                "line_number": 413,
                "reason": "Standard-library subprocess.check_call raised subprocess.CalledProcessError when 'python -m build' returned non-zero; appears in the final traceback reported by the CI run."
            }
        ],
        "error_types": [
            {
                "category": "Runtime Error",
                "subcategory": "SyntaxError in source (invalid f-string)",
                "evidence": "Log: \"f'The user-provided path {params['src']} does not exist.'\" and \"SyntaxError: f-string: unmatched '['\" (awscli/customizations/s3/subcommands.py:1638)."
            },
            {
                "category": "Build Failure",
                "subcategory": "Packaging aborted (pep517 build_wheel exited)",
                "evidence": "Log: \"ERROR Backend subproccess exited when trying to invoke build_wheel\" and scripts/ci/install raised \"subprocess.CalledProcessError: Command 'python -m build' returned non-zero exit status 1.\""
            }
        ],
        "failed_job": [
            {
                "job": "build",
                "step": "build (3.10, ubuntu-latest)",
                "command": "python scripts/ci/install"
            },
            {
                "job": "build",
                "step": "build (3.11, ubuntu-latest)",
                "command": "python scripts/ci/install"
            }
        ]
    },
    {
        "sha_fail": "be50f3d712d91eb02d020a6704b27ebb4cae29d1",
        "error_context": [
            "The CI run completed installation successfully (python scripts/ci/install) but failed during the test step. In the \"Run tests\" step (python scripts/ci/run-tests --with-cov), pytest executed the test suite and one functional test failed: functional/test_telemetry.py::TestCLISessionDatabaseConnection::test_timeout_does_not_raise_exception. The test constructs a FakeConnection whose execute() always raises sqlite3.OperationalError to simulate a timeout; during CLISessionDatabaseConnection initialization the code calls self.execute(...) and then does cur.fetchone()[0]. Because the simulated execute path resulted in no valid cursor/result (cur.fetchone() returned None), a TypeError ('NoneType' object is not subscriptable) was raised in awscli/telemetry.py (host id check), causing pytest to exit with status 1. The scripts/ci/run-tests wrapper then surfaced this as a subprocess.CalledProcessError, causing the job to fail. Warnings (CoverageWarning for s3transfer, DeprecationWarning from xdist, and RuntimeWarning about an awaited coroutine) appeared in the logs but are secondary to the failing test and did not directly cause the non-zero exit."
        ],
        "relevant_files": [
            {
                "file": "functional/test_telemetry.py",
                "line_number": 116,
                "reason": "Location of the failing test invocation: the test constructs CLISessionDatabaseConnection(FakeConnection(':memory:')) at functional/test_telemetry.py:116; this test simulates sqlite timeouts and triggered the failure."
            },
            {
                "file": "awscli/telemetry.py",
                "line_number": 114,
                "reason": "Traceback shows the TypeError originates here: _ensure_host_id does cur.fetchone()[0] and raised \"TypeError: 'NoneType' object is not subscriptable\" when cur.fetchone() returned None."
            },
            {
                "file": "scripts/ci/run-tests",
                "line_number": 129,
                "reason": "Top-level CI test wrapper that invoked pytest and propagated the non-zero exit; log shows run-tests called check_call(...) and the wrapper raised CalledProcessError after pytest returned status 1."
            },
            {
                "file": "subprocess.py",
                "line_number": null,
                "reason": "Standard library subprocess.check_call raised subprocess.CalledProcessError after pytest exited non-zero; present in the traceback that bubbled up to the run-tests wrapper and CI."
            },
            {
                "file": "coverage/inorout.py",
                "line_number": 536,
                "reason": "Coverage emitted a CoverageWarning: \"Module s3transfer was previously imported, but not measured\" (repeated in the test logs)."
            },
            {
                "file": "xdist/plugin.py",
                "line_number": 227,
                "reason": "DeprecationWarning origin in logs: \"The --rsyncdir command line argument and rsyncdirs config variable are deprecated.\""
            },
            {
                "file": "tests/unit/customizations/logs/test_startlivetail.py",
                "line_number": null,
                "reason": "RuntimeWarnings in the test warnings summary point to this file: \"coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" during tests in this module."
            },
            {
                "file": "prompt_toolkit/key_binding/key_bindings.py",
                "line_number": 448,
                "reason": "RuntimeWarning reported here: \"coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" referenced in pytest warnings summary."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "TypeError during test execution",
                "evidence": "pytest failure: \"TypeError: 'NoneType' object is not subscriptable\" at awscli/telemetry.py:114 (when calling host_id_ct = cur.fetchone()[0]) during functional/test_telemetry.py::TestCLISessionDatabaseConnection::test_timeout_does_not_raise_exception."
            },
            {
                "category": "CI Script Failure",
                "subcategory": "CalledProcessError (pytest non-zero exit)",
                "evidence": "scripts/ci/run-tests wrapper raised subprocess.CalledProcessError: \"Command 'pytest ...' returned non-zero exit status 1.\""
            },
            {
                "category": "Warning",
                "subcategory": "CoverageWarning",
                "evidence": "\"CoverageWarning: Module s3transfer was previously imported, but not measured (module-not-measured)\" (coverage/inorout.py:536) appeared multiple times."
            },
            {
                "category": "Warning",
                "subcategory": "DeprecationWarning",
                "evidence": "\"DeprecationWarning: The --rsyncdir command line argument and rsyncdirs config variable are deprecated.\" (xdist/plugin.py:227) shown in warnings summary."
            },
            {
                "category": "Warning",
                "subcategory": "RuntimeWarning (coroutine not awaited)",
                "evidence": "\"RuntimeWarning: coroutine 'AsyncMockMixin._execute_mock_call' was never awaited\" reported for tests in tests/unit/customizations/logs/test_startlivetail.py and prompt_toolkit key_bindings."
            }
        ],
        "failed_job": [
            {
                "job": "build (3.10, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            },
            {
                "job": "build (3.11, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            },
            {
                "job": "build (3.12, ubuntu-latest)",
                "step": "Run tests",
                "command": "python scripts/ci/run-tests --with-cov"
            }
        ]
    },
    {
        "sha_fail": "066ba5bb325850910e8f4cb76a91e3293c3b7619",
        "error_context": [
            "The CI run failed mainly because the test matrix produced test-level failures and then a Codecov upload step exited non\u2011zero. In the pytest job (step: \"Test with pytest\") multiple deterministic test failures occurred (notably in tests/_files/test_sticker.py, tests/_files/test_audio.py, tests/_files/test_video.py and related tests) producing AssertionError/AttributeError/KeyError traces (examples: \"assert 510 == 0\", \"assert 1395 == 1427\", \"AttributeError: 'NoneType' object has no attribute 'to_dict'\", \"KeyError: 'thumbnail'\"). Many other tests interacting with the network were marked XFAIL by the flaky plugin because they hit Telegram API rate\u2011limits (flood control) or network timeouts; repeated log lines show \"Not waiting for flood control: Flood control exceeded. Retry in <N> seconds\" and \"Ignoring TimedOut error: Timed out\" pointing to tests/auxil/networking.py and the request layer (src/telegram/request/_baserequest.py) as the call path. Those network/XFail conditions increased instability but the concrete failing assertions are rooted in test expectations about returned objects (thumbnail presence, dimensions, file_size) that did not match actual API/test fixtures. Finally, after tests completed, the Codecov upload step (step: \"Submit coverage\" / codecov/codecov-action) failed because no upload token was provided: the Codecov CLI reported \"Upload failed: {\"message\":\"Token required - not valid tokenless upload\"}\", which caused the job to exit with code 1. Evidence: pytest produced failing tests and an aggregated summary (e.g., \"6 failed ...\" in Python 3.10 run) and the codecov action printed the token-required error and then \"Process completed with exit code 1.\""
        ],
        "relevant_files": [
            {
                "file": "tests/_files/test_sticker.py",
                "line_number": 322,
                "reason": "Multiple deterministic test failures originate here (assertion mismatches and AttributeError/KeyError around sticker.thumbnail and width). Log evidence: failing assertions at tests/_files/test_sticker.py:322 and earlier de_json/to_dict assertions (e.g. 'AttributeError: 'NoneType' object has no attribute 'to_dict'', 'KeyError: \"thumbnail\"')."
            },
            {
                "file": "tests/_files/test_audio.py",
                "line_number": 266,
                "reason": "Contains an assertion failure comparing PhotoSize/file_size expectations (log shows 'assert 1395 == 1427' with traceback referencing tests/_files/test_audio.py:266)."
            },
            {
                "file": "tests/_files/test_video.py",
                "line_number": 307,
                "reason": "Contains an assertion failure comparing video thumbnail file sizes (log shows 'assert 1769 == 1767' with traceback referencing tests/_files/test_video.py:307)."
            },
            {
                "file": "tests/_files/test_chatphoto.py",
                "line_number": 182,
                "reason": "Referenced in flaky/XFail traces for photo-related tests; log shows test failures pointing to tests/_files/test_chatphoto.py:182 in the stack for test_send_all_args and similar traces."
            },
            {
                "file": "tests/_files/test_contact.py",
                "line_number": 199,
                "reason": "Appears repeatedly in flaky/XFail tracebacks for contact-sending tests that hit flood control (evidence: TracebackEntry entries referencing tests/_files/test_contact.py:199 and related lines)."
            },
            {
                "file": "tests/_files/test_location.py",
                "line_number": 230,
                "reason": "Referenced by multiple failing/XFailed live-location and location tests (log shows traces pointing to tests/_files/test_location.py:230 and :267)."
            },
            {
                "file": "tests/_files/test_inputmedia.py",
                "line_number": 1244,
                "reason": "Referenced in failing paid-media / inputmedia-related tests (log shows TracebackEntry to tests/_files/test_inputmedia.py:1244 for test_send_paid_media)."
            },
            {
                "file": "tests/test_bot.py",
                "line_number": 3533,
                "reason": "Contains bot-level tests that produced failures or BadRequest results (e.g. test_set_game_score_and_high_scores raised telegram.error.BadRequest 'Bot_score_not_modified' with traceback into tests/test_bot.py:3533)."
            },
            {
                "file": "src/telegram/ext/_extbot.py",
                "line_number": 2649,
                "reason": "Library extension bot layer is repeatedly on the failing call stacks for many networked tests (trace entries like src/telegram/ext/_extbot.py:2649, :3284, :3107 appear across flaky/failure logs)."
            },
            {
                "file": "src/telegram/_bot.py",
                "line_number": 3575,
                "reason": "Core bot implementation frames appear in many failure traces (examples: src/telegram/_bot.py:3575, :6426, :1118) where API calls and responses propagate into tests that timed out or hit flood control."
            },
            {
                "file": "src/telegram/request/_baserequest.py",
                "line_number": 198,
                "reason": "Request layer appears in nearly every network-related traceback (evidence: TracebackEntry '/.../src/telegram/request/_baserequest.py:198'), tying flood-control/timeouts to the HTTP/request layer used by the tests."
            },
            {
                "file": "tests/auxil/networking.py",
                "line_number": 58,
                "reason": "Test networking helper is present in many tracebacks for timeouts/flood-control; logs show traces to tests/auxil/networking.py:58/60/109 as the network stub used by failing tests."
            }
        ],
        "error_types": [
            {
                "category": "Test Failure",
                "subcategory": "AssertionError",
                "evidence": "Concrete assertion failures in tests: examples in logs include \"assert 510 == 0\" (tests/_files/test_sticker.py) and \"assert 1395 == 1427\" (tests/_files/test_audio.py)."
            },
            {
                "category": "Test Failure",
                "subcategory": "AttributeError / KeyError (missing thumbnail)",
                "evidence": "Errors showing missing thumbnail handling: \"AttributeError: 'NoneType' object has no attribute 'to_dict'\" and \"KeyError: 'thumbnail'\" in tests/_files/test_sticker.py (de_json / to_dict assertions)."
            },
            {
                "category": "Test Failure",
                "subcategory": "API rate limit / Flood control (XFailed)",
                "evidence": "Many flaky entries marked XFailed with flood control messages: \"Not waiting for flood control: Flood control exceeded. Retry in 38679 seconds\" (present in multiple TracebackEntry lists)."
            },
            {
                "category": "Test Failure",
                "subcategory": "Network Timeout (XFailed)",
                "evidence": "Multiple flaky entries show timeouts: \"Ignoring TimedOut error: Timed out\" (e.g., test_send_sticker_default_protect_content, test_send_mp3_url_file)."
            },
            {
                "category": "Runtime Error",
                "subcategory": "API Error (BadRequest)",
                "evidence": "telegram.error.BadRequest occurred in tests: example message 'Bot_score_not_modified' (logged for test_set_game_score_and_high_scores)."
            },
            {
                "category": "Configuration Error",
                "subcategory": "Missing CI secret / token",
                "evidence": "Codecov upload failed with: \"Upload failed: {\"message\":\"Token required - not valid tokenless upload\"}\" and the codecov step returned exit code 1."
            }
        ],
        "failed_job": [
            {
                "job": "pytest",
                "step": "Test with pytest",
                "command": "pytest -v --cov -k \"${TO_TEST}\" --junit-xml=.test_report_no_optionals_junit.xml && pytest -v --cov --cov-append -n auto --dist worksteal --junit-xml=.test_report_optionals_junit.xml"
            },
            {
                "job": "pytest",
                "step": "Submit coverage",
                "command": "uses: codecov/codecov-action@fdcc8476540edceab3de004e990f80d881c6cc00"
            }
        ]
    }
]