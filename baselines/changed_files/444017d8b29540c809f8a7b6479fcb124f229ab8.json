{
    "sha_fail": "444017d8b29540c809f8a7b6479fcb124f229ab8",
    "changed_files": [
        {
            "commit": "444017d8b29540c809f8a7b6479fcb124f229ab8",
            "file_path": "datasets/flwr_datasets/partitioner/continuous_partitioner.py",
            "diff": "diff --git a/datasets/flwr_datasets/partitioner/continuous_partitioner.py b/datasets/flwr_datasets/partitioner/continuous_partitioner.py\nindex d65412a3a..8fb32503f 100644\n--- a/datasets/flwr_datasets/partitioner/continuous_partitioner.py\n+++ b/datasets/flwr_datasets/partitioner/continuous_partitioner.py\n@@ -27,10 +27,21 @@ from flwr_datasets.partitioner.partitioner import Partitioner\n class ContinuousPartitioner(\n     Partitioner\n ):  # pylint: disable=too-many-instance-attributes\n-    \"\"\"Partitioner based on a continuous dataset property with adjustable strictness.\n+    \"\"\"Partitioner based on a real-valued (continuous) dataset property with adjustable strictness.\n \n-    This partitioner enables non-IID partitioning by sorting the dataset based on a\n-    continuous property and introducing Gaussian noise controlled by a strictness parameter.\n+    This partitioner enables non-IID partitioning by sorting the dataset according to a\n+    continuous (i.e., real-valued, not categorical) property and introducing controlled noise\n+    to adjust the level of heterogeneity.\n+\n+    To interpolate between IID and non-IID partitioning, a `strictness` parameter\n+    (\ud835\udf0e \u2208 [0, 1]) blends a standardized property vector (z \u2208 \u211d\u207f) with Gaussian noise\n+    (\u03b5 ~ \ud835\udca9(0, I)), producing blended scores:\n+\n+    b = \ud835\udf0e \u00b7 z + (1 - \ud835\udf0e) \u00b7 \u03b5\n+\n+    Samples are then sorted by `b` to assign them to partitions. When `strictness` is 0,\n+    partitioning is purely random (IID), while a value of 1 strictly follows the property ranking\n+    (strongly non-IID).\n \n     Parameters\n     ----------\n@@ -47,18 +58,33 @@ class ContinuousPartitioner(\n \n     Examples\n     --------\n-    >>> from flwr_datasets import FederatedDataset\n+    >>> from datasets import Dataset\n+    >>> import numpy as np\n+    >>> import pandas as pd\n     >>> from flwr_datasets.partitioner import ContinuousPartitioner\n     >>>\n+    >>> # Create synthetic data\n+    >>> np.random.seed(42)\n+    >>> df = pd.DataFrame({\n+    >>>     \"continuous\": np.linspace(0, 10, 100),\n+    >>>     \"category\": np.random.choice([0, 1, 2, 3], size=100)\n+    >>> })\n+    >>>\n+    >>> # Convert to Hugging Face Dataset\n+    >>> hf_dataset = Dataset.from_pandas(df)\n+    >>>\n+    >>> # Create and configure the partitioner\n     >>> partitioner = ContinuousPartitioner(\n     >>>     num_partitions=5,\n-    >>>     partition_by=\"logS\",\n+    >>>     partition_by=\"continuous\",\n     >>>     strictness=0.7,\n     >>>     shuffle=True\n     >>> )\n-    >>> fds = FederatedDataset(dataset=\"chembl_aqsol\", partitioners={\"train\": partitioner})\n-    >>> partition = fds.load_partition(0)\n-    >>> print(partition[0])\n+    >>> partitioner.dataset = hf_dataset  # Assign dataset manually\n+    >>>\n+    >>> # Load and inspect one partition\n+    >>> partition = partitioner.load_partition(0)\n+    >>> print(partition.to_pandas())\n     \"\"\"\n \n     def __init__(\n@@ -131,17 +157,17 @@ class ContinuousPartitioner(\n         if np.any(property_values is None) or np.isnan(property_values).any():\n             raise ValueError(\n                 f\"The column '{self._partition_by}' contains None or NaN values, \"\n-                \"which are not supported by ContinuousPartitioner. \"\n+                f\"which are not supported by {self.__class__.__qualname__}. \"\n                 \"Please clean or filter your dataset before partitioning.\"\n             )\n \n         # Standardize\n         std = np.std(property_values)\n-        if std < 1e-6:\n+        if std < 1e-6 and self._strictness > 0:\n             raise ValueError(\n-                f\"Cannot standardize column '{self._partition_by}' because it has near-zero s.d. \"\n-                f\"(std={std}). All values are nearly identical, which prevents meaningful\"\n-                \" partitioning. Please choose a different column or adjust the dataset.\"\n+                f\"Cannot standardize column '{self._partition_by}' because it has near-zero std \"\n+                f\"(std={std}). All values are nearly identical, which prevents meaningful non-IID partitioning. \"\n+                \"Either choose a different partition property or set strictness to 0 for IID partitioning.\"\n             )\n \n         standardized_values = (property_values - np.mean(property_values)) / std\n"
        }
    ]
}