{
    "sha_fail": "f06bfb4ef15132a04a3983b4aa40f2e385ef7c04",
    "changed_files": [
        {
            "commit": "f06bfb4ef15132a04a3983b4aa40f2e385ef7c04",
            "file_path": "libs/agno/agno/agent/agent.py",
            "diff": "diff --git a/libs/agno/agno/agent/agent.py b/libs/agno/agno/agent/agent.py\nindex 052a4175a..76bbe00d4 100644\n--- a/libs/agno/agno/agent/agent.py\n+++ b/libs/agno/agno/agent/agent.py\n@@ -567,6 +567,7 @@ class Agent:\n         files: Optional[Sequence[File]] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n         stream_intermediate_steps: bool = False,\n+        run_response: Optional[RunResponse] = None,\n         **kwargs: Any,\n     ) -> Iterator[RunResponse]:\n         \"\"\"Run the Agent and yield the RunResponse.\n@@ -597,13 +598,21 @@ class Agent:\n         self.stream_intermediate_steps = self.stream_intermediate_steps or (stream_intermediate_steps and self.stream)\n         # 1.3 Create a run_id and RunResponse\n         self.run_id = str(uuid4())\n-        self.run_response = RunResponse(run_id=self.run_id, session_id=session_id, agent_id=self.agent_id)\n \n-        log_debug(f\"Agent Run Start: {self.run_response.run_id}\", center=True)\n+        # If run_response is None, create a new one\n+        if run_response is None:\n+            # For backwards compatibility, still set self.run_response\n+            self.run_response = RunResponse(run_id=self.run_id, session_id=session_id, agent_id=self.agent_id)\n+            run_response = self.run_response\n+        else:\n+            # For backward compatibility, also set self.run_response\n+            self.run_response = run_response\n+\n+        log_debug(f\"Async Agent Run Start: {run_response.run_id}\", center=True)\n \n         # 2. Update the Model and resolve context\n         self.update_model(async_mode=False, user_id=user_id, session_id=session_id)\n-        self.run_response.model = self.model.id if self.model is not None else None\n+        run_response.model = self.model.id if self.model is not None else None\n         if self.context is not None and self.resolve_context:\n             self.resolve_run_context()\n \n@@ -658,11 +667,11 @@ class Agent:\n                     # Process content and thinking\n                     if model_response_chunk.content is not None:\n                         model_response.content = (model_response.content or \"\") + model_response_chunk.content\n-                        self.run_response.content = model_response.content\n+                        run_response.content = model_response.content\n \n                     if model_response_chunk.thinking is not None:\n                         model_response.thinking = (model_response.thinking or \"\") + model_response_chunk.thinking\n-                        self.run_response.thinking = model_response.thinking\n+                        run_response.thinking = model_response.thinking\n \n                     if model_response_chunk.redacted_thinking is not None:\n                         model_response.redacted_thinking = (\n@@ -670,11 +679,11 @@ class Agent:\n                         ) + model_response_chunk.redacted_thinking\n \n                         # We only have thinking on response\n-                        self.run_response.thinking = model_response.redacted_thinking\n+                        run_response.thinking = model_response.redacted_thinking\n \n                     if model_response_chunk.citations is not None:\n                         # We get citations in one chunk\n-                        self.run_response.citations = model_response_chunk.citations\n+                        run_response.citations = model_response_chunk.citations\n \n                     # Only yield if we have content or thinking to show\n                     if (\n@@ -711,21 +720,21 @@ class Agent:\n                         model_response.audio.channels = model_response_chunk.audio.channels\n \n                         # Yield the audio and transcript bit by bit\n-                        self.run_response.response_audio = AudioResponse(\n+                        run_response.response_audio = AudioResponse(\n                             id=model_response_chunk.audio.id,\n                             content=model_response_chunk.audio.content,\n                             transcript=model_response_chunk.audio.transcript,\n                             sample_rate=model_response_chunk.audio.sample_rate,\n                             channels=model_response_chunk.audio.channels,\n                         )\n-                        self.run_response.created_at = model_response_chunk.created_at\n+                        run_response.created_at = model_response_chunk.created_at\n \n-                        yield self.run_response\n+                        yield run_response\n \n                     if model_response_chunk.image is not None:\n                         self.add_image(model_response_chunk.image)\n \n-                        yield self.run_response\n+                        yield run_response\n \n                 # If the model response is a tool_call_started, add the tool call to the run_response\n                 elif (\n@@ -734,13 +743,13 @@ class Agent:\n                     new_tool_calls_list = model_response_chunk.tool_calls\n                     if new_tool_calls_list is not None:\n                         # Add tool calls to the agent.run_response\n-                        if self.run_response.tools is None:\n-                            self.run_response.tools = new_tool_calls_list\n+                        if run_response.tools is None:\n+                            run_response.tools = new_tool_calls_list\n                         else:\n-                            self.run_response.tools.extend(new_tool_calls_list)\n+                            run_response.tools.extend(new_tool_calls_list)\n \n                         # Format tool calls whenever new ones are added during streaming\n-                        self.run_response.formatted_tool_calls = format_tool_calls(self.run_response.tools)\n+                        run_response.formatted_tool_calls = format_tool_calls(run_response.tools)\n \n                     # If the agent is streaming intermediate steps, yield a RunResponse with the tool_call_started event\n                     if self.stream_intermediate_steps:\n@@ -757,11 +766,11 @@ class Agent:\n                     new_tool_calls_list = model_response_chunk.tool_calls\n                     if new_tool_calls_list is not None:\n                         # Update the existing tool call in the run_response\n-                        if self.run_response.tools:\n+                        if run_response.tools:\n                             # Create a mapping of tool_call_id to index\n                             tool_call_index_map = {\n                                 tc[\"tool_call_id\"]: i\n-                                for i, tc in enumerate(self.run_response.tools)\n+                                for i, tc in enumerate(run_response.tools)\n                                 if tc.get(\"tool_call_id\") is not None\n                             }\n                             # Process tool calls\n@@ -769,9 +778,9 @@ class Agent:\n                                 tool_call_id = tool_call_dict.get(\"tool_call_id\")\n                                 index = tool_call_index_map.get(tool_call_id)\n                                 if index is not None:\n-                                    self.run_response.tools[index] = tool_call_dict\n+                                    run_response.tools[index] = tool_call_dict\n                         else:\n-                            self.run_response.tools = new_tool_calls_list\n+                            run_response.tools = new_tool_calls_list\n \n                         # Only iterate through new tool calls\n                         for tool_call in new_tool_calls_list:\n@@ -798,7 +807,7 @@ class Agent:\n                                 content=reasoning_step,\n                                 content_type=reasoning_step.__class__.__name__,\n                                 event=RunEvent.reasoning_step,\n-                                reasoning_content=self.run_response.reasoning_content,\n+                                reasoning_content=run_response.reasoning_content,\n                             )\n \n                         yield self.create_run_response(\n@@ -811,39 +820,39 @@ class Agent:\n             model_response = self.model.response(messages=run_messages.messages)\n             # Format tool calls if they exist\n             if model_response.tool_calls:\n-                self.run_response.formatted_tool_calls = format_tool_calls(model_response.tool_calls)\n+                run_response.formatted_tool_calls = format_tool_calls(model_response.tool_calls)\n \n             # Handle structured outputs\n             if self.response_model is not None and model_response.parsed is not None:\n                 # We get native structured outputs from the model\n                 if self.model.structured_outputs:\n                     # Update the run_response content with the structured output\n-                    self.run_response.content = model_response.parsed\n+                    run_response.content = model_response.parsed\n                     # Update the run_response content_type with the structured output class name\n-                    self.run_response.content_type = self.response_model.__name__\n+                    run_response.content_type = self.response_model.__name__\n             else:\n                 # Update the run_response content with the model response content\n-                self.run_response.content = model_response.content\n+                run_response.content = model_response.content\n \n             # Update the run_response thinking with the model response thinking\n             if model_response.thinking is not None:\n-                self.run_response.thinking = model_response.thinking\n+                run_response.thinking = model_response.thinking\n             if model_response.redacted_thinking is not None:\n-                if self.run_response.thinking is None:\n-                    self.run_response.thinking = model_response.redacted_thinking\n+                if run_response.thinking is None:\n+                    run_response.thinking = model_response.redacted_thinking\n                 else:\n-                    self.run_response.thinking += model_response.redacted_thinking\n+                    run_response.thinking += model_response.redacted_thinking\n \n             # Update the run_response citations with the model response citations\n             if model_response.citations is not None:\n-                self.run_response.citations = model_response.citations\n+                run_response.citations = model_response.citations\n \n             # Update the run_response tools with the model response tools\n             if model_response.tool_calls is not None:\n-                if self.run_response.tools is None:\n-                    self.run_response.tools = model_response.tool_calls\n+                if run_response.tools is None:\n+                    run_response.tools = model_response.tool_calls\n                 else:\n-                    self.run_response.tools.extend(model_response.tool_calls)\n+                    run_response.tools.extend(model_response.tool_calls)\n \n                 # For Reasoning/Thinking/Knowledge Tools update reasoning_content in RunResponse\n                 for tool_call in model_response.tool_calls:\n@@ -854,24 +863,20 @@ class Agent:\n \n             # Update the run_response audio with the model response audio\n             if model_response.audio is not None:\n-                self.run_response.response_audio = model_response.audio\n+                run_response.response_audio = model_response.audio\n \n             if model_response.image is not None:\n                 self.add_image(model_response.image)\n \n             # Update the run_response messages with the messages\n-            self.run_response.messages = run_messages.messages\n+            run_response.messages = run_messages.messages\n             # Update the run_response created_at with the model response created_at\n-            self.run_response.created_at = model_response.created_at\n+            run_response.created_at = model_response.created_at\n \n         if self.stream_intermediate_steps and reasoning_started:\n             all_reasoning_steps: List[ReasoningStep] = []\n-            if (\n-                self.run_response\n-                and self.run_response.extra_data\n-                and hasattr(self.run_response.extra_data, \"reasoning_steps\")\n-            ):\n-                all_reasoning_steps = cast(List[ReasoningStep], self.run_response.extra_data.reasoning_steps)\n+            if run_response and run_response.extra_data and hasattr(run_response.extra_data, \"reasoning_steps\"):\n+                all_reasoning_steps = cast(List[ReasoningStep], run_response.extra_data.reasoning_steps)\n \n             if all_reasoning_steps:\n                 self._add_reasoning_metrics_to_extra_data(reasoning_time_taken)\n@@ -885,13 +890,13 @@ class Agent:\n         # Build a list of messages that should be added to the RunResponse\n         messages_for_run_response = [m for m in run_messages.messages if m.add_to_agent_memory]\n         # Update the RunResponse messages\n-        self.run_response.messages = messages_for_run_response\n+        run_response.messages = messages_for_run_response\n         # Update the RunResponse metrics\n-        self.run_response.metrics = self.aggregate_metrics_from_messages(messages_for_run_response)\n+        run_response.metrics = self.aggregate_metrics_from_messages(messages_for_run_response)\n \n         # Update the run_response audio if streaming\n         if self.stream and model_response.audio is not None:\n-            self.run_response.response_audio = model_response.audio\n+            run_response.response_audio = model_response.audio\n \n         # 9. Update Agent Memory\n         if isinstance(self.memory, AgentMemory):\n@@ -913,7 +918,7 @@ class Agent:\n                 self.memory.add_messages(messages=messages_for_memory)\n \n             # Create an AgentRun object to add to memory\n-            agent_run = AgentRun(response=self.run_response)\n+            agent_run = AgentRun(response=run_response)\n             agent_run.message = run_messages.user_message\n \n             # Update the memories with the user message if needed\n@@ -958,7 +963,7 @@ class Agent:\n             self.session_metrics = self.calculate_metrics(self.memory.messages)\n         elif isinstance(self.memory, Memory):\n             # Add AgentRun to memory\n-            self.memory.add_run(session_id=session_id, run=self.run_response)\n+            self.memory.add_run(session_id=session_id, run=run_response)\n \n             self._make_memories_and_summaries(run_messages, session_id, user_id, messages)  # type: ignore\n \n@@ -997,18 +1002,18 @@ class Agent:\n         # Log Agent Run\n         self._log_agent_run(user_id=user_id, session_id=session_id)\n \n-        log_debug(f\"Agent Run End: {self.run_response.run_id}\", center=True, symbol=\"*\")\n+        log_debug(f\"Agent Run End: {run_response.run_id}\", center=True, symbol=\"*\")\n         if self.stream_intermediate_steps:\n             yield self.create_run_response(\n-                content=self.run_response.content,\n-                reasoning_content=self.run_response.reasoning_content,\n+                content=run_response.content,\n+                reasoning_content=run_response.reasoning_content,\n                 session_id=session_id,\n                 event=RunEvent.run_completed,\n             )\n \n         # Yield final response if not streaming so that run() can get the response\n         if not self.stream:\n-            yield self.run_response\n+            yield run_response\n \n     @overload\n     def run(\n@@ -1093,10 +1098,16 @@ class Agent:\n \n         last_exception = None\n         num_attempts = retries + 1\n+\n+        # Create a run_id for this specific run\n+        run_id = str(uuid4())\n+\n         for attempt in range(num_attempts):\n             try:\n-                # If a response_model is set, return the response as a structured output\n+                # Create a new run_response for this attempt\n+                run_response = RunResponse(run_id=run_id, session_id=session_id, agent_id=self.agent_id)\n \n+                # If a response_model is set, return the response as a structured output\n                 if self.response_model is not None and self.parse_response:\n                     # Set stream=False and run the agent\n                     if self.stream and self.stream is True:\n@@ -1114,6 +1125,7 @@ class Agent:\n                             files=files,\n                             messages=messages,\n                             stream_intermediate_steps=stream_intermediate_steps,\n+                            run_response=run_response,\n                             **kwargs,\n                         )\n                     )\n@@ -1154,6 +1166,7 @@ class Agent:\n                             files=files,\n                             messages=messages,\n                             stream_intermediate_steps=stream_intermediate_steps,\n+                            run_response=run_response,\n                             **kwargs,\n                         )\n                         return resp\n@@ -1169,6 +1182,7 @@ class Agent:\n                             files=files,\n                             messages=messages,\n                             stream_intermediate_steps=stream_intermediate_steps,\n+                            run_response=run_response,\n                             **kwargs,\n                         )\n                         return next(resp)\n"
        }
    ]
}