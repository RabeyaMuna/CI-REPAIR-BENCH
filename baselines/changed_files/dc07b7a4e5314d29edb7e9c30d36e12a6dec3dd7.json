{
    "sha_fail": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
    "changed_files": [
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py",
            "diff": "diff --git a/cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py b/cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py\nnew file mode 100644\nindex 000000000..60ac3bbd7\n--- /dev/null\n+++ b/cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py\n@@ -0,0 +1,141 @@\n+\"\"\"This cookbook shows how to implement Agentic RAG using Infinity Reranker.\n+\n+Infinity is a high-performance inference server for text-embeddings, reranking, and classification models.\n+It provides fast and efficient reranking capabilities for RAG applications.\n+\n+## Setup Instructions:\n+\n+### 1. Install Dependencies\n+Run: `pip install agno anthropic infinity-client lancedb`\n+\n+### 2. Set up Infinity Server\n+You have several options to deploy Infinity:\n+\n+#### Local Installation\n+```bash\n+# Install infinity\n+pip install \"infinity-emb[all]\"\n+\n+# Run infinity server with reranking model\n+infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997\n+```\n+Wait for the engine to start.\n+\n+# For better performance, you can use larger models:\n+# BAAI/bge-reranker-large\n+# BAAI/bge-reranker-v2-m3\n+# ms-marco-MiniLM-L-12-v2\n+\n+\n+### 3. Export API Keys\n+```bash\n+export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n+```\n+\n+### 4. Run the Example\n+```bash\n+python cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py\n+```\n+\n+## About Infinity Reranker:\n+- Provides fast, local reranking without external API calls\n+- Supports multiple state-of-the-art reranking models\n+- Can be deployed on GPU for better performance\n+- Offers both sync and async reranking capabilities\n+- More deployment options: https://michaelfeil.eu/infinity/0.0.76/deploy/\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.embedder.cohere import CohereEmbedder\n+from agno.knowledge.url import UrlKnowledge\n+from agno.models.anthropic import Claude\n+from agno.reranker.infinity import InfinityReranker\n+from agno.vectordb.lancedb import LanceDb, SearchType\n+\n+# Create a knowledge base, loaded with documents from a URL\n+knowledge_base = UrlKnowledge(\n+    urls=[\n+        \"https://docs.agno.com/introduction/agents.md\",\n+        \"https://docs.agno.com/agents/tools.md\",\n+        \"https://docs.agno.com/agents/knowledge.md\",\n+    ],\n+    # Use LanceDB as the vector database, store embeddings in the `agno_docs_infinity` table\n+    vector_db=LanceDb(\n+        uri=\"tmp/lancedb\",\n+        table_name=\"agno_docs_infinity\",\n+        search_type=SearchType.hybrid,\n+        embedder=CohereEmbedder(id=\"embed-v4.0\"),\n+        # Use Infinity reranker for local, fast reranking\n+        reranker=InfinityReranker(\n+            model=\"BAAI/bge-reranker-base\",  # You can change this to other models\n+            host=\"localhost\",\n+            port=7997,\n+            top_n=5,  # Return top 5 reranked documents\n+        ),\n+    ),\n+)\n+\n+agent = Agent(\n+    model=Claude(id=\"claude-3-7-sonnet-latest\"),\n+    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.\n+    knowledge=knowledge_base,\n+    # search_knowledge=True gives the Agent the ability to search on demand\n+    # search_knowledge is True by default\n+    search_knowledge=True,\n+    instructions=[\n+        \"Include sources in your response.\",\n+        \"Always search your knowledge before answering the question.\",\n+        \"Provide detailed and accurate information based on the retrieved documents.\",\n+    ],\n+    markdown=True,\n+)\n+\n+\n+def test_infinity_connection():\n+    \"\"\"Test if Infinity server is running and accessible\"\"\"\n+    try:\n+        from infinity_client import Client\n+\n+        client = Client(base_url=\"http://localhost:7997\")\n+        print(\"\u2705 Successfully connected to Infinity server at localhost:7997\")\n+        return True\n+    except Exception as e:\n+        print(f\"\u274c Failed to connect to Infinity server: {e}\")\n+        print(\n+            \"\\nPlease make sure Infinity server is running. See setup instructions above.\"\n+        )\n+        return False\n+\n+\n+if __name__ == \"__main__\":\n+    print(\"\ud83d\ude80 Agentic RAG with Infinity Reranker Example\")\n+    print(\"=\" * 50)\n+\n+    # Test Infinity connection first\n+    if not test_infinity_connection():\n+        exit(1)\n+\n+    print(\"\\n\ud83d\udcda Loading knowledge base...\")\n+    # Load the knowledge base, comment after first run\n+    knowledge_base.load(recreate=True)\n+    print(\"\u2705 Knowledge base loaded successfully!\")\n+\n+    print(\"\\n\ud83e\udd16 Starting agent interaction...\")\n+    print(\"=\" * 50)\n+\n+    # Example questions to test the reranking capabilities\n+    questions = [\n+        \"What are Agents and how do they work?\",\n+        \"How do I use tools with agents?\",\n+        \"What is the difference between knowledge and tools?\",\n+    ]\n+\n+    for i, question in enumerate(questions, 1):\n+        print(f\"\\n\ud83d\udd0d Question {i}: {question}\")\n+        print(\"-\" * 40)\n+        agent.print_response(question, stream=True)\n+        print(\"\\n\" + \"=\" * 50)\n+\n+    print(\"\\n\ud83c\udf89 Example completed!\")\n+    print(\"\\nThe Infinity reranker helped improve the relevance of retrieved documents\")\n+    print(\"by reranking them based on semantic similarity to your queries.\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/agentic_search/lightrag/agentic_rag_with_lightrag.py",
            "diff": "diff --git a/cookbook/agent_concepts/agentic_search/lightrag/agentic_rag_with_lightrag.py b/cookbook/agent_concepts/agentic_search/lightrag/agentic_rag_with_lightrag.py\nnew file mode 100644\nindex 000000000..09e7ef110\n--- /dev/null\n+++ b/cookbook/agent_concepts/agentic_search/lightrag/agentic_rag_with_lightrag.py\n@@ -0,0 +1,46 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.knowledge.light_rag import LightRagKnowledgeBase, lightrag_retriever\n+from agno.models.anthropic import Claude\n+\n+# Create a knowledge base, loaded with documents from a URL\n+knowledge_base = LightRagKnowledgeBase(\n+    lightrag_server_url=\"http://localhost:9621\",\n+    path=\"tmp/\",  # Load documents from a local directory\n+    urls=[\"https://docs.agno.com/introduction/agents.md\"],  # Load documents from a URL\n+)\n+\n+# Load the knowledge base with the documents from the local directory and the URL\n+asyncio.run(knowledge_base.load())\n+\n+# Load the knowledge base with the text\n+asyncio.run(\n+    knowledge_base.load_text(text=\"Dogs and cats are not pets, they are friends.\")\n+)\n+\n+\n+# Create an agent with the knowledge base and the retriever\n+agent = Agent(\n+    model=Claude(id=\"claude-3-7-sonnet-latest\"),\n+    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.\n+    knowledge=knowledge_base,\n+    retriever=lightrag_retriever,\n+    # search_knowledge=True gives the Agent the ability to search on demand\n+    # search_knowledge is True by default\n+    search_knowledge=True,\n+    instructions=[\n+        \"Include sources in your response.\",\n+        \"Always search your knowledge before answering the question.\",\n+        \"Use the async_search method to search the knowledge base.\",\n+    ],\n+    markdown=True,\n+)\n+\n+\n+asyncio.run(\n+    agent.aprint_response(\n+        \"Which candidates are available for the role of a Senior Software Engineer?\"\n+    )\n+)\n+asyncio.run(agent.aprint_response(\"What are Agno Agents?\"))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/knowledge/embedders/langdb_embedder.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/embedders/langdb_embedder.py b/cookbook/agent_concepts/knowledge/embedders/langdb_embedder.py\nnew file mode 100644\nindex 000000000..26578c3de\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/embedders/langdb_embedder.py\n@@ -0,0 +1,19 @@\n+from agno.agent import AgentKnowledge\n+from agno.embedder.langdb import LangDBEmbedder\n+from agno.vectordb.pgvector import PgVector\n+\n+embeddings = LangDBEmbedder().get_embedding(\"Embed me\")\n+\n+# Print the embeddings and their dimensions\n+print(f\"Embeddings: {embeddings[:5]}\")\n+print(f\"Dimensions: {len(embeddings)}\")\n+\n+# Example usage:\n+knowledge_base = AgentKnowledge(\n+    vector_db=PgVector(\n+        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n+        table_name=\"langdb_embeddings\",\n+        embedder=LangDBEmbedder(),\n+    ),\n+    num_documents=2,\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py b/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py\nnew file mode 100644\nindex 000000000..0606a6667\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py\n@@ -0,0 +1,122 @@\n+\"\"\"\n+User-Level Knowledge Filtering Example\n+\n+This cookbook demonstrates how to use knowledge filters to restrict knowledge base searches to specific users, document types, or any other metadata attributes.\n+\n+Key concepts demonstrated:\n+1. Loading documents with user-specific metadata\n+2. Filtering knowledge base searches by user ID\n+3. Combining multiple filter criteria\n+4. Comparing results across different filter combinations\n+\n+You can pass filters in the following ways:\n+1. If you pass on Agent only, we use that for all runs\n+2. If you pass on run/print_response only, we use that for that run\n+3. If you pass on both, we override with the filters passed on run/print_response for that run\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.knowledge.text import TextKnowledgeBase\n+from agno.utils.media import (\n+    SampleDataFileExtension,\n+    download_knowledge_filters_sample_data,\n+)\n+from agno.vectordb.lancedb import LanceDb\n+\n+# Download all sample CVs and get their paths\n+downloaded_cv_paths = download_knowledge_filters_sample_data(\n+    num_files=5, file_extension=SampleDataFileExtension.TXT\n+)\n+\n+# Initialize LanceDB\n+# By default, it stores data in /tmp/lancedb\n+vector_db = LanceDb(\n+    table_name=\"recipes\",\n+    uri=\"tmp/lancedb\",  # You can change this path to store data elsewhere\n+)\n+\n+# Step 1: Initialize knowledge base with documents and metadata\n+# ------------------------------------------------------------------------------\n+# When initializing the knowledge base, we can attach metadata that will be used for filtering\n+# This metadata can include user IDs, document types, dates, or any other attributes\n+\n+knowledge_base = TextKnowledgeBase(\n+    path=[\n+        {\n+            \"path\": downloaded_cv_paths[0],\n+            \"metadata\": {\n+                \"user_id\": \"jordan_mitchell\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[1],\n+            \"metadata\": {\n+                \"user_id\": \"taylor_brooks\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[2],\n+            \"metadata\": {\n+                \"user_id\": \"morgan_lee\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[3],\n+            \"metadata\": {\n+                \"user_id\": \"casey_jordan\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[4],\n+            \"metadata\": {\n+                \"user_id\": \"alex_rivera\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+    ],\n+    vector_db=vector_db,\n+)\n+\n+# Load all documents into the vector database\n+knowledge_base.load(recreate=True)\n+\n+# Step 2: Query the knowledge base with different filter combinations\n+# ------------------------------------------------------------------------------\n+\n+# Option 1: Filters on the Agent\n+# Initialize the Agent with the knowledge base and filters\n+agent = Agent(\n+    knowledge=knowledge_base,\n+    search_knowledge=False,\n+    add_references=True,\n+    knowledge_filters={\"user_id\": \"jordan_mitchell\"},\n+)\n+\n+# Query for Jordan Mitchell's experience and skills\n+agent.print_response(\n+    \"Tell me about Jordan Mitchell's experience and skills\",\n+    markdown=True,\n+)\n+\n+# # Option 2: Filters on the run/print_response\n+# agent = Agent(\n+#     knowledge=knowledge_base,\n+#     add_references=True,\n+#     search_knowledge=False,\n+# )\n+\n+# # Query for Taylor Brooks as a candidate\n+# agent.print_response(\n+#     \"Tell me about Taylor Brooks as a candidate\",\n+#     knowledge_filters={\"user_id\": \"taylor_brooks\"},\n+#     markdown=True,\n+# )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/knowledge/pdf_bytes_kb.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/pdf_bytes_kb.py b/cookbook/agent_concepts/knowledge/pdf_bytes_kb.py\nnew file mode 100644\nindex 000000000..7a1f0903d\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/pdf_bytes_kb.py\n@@ -0,0 +1,24 @@\n+from agno.agent import Agent\n+from agno.knowledge.pdf import PDFBytesKnowledgeBase\n+from agno.vectordb.lancedb import LanceDb\n+\n+vector_db = LanceDb(\n+    table_name=\"recipes_async\",\n+    uri=\"tmp/lancedb\",\n+)\n+\n+with open(\"data/pdfs/ThaiRecipes.pdf\", \"rb\") as f:\n+    pdf_bytes = f.read()\n+\n+knowledge_base = PDFBytesKnowledgeBase(\n+    pdfs=[pdf_bytes],\n+    vector_db=vector_db,\n+)\n+knowledge_base.load(recreate=False)  # Comment out after first run\n+\n+agent = Agent(\n+    knowledge=knowledge_base,\n+    search_knowledge=True,\n+)\n+\n+agent.print_response(\"How to make Tom Kha Gai?\", markdown=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/knowledge/pdf_bytes_kb_async.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/pdf_bytes_kb_async.py b/cookbook/agent_concepts/knowledge/pdf_bytes_kb_async.py\nnew file mode 100644\nindex 000000000..6bf98f282\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/pdf_bytes_kb_async.py\n@@ -0,0 +1,30 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.knowledge.pdf import PDFBytesKnowledgeBase\n+from agno.vectordb.lancedb import LanceDb\n+\n+vector_db = LanceDb(\n+    table_name=\"recipes_async\",\n+    uri=\"tmp/lancedb\",\n+)\n+\n+with open(\"data/pdfs/ThaiRecipes.pdf\", \"rb\") as f:\n+    pdf_bytes = f.read()\n+\n+knowledge_base = PDFBytesKnowledgeBase(\n+    pdfs=[pdf_bytes],\n+    vector_db=vector_db,\n+)\n+\n+agent = Agent(\n+    knowledge=knowledge_base,\n+    search_knowledge=True,\n+)\n+\n+if __name__ == \"__main__\":\n+    # Comment out after first run\n+    asyncio.run(knowledge_base.aload(recreate=False))\n+\n+    # Create and use the agent\n+    asyncio.run(agent.aprint_response(\"How to make Tom Kha Gai?\", markdown=True))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/other/parse_model.py",
            "diff": "diff --git a/cookbook/agent_concepts/other/parse_model.py b/cookbook/agent_concepts/other/parse_model.py\nnew file mode 100644\nindex 000000000..942c2a43a\n--- /dev/null\n+++ b/cookbook/agent_concepts/other/parse_model.py\n@@ -0,0 +1,81 @@\n+import random\n+from typing import List\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.anthropic import Claude\n+from agno.models.openai import OpenAIChat\n+from pydantic import BaseModel, Field\n+from rich.pretty import pprint  # noqa\n+\n+\n+class NationalParkAdventure(BaseModel):\n+    park_name: str = Field(..., description=\"Name of the national park\")\n+    best_season: str = Field(\n+        ...,\n+        description=\"Optimal time of year to visit this park (e.g., 'Late spring to early fall')\",\n+    )\n+    signature_attractions: List[str] = Field(\n+        ...,\n+        description=\"Must-see landmarks, viewpoints, or natural features in the park\",\n+    )\n+    recommended_trails: List[str] = Field(\n+        ...,\n+        description=\"Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')\",\n+    )\n+    wildlife_encounters: List[str] = Field(\n+        ..., description=\"Animals visitors are likely to spot, with viewing tips\"\n+    )\n+    photography_spots: List[str] = Field(\n+        ...,\n+        description=\"Best locations for capturing stunning photos, including sunrise/sunset spots\",\n+    )\n+    camping_options: List[str] = Field(\n+        ..., description=\"Available camping areas, from primitive to RV-friendly sites\"\n+    )\n+    safety_warnings: List[str] = Field(\n+        ..., description=\"Important safety considerations specific to this park\"\n+    )\n+    hidden_gems: List[str] = Field(\n+        ..., description=\"Lesser-known spots or experiences that most visitors miss\"\n+    )\n+    difficulty_rating: int = Field(\n+        ...,\n+        ge=1,\n+        le=5,\n+        description=\"Overall park difficulty for average visitor (1=easy, 5=very challenging)\",\n+    )\n+    estimated_days: int = Field(\n+        ...,\n+        ge=1,\n+        le=14,\n+        description=\"Recommended number of days to properly explore the park\",\n+    )\n+    special_permits_needed: List[str] = Field(\n+        default=[],\n+        description=\"Any special permits or reservations required for certain activities\",\n+    )\n+\n+\n+agent = Agent(\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n+    description=\"You help people plan amazing national park adventures and provide detailed park guides.\",\n+    response_model=NationalParkAdventure,\n+    parser_model=OpenAIChat(id=\"gpt-4o\"),\n+)\n+\n+# Get the response in a variable\n+national_parks = [\n+    \"Yellowstone National Park\",\n+    \"Yosemite National Park\",\n+    \"Grand Canyon National Park\",\n+    \"Zion National Park\",\n+    \"Grand Teton National Park\",\n+    \"Rocky Mountain National Park\",\n+    \"Acadia National Park\",\n+    \"Mount Rainier National Park\",\n+    \"Great Smoky Mountains National Park\",\n+    \"Rocky National Park\",\n+]\n+# Get the response in a variable\n+run: RunResponse = agent.run(national_parks[random.randint(0, len(national_parks) - 1)])\n+pprint(run.content)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/other/parse_model_ollama.py",
            "diff": "diff --git a/cookbook/agent_concepts/other/parse_model_ollama.py b/cookbook/agent_concepts/other/parse_model_ollama.py\nnew file mode 100644\nindex 000000000..4f803c0fc\n--- /dev/null\n+++ b/cookbook/agent_concepts/other/parse_model_ollama.py\n@@ -0,0 +1,80 @@\n+import random\n+from typing import List\n+\n+from agno.agent import Agent, RunResponse\n+from agno.models.ollama import Ollama\n+from agno.models.openai import OpenAIChat\n+from pydantic import BaseModel, Field\n+from rich.pretty import pprint\n+\n+\n+class NationalParkAdventure(BaseModel):\n+    park_name: str = Field(..., description=\"Name of the national park\")\n+    best_season: str = Field(\n+        ...,\n+        description=\"Optimal time of year to visit this park (e.g., 'Late spring to early fall')\",\n+    )\n+    signature_attractions: List[str] = Field(\n+        ...,\n+        description=\"Must-see landmarks, viewpoints, or natural features in the park\",\n+    )\n+    recommended_trails: List[str] = Field(\n+        ...,\n+        description=\"Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')\",\n+    )\n+    wildlife_encounters: List[str] = Field(\n+        ..., description=\"Animals visitors are likely to spot, with viewing tips\"\n+    )\n+    photography_spots: List[str] = Field(\n+        ...,\n+        description=\"Best locations for capturing stunning photos, including sunrise/sunset spots\",\n+    )\n+    camping_options: List[str] = Field(\n+        ..., description=\"Available camping areas, from primitive to RV-friendly sites\"\n+    )\n+    safety_warnings: List[str] = Field(\n+        ..., description=\"Important safety considerations specific to this park\"\n+    )\n+    hidden_gems: List[str] = Field(\n+        ..., description=\"Lesser-known spots or experiences that most visitors miss\"\n+    )\n+    difficulty_rating: int = Field(\n+        ...,\n+        ge=1,\n+        le=5,\n+        description=\"Overall park difficulty for average visitor (1=easy, 5=very challenging)\",\n+    )\n+    estimated_days: int = Field(\n+        ...,\n+        ge=1,\n+        le=14,\n+        description=\"Recommended number of days to properly explore the park\",\n+    )\n+    special_permits_needed: List[str] = Field(\n+        default=[],\n+        description=\"Any special permits or reservations required for certain activities\",\n+    )\n+\n+\n+agent = Agent(\n+    model=OpenAIChat(id=\"o3\"),\n+    description=\"You help people plan amazing national park adventures and provide detailed park guides.\",\n+    response_model=NationalParkAdventure,\n+    parser_model=Ollama(id=\"Osmosis/Osmosis-Structure-0.6B\"),\n+)\n+\n+national_parks = [\n+    \"Yellowstone National Park\",\n+    \"Yosemite National Park\",\n+    \"Grand Canyon National Park\",\n+    \"Zion National Park\",\n+    \"Grand Teton National Park\",\n+    \"Rocky Mountain National Park\",\n+    \"Acadia National Park\",\n+    \"Mount Rainier National Park\",\n+    \"Great Smoky Mountains National Park\",\n+    \"Rocky National Park\",\n+]\n+# Get the response in a variable\n+run: RunResponse = agent.run(national_parks[random.randint(0, len(national_parks) - 1)])\n+pprint(run.content)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/agent_concepts/other/success_criteria.py",
            "diff": "diff --git a/cookbook/agent_concepts/other/success_criteria.py b/cookbook/agent_concepts/other/success_criteria.py\nindex e1e620566..df2c922c1 100644\n--- a/cookbook/agent_concepts/other/success_criteria.py\n+++ b/cookbook/agent_concepts/other/success_criteria.py\n@@ -1,25 +1,44 @@\n+from textwrap import dedent\n+\n from agno.agent import Agent\n-from agno.models.google import Gemini\n-from agno.tools.thinking import ThinkingTools\n+from agno.models.anthropic import Claude\n+from agno.tools.reasoning import ReasoningTools\n \n puzzle_master = Agent(\n-    model=Gemini(id=\"gemini-2.0-flash\"),\n-    tools=[ThinkingTools(add_instructions=True)],\n-    instructions=\"You are a puzzle master for small logic puzzles.\",\n-    show_tool_calls=False,\n-    markdown=False,\n-    stream_intermediate_steps=False,\n-    success_criteria=\"The puzzle has been solved correctly with all drinks uniquely assigned.\",\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n+    tools=[ReasoningTools(add_instructions=True)],\n+    instructions=dedent(\"\"\"\\\n+    You are a puzzle master who creates and solves logic puzzles.\n+    - Create clear puzzles with unique solutions\n+    - Solve systematically using logical deduction\n+    - Verify all clues are satisfied\n+    - Show your reasoning step-by-step\\\n+    \"\"\"),\n+    success_criteria=dedent(\"\"\"\\\n+    The puzzle must be:\n+    1. Completely solved with a unique, correct solution\n+    2. All clues satisfied and verified\n+    3. Solution process clearly explained with logical reasoning\n+    4. Final answer explicitly stated in a clear format\\\n+    \"\"\"),\n+    markdown=True,\n )\n \n+puzzle = \"\"\"\\\n+Create and solve this logic puzzle:\n \n-prompt = \"\"\"\n-Create a small logic puzzle:\n Three friends\u2014Alice, Bob, and Carol\u2014each choose a different drink from tea, coffee, and milk.\n-Clues:\n+\n+CLUES:\n 1. Alice does not drink tea.\n 2. The person who drinks coffee is not Carol.\n-Ask: Who drinks which beverage?\n+\n+Present the final answer as: \"Alice drinks X, Bob drinks Y, Carol drinks Z\"\\\n \"\"\"\n \n-puzzle_master.print_response(prompt, stream=True, show_reasoning=True)\n+puzzle_master.print_response(\n+    puzzle,\n+    stream=True,\n+    show_full_reasoning=True,\n+    stream_intermediate_steps=True,\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/agui/__init__.py",
            "diff": "diff --git a/cookbook/apps/agui/__init__.py b/cookbook/apps/agui/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/agui/agent_with_tool.py",
            "diff": "diff --git a/cookbook/apps/agui/agent_with_tool.py b/cookbook/apps/agui/agent_with_tool.py\nnew file mode 100644\nindex 000000000..9f7228e25\n--- /dev/null\n+++ b/cookbook/apps/agui/agent_with_tool.py\n@@ -0,0 +1,27 @@\n+from agno.agent.agent import Agent\n+from agno.app.agui.app import AGUIApp\n+from agno.models.openai import OpenAIChat\n+from agno.tools.yfinance import YFinanceTools\n+\n+agent = Agent(\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    tools=[\n+        YFinanceTools(\n+            stock_price=True, analyst_recommendations=True, stock_fundamentals=True\n+        )\n+    ],\n+    description=\"You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.\",\n+    instructions=\"Format your response using markdown and use tables to display data where possible.\",\n+)\n+\n+agui_app = AGUIApp(\n+    agent=agent,\n+    name=\"Investment Analyst\",\n+    app_id=\"investment_analyst\",\n+    description=\"An investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.\",\n+)\n+\n+app = agui_app.get_app()\n+\n+if __name__ == \"__main__\":\n+    agui_app.serve(app=\"agent_with_tool:app\", port=8000, reload=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/agui/basic.py",
            "diff": "diff --git a/cookbook/apps/agui/basic.py b/cookbook/apps/agui/basic.py\nnew file mode 100644\nindex 000000000..88431d292\n--- /dev/null\n+++ b/cookbook/apps/agui/basic.py\n@@ -0,0 +1,23 @@\n+from agno.agent.agent import Agent\n+from agno.app.agui.app import AGUIApp\n+from agno.models.openai import OpenAIChat\n+\n+chat_agent = Agent(\n+    name=\"Assistant\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    instructions=\"You are a helpful AI assistant.\",\n+    add_datetime_to_instructions=True,\n+    markdown=True,\n+)\n+\n+agui_app = AGUIApp(\n+    agent=chat_agent,\n+    name=\"Basic AG-UI Agent\",\n+    app_id=\"basic_agui_agent\",\n+    description=\"A basic agent that demonstrates AG-UI protocol integration.\",\n+)\n+\n+app = agui_app.get_app()\n+\n+if __name__ == \"__main__\":\n+    agui_app.serve(app=\"basic:app\", port=8000, reload=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/agui/research_team.py",
            "diff": "diff --git a/cookbook/apps/agui/research_team.py b/cookbook/apps/agui/research_team.py\nnew file mode 100644\nindex 000000000..374a6ff10\n--- /dev/null\n+++ b/cookbook/apps/agui/research_team.py\n@@ -0,0 +1,45 @@\n+from agno.agent.agent import Agent\n+from agno.app.agui.app import AGUIApp\n+from agno.models.openai import OpenAIChat\n+from agno.team.team import Team\n+\n+researcher = Agent(\n+    name=\"researcher\",\n+    role=\"Research Assistant\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    instructions=\"You are a research assistant. Find information and provide detailed analysis.\",\n+    markdown=True,\n+)\n+\n+writer = Agent(\n+    name=\"writer\",\n+    role=\"Content Writer\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    instructions=\"You are a content writer. Create well-structured content based on research.\",\n+    markdown=True,\n+)\n+\n+research_team = Team(\n+    members=[researcher, writer],\n+    name=\"research_team\",\n+    instructions=\"\"\"\n+    You are a research team that helps users with research and content creation.\n+    First, use the researcher to gather information, then use the writer to create content.\n+    \"\"\",\n+    show_tool_calls=True,\n+    show_members_responses=True,\n+    get_member_information_tool=True,\n+    add_member_tools_to_system_message=True,\n+)\n+\n+agui_app = AGUIApp(\n+    team=research_team,\n+    name=\"Research Team AG-UI\",\n+    app_id=\"research_team_agui\",\n+    description=\"A research team that demonstrates AG-UI protocol integration.\",\n+)\n+\n+app = agui_app.get_app()\n+\n+if __name__ == \"__main__\":\n+    agui_app.serve(app=\"research_team:app\", port=8000, reload=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/fastapi/advanced.py",
            "diff": "diff --git a/cookbook/apps/fastapi/advanced.py b/cookbook/apps/fastapi/advanced.py\nnew file mode 100644\nindex 000000000..08eac3c31\n--- /dev/null\n+++ b/cookbook/apps/fastapi/advanced.py\n@@ -0,0 +1,149 @@\n+from textwrap import dedent\n+\n+from agno.agent import Agent\n+from agno.app.fastapi.app import FastAPIApp\n+from agno.memory.v2 import Memory\n+from agno.memory.v2.db.sqlite import SqliteMemoryDb\n+from agno.models.openai import OpenAIChat\n+from agno.storage.sqlite import SqliteStorage\n+from agno.team.team import Team\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+from agno.tools.exa import ExaTools\n+from agno.tools.yfinance import YFinanceTools\n+\n+agent_storage_file: str = \"tmp/agents.db\"\n+memory_storage_file: str = \"tmp/memory.db\"\n+\n+memory_db = SqliteMemoryDb(table_name=\"memory\", db_file=memory_storage_file)\n+\n+# No need to set the model, it gets set by the agent to the agent's model\n+memory = Memory(db=memory_db)\n+\n+simple_agent = Agent(\n+    name=\"Simple Agent\",\n+    role=\"Answer basic questions\",\n+    agent_id=\"simple-agent\",\n+    model=OpenAIChat(id=\"gpt-4o-mini\"),\n+    storage=SqliteStorage(\n+        table_name=\"simple_agent\", db_file=agent_storage_file, auto_upgrade_schema=True\n+    ),\n+    memory=memory,\n+    enable_user_memories=True,\n+    add_history_to_messages=True,\n+    num_history_responses=5,\n+    add_datetime_to_instructions=True,\n+    markdown=True,\n+)\n+\n+web_agent = Agent(\n+    name=\"Web Agent\",\n+    role=\"Search the web for information\",\n+    agent_id=\"web-agent\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    tools=[DuckDuckGoTools()],\n+    instructions=[\n+        \"Break down the users request into 2-3 different searches.\",\n+        \"Always include sources\",\n+    ],\n+    storage=SqliteStorage(\n+        table_name=\"web_agent\", db_file=agent_storage_file, auto_upgrade_schema=True\n+    ),\n+    memory=memory,\n+    enable_user_memories=True,\n+    add_history_to_messages=True,\n+    num_history_responses=5,\n+    add_datetime_to_instructions=True,\n+    markdown=True,\n+)\n+\n+finance_agent = Agent(\n+    name=\"Finance Agent\",\n+    role=\"Get financial data\",\n+    agent_id=\"finance-agent\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    tools=[\n+        YFinanceTools(\n+            stock_price=True,\n+            analyst_recommendations=True,\n+            company_info=True,\n+            company_news=True,\n+        )\n+    ],\n+    instructions=[\"Always use tables to display data\"],\n+    storage=SqliteStorage(\n+        table_name=\"finance_agent\", db_file=agent_storage_file, auto_upgrade_schema=True\n+    ),\n+    memory=memory,\n+    enable_user_memories=True,\n+    add_history_to_messages=True,\n+    num_history_responses=5,\n+    add_datetime_to_instructions=True,\n+    markdown=True,\n+)\n+\n+research_agent = Agent(\n+    name=\"Research Agent\",\n+    role=\"Research agent\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    instructions=[\"You are a research agent\"],\n+    tools=[DuckDuckGoTools(), ExaTools()],\n+    agent_id=\"research_agent\",\n+    memory=memory,\n+    storage=SqliteStorage(\n+        table_name=\"research_agent\",\n+        db_file=agent_storage_file,\n+        auto_upgrade_schema=True,\n+    ),\n+    enable_user_memories=True,\n+)\n+\n+research_team = Team(\n+    name=\"Research Team\",\n+    description=\"A team of agents that research the web\",\n+    members=[research_agent, simple_agent],\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    mode=\"coordinate\",\n+    team_id=\"research-team\",\n+    success_criteria=dedent(\"\"\"\\\n+        A comprehensive research report with clear sections and data-driven insights.\n+    \"\"\"),\n+    instructions=[\n+        \"You are the lead researcher of a research team! \ud83d\udd0d\",\n+    ],\n+    memory=memory,\n+    enable_user_memories=True,\n+    add_datetime_to_instructions=True,\n+    show_tool_calls=True,\n+    markdown=True,\n+    enable_agentic_context=True,\n+    storage=SqliteStorage(\n+        table_name=\"research_team\",\n+        db_file=agent_storage_file,\n+        auto_upgrade_schema=True,\n+        mode=\"team\",\n+    ),\n+)\n+\n+\n+fastapi_app = FastAPIApp(\n+    agents=[\n+        simple_agent,\n+        web_agent,\n+        finance_agent,\n+    ],\n+    teams=[research_team],\n+    app_id=\"advanced-app\",\n+    name=\"Advanced FastAPI App\",\n+    description=\"A FastAPI app for advanced agents\",\n+)\n+app = fastapi_app.get_app()\n+\n+if __name__ == \"__main__\":\n+    \"\"\"\n+    Now you can reach your agents/teams with the following URLs:\n+    - http://localhost:8001/runs?agent_id=simple-agent\n+    - http://localhost:8001/runs?agent_id=web-agent\n+    - http://localhost:8001/runs?agent_id=finance-agent\n+    - http://localhost:8001/runs?team_id=research-team\n+    \"\"\"\n+    fastapi_app.serve(app=\"advanced:app\", port=8001, reload=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/playground/competitor_analysis.py",
            "diff": "diff --git a/cookbook/apps/playground/competitor_analysis.py b/cookbook/apps/playground/competitor_analysis.py\nnew file mode 100644\nindex 000000000..74ecd9165\n--- /dev/null\n+++ b/cookbook/apps/playground/competitor_analysis.py\n@@ -0,0 +1,199 @@\n+\"\"\"\ud83d\udd0d Competitor Analysis Agent!\n+\n+Key capabilities:\n+- Company discovery using Firecrawl search\n+- Website scraping and content analysis\n+- Competitive intelligence gathering\n+- SWOT analysis with reasoning\n+- Strategic recommendations\n+- Structured thinking and analysis\n+\n+Example queries to try:\n+- \"Analyze OpenAI's main competitors in the LLM space\"\n+- \"Compare Uber vs Lyft in the ride-sharing market\"\n+- \"Analyze Tesla's competitive position vs traditional automakers\"\n+- \"Research fintech competitors to Stripe\"\n+- \"Analyze Nike vs Adidas in the athletic apparel market\"\n+\n+Dependencies: `pip install openai firecrawl-py agno`\n+\"\"\"\n+\n+from textwrap import dedent\n+\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.playground import Playground\n+from agno.storage.sqlite import SqliteStorage\n+from agno.tools.firecrawl import FirecrawlTools\n+from agno.tools.reasoning import ReasoningTools\n+\n+competitor_analysis_agent = Agent(\n+    model=OpenAIChat(id=\"gpt-4.1\"),\n+    name=\"Competitor Analysis Agent\",\n+    tools=[\n+        FirecrawlTools(\n+            search=True,\n+            scrape=True,\n+            mapping=True,\n+            formats=[\"markdown\", \"links\", \"html\"],\n+            search_params={\n+                \"limit\": 2,\n+            },\n+            limit=5,\n+        ),\n+        ReasoningTools(add_instructions=True),\n+    ],\n+    description=\"You run competitor analysis for a company.\",\n+    instructions=dedent(\"\"\"\\\n+        1. Initial Research & Discovery:\n+           - Use search tool to find information about the target company\n+           - Search for 'companies like [company name]'. Do only 1 search.\n+           - Search for industry reports and market analysis. Do only 1 search.\n+           - Use the think tool to plan your research approach.\n+        2. Competitor Identification:\n+           - Search for 3 identified competitor using Firecrawl.\n+           - Scrape competitor websites using Firecrawl.\n+           - Extract product information, pricing, and value propositions.\n+        3. Map out the competitive landscape.\n+           - Use the analyze tool after gathering information on each competitor\n+           - Compare features, pricing, and market positioning\n+           - Identify patterns and competitive dynamics\n+        4. Conduct SWOT analysis for each major competitor\n+           - Use reasoning to identify competitive advantages\n+           - Analyze market trends and opportunities\n+           - Develop strategic recommendations\n+\n+        - Always use the think tool before starting major research phases\n+        - Use the analyze tool to process findings and draw insights\n+        - Be thorough but focused in your analysis\n+        - Provide evidence-based recommendations\n+    \"\"\"),\n+    expected_output=dedent(\"\"\"\\\n+    # Competitive Analysis Report: {Target Company}\n+\n+    ## Executive Summary\n+    {High-level overview of competitive landscape and key findings}\n+\n+    ## Research Methodology\n+    - Search queries used\n+    - Websites analyzed\n+    - Key information sources\n+\n+    ## Market Overview\n+    ### Industry Context\n+    - Market size and growth rate\n+    - Key trends and drivers\n+    - Regulatory environment\n+\n+    ### Competitive Landscape\n+    - Major players identified\n+    - Market segmentation\n+    - Competitive dynamics\n+\n+    ## Competitor Analysis\n+\n+    ### Competitor 1: {Name}\n+    #### Company Overview\n+    - Website: {URL}\n+    - Founded: {Year}\n+    - Headquarters: {Location}\n+    - Company size: {Employees/Revenue if available}\n+\n+    #### Products & Services\n+    - Core offerings\n+    - Key features and capabilities\n+    - Pricing model and tiers\n+    - Target market segments\n+\n+    #### Digital Presence Analysis\n+    - Website structure and user experience\n+    - Key messaging and value propositions\n+    - Content strategy and resources\n+    - Customer proof points\n+\n+    #### SWOT Analysis\n+    **Strengths:**\n+    - {Evidence-based strengths}\n+\n+    **Weaknesses:**\n+    - {Identified weaknesses}\n+\n+    **Opportunities:**\n+    - {Market opportunities}\n+\n+    **Threats:**\n+    - {Competitive threats}\n+\n+    ### Competitor 2: {Name}\n+    {Similar structure as above}\n+\n+    ### Competitor 3: {Name}\n+    {Similar structure as above}\n+\n+    ## Comparative Analysis\n+\n+    ### Feature Comparison Matrix\n+    | Feature | {Target} | Competitor 1 | Competitor 2 | Competitor 3 |\n+    |---------|----------|--------------|--------------|--------------|\n+    | {Feature 1} | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 |\n+    | {Feature 2} | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 |\n+\n+    ### Pricing Comparison\n+    | Company | Entry Level | Professional | Enterprise |\n+    |---------|-------------|--------------|------------|\n+    | {Pricing details extracted from websites} |\n+\n+    ### Market Positioning Analysis\n+    {Analysis of how each competitor positions themselves}\n+\n+    ## Strategic Insights\n+\n+    ### Key Findings\n+    1. {Major insight with evidence}\n+    2. {Competitive dynamics observed}\n+    3. {Market gaps identified}\n+\n+    ### Competitive Advantages\n+    - {Target company's advantages}\n+    - {Unique differentiators}\n+\n+    ### Competitive Risks\n+    - {Main threats from competitors}\n+    - {Market challenges}\n+\n+    ## Strategic Recommendations\n+\n+    ### Immediate Actions (0-3 months)\n+    1. {Quick competitive responses}\n+    2. {Low-hanging fruit opportunities}\n+\n+    ### Short-term Strategy (3-12 months)\n+    1. {Product/service enhancements}\n+    2. {Market positioning adjustments}\n+\n+    ### Long-term Strategy (12+ months)\n+    1. {Sustainable differentiation}\n+    2. {Market expansion opportunities}\n+\n+    ## Conclusion\n+    {Summary of competitive position and strategic imperatives}\n+    \"\"\"),\n+    markdown=True,\n+    add_datetime_to_instructions=True,\n+    storage=SqliteStorage(\n+        table_name=\"competitor_analysis\",\n+        db_file=\"tmp/competitor_analysis.db\",\n+    ),\n+)\n+\n+\n+playground = Playground(\n+    agents=[competitor_analysis_agent],\n+    name=\"Competitor Analysis\",\n+    description=\"Agents for competitor analysis\",\n+    app_id=\"competitor-analysis\",\n+)\n+app = playground.get_app(use_async=False)\n+\n+if __name__ == \"__main__\":\n+    playground.serve(app=\"competitor_analysis:app\", reload=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/slack/agent_with_user_memory.py",
            "diff": "diff --git a/cookbook/apps/slack/agent_with_user_memory.py b/cookbook/apps/slack/agent_with_user_memory.py\nindex f9bf70ba0..fdd188652 100644\n--- a/cookbook/apps/slack/agent_with_user_memory.py\n+++ b/cookbook/apps/slack/agent_with_user_memory.py\n@@ -54,6 +54,9 @@ personal_agent = Agent(\n \n slack_api_app = SlackAPI(\n     agent=personal_agent,\n+    name=\"Agent with User Memory\",\n+    app_id=\"agent_with_user_memory\",\n+    description=\"A agent with user memory that can chat with the user about things and make them feel good.\",\n )\n app = slack_api_app.get_app()\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/slack/basic.py",
            "diff": "diff --git a/cookbook/apps/slack/basic.py b/cookbook/apps/slack/basic.py\nindex f388b1ea0..208ecf933 100644\n--- a/cookbook/apps/slack/basic.py\n+++ b/cookbook/apps/slack/basic.py\n@@ -12,6 +12,9 @@ basic_agent = Agent(\n \n slack_api_app = SlackAPI(\n     agent=basic_agent,\n+    name=\"Basic Agent Slack\",\n+    app_id=\"basic_agent\",\n+    description=\"A basic agent that can answer questions and help with tasks.\",\n )\n app = slack_api_app.get_app()\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/apps/slack/reasoning_agent.py",
            "diff": "diff --git a/cookbook/apps/slack/reasoning_agent.py b/cookbook/apps/slack/reasoning_agent.py\nindex fb1751881..c1b376de5 100644\n--- a/cookbook/apps/slack/reasoning_agent.py\n+++ b/cookbook/apps/slack/reasoning_agent.py\n@@ -23,6 +23,9 @@ reasoning_finance_agent = Agent(\n \n slack_api_app = SlackAPI(\n     agent=reasoning_finance_agent,\n+    name=\"Reasoning Finance Agent\",\n+    app_id=\"reasoning_finance_agent\",\n+    description=\"A agent that can reason about finance and stock prices.\",\n )\n app = slack_api_app.get_app()\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/accuracy/accuracy_9_11_bigger_or_9_99.py",
            "diff": "diff --git a/cookbook/evals/accuracy/accuracy_9_11_bigger_or_9_99.py b/cookbook/evals/accuracy/accuracy_9_11_bigger_or_9_99.py\nindex bb5104563..0dfa732d1 100644\n--- a/cookbook/evals/accuracy/accuracy_9_11_bigger_or_9_99.py\n+++ b/cookbook/evals/accuracy/accuracy_9_11_bigger_or_9_99.py\n@@ -6,6 +6,7 @@ from agno.models.openai import OpenAIChat\n from agno.tools.calculator import CalculatorTools\n \n evaluation = AccuracyEval(\n+    name=\"Comparison Evaluation\",\n     model=OpenAIChat(id=\"o4-mini\"),\n     agent=Agent(\n         model=OpenAIChat(id=\"gpt-4o\"),\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/accuracy/accuracy_basic.py",
            "diff": "diff --git a/cookbook/evals/accuracy/accuracy_basic.py b/cookbook/evals/accuracy/accuracy_basic.py\nindex b758c711a..d1cb114a3 100644\n--- a/cookbook/evals/accuracy/accuracy_basic.py\n+++ b/cookbook/evals/accuracy/accuracy_basic.py\n@@ -6,6 +6,7 @@ from agno.models.openai import OpenAIChat\n from agno.tools.calculator import CalculatorTools\n \n evaluation = AccuracyEval(\n+    name=\"Calculator Evaluation\",\n     model=OpenAIChat(id=\"o4-mini\"),\n     agent=Agent(\n         model=OpenAIChat(id=\"gpt-4o\"),\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/accuracy/accuracy_team.py",
            "diff": "diff --git a/cookbook/evals/accuracy/accuracy_team.py b/cookbook/evals/accuracy/accuracy_team.py\nindex e9a28a132..b3e542a99 100644\n--- a/cookbook/evals/accuracy/accuracy_team.py\n+++ b/cookbook/evals/accuracy/accuracy_team.py\n@@ -33,6 +33,7 @@ multi_language_team = Team(\n \n # Evaluate the accuracy of the Team's responses\n evaluation = AccuracyEval(\n+    name=\"Multi Language Team\",\n     model=OpenAIChat(id=\"o4-mini\"),\n     team=multi_language_team,\n     input=\"Comment allez-vous?\",\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/accuracy/accuracy_with_given_answer.py",
            "diff": "diff --git a/cookbook/evals/accuracy/accuracy_with_given_answer.py b/cookbook/evals/accuracy/accuracy_with_given_answer.py\nindex 0412f8abc..b3d410db9 100644\n--- a/cookbook/evals/accuracy/accuracy_with_given_answer.py\n+++ b/cookbook/evals/accuracy/accuracy_with_given_answer.py\n@@ -4,6 +4,7 @@ from agno.eval.accuracy import AccuracyEval, AccuracyResult\n from agno.models.openai import OpenAIChat\n \n evaluation = AccuracyEval(\n+    name=\"Given Answer Evaluation\",\n     model=OpenAIChat(id=\"o4-mini\"),\n     input=\"What is 10*5 then to the power of 2? do it step by step\",\n     expected_output=\"2500\",\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/accuracy/accuracy_with_tools.py",
            "diff": "diff --git a/cookbook/evals/accuracy/accuracy_with_tools.py b/cookbook/evals/accuracy/accuracy_with_tools.py\nindex a691bb7b9..6db37a704 100644\n--- a/cookbook/evals/accuracy/accuracy_with_tools.py\n+++ b/cookbook/evals/accuracy/accuracy_with_tools.py\n@@ -6,6 +6,7 @@ from agno.models.openai import OpenAIChat\n from agno.tools.calculator import CalculatorTools\n \n evaluation = AccuracyEval(\n+    name=\"Tools Evaluation\",\n     model=OpenAIChat(id=\"o4-mini\"),\n     agent=Agent(\n         model=OpenAIChat(id=\"gpt-4o-mini\"),\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/instantiation_agent.py",
            "diff": "diff --git a/cookbook/evals/performance/instantiation_agent.py b/cookbook/evals/performance/instantiation_agent.py\nindex abc5e1c11..7af0f4a16 100644\n--- a/cookbook/evals/performance/instantiation_agent.py\n+++ b/cookbook/evals/performance/instantiation_agent.py\n@@ -8,7 +8,9 @@ def instantiate_agent():\n     return Agent(system_message=\"Be concise, reply with one sentence.\")\n \n \n-instantiation_perf = PerformanceEval(func=instantiate_agent, num_iterations=1000)\n+instantiation_perf = PerformanceEval(\n+    name=\"Instantiation Performance\", func=instantiate_agent, num_iterations=1000\n+)\n \n if __name__ == \"__main__\":\n     instantiation_perf.run(print_results=True, print_summary=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/instantiation_agent_with_tool.py",
            "diff": "diff --git a/cookbook/evals/performance/instantiation_agent_with_tool.py b/cookbook/evals/performance/instantiation_agent_with_tool.py\nindex c1353a409..46a481681 100644\n--- a/cookbook/evals/performance/instantiation_agent_with_tool.py\n+++ b/cookbook/evals/performance/instantiation_agent_with_tool.py\n@@ -13,8 +13,6 @@ def get_weather(city: Literal[\"nyc\", \"sf\"]):\n         return \"It might be cloudy in nyc\"\n     elif city == \"sf\":\n         return \"It's always sunny in sf\"\n-    else:\n-        raise AssertionError(\"Unknown city\")\n \n \n tools = [get_weather]\n@@ -24,7 +22,9 @@ def instantiate_agent():\n     return Agent(model=OpenAIChat(id=\"gpt-4o\"), tools=tools)\n \n \n-instantiation_perf = PerformanceEval(func=instantiate_agent, num_iterations=1000)\n+instantiation_perf = PerformanceEval(\n+    name=\"Tool Instantiation Performance\", func=instantiate_agent, num_iterations=1000\n+)\n \n if __name__ == \"__main__\":\n     instantiation_perf.run(print_results=True, print_summary=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/instantiation_team.py",
            "diff": "diff --git a/cookbook/evals/performance/instantiation_team.py b/cookbook/evals/performance/instantiation_team.py\nindex 9b0b7f0a4..736d132b4 100644\n--- a/cookbook/evals/performance/instantiation_team.py\n+++ b/cookbook/evals/performance/instantiation_team.py\n@@ -12,7 +12,9 @@ def instantiate_team():\n     return Team(members=[team_member])\n \n \n-instantiation_perf = PerformanceEval(func=instantiate_team, num_iterations=1000)\n+instantiation_perf = PerformanceEval(\n+    name=\"Instantiation Performance Team\", func=instantiate_team, num_iterations=1000\n+)\n \n if __name__ == \"__main__\":\n     instantiation_perf.run(print_results=True, print_summary=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/response_with_memory_updates.py",
            "diff": "diff --git a/cookbook/evals/performance/response_with_memory_updates.py b/cookbook/evals/performance/response_with_memory_updates.py\nindex 5247f5907..c4b85bdb5 100644\n--- a/cookbook/evals/performance/response_with_memory_updates.py\n+++ b/cookbook/evals/performance/response_with_memory_updates.py\n@@ -25,7 +25,7 @@ def run_agent():\n \n \n response_with_memory_updates_perf = PerformanceEval(\n-    func=run_agent, num_iterations=5, warmup_runs=0\n+    name=\"Memory Updates Performance\", func=run_agent, num_iterations=5, warmup_runs=0\n )\n \n if __name__ == \"__main__\":\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/response_with_storage.py",
            "diff": "diff --git a/cookbook/evals/performance/response_with_storage.py b/cookbook/evals/performance/response_with_storage.py\nindex 6f2a27c8e..c32966eeb 100644\n--- a/cookbook/evals/performance/response_with_storage.py\n+++ b/cookbook/evals/performance/response_with_storage.py\n@@ -19,7 +19,7 @@ def run_agent():\n \n \n response_with_storage_perf = PerformanceEval(\n-    func=run_agent, num_iterations=1, warmup_runs=0\n+    name=\"Storage Performance\", func=run_agent, num_iterations=1, warmup_runs=0\n )\n \n if __name__ == \"__main__\":\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/performance/simple_response.py",
            "diff": "diff --git a/cookbook/evals/performance/simple_response.py b/cookbook/evals/performance/simple_response.py\nindex 1f7be08ba..eb40710b5 100644\n--- a/cookbook/evals/performance/simple_response.py\n+++ b/cookbook/evals/performance/simple_response.py\n@@ -15,7 +15,12 @@ def run_agent():\n     return response\n \n \n-simple_response_perf = PerformanceEval(func=run_agent, num_iterations=1, warmup_runs=0)\n+simple_response_perf = PerformanceEval(\n+    name=\"Simple Performance Evaluation\",\n+    func=run_agent,\n+    num_iterations=1,\n+    warmup_runs=0,\n+)\n \n if __name__ == \"__main__\":\n     simple_response_perf.run(print_results=True, print_summary=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/reliability/multiple_tool_calls/openai/calculator.py",
            "diff": "diff --git a/cookbook/evals/reliability/multiple_tool_calls/openai/calculator.py b/cookbook/evals/reliability/multiple_tool_calls/openai/calculator.py\nindex 27972ebb5..94d8571e7 100644\n--- a/cookbook/evals/reliability/multiple_tool_calls/openai/calculator.py\n+++ b/cookbook/evals/reliability/multiple_tool_calls/openai/calculator.py\n@@ -16,6 +16,7 @@ def multiply_and_exponentiate():\n         \"What is 10*5 then to the power of 2? do it step by step\"\n     )\n     evaluation = ReliabilityEval(\n+        name=\"Tool Calls Reliability\",\n         agent_response=response,\n         expected_tool_calls=[\"multiply\", \"exponentiate\"],\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/reliability/single_tool_calls/google/calculator.py",
            "diff": "diff --git a/cookbook/evals/reliability/single_tool_calls/google/calculator.py b/cookbook/evals/reliability/single_tool_calls/google/calculator.py\nindex 1d3263b9a..d699222a3 100644\n--- a/cookbook/evals/reliability/single_tool_calls/google/calculator.py\n+++ b/cookbook/evals/reliability/single_tool_calls/google/calculator.py\n@@ -13,7 +13,9 @@ def factorial():\n     response: RunResponse = agent.run(\"What is 10!?\")\n \n     evaluation = ReliabilityEval(\n-        agent_response=response, expected_tool_calls=[\"factorial\"]\n+        name=\"Tool Call Reliability\",\n+        agent_response=response,\n+        expected_tool_calls=[\"factorial\"],\n     )\n     result: Optional[ReliabilityResult] = evaluation.run(print_results=True)\n     result.assert_passed()\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/reliability/single_tool_calls/openai/calculator.py",
            "diff": "diff --git a/cookbook/evals/reliability/single_tool_calls/openai/calculator.py b/cookbook/evals/reliability/single_tool_calls/openai/calculator.py\nindex 94e22c5f9..70b97b7a0 100644\n--- a/cookbook/evals/reliability/single_tool_calls/openai/calculator.py\n+++ b/cookbook/evals/reliability/single_tool_calls/openai/calculator.py\n@@ -14,6 +14,7 @@ def factorial():\n     )\n     response: RunResponse = agent.run(\"What is 10!?\")\n     evaluation = ReliabilityEval(\n+        name=\"Tool Call Reliability\",\n         agent_response=response,\n         expected_tool_calls=[\"factorial\"],\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/reliability/team/google/company_info.py",
            "diff": "diff --git a/cookbook/evals/reliability/team/google/company_info.py b/cookbook/evals/reliability/team/google/company_info.py\nindex 9a7617d71..0a414ed40 100644\n--- a/cookbook/evals/reliability/team/google/company_info.py\n+++ b/cookbook/evals/reliability/team/google/company_info.py\n@@ -31,6 +31,7 @@ expected_tool_calls = [\n def evaluate_team_reliability():\n     response: TeamRunResponse = team.run(\"What is the current stock price of NVDA?\")\n     evaluation = ReliabilityEval(\n+        name=\"Team Reliability Evaluation\",\n         team_response=response,\n         expected_tool_calls=expected_tool_calls,\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/evals/reliability/team/openai/company_info.py",
            "diff": "diff --git a/cookbook/evals/reliability/team/openai/company_info.py b/cookbook/evals/reliability/team/openai/company_info.py\nindex ea6260459..7c476ef31 100644\n--- a/cookbook/evals/reliability/team/openai/company_info.py\n+++ b/cookbook/evals/reliability/team/openai/company_info.py\n@@ -31,6 +31,7 @@ expected_tool_calls = [\n def evaluate_team_reliability():\n     response: TeamRunResponse = team.run(\"What is the current stock price of NVDA?\")\n     evaluation = ReliabilityEval(\n+        name=\"Team Reliability Evaluation\",\n         team_response=response,\n         expected_tool_calls=expected_tool_calls,\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/examples/agents/competitor_analysis_agent.py",
            "diff": "diff --git a/cookbook/examples/agents/competitor_analysis_agent.py b/cookbook/examples/agents/competitor_analysis_agent.py\nnew file mode 100644\nindex 000000000..2e018f2c5\n--- /dev/null\n+++ b/cookbook/examples/agents/competitor_analysis_agent.py\n@@ -0,0 +1,204 @@\n+\"\"\"\ud83d\udd0d Competitor Analysis Agent - Your AI-Powered Market Intelligence System!\n+\n+This example demonstrates how to build a sophisticated competitor analysis agent that combines powerful search and scraping capabilities with advanced reasoning tools to provide\n+comprehensive competitive intelligence. The agent performs deep analysis of competitors including\n+market positioning, product offerings, and strategic insights.\n+\n+Key capabilities:\n+- Company discovery using Firecrawl search\n+- Website scraping and content analysis\n+- Competitive intelligence gathering\n+- SWOT analysis with reasoning\n+- Strategic recommendations\n+- Structured thinking and analysis\n+\n+Example queries to try:\n+- \"Analyze OpenAI's main competitors in the LLM space\"\n+- \"Compare Uber vs Lyft in the ride-sharing market\"\n+- \"Analyze Tesla's competitive position vs traditional automakers\"\n+- \"Research fintech competitors to Stripe\"\n+- \"Analyze Nike vs Adidas in the athletic apparel market\"\n+\n+Dependencies: `pip install openai firecrawl-py agno`\n+\"\"\"\n+\n+from textwrap import dedent\n+\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.tools.firecrawl import FirecrawlTools\n+from agno.tools.reasoning import ReasoningTools\n+\n+competitor_analysis_agent = Agent(\n+    model=OpenAIChat(id=\"gpt-4.1\"),\n+    tools=[\n+        FirecrawlTools(\n+            search=True,\n+            crawl=True,\n+            mapping=True,\n+            formats=[\"markdown\", \"links\", \"html\"],\n+            search_params={\n+                \"limit\": 2,\n+            },\n+            limit=5,\n+        ),\n+        ReasoningTools(\n+            add_instructions=True,\n+        ),\n+    ],\n+    instructions=[\n+        \"1. Initial Research & Discovery:\",\n+        \"   - Use search tool to find information about the target company\",\n+        \"   - Search for '[company name] competitors', 'companies like [company name]'\",\n+        \"   - Search for industry reports and market analysis\",\n+        \"   - Use the think tool to plan your research approach\",\n+        \"2. Competitor Identification:\",\n+        \"   - Search for each identified competitor using Firecrawl\",\n+        \"   - Find their official websites and key information sources\",\n+        \"   - Map out the competitive landscape\",\n+        \"3. Website Analysis:\",\n+        \"   - Scrape competitor websites using Firecrawl\",\n+        \"   - Map their site structure to understand their offerings\",\n+        \"   - Extract product information, pricing, and value propositions\",\n+        \"   - Look for case studies and customer testimonials\",\n+        \"4. Deep Competitive Analysis:\",\n+        \"   - Use the analyze tool after gathering information on each competitor\",\n+        \"   - Compare features, pricing, and market positioning\",\n+        \"   - Identify patterns and competitive dynamics\",\n+        \"   - Think through the implications of your findings\",\n+        \"5. Strategic Synthesis:\",\n+        \"   - Conduct SWOT analysis for each major competitor\",\n+        \"   - Use reasoning to identify competitive advantages\",\n+        \"   - Analyze market trends and opportunities\",\n+        \"   - Develop strategic recommendations\",\n+        \"- Always use the think tool before starting major research phases\",\n+        \"- Use the analyze tool to process findings and draw insights\",\n+        \"- Search for multiple perspectives on each competitor\",\n+        \"- Verify information by checking multiple sources\",\n+        \"- Be thorough but focused in your analysis\",\n+        \"- Provide evidence-based recommendations\",\n+    ],\n+    expected_output=dedent(\"\"\"\\\n+    # Competitive Analysis Report: {Target Company}\n+\n+    ## Executive Summary\n+    {High-level overview of competitive landscape and key findings}\n+\n+    ## Research Methodology\n+    - Search queries used\n+    - Websites analyzed\n+    - Key information sources\n+\n+    ## Market Overview\n+    ### Industry Context\n+    - Market size and growth rate\n+    - Key trends and drivers\n+    - Regulatory environment\n+\n+    ### Competitive Landscape\n+    - Major players identified\n+    - Market segmentation\n+    - Competitive dynamics\n+\n+    ## Competitor Analysis\n+\n+    ### Competitor 1: {Name}\n+    #### Company Overview\n+    - Website: {URL}\n+    - Founded: {Year}\n+    - Headquarters: {Location}\n+    - Company size: {Employees/Revenue if available}\n+\n+    #### Products & Services\n+    - Core offerings\n+    - Key features and capabilities\n+    - Pricing model and tiers\n+    - Target market segments\n+\n+    #### Digital Presence Analysis\n+    - Website structure and user experience\n+    - Key messaging and value propositions\n+    - Content strategy and resources\n+    - Customer proof points\n+\n+    #### SWOT Analysis\n+    **Strengths:**\n+    - {Evidence-based strengths}\n+\n+    **Weaknesses:**\n+    - {Identified weaknesses}\n+\n+    **Opportunities:**\n+    - {Market opportunities}\n+\n+    **Threats:**\n+    - {Competitive threats}\n+\n+    ### Competitor 2: {Name}\n+    {Similar structure as above}\n+\n+    ### Competitor 3: {Name}\n+    {Similar structure as above}\n+\n+    ## Comparative Analysis\n+\n+    ### Feature Comparison Matrix\n+    | Feature | {Target} | Competitor 1 | Competitor 2 | Competitor 3 |\n+    |---------|----------|--------------|--------------|--------------|\n+    | {Feature 1} | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 |\n+    | {Feature 2} | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 | \u2713/\u2717 |\n+\n+    ### Pricing Comparison\n+    | Company | Entry Level | Professional | Enterprise |\n+    |---------|-------------|--------------|------------|\n+    | {Pricing details extracted from websites} |\n+\n+    ### Market Positioning Analysis\n+    {Analysis of how each competitor positions themselves}\n+\n+    ## Strategic Insights\n+\n+    ### Key Findings\n+    1. {Major insight with evidence}\n+    2. {Competitive dynamics observed}\n+    3. {Market gaps identified}\n+\n+    ### Competitive Advantages\n+    - {Target company's advantages}\n+    - {Unique differentiators}\n+\n+    ### Competitive Risks\n+    - {Main threats from competitors}\n+    - {Market challenges}\n+\n+    ## Strategic Recommendations\n+\n+    ### Immediate Actions (0-3 months)\n+    1. {Quick competitive responses}\n+    2. {Low-hanging fruit opportunities}\n+\n+    ### Short-term Strategy (3-12 months)\n+    1. {Product/service enhancements}\n+    2. {Market positioning adjustments}\n+\n+    ### Long-term Strategy (12+ months)\n+    1. {Sustainable differentiation}\n+    2. {Market expansion opportunities}\n+\n+    ## Conclusion\n+    {Summary of competitive position and strategic imperatives}\n+    \"\"\"),\n+    markdown=True,\n+    show_tool_calls=True,\n+    add_datetime_to_instructions=True,\n+    stream_intermediate_steps=True,\n+)\n+\n+competitor_analysis_agent.print_response(\n+    \"\"\"\\\n+    Analyze the competitive landscape for Stripe in the payments industry.\n+    Focus on their products, pricing models, and market positioning.\\\n+    \"\"\",\n+    stream=True,\n+    show_full_reasoning=True,\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/examples/agents/social_media_agent.py",
            "diff": "diff --git a/cookbook/examples/agents/social_media_agent.py b/cookbook/examples/agents/social_media_agent.py\nnew file mode 100644\nindex 000000000..37e3d120d\n--- /dev/null\n+++ b/cookbook/examples/agents/social_media_agent.py\n@@ -0,0 +1,102 @@\n+\"\"\"Social Media Agent Example with Dummy Dataset\n+\n+This example demonstrates how to create an agent that:\n+1. Analyzes a dummy dataset of tweets\n+2. Leverages LLM capabilities to perform sophisticated sentiment analysis\n+3. Provides insights about the overall sentiment around a topic\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.tools.x import XTools\n+\n+# Create the social media analysis agent\n+social_media_agent = Agent(\n+    name=\"Social Media Analyst\",\n+    model=OpenAIChat(id=\"gpt-4o\"),\n+    tools=[\n+        XTools(\n+            include_post_metrics=True,\n+            wait_on_rate_limit=True,\n+        )\n+    ],\n+    instructions=\"\"\"\n+    You are a senior Brand Intelligence Analyst with a specialty in social-media listening  on the X (Twitter) platform.  \n+    Your job is to transform raw tweet content and engagement metrics into an executive-ready intelligence report that helps product, marketing, and support teams  make data-driven decisions.  \n+\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    CORE RESPONSIBILITIES\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    1. Retrieve tweets with X tools that you have access to and analyze both the text and metrics such as likes, retweets, replies.\n+    2. Classify every tweet as Positive / Negative / Neutral / Mixed, capturing the reasoning (e.g., praise for feature X, complaint about bugs, etc.).\n+    3. Detect patterns in engagement metrics to surface:\n+       \u2022 Viral advocacy (high likes & retweets, low replies)\n+       \u2022 Controversy (low likes, high replies)\n+       \u2022 Influence concentration (verified or high-reach accounts driving sentiment)\n+    4. Extract thematic clusters and recurring keywords covering:\n+       \u2022 Feature praise / pain points  \n+       \u2022 UX / performance issues  \n+       \u2022 Customer-service interactions  \n+       \u2022 Pricing & ROI perceptions  \n+       \u2022 Competitor mentions & comparisons  \n+       \u2022 Emerging use-cases & adoption barriers\n+    5. Produce actionable, prioritized recommendations (Immediate, Short-term, Long-term) that address the issues and pain points.\n+    6. Supply a response strategy: which posts to engage, suggested tone & template,    influencer outreach, and community-building ideas. \n+\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    DELIVERABLE FORMAT (markdown)\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    ### 1 \u00b7 Executive Snapshot\n+    \u2022 Brand-health score (1-10)  \n+    \u2022 Net sentiment ( % positive \u2013 % negative )  \n+    \u2022 Top 3 positive & negative drivers  \n+    \u2022 Red-flag issues that need urgent attention    \n+\n+    ### 2 \u00b7 Quantitative Dashboard\n+    | Sentiment | #Posts | % | Avg Likes | Avg Retweets | Avg Replies | Notes |\n+    |-----------|-------:|---:|----------:|-------------:|------------:|------|\n+    ( fill table )  \n+\n+    ### 3 \u00b7 Key Themes & Representative Quotes\n+    For each major theme list: description, sentiment trend, excerpted tweets (truncated),  and key metrics. \n+\n+    ### 4 \u00b7 Competitive & Market Signals\n+    \u2022 Competitors referenced, sentiment vs. Agno  \n+    \u2022 Feature gaps users mention  \n+    \u2022 Market positioning insights   \n+\n+    ### 5 \u00b7 Risk Analysis\n+    \u2022 Potential crises / viral negativity  \n+    \u2022 Churn indicators  \n+    \u2022 Trust & security concerns \n+\n+    ### 6 \u00b7 Opportunity Landscape\n+    \u2022 Features or updates that delight users  \n+    \u2022 Advocacy moments & influencer opportunities  \n+    \u2022 Untapped use-cases highlighted by the community   \n+\n+    ### 7 \u00b7 Strategic Recommendations\n+    **Immediate (\u226448 h)** \u2013 urgent fixes or comms  \n+    **Short-term (1-2 wks)** \u2013 quick wins & tests  \n+    **Long-term (1-3 mo)** \u2013 roadmap & positioning  \n+\n+    ### 8 \u00b7 Response Playbook\n+    For high-impact posts list: tweet-id/url, suggested response, recommended responder (e. g., support, PM, exec), and goal (defuse, amplify, learn).   \n+\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    ASSESSMENT & REASONING GUIDELINES\n+    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n+    \u2022 Weigh sentiment by engagement volume & author influence (verified == \u00d71.5 weight).  \n+    \u2022 Use reply-to-like ratio > 0.5 as controversy flag.  \n+    \u2022 Highlight any coordinated or bot-like behaviour.  \n+    \u2022 Use the tools provided to you to get the data you need.\n+\n+    Remember: your insights will directly inform the product strategy, customer-experience efforts, and brand reputation.  Be objective, evidence-backed, and solution-oriented.\n+\"\"\",\n+    markdown=True,\n+    show_tool_calls=True,\n+)\n+\n+social_media_agent.print_response(\n+    \"Analyze the sentiment of Agno and AgnoAGI on X (Twitter) for past 10 tweets\"\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/async_basic.py",
            "diff": "diff --git a/cookbook/models/anthropic/async_basic.py b/cookbook/models/anthropic/async_basic.py\nindex 1d766ab6d..65202ecd1 100644\n--- a/cookbook/models/anthropic/async_basic.py\n+++ b/cookbook/models/anthropic/async_basic.py\n@@ -8,7 +8,7 @@ from agno.agent import Agent\n from agno.models.anthropic import Claude\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     markdown=True,\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/async_basic_stream.py",
            "diff": "diff --git a/cookbook/models/anthropic/async_basic_stream.py b/cookbook/models/anthropic/async_basic_stream.py\nindex 5451e1c4a..2a047fc58 100644\n--- a/cookbook/models/anthropic/async_basic_stream.py\n+++ b/cookbook/models/anthropic/async_basic_stream.py\n@@ -8,7 +8,7 @@ from agno.agent import Agent\n from agno.models.anthropic import Claude\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     markdown=True,\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/async_tool_use.py",
            "diff": "diff --git a/cookbook/models/anthropic/async_tool_use.py b/cookbook/models/anthropic/async_tool_use.py\nindex 024466d1d..c5d04c68a 100644\n--- a/cookbook/models/anthropic/async_tool_use.py\n+++ b/cookbook/models/anthropic/async_tool_use.py\n@@ -9,7 +9,7 @@ from agno.models.anthropic import Claude\n from agno.tools.duckduckgo import DuckDuckGoTools\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     tools=[DuckDuckGoTools()],\n     show_tool_calls=True,\n     markdown=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/basic.py",
            "diff": "diff --git a/cookbook/models/anthropic/basic.py b/cookbook/models/anthropic/basic.py\nindex 33fd957c7..153c17d2b 100644\n--- a/cookbook/models/anthropic/basic.py\n+++ b/cookbook/models/anthropic/basic.py\n@@ -1,7 +1,7 @@\n from agno.agent import Agent, RunResponse  # noqa\n from agno.models.anthropic import Claude\n \n-agent = Agent(model=Claude(id=\"claude-3-5-sonnet-20241022\"), markdown=True)\n+agent = Agent(model=Claude(id=\"claude-sonnet-4-20250514\"), markdown=True)\n \n # Get the response in a variable\n # run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/basic_stream.py",
            "diff": "diff --git a/cookbook/models/anthropic/basic_stream.py b/cookbook/models/anthropic/basic_stream.py\nindex 896293f72..1b95c6ed5 100644\n--- a/cookbook/models/anthropic/basic_stream.py\n+++ b/cookbook/models/anthropic/basic_stream.py\n@@ -2,7 +2,7 @@ from typing import Iterator  # noqa\n from agno.agent import Agent, RunResponse  # noqa\n from agno.models.anthropic import Claude\n \n-agent = Agent(model=Claude(id=\"claude-3-5-sonnet-20241022\"), markdown=True)\n+agent = Agent(model=Claude(id=\"claude-sonnet-4-20250514\"), markdown=True)\n \n # Get the response in a variable\n # run_response: Iterator[RunResponse] = agent.run(\"Share a 2 sentence horror story\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/image_input_bytes.py",
            "diff": "diff --git a/cookbook/models/anthropic/image_input_bytes.py b/cookbook/models/anthropic/image_input_bytes.py\nindex a9c894d57..06969b13a 100644\n--- a/cookbook/models/anthropic/image_input_bytes.py\n+++ b/cookbook/models/anthropic/image_input_bytes.py\n@@ -7,7 +7,7 @@ from agno.tools.duckduckgo import DuckDuckGoTools\n from agno.utils.media import download_image\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     tools=[DuckDuckGoTools()],\n     markdown=True,\n )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/image_input_url.py",
            "diff": "diff --git a/cookbook/models/anthropic/image_input_url.py b/cookbook/models/anthropic/image_input_url.py\nindex 65d96dec5..56aeeb5e1 100644\n--- a/cookbook/models/anthropic/image_input_url.py\n+++ b/cookbook/models/anthropic/image_input_url.py\n@@ -4,7 +4,7 @@ from agno.models.anthropic import Claude\n from agno.tools.duckduckgo import DuckDuckGoTools\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     tools=[DuckDuckGoTools()],\n     markdown=True,\n )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/knowledge.py",
            "diff": "diff --git a/cookbook/models/anthropic/knowledge.py b/cookbook/models/anthropic/knowledge.py\nindex 6af25456c..c2aba4656 100644\n--- a/cookbook/models/anthropic/knowledge.py\n+++ b/cookbook/models/anthropic/knowledge.py\n@@ -19,7 +19,7 @@ knowledge_base = PDFUrlKnowledgeBase(\n knowledge_base.load(recreate=False)  # Comment out after first run\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     knowledge=knowledge_base,\n     show_tool_calls=True,\n     debug_mode=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/memory.py",
            "diff": "diff --git a/cookbook/models/anthropic/memory.py b/cookbook/models/anthropic/memory.py\nindex 292b70042..4f6fceeee 100644\n--- a/cookbook/models/anthropic/memory.py\n+++ b/cookbook/models/anthropic/memory.py\n@@ -14,7 +14,7 @@ from agno.storage.postgres import PostgresStorage\n \n db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     # Store the memories and summary in a database\n     memory=Memory(\n         db=PostgresMemoryDb(table_name=\"agent_memory\", db_url=db_url),\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/pdf_input_bytes.py",
            "diff": "diff --git a/cookbook/models/anthropic/pdf_input_bytes.py b/cookbook/models/anthropic/pdf_input_bytes.py\nindex ae8d9446e..a273e6e8c 100644\n--- a/cookbook/models/anthropic/pdf_input_bytes.py\n+++ b/cookbook/models/anthropic/pdf_input_bytes.py\n@@ -13,7 +13,7 @@ download_file(\n )\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     markdown=True,\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/pdf_input_local.py",
            "diff": "diff --git a/cookbook/models/anthropic/pdf_input_local.py b/cookbook/models/anthropic/pdf_input_local.py\nindex e51953e7b..6aab77e53 100644\n--- a/cookbook/models/anthropic/pdf_input_local.py\n+++ b/cookbook/models/anthropic/pdf_input_local.py\n@@ -13,7 +13,7 @@ download_file(\n )\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     markdown=True,\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/pdf_input_url.py",
            "diff": "diff --git a/cookbook/models/anthropic/pdf_input_url.py b/cookbook/models/anthropic/pdf_input_url.py\nindex 2cbc1b25d..034aa2a8e 100644\n--- a/cookbook/models/anthropic/pdf_input_url.py\n+++ b/cookbook/models/anthropic/pdf_input_url.py\n@@ -3,7 +3,7 @@ from agno.media import File\n from agno.models.anthropic import Claude\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     markdown=True,\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/prompt_caching_extended.py",
            "diff": "diff --git a/cookbook/models/anthropic/prompt_caching_extended.py b/cookbook/models/anthropic/prompt_caching_extended.py\nindex 9a387bf10..9ebe90699 100644\n--- a/cookbook/models/anthropic/prompt_caching_extended.py\n+++ b/cookbook/models/anthropic/prompt_caching_extended.py\n@@ -30,15 +30,14 @@ agent = Agent(\n     markdown=True,\n )\n \n-\n # First run - this will create the cache\n response = agent.run(\n     \"Explain the difference between REST and GraphQL APIs with examples\"\n )\n-print(f\"First run cache write tokens = {response.metrics['cache_write_tokens']}\")  # type: ignore\n+print(f\"First run cache write tokens = {response.metrics['cache_write_tokens']}\")\n \n # Second run - this will use the cached system prompt\n response = agent.run(\n     \"What are the key principles of clean code and how do I apply them in Python?\"\n )\n-print(f\"Second run cache read tokens = {response.metrics['cached_tokens']}\")  # type: ignore\n+print(f\"Second run cache read tokens = {response.metrics['cached_tokens']}\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/storage.py",
            "diff": "diff --git a/cookbook/models/anthropic/storage.py b/cookbook/models/anthropic/storage.py\nindex 395110c6d..d2016657b 100644\n--- a/cookbook/models/anthropic/storage.py\n+++ b/cookbook/models/anthropic/storage.py\n@@ -8,7 +8,7 @@ from agno.tools.duckduckgo import DuckDuckGoTools\n db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20241022\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     storage=PostgresStorage(table_name=\"agent_sessions\", db_url=db_url),\n     tools=[DuckDuckGoTools()],\n     add_history_to_messages=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/structured_output.py",
            "diff": "diff --git a/cookbook/models/anthropic/structured_output.py b/cookbook/models/anthropic/structured_output.py\nindex 5382cffbc..907ca2115 100644\n--- a/cookbook/models/anthropic/structured_output.py\n+++ b/cookbook/models/anthropic/structured_output.py\n@@ -26,7 +26,7 @@ class MovieScript(BaseModel):\n \n \n movie_agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     description=\"You help people write movie scripts.\",\n     response_model=MovieScript,\n )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/tool_use.py",
            "diff": "diff --git a/cookbook/models/anthropic/tool_use.py b/cookbook/models/anthropic/tool_use.py\nindex 2ae6feb2d..6fc50b035 100644\n--- a/cookbook/models/anthropic/tool_use.py\n+++ b/cookbook/models/anthropic/tool_use.py\n@@ -5,7 +5,7 @@ from agno.models.anthropic import Claude\n from agno.tools.duckduckgo import DuckDuckGoTools\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     tools=[DuckDuckGoTools()],\n     show_tool_calls=True,\n     markdown=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/tool_use_stream.py",
            "diff": "diff --git a/cookbook/models/anthropic/tool_use_stream.py b/cookbook/models/anthropic/tool_use_stream.py\nindex 04d3c0485..ec6487d13 100644\n--- a/cookbook/models/anthropic/tool_use_stream.py\n+++ b/cookbook/models/anthropic/tool_use_stream.py\n@@ -5,7 +5,7 @@ from agno.models.anthropic import Claude\n from agno.tools.duckduckgo import DuckDuckGoTools\n \n agent = Agent(\n-    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n     tools=[DuckDuckGoTools()],\n     show_tool_calls=True,\n     markdown=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/anthropic/web_search.py",
            "diff": "diff --git a/cookbook/models/anthropic/web_search.py b/cookbook/models/anthropic/web_search.py\nindex 0a24899a6..6c799879c 100644\n--- a/cookbook/models/anthropic/web_search.py\n+++ b/cookbook/models/anthropic/web_search.py\n@@ -3,7 +3,7 @@ from agno.models.anthropic import Claude\n \n agent = Agent(\n     model=Claude(\n-        id=\"claude-3-5-sonnet-20241022\",\n+        id=\"claude-sonnet-4-20250514\",\n     ),\n     tools=[\n         {\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/__init__.py",
            "diff": "diff --git a/cookbook/models/langdb/__init__.py b/cookbook/models/langdb/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/agent.py",
            "diff": "diff --git a/cookbook/models/langdb/agent.py b/cookbook/models/langdb/agent.py\nnew file mode 100644\nindex 000000000..916026ec5\n--- /dev/null\n+++ b/cookbook/models/langdb/agent.py\n@@ -0,0 +1,20 @@\n+\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+from agno.tools.yfinance import YFinanceTools\n+\n+agent = Agent(\n+    model=LangDB(id=\"gpt-4o\"),\n+    tools=[YFinanceTools(stock_price=True)],\n+    instructions=[\"Use tables where possible.\"],\n+    markdown=True,\n+    show_tool_calls=True,\n+)\n+\n+# Get the response in a variable\n+# run: RunResponse = agent.run(\"What is the stock price of NVDA and TSLA\")\n+# print(run.content)\n+\n+# Print the response in the terminal\n+agent.print_response(\"What is the stock price of NVDA and TSLA\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/agent_stream.py",
            "diff": "diff --git a/cookbook/models/langdb/agent_stream.py b/cookbook/models/langdb/agent_stream.py\nnew file mode 100644\nindex 000000000..40fdea751\n--- /dev/null\n+++ b/cookbook/models/langdb/agent_stream.py\n@@ -0,0 +1,22 @@\n+\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n+\n+from typing import Iterator  # noqa\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+from agno.tools.yfinance import YFinanceTools\n+\n+agent = Agent(\n+    model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+    tools=[YFinanceTools(stock_price=True)],\n+    instructions=[\"Use tables where possible.\"],\n+    markdown=True,\n+    show_tool_calls=True,\n+)\n+\n+# Get the response in a variable\n+# run_response: Iterator[RunResponse] = agent.run(\"What is the stock price of NVDA and TSLA\", stream=True)\n+# for chunk in run_response:\n+#     print(chunk.content)\n+\n+# Print the response in the terminal\n+agent.print_response(\"What is the stock price of NVDA and TSLA\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/basic.py",
            "diff": "diff --git a/cookbook/models/langdb/basic.py b/cookbook/models/langdb/basic.py\nnew file mode 100644\nindex 000000000..71152c8f7\n--- /dev/null\n+++ b/cookbook/models/langdb/basic.py\n@@ -0,0 +1,13 @@\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+\n+agent = Agent(\n+    model=LangDB(id=\"deepseek-chat\", project_id=\"langdb-project-id\"), markdown=True\n+)\n+\n+# Get the response in a variable\n+# run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n+# print(run.content)\n+\n+# Print the response in the terminal\n+agent.print_response(\"Share a 2 sentence horror story\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/basic_stream.py",
            "diff": "diff --git a/cookbook/models/langdb/basic_stream.py b/cookbook/models/langdb/basic_stream.py\nnew file mode 100644\nindex 000000000..77493d3d9\n--- /dev/null\n+++ b/cookbook/models/langdb/basic_stream.py\n@@ -0,0 +1,16 @@\n+from typing import Iterator  # noqa\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+\n+agent = Agent(\n+    model=LangDB(id=\"llama3-1-70b-instruct-v1.0\"),\n+    markdown=True,\n+)\n+\n+# Get the response in a variable\n+# run_response: Iterator[RunResponse] = agent.run(\"Share a 2 sentence horror story\", stream=True)\n+# for chunk in run_response:\n+#     print(chunk.content)\n+\n+# Print the response in the terminal\n+agent.print_response(\"Share a 2 sentence horror story\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/data_analyst.py",
            "diff": "diff --git a/cookbook/models/langdb/data_analyst.py b/cookbook/models/langdb/data_analyst.py\nnew file mode 100644\nindex 000000000..6063ef1ce\n--- /dev/null\n+++ b/cookbook/models/langdb/data_analyst.py\n@@ -0,0 +1,27 @@\n+\"\"\"Run `pip install duckdb` to install dependencies.\"\"\"\n+\n+from textwrap import dedent\n+\n+from agno.agent import Agent\n+from agno.models.langdb import LangDB\n+from agno.tools.duckdb import DuckDbTools\n+\n+duckdb_tools = DuckDbTools(\n+    create_tables=False, export_tables=False, summarize_tables=False\n+)\n+duckdb_tools.create_table_from_path(\n+    path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n+    table=\"movies\",\n+)\n+\n+agent = Agent(\n+    model=LangDB(id=\"grok-2\", project_id=\"langdb-project-id\"),\n+    tools=[duckdb_tools],\n+    markdown=True,\n+    show_tool_calls=True,\n+    additional_context=dedent(\"\"\"\\\n+    You have access to the following tables:\n+    - movies: contains information about movies from IMDB.\n+    \"\"\"),\n+)\n+agent.print_response(\"What is the average rating of movies?\", stream=False)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/finance_agent.py",
            "diff": "diff --git a/cookbook/models/langdb/finance_agent.py b/cookbook/models/langdb/finance_agent.py\nnew file mode 100644\nindex 000000000..b88af47e1\n--- /dev/null\n+++ b/cookbook/models/langdb/finance_agent.py\n@@ -0,0 +1,21 @@\n+\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.langdb import LangDB\n+from agno.tools.yfinance import YFinanceTools\n+\n+agent = Agent(\n+    model=LangDB(id=\"gpt-4o\"),\n+    tools=[\n+        YFinanceTools(\n+            stock_price=True, analyst_recommendations=True, stock_fundamentals=True\n+        )\n+    ],\n+    show_tool_calls=True,\n+    description=\"You are an investment analyst that researches stocks and helps users make informed decisions.\",\n+    instructions=[\"Use tables to display data where possible.\"],\n+    markdown=True,\n+)\n+\n+# agent.print_response(\"Share the NVDA stock price and analyst recommendations\", stream=True)\n+agent.print_response(\"Summarize fundamentals for TSLA\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/structured_output.py",
            "diff": "diff --git a/cookbook/models/langdb/structured_output.py b/cookbook/models/langdb/structured_output.py\nnew file mode 100644\nindex 000000000..a1754e051\n--- /dev/null\n+++ b/cookbook/models/langdb/structured_output.py\n@@ -0,0 +1,51 @@\n+from typing import List\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+from pydantic import BaseModel, Field\n+from rich.pretty import pprint  # noqa\n+\n+\n+class MovieScript(BaseModel):\n+    setting: str = Field(\n+        ..., description=\"Provide a nice setting for a blockbuster movie.\"\n+    )\n+    ending: str = Field(\n+        ...,\n+        description=\"Ending of the movie. If not available, provide a happy ending.\",\n+    )\n+    genre: str = Field(\n+        ...,\n+        description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\",\n+    )\n+    name: str = Field(..., description=\"Give a name to this movie\")\n+    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n+    storyline: str = Field(\n+        ..., description=\"3 sentence storyline for the movie. Make it exciting!\"\n+    )\n+\n+\n+# Agent that uses JSON mode\n+json_mode_agent = Agent(\n+    model=LangDB(id=\"gpt-4o\"),\n+    description=\"You write movie scripts.\",\n+    response_model=MovieScript,\n+    use_json_mode=True,\n+)\n+\n+# Agent that uses structured outputs\n+structured_output_agent = Agent(\n+    model=LangDB(id=\"gpt-4o\", project_id=\"langdb-project-id\"),\n+    description=\"You write movie scripts.\",\n+    response_model=MovieScript,\n+)\n+\n+\n+# Get the response in a variable\n+# json_mode_response: RunResponse = json_mode_agent.run(\"New York\")\n+# pprint(json_mode_response.content)\n+# structured_output_response: RunResponse = structured_output_agent.run(\"New York\")\n+# pprint(structured_output_response.content)\n+\n+json_mode_agent.print_response(\"New York\")\n+structured_output_agent.print_response(\"New York\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/langdb/web_search.py",
            "diff": "diff --git a/cookbook/models/langdb/web_search.py b/cookbook/models/langdb/web_search.py\nnew file mode 100644\nindex 000000000..0e56b0bab\n--- /dev/null\n+++ b/cookbook/models/langdb/web_search.py\n@@ -0,0 +1,13 @@\n+\"\"\"Run `pip install duckduckgo-search` to install dependencies.\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.langdb import LangDB\n+from agno.tools.duckduckgo import DuckDuckGo\n+\n+agent = Agent(\n+    model=LangDB(id=\"claude-3-5-sonnet-20240620\", project_id=\"langdb-project-id\"),\n+    tools=[DuckDuckGo()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+agent.print_response(\"Whats happening in France?\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/ollama/structured_output.py",
            "diff": "diff --git a/cookbook/models/ollama/structured_output.py b/cookbook/models/ollama/structured_output.py\nindex a28ec132d..b4b661a75 100644\n--- a/cookbook/models/ollama/structured_output.py\n+++ b/cookbook/models/ollama/structured_output.py\n@@ -1,9 +1,7 @@\n-import asyncio\n from typing import List\n \n-from agno.agent import Agent\n+from agno.agent import Agent, RunResponse  # noqa\n from agno.models.ollama import Ollama\n-from agno.run.response import RunResponse\n from pydantic import BaseModel, Field\n from rich.pretty import pprint  # noqa\n \n@@ -34,10 +32,11 @@ structured_output_agent = Agent(\n     response_model=MovieScript,\n )\n \n-# Run the agent synchronously\n-structured_output_response: RunResponse = structured_output_agent.run(\"New York\")\n-pprint(structured_output_response.content)\n+# Get the response in a variable\n+# json_mode_response: RunResponse = json_mode_agent.run(\"New York\")\n+# pprint(json_mode_response.content)\n+# structured_output_response: RunResponse = structured_output_agent.run(\"New York\")\n+# pprint(structured_output_response.content)\n \n-\n-# Run the agent asynchronously\n-asyncio.run(structured_output_agent.aprint_response(\"New York\"))\n+# Run the agent\n+structured_output_agent.print_response(\"New York\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/__init__.py",
            "diff": "diff --git a/cookbook/models/vllm/__init__.py b/cookbook/models/vllm/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/async_basic.py",
            "diff": "diff --git a/cookbook/models/vllm/async_basic.py b/cookbook/models/vllm/async_basic.py\nnew file mode 100644\nindex 000000000..15f8292ac\n--- /dev/null\n+++ b/cookbook/models/vllm/async_basic.py\n@@ -0,0 +1,7 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+\n+agent = Agent(model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\"), markdown=True)\n+asyncio.run(agent.aprint_response(\"Share a 2 sentence horror story\"))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/async_basic_stream.py",
            "diff": "diff --git a/cookbook/models/vllm/async_basic_stream.py b/cookbook/models/vllm/async_basic_stream.py\nnew file mode 100644\nindex 000000000..cec43d9a9\n--- /dev/null\n+++ b/cookbook/models/vllm/async_basic_stream.py\n@@ -0,0 +1,7 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+\n+agent = Agent(model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\"), markdown=True)\n+asyncio.run(agent.aprint_response(\"Share a 2 sentence horror story\", stream=True))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/async_tool_use.py",
            "diff": "diff --git a/cookbook/models/vllm/async_tool_use.py b/cookbook/models/vllm/async_tool_use.py\nnew file mode 100644\nindex 000000000..939584d63\n--- /dev/null\n+++ b/cookbook/models/vllm/async_tool_use.py\n@@ -0,0 +1,15 @@\n+\"\"\"Run `pip install duckduckgo-search` to install dependencies.\"\"\"\n+\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\", top_k=20, enable_thinking=False),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+asyncio.run(agent.aprint_response(\"Whats happening in France?\", stream=True))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/basic.py",
            "diff": "diff --git a/cookbook/models/vllm/basic.py b/cookbook/models/vllm/basic.py\nnew file mode 100644\nindex 000000000..455f03a33\n--- /dev/null\n+++ b/cookbook/models/vllm/basic.py\n@@ -0,0 +1,9 @@\n+from agno.agent import Agent, RunResponse\n+from agno.models.vllm import vLLM\n+\n+agent = Agent(\n+    model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\", top_k=20, enable_thinking=False),\n+    markdown=True,\n+)\n+\n+agent.print_response(\"Share a 2 sentence horror story\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/basic_stream.py",
            "diff": "diff --git a/cookbook/models/vllm/basic_stream.py b/cookbook/models/vllm/basic_stream.py\nnew file mode 100644\nindex 000000000..b530bba22\n--- /dev/null\n+++ b/cookbook/models/vllm/basic_stream.py\n@@ -0,0 +1,8 @@\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+\n+agent = Agent(\n+    model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\", top_k=20, enable_thinking=False),\n+    markdown=True,\n+)\n+agent.print_response(\"Share a 2 sentence horror story\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/code_generation.py",
            "diff": "diff --git a/cookbook/models/vllm/code_generation.py b/cookbook/models/vllm/code_generation.py\nnew file mode 100644\nindex 000000000..11a9611d8\n--- /dev/null\n+++ b/cookbook/models/vllm/code_generation.py\n@@ -0,0 +1,18 @@\n+\"\"\"Code generation example with DeepSeek-Coder.\n+Run vLLM model: vllm serve deepseek-ai/deepseek-coder-6.7b-instruct \\\n+        --dtype float32 \\\n+        --tool-call-parser pythonic\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+\n+agent = Agent(\n+    model=vLLM(id=\"deepseek-ai/deepseek-coder-6.7b-instruct\"),\n+    description=\"You are an expert Python developer.\",\n+    markdown=True,\n+)\n+\n+agent.print_response(\n+    \"Write a Python function that returns the nth Fibonacci number using dynamic programming.\"\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/memory.py",
            "diff": "diff --git a/cookbook/models/vllm/memory.py b/cookbook/models/vllm/memory.py\nnew file mode 100644\nindex 000000000..0acf19532\n--- /dev/null\n+++ b/cookbook/models/vllm/memory.py\n@@ -0,0 +1,58 @@\n+\"\"\"\n+Personalized memory and session summaries with vLLM.\n+Prerequisites:\n+1. Start a Postgres + pgvector container (helper script is provided):\n+       ./cookbook/scripts/run_pgvector.sh\n+2. Install dependencies:\n+       pip install sqlalchemy 'psycopg[binary]' pgvector\n+3. Run a vLLM server (any open model).  Example with Phi-3:\n+       vllm serve microsoft/Phi-3-mini-128k-instruct \\\n+         --dtype float32 \\\n+         --enable-auto-tool-choice \\\n+         --tool-call-parser pythonic\n+Then execute this script \u2013 it will remember facts you tell it and generate a\n+summary.\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.memory.v2.db.postgres import PostgresMemoryDb\n+from agno.memory.v2.memory import Memory\n+from agno.models.vllm import vLLM\n+from agno.storage.postgres import PostgresStorage\n+\n+# Change this if your Postgres container is running elsewhere\n+DB_URL = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n+\n+agent = Agent(\n+    model=vLLM(id=\"microsoft/Phi-3-mini-128k-instruct\"),\n+    memory=Memory(\n+        db=PostgresMemoryDb(table_name=\"agent_memory\", db_url=DB_URL),\n+    ),\n+    enable_user_memories=True,\n+    enable_session_summaries=True,\n+    storage=PostgresStorage(table_name=\"personalized_agent_sessions\", db_url=DB_URL),\n+)\n+\n+# Share personal details; the agent should remember them.\n+agent.print_response(\"My name is John Billings.\", stream=True)\n+print(\"Current memories \u2192\")\n+pprint(agent.memory.memories)\n+print(\"Current summary \u2192\")\n+pprint(agent.memory.summaries)\n+\n+agent.print_response(\"I live in NYC.\", stream=True)\n+print(\"Memories \u2192\")\n+pprint(agent.memory.memories)\n+print(\"Summary \u2192\")\n+pprint(agent.memory.summaries)\n+\n+agent.print_response(\"I'm going to a concert tomorrow.\", stream=True)\n+print(\"Memories \u2192\")\n+pprint(agent.memory.memories)\n+print(\"Summary \u2192\")\n+pprint(agent.memory.summaries)\n+\n+# Ask the agent to recall\n+agent.print_response(\n+    \"What have we been talking about, do you know my name?\", stream=True\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/storage.py",
            "diff": "diff --git a/cookbook/models/vllm/storage.py b/cookbook/models/vllm/storage.py\nnew file mode 100644\nindex 000000000..c1ce1ae98\n--- /dev/null\n+++ b/cookbook/models/vllm/storage.py\n@@ -0,0 +1,18 @@\n+\"\"\"Run `pip install sqlalchemy` and ensure Postgres is running (`./cookbook/scripts/run_pgvector.sh`).\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+from agno.storage.postgres import PostgresStorage\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+DB_URL = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n+\n+agent = Agent(\n+    model=vLLM(id=\"Qwen/Qwen2.5-7B-Instruct\"),\n+    storage=PostgresStorage(table_name=\"agent_sessions\", db_url=DB_URL),\n+    tools=[DuckDuckGoTools()],\n+    add_history_to_messages=True,\n+)\n+\n+agent.print_response(\"How many people live in Canada?\")\n+agent.print_response(\"What is their national anthem called?\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/structured_output.py",
            "diff": "diff --git a/cookbook/models/vllm/structured_output.py b/cookbook/models/vllm/structured_output.py\nnew file mode 100644\nindex 000000000..1b092ed0b\n--- /dev/null\n+++ b/cookbook/models/vllm/structured_output.py\n@@ -0,0 +1,35 @@\n+from typing import List\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+from pydantic import BaseModel, Field\n+\n+\n+class MovieScript(BaseModel):\n+    name: str = Field(..., description=\"Give a name to this movie\")\n+    setting: str = Field(\n+        ..., description=\"Provide a nice setting for a blockbuster movie.\"\n+    )\n+    ending: str = Field(\n+        ...,\n+        description=\"Ending of the movie. If not available, provide a happy ending.\",\n+    )\n+    genre: str = Field(\n+        ...,\n+        description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\",\n+    )\n+    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n+    storyline: str = Field(\n+        ..., description=\"3 sentence storyline for the movie. Make it exciting!\"\n+    )\n+\n+\n+agent = Agent(\n+    model=vLLM(\n+        id=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\", top_k=20, enable_thinking=False\n+    ),\n+    description=\"You write movie scripts.\",\n+    response_model=MovieScript,\n+)\n+\n+agent.print_response(\"Llamas ruling the world\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/models/vllm/tool_use.py",
            "diff": "diff --git a/cookbook/models/vllm/tool_use.py b/cookbook/models/vllm/tool_use.py\nnew file mode 100644\nindex 000000000..5549c741f\n--- /dev/null\n+++ b/cookbook/models/vllm/tool_use.py\n@@ -0,0 +1,15 @@\n+\"\"\"Build a Web Search Agent using xAI.\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.vllm import vLLM\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=vLLM(\n+        id=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\", top_k=20, enable_thinking=False\n+    ),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+agent.print_response(\"Whats happening in France?\", stream=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/observability/langfuse_via_openinference_response_model.py",
            "diff": "diff --git a/cookbook/observability/langfuse_via_openinference_response_model.py b/cookbook/observability/langfuse_via_openinference_response_model.py\nnew file mode 100644\nindex 000000000..3f3cd1e30\n--- /dev/null\n+++ b/cookbook/observability/langfuse_via_openinference_response_model.py\n@@ -0,0 +1,69 @@\n+\"\"\"\n+This example shows how to instrument your agno agent with OpenInference and send traces to Langfuse,\n+using an Agent with a response model.\n+\n+1. Install dependencies: pip install openai langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno\n+2. Either self-host or sign up for an account at https://us.cloud.langfuse.com\n+3. Set your Langfuse API key as an environment variables:\n+  - export LANGFUSE_PUBLIC_KEY=<your-key>\n+  - export LANGFUSE_SECRET_KEY=<your-key>\n+\"\"\"\n+\n+import base64\n+import os\n+from enum import Enum\n+\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.tools.yfinance import YFinanceTools\n+from openinference.instrumentation.agno import AgnoInstrumentor\n+from opentelemetry import trace as trace_api\n+from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n+from opentelemetry.sdk.trace import TracerProvider\n+from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n+from pydantic import BaseModel, Field\n+\n+LANGFUSE_AUTH = base64.b64encode(\n+    f\"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}\".encode()\n+).decode()\n+os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = (\n+    \"https://us.cloud.langfuse.com/api/public/otel\"  # \ud83c\uddfa\ud83c\uddf8 US data region\n+)\n+# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"]=\"https://cloud.langfuse.com/api/public/otel\" # \ud83c\uddea\ud83c\uddfa EU data region\n+# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"]=\"http://localhost:3000/api/public/otel\" # \ud83c\udfe0 Local deployment (>= v3.22.0)\n+\n+os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n+\n+\n+tracer_provider = TracerProvider()\n+tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n+trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n+\n+# Start instrumenting agno\n+AgnoInstrumentor().instrument()\n+\n+\n+class MarketArea(Enum):\n+    USA = \"USA\"\n+    UK = \"UK\"\n+    EU = \"EU\"\n+    ASIA = \"ASIA\"\n+\n+\n+class StockPrice(BaseModel):\n+    price: str = Field(description=\"The price of the stock\")\n+    symbol: str = Field(description=\"The symbol of the stock\")\n+    date: str = Field(description=\"Current day\")\n+    area: MarketArea\n+\n+\n+agent = Agent(\n+    name=\"Stock Price Agent\",\n+    model=OpenAIChat(id=\"gpt-4o-mini\"),\n+    tools=[YFinanceTools()],\n+    instructions=\"You are a stock price agent. You check and return the current price of a stock.\",\n+    debug_mode=True,\n+    response_model=StockPrice,\n+)\n+\n+agent.print_response(\"What is the current price of Tesla?\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/scripts/lightrag-init/example.env",
            "diff": "diff --git a/cookbook/scripts/lightrag-init/example.env b/cookbook/scripts/lightrag-init/example.env\nnew file mode 100644\nindex 000000000..b68a17b01\n--- /dev/null\n+++ b/cookbook/scripts/lightrag-init/example.env\n@@ -0,0 +1,166 @@\n+### This is sample file of .env\n+\n+\n+### Server Configuration\n+HOST=0.0.0.0\n+PORT=9621\n+WEBUI_TITLE='My Graph KB'\n+WEBUI_DESCRIPTION=\"Simple and Fast Graph Based RAG System\"\n+OLLAMA_EMULATING_MODEL_TAG=latest\n+# WORKERS=2\n+# CORS_ORIGINS=http://localhost:3000,http://localhost:8080\n+\n+### Login Configuration\n+# AUTH_ACCOUNTS='admin:admin123,user1:pass456'\n+# TOKEN_SECRET=Your-Key-For-LightRAG-API-Server\n+# TOKEN_EXPIRE_HOURS=48\n+# GUEST_TOKEN_EXPIRE_HOURS=24\n+# JWT_ALGORITHM=HS256\n+\n+### API-Key to access LightRAG Server API\n+# LIGHTRAG_API_KEY=your-secure-api-key-here\n+# WHITELIST_PATHS=/health,/api/*\n+\n+### Optional SSL Configuration\n+# SSL=true\n+# SSL_CERTFILE=/path/to/cert.pem\n+# SSL_KEYFILE=/path/to/key.pem\n+\n+### Directory Configuration (defaults to current working directory)\n+### Should not be set if deploy by docker (Set by Dockerfile instead of .env)\n+### Default value is ./inputs and ./rag_storage\n+# INPUT_DIR=<absolute_path_for_doc_input_dir>\n+# WORKING_DIR=<absolute_path_for_working_dir>\n+\n+### Max nodes return from grap retrieval\n+# MAX_GRAPH_NODES=1000\n+\n+### Logging level\n+# LOG_LEVEL=INFO\n+# VERBOSE=False\n+# LOG_MAX_BYTES=10485760\n+# LOG_BACKUP_COUNT=5\n+### Logfile location (defaults to current working directory)\n+# LOG_DIR=/path/to/log/directory\n+\n+### Settings for RAG query\n+# HISTORY_TURNS=3\n+# COSINE_THRESHOLD=0.2\n+# TOP_K=60\n+# MAX_TOKEN_TEXT_CHUNK=4000\n+# MAX_TOKEN_RELATION_DESC=4000\n+# MAX_TOKEN_ENTITY_DESC=4000\n+\n+### Entity and ralation summarization configuration\n+### Language: English, Chinese, French, German ...\n+SUMMARY_LANGUAGE=English\n+### Number of duplicated entities/edges to trigger LLM re-summary on merge ( at least 3 is recommented)\n+# FORCE_LLM_SUMMARY_ON_MERGE=6\n+### Max tokens for entity/relations description after merge\n+# MAX_TOKEN_SUMMARY=500\n+\n+### Number of parallel processing documents(Less than MAX_ASYNC/2 is recommended)\n+# MAX_PARALLEL_INSERT=2\n+### Chunk size for document splitting, 500~1500 is recommended\n+# CHUNK_SIZE=1200\n+# CHUNK_OVERLAP_SIZE=100\n+\n+### LLM Configuration\n+ENABLE_LLM_CACHE=true\n+ENABLE_LLM_CACHE_FOR_EXTRACT=true\n+### Time out in seconds for LLM, None for infinite timeout\n+TIMEOUT=240\n+### Some models like o1-mini require temperature to be set to 1\n+TEMPERATURE=0\n+### Max concurrency requests of LLM\n+MAX_ASYNC=4\n+### MAX_TOKENS: max tokens send to LLM for entity relation summaries (less than context size of the model)\n+### MAX_TOKENS: set as num_ctx option for Ollama by API Server\n+MAX_TOKENS=32768\n+### LLM Binding type: openai, ollama, lollms, azure_openai\n+LLM_BINDING=openai\n+LLM_MODEL=gpt-4o\n+LLM_BINDING_HOST=https://api.openai.com/v1\n+LLM_BINDING_API_KEY=sk-proj-***\n+### Optional for Azure\n+# AZURE_OPENAI_API_VERSION=2024-08-01-preview\n+# AZURE_OPENAI_DEPLOYMENT=gpt-4o\n+\n+### Embedding Configuration\n+### Embedding Binding type: openai, ollama, lollms, azure_openai\n+EMBEDDING_BINDING=openai\n+EMBEDDING_MODEL=text-embedding-3-large\n+EMBEDDING_DIM=3072\n+EMBEDDING_BINDING_API_KEY=sk-proj-***\n+EMBEDDING_BINDING_HOST=https://api.openai.com/v1\n+### Num of chunks send to Embedding in single request\n+# EMBEDDING_BATCH_NUM=32\n+### Max concurrency requests for Embedding\n+# EMBEDDING_FUNC_MAX_ASYNC=16\n+### Maximum tokens sent to Embedding for each chunk (no longer in use?)\n+# MAX_EMBED_TOKENS=8192\n+### Optional for Azure\n+# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-large\n+# AZURE_EMBEDDING_API_VERSION=2023-05-15\n+\n+### Data storage selection\n+# LIGHTRAG_KV_STORAGE=PGKVStorage\n+# LIGHTRAG_VECTOR_STORAGE=PGVectorStorage\n+# LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage\n+# LIGHTRAG_GRAPH_STORAGE=Neo4JStorage\n+\n+### TiDB Configuration (Deprecated)\n+# TIDB_HOST=localhost\n+# TIDB_PORT=4000\n+# TIDB_USER=your_username\n+# TIDB_PASSWORD='your_password'\n+# TIDB_DATABASE=your_database\n+### separating all data from difference Lightrag instances(deprecating)\n+# TIDB_WORKSPACE=default\n+\n+### PostgreSQL Configuration\n+POSTGRES_HOST=localhost\n+POSTGRES_PORT=5432\n+POSTGRES_USER=ai\n+POSTGRES_PASSWORD='ai'\n+POSTGRES_DATABASE=ai\n+POSTGRES_MAX_CONNECTIONS=12\n+### separating all data from difference Lightrag instances(deprecating)\n+# POSTGRES_WORKSPACE=default\n+\n+### Neo4j Configuration\n+#NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io\n+NEO4J_URI=bolt://neo4j:7687\n+NEO4J_USERNAME=neo4j\n+NEO4J_PASSWORD='testpassword'\n+\n+### Independent AGM Configuration(not for AMG embedded in PostreSQL)\n+# AGE_POSTGRES_DB=\n+# AGE_POSTGRES_USER=\n+# AGE_POSTGRES_PASSWORD=\n+# AGE_POSTGRES_HOST=\n+# AGE_POSTGRES_PORT=8529\n+\n+# AGE Graph Name(apply to PostgreSQL and independent AGM)\n+### AGE_GRAPH_NAME is precated\n+# AGE_GRAPH_NAME=lightrag\n+\n+### MongoDB Configuration\n+MONGO_URI=mongodb://root:root@localhost:27017/\n+MONGO_DATABASE=LightRAG\n+### separating all data from difference Lightrag instances(deprecating)\n+# MONGODB_GRAPH=false\n+\n+### Milvus Configuration\n+MILVUS_URI=http://localhost:19530\n+MILVUS_DB_NAME=lightrag\n+# MILVUS_USER=root\n+# MILVUS_PASSWORD=your_password\n+# MILVUS_TOKEN=your_token\n+\n+### Qdrant\n+QDRANT_URL=http://localhost:16333\n+# QDRANT_API_KEY=your-api-key\n+\n+### Redis\n+REDIS_URI=redis://localhost:6379\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/scripts/lightrag-init/run_lightrag.sh",
            "diff": "diff --git a/cookbook/scripts/lightrag-init/run_lightrag.sh b/cookbook/scripts/lightrag-init/run_lightrag.sh\nnew file mode 100755\nindex 000000000..f5fd9c7ef\n--- /dev/null\n+++ b/cookbook/scripts/lightrag-init/run_lightrag.sh\n@@ -0,0 +1 @@\n+docker-compose -f cookbook/scripts/lightrag-init/docker-compose.yml up -d\n\\ No newline at end of file\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/scripts/lightrag-init/stop_lightrag.sh",
            "diff": "diff --git a/cookbook/scripts/lightrag-init/stop_lightrag.sh b/cookbook/scripts/lightrag-init/stop_lightrag.sh\nnew file mode 100755\nindex 000000000..d84571249\n--- /dev/null\n+++ b/cookbook/scripts/lightrag-init/stop_lightrag.sh\n@@ -0,0 +1 @@\n+docker-compose -f cookbook/scripts/lightrag-init/docker-compose.yml down\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/crawl4ai_tools.py",
            "diff": "diff --git a/cookbook/tools/crawl4ai_tools.py b/cookbook/tools/crawl4ai_tools.py\nindex 325a24cdc..318d8326d 100644\n--- a/cookbook/tools/crawl4ai_tools.py\n+++ b/cookbook/tools/crawl4ai_tools.py\n@@ -1,5 +1,37 @@\n from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n from agno.tools.crawl4ai import Crawl4aiTools\n \n-agent = Agent(tools=[Crawl4aiTools(max_length=None)], show_tool_calls=True)\n-agent.print_response(\"Tell me about https://github.com/agno-agi/agno.\")\n+# # Example 1: Basic usage\n+agent = Agent(\n+    model=OpenAIChat(id=\"gpt-4.1\"),\n+    tools=[Crawl4aiTools(use_pruning=True)],\n+    instructions=\"You are a helpful assistant that can crawl the web and extract information. Use have access to crawl4ai tools to extract information from the web.\",\n+)\n+agent.print_response(\n+    \"Give me a detailed summary of the Agno project from https://github.com/agno-agi/agno and what are its main features?\"\n+)\n+\n+# Example 2: Extract main content only (remove navigation, ads, etc.)\n+# agent_clean = Agent(tools=[Crawl4aiTools(use_pruning=True)], show_tool_calls=True)\n+# agent_clean.print_response(\n+#     \"Get the History from https://en.wikipedia.org/wiki/Python_(programming_language)\"\n+# )\n+\n+# Example 3: Search for specific content on a page\n+# agent_search = Agent(\n+#     instructions=\"You are a helpful assistant that can crawl the web and extract information. Use have access to crawl4ai tools to extract information from the web.\",\n+#     tools=[Crawl4aiTools()],\n+#     show_tool_calls=True,\n+# )\n+# agent_search.print_response(\n+#     \"What are the diferent Techniques used in AI? https://en.wikipedia.org/wiki/Artificial_intelligence\"\n+# )\n+\n+# Example 4: Multiple URLs with clean extraction\n+# agent_multi = Agent(\n+#     tools=[Crawl4aiTools(use_pruning=True, headless=False)], show_tool_calls=True\n+# )\n+# agent_multi.print_response(\n+#     \"Compare the main content from https://en.wikipedia.org/wiki/Artificial_intelligence and https://en.wikipedia.org/wiki/Machine_learning\"\n+# )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/daytona_tools.py",
            "diff": "diff --git a/cookbook/tools/daytona_tools.py b/cookbook/tools/daytona_tools.py\nnew file mode 100644\nindex 000000000..70813e6d0\n--- /dev/null\n+++ b/cookbook/tools/daytona_tools.py\n@@ -0,0 +1,52 @@\n+\"\"\"\n+\ud83d\udc69\u200d\ud83d\udcbb Agent with Daytona tools\n+\n+This example shows how to use Agno's Daytona integration to run Agent-generated code in a remote, secure sandbox.\n+\n+1. Get your Daytona API key and API URL: https://app.daytona.io/dashboard/keys\n+2. Set the API key and API URL as environment variables:\n+    export DAYTONA_API_KEY=<your_api_key>\n+    export DAYTONA_API_URL=<your_api_url>\n+3. Install the dependencies:\n+    pip install agno anthropic daytona_sdk\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.models.anthropic import Claude\n+from agno.tools.daytona import DaytonaTools\n+\n+daytona_tools = DaytonaTools()\n+\n+# Setup an Agent focused on coding tasks, with access to the Daytona tools\n+agent = Agent(\n+    name=\"Coding Agent with Daytona tools\",\n+    agent_id=\"coding-agent\",\n+    model=Claude(id=\"claude-sonnet-4-20250514\"),\n+    tools=[daytona_tools],\n+    markdown=True,\n+    show_tool_calls=True,\n+    instructions=[\n+        \"You are an expert at writing and validating Python code. You have access to a remote, secure Daytona sandbox.\",\n+        \"Your primary purpose is to:\",\n+        \"1. Write clear, efficient Python code based on user requests\",\n+        \"2. Execute and verify the code in the Daytona sandbox\",\n+        \"3. Share the complete code with the user, as this is the main use case\",\n+        \"4. Provide thorough explanations of how the code works\",\n+        \"You can use the run_python_code tool to run Python code in the Daytona sandbox.\",\n+        \"Guidelines:\",\n+        \"- ALWAYS share the complete code with the user, properly formatted in code blocks\",\n+        \"- Verify code functionality by executing it in the sandbox before sharing\",\n+        \"- Iterate and debug code as needed to ensure it works correctly\",\n+        \"- Use pandas, matplotlib, and other Python libraries for data analysis when appropriate\",\n+        \"- Create proper visualizations when requested and add them as image artifacts to show inline\",\n+        \"- Handle file uploads and downloads properly\",\n+        \"- Explain your approach and the code's functionality in detail\",\n+        \"- Format responses with both code and explanations for maximum clarity\",\n+        \"- Handle errors gracefully and explain any issues encountered\",\n+    ],\n+)\n+\n+\n+agent.print_response(\n+    \"Write Python code to generate the first 10 Fibonacci numbers and calculate their sum and average\"\n+)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/gmail_tools.py",
            "diff": "diff --git a/cookbook/tools/gmail_tools.py b/cookbook/tools/gmail_tools.py\nindex f5e06283b..780c5522b 100644\n--- a/cookbook/tools/gmail_tools.py\n+++ b/cookbook/tools/gmail_tools.py\n@@ -27,12 +27,14 @@ agent = Agent(\n         \"Based on user query, you can read, draft and send emails using Gmail.\",\n         \"While showing email contents, you can summarize the email contents, extract key details and dates.\",\n         \"Show the email contents in a structured markdown format.\",\n+        \"Attachments can be added to the email\",\n     ],\n     markdown=True,\n     show_tool_calls=False,\n     response_model=FindEmailOutput,\n )\n \n+# Example 1: Find the last email from a specific sender\n email = \"<replace_with_email_address>\"\n response: FindEmailOutput = agent.run(\n     f\"Find the last email from {email} along with the message id, references and in-reply-to\",\n@@ -47,3 +49,11 @@ agent.print_response(\n     markdown=True,\n     stream=True,\n )\n+\n+# Example 2: Send a new email with attachments\n+# agent.print_response(\n+#     \"\"\"Send an email to user@example.com with subject 'Subject'\n+#     and body 'Body' and Attach the file 'tmp/attachment.pdf'\"\"\",\n+#     markdown=True,\n+#     stream=True,\n+# )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/mcp/brave.py",
            "diff": "diff --git a/cookbook/tools/mcp/brave.py b/cookbook/tools/mcp/brave.py\nindex ce2820b2c..c2bf3762b 100644\n--- a/cookbook/tools/mcp/brave.py\n+++ b/cookbook/tools/mcp/brave.py\n@@ -30,7 +30,7 @@ async def run_agent(message: str) -> None:\n         )\n \n         response_stream = await agent.arun(message)\n-        await apprint_run_response(response_stream, markdown=True)\n+        await apprint_run_response(response_stream)\n \n \n if __name__ == \"__main__\":\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/mcp/qdrant.py",
            "diff": "diff --git a/cookbook/tools/mcp/qdrant.py b/cookbook/tools/mcp/qdrant.py\nnew file mode 100644\nindex 000000000..1b074db44\n--- /dev/null\n+++ b/cookbook/tools/mcp/qdrant.py\n@@ -0,0 +1,47 @@\n+import asyncio\n+from os import getenv\n+\n+from agno.agent import Agent\n+from agno.models.google import Gemini\n+from agno.tools.mcp import MCPTools\n+from agno.utils.pprint import apprint_run_response\n+\n+QDRANT_URL = getenv(\"QDRANT_URL\")\n+QDRANT_API_KEY = getenv(\"QDRANT_API_KEY\")\n+COLLECTION_NAME = \"qdrant_collection\"\n+EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n+\n+\n+async def run_agent(message: str) -> None:\n+    async with MCPTools(\n+        \"uvx mcp-server-qdrant\",\n+        env={\n+            \"QDRANT_URL\": QDRANT_URL,\n+            \"QDRANT_API_KEY\": QDRANT_API_KEY,\n+            \"COLLECTION_NAME\": COLLECTION_NAME,\n+            \"EMBEDDING_MODEL\": EMBEDDING_MODEL,\n+        },\n+    ) as mcp_tools:\n+        agent = Agent(\n+            model=Gemini(id=\"gemini-2.5-flash-preview-05-20\"),\n+            tools=[mcp_tools],\n+            instructions=\"\"\"\n+            You are the storage agent for the Model Context Protocol (MCP) server.\n+            You need to save the files in the vector database and answer the user's questions.\n+            You can use the following tools:\n+            - qdrant-store: Store data/output in the Qdrant vector database.\n+            - qdrant-find: Retrieve data/output from the Qdrant vector database.\n+            \"\"\",\n+            markdown=True,\n+            show_tool_calls=True,\n+        )\n+\n+        response = await agent.arun(message, stream=True)\n+        await apprint_run_response(response)\n+\n+\n+if __name__ == \"__main__\":\n+    query = \"\"\"\n+    Tell me about the extinction event of dinosaurs in detail. Include all possible theories and evidence. Store the result in the vector database.\n+    \"\"\"\n+    asyncio.run(run_agent(query))\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/serper_tools.py",
            "diff": "diff --git a/cookbook/tools/serper_tools.py b/cookbook/tools/serper_tools.py\nnew file mode 100644\nindex 000000000..8179f8a66\n--- /dev/null\n+++ b/cookbook/tools/serper_tools.py\n@@ -0,0 +1,9 @@\n+\"\"\"\n+This is a simple example of how to use the SerperApiTools class. You can obtain an API key from https://serper.dev/\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.tools.serperapi import SerperApiTools\n+\n+agent = Agent(tools=[SerperApiTools(location=\"us\")], show_tool_calls=True)\n+agent.print_response(\"Whats happening in the USA?\", markdown=True)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/tools/web_tools.py",
            "diff": "diff --git a/cookbook/tools/web_tools.py b/cookbook/tools/web_tools.py\nnew file mode 100644\nindex 000000000..0cc9704e3\n--- /dev/null\n+++ b/cookbook/tools/web_tools.py\n@@ -0,0 +1,5 @@\n+from agno.agent import Agent\n+from agno.tools.webtools import WebTools\n+\n+agent = Agent(tools=[WebTools()], show_tool_calls=True)\n+agent.print_response(\"Tell me about https://tinyurl.com/57bmajz4\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/workflows/blog_post_generator.py",
            "diff": "diff --git a/cookbook/workflows/blog_post_generator.py b/cookbook/workflows/blog_post_generator.py\nindex 55cef44e1..b4f300b18 100644\n--- a/cookbook/workflows/blog_post_generator.py\n+++ b/cookbook/workflows/blog_post_generator.py\n@@ -412,6 +412,8 @@ if __name__ == \"__main__\":\n         session_id=f\"generate-blog-post-on-{url_safe_topic}\",\n         storage=SqliteStorage(\n             table_name=\"generate_blog_post_workflows\",\n+            mode=\"workflow\",\n+            auto_upgrade_schema=True,\n             db_file=\"tmp/agno_workflows.db\",\n         ),\n         debug_mode=True,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/workflows/investment_report_generator.py",
            "diff": "diff --git a/cookbook/workflows/investment_report_generator.py b/cookbook/workflows/investment_report_generator.py\nindex c062bf4b4..c9af62d0b 100644\n--- a/cookbook/workflows/investment_report_generator.py\n+++ b/cookbook/workflows/investment_report_generator.py\n@@ -218,6 +218,8 @@ if __name__ == \"__main__\":\n         session_id=f\"investment-report-{url_safe_companies}\",\n         storage=SqliteStorage(\n             table_name=\"investment_report_workflows\",\n+            mode=\"workflow\",\n+            auto_upgrade_schema=True,\n             db_file=\"tmp/agno_workflows.db\",\n         ),\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/workflows/personalized_email_generator.py",
            "diff": "diff --git a/cookbook/workflows/personalized_email_generator.py b/cookbook/workflows/personalized_email_generator.py\nindex da3f0ee5b..543e6899f 100644\n--- a/cookbook/workflows/personalized_email_generator.py\n+++ b/cookbook/workflows/personalized_email_generator.py\n@@ -440,6 +440,8 @@ def main():\n             session_id=\"personalized-email-generator\",\n             storage=SqliteStorage(\n                 table_name=\"personalized_email_workflows\",\n+                mode=\"workflow\",\n+                auto_upgrade_schema=True,\n                 db_file=\"tmp/agno_workflows.db\",\n             ),\n         )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/workflows/startup_idea_validator.py",
            "diff": "diff --git a/cookbook/workflows/startup_idea_validator.py b/cookbook/workflows/startup_idea_validator.py\nindex f16bbeb42..50938b7eb 100644\n--- a/cookbook/workflows/startup_idea_validator.py\n+++ b/cookbook/workflows/startup_idea_validator.py\n@@ -263,6 +263,8 @@ if __name__ == \"__main__\":\n         session_id=f\"validate-startup-idea-{url_safe_idea}\",\n         storage=SqliteStorage(\n             table_name=\"validate_startup_ideas_workflow\",\n+            mode=\"workflow\",\n+            auto_upgrade_schema=True,\n             db_file=\"tmp/agno_workflows.db\",\n         ),\n     )\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "cookbook/workflows/workflows_playground.py",
            "diff": "diff --git a/cookbook/workflows/workflows_playground.py b/cookbook/workflows/workflows_playground.py\nindex 8ced4d547..aac842b74 100644\n--- a/cookbook/workflows/workflows_playground.py\n+++ b/cookbook/workflows/workflows_playground.py\n@@ -21,6 +21,8 @@ blog_post_generator = BlogPostGenerator(\n     storage=SqliteStorage(\n         table_name=\"generate_blog_post_workflows\",\n         db_file=\"tmp/agno_workflows.db\",\n+        mode=\"workflow\",\n+        auto_upgrade_schema=True,\n     ),\n )\n personalised_email_generator = PersonalisedEmailGenerator(\n@@ -28,6 +30,8 @@ personalised_email_generator = PersonalisedEmailGenerator(\n     storage=SqliteStorage(\n         table_name=\"personalized_email_workflows\",\n         db_file=\"tmp/agno_workflows.db\",\n+        mode=\"workflow\",\n+        auto_upgrade_schema=True,\n     ),\n )\n \n@@ -36,6 +40,8 @@ investment_report_generator = InvestmentReportGenerator(\n     storage=SqliteStorage(\n         table_name=\"investment_report_workflows\",\n         db_file=\"tmp/agno_workflows.db\",\n+        mode=\"workflow\",\n+        auto_upgrade_schema=True,\n     ),\n )\n \n@@ -44,6 +50,8 @@ startup_idea_validator = StartupIdeaValidator(\n     storage=SqliteStorage(\n         table_name=\"validate_startup_ideas_workflow\",\n         db_file=\"tmp/agno_workflows.db\",\n+        mode=\"workflow\",\n+        auto_upgrade_schema=True,\n     ),\n )\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/agent/agent.py",
            "diff": "diff --git a/libs/agno/agno/agent/agent.py b/libs/agno/agno/agent/agent.py\nindex 0d8747580..86e8e29b2 100644\n--- a/libs/agno/agno/agent/agent.py\n+++ b/libs/agno/agno/agent/agent.py\n@@ -53,7 +53,7 @@ from agno.utils.log import (\n     set_log_level_to_info,\n )\n from agno.utils.message import get_text_from_message\n-from agno.utils.prompts import get_json_output_prompt\n+from agno.utils.prompts import get_json_output_prompt, get_response_model_format_prompt\n from agno.utils.response import create_panel, escape_markdown_tags, format_tool_calls\n from agno.utils.safe_formatter import SafeFormatter\n from agno.utils.string import parse_response_model_str\n@@ -118,13 +118,10 @@ class Agent:\n     # --- Agent Knowledge ---\n     knowledge: Optional[AgentKnowledge] = None\n     # Enable RAG by adding references from AgentKnowledge to the user prompt.\n-\n     # Add knowledge_filters to the Agent class attributes\n     knowledge_filters: Optional[Dict[str, Any]] = None\n-\n     # Let the agent choose the knowledge filters\n     enable_agentic_knowledge_filters: Optional[bool] = False\n-\n     add_references: bool = False\n     # Retrieval function to get references\n     # This function, if provided, is used instead of the default search_knowledge function\n@@ -234,6 +231,10 @@ class Agent:\n     # --- Agent Response Model Settings ---\n     # Provide a response model to get the response as a Pydantic model\n     response_model: Optional[Type[BaseModel]] = None\n+    # Provide a secondary model to parse the response from the primary model\n+    parser_model: Optional[Model] = None\n+    # Provide a prompt for the parser model\n+    parser_model_prompt: Optional[str] = None\n     # If True, the response from the Model is converted into the response_model\n     # Otherwise, the response is returned as a JSON string\n     parse_response: bool = True\n@@ -357,6 +358,8 @@ class Agent:\n         retries: int = 0,\n         delay_between_retries: int = 1,\n         exponential_backoff: bool = False,\n+        parser_model: Optional[Model] = None,\n+        parser_model_prompt: Optional[str] = None,\n         response_model: Optional[Type[BaseModel]] = None,\n         parse_response: bool = True,\n         structured_outputs: Optional[bool] = None,\n@@ -452,6 +455,8 @@ class Agent:\n         self.retries = retries\n         self.delay_between_retries = delay_between_retries\n         self.exponential_backoff = exponential_backoff\n+        self.parser_model = parser_model\n+        self.parser_model_prompt = parser_model_prompt\n         self.response_model = response_model\n         self.parse_response = parse_response\n \n@@ -640,13 +645,36 @@ class Agent:\n         self.model = cast(Model, self.model)\n         model_response: ModelResponse = self.model.response(\n             messages=run_messages.messages,\n-            response_format=response_format,\n             tools=self._tools_for_model,\n             functions=self._functions_for_model,\n             tool_choice=self.tool_choice,\n             tool_call_limit=self.tool_call_limit,\n+            response_format=response_format,\n         )\n \n+        # If a parser model is provided, structure the response separately\n+        if self.parser_model is not None:\n+            if self.response_model is not None:\n+                parser_response_format = self._get_response_format(self.parser_model)\n+                messages_for_parser_model = self.get_messages_for_parser_model(model_response, parser_response_format)\n+                parser_model_response: ModelResponse = self.parser_model.response(\n+                    messages=messages_for_parser_model,\n+                    response_format=parser_response_format,\n+                )\n+                parser_model_response_message: Optional[Message] = None\n+                for message in reversed(messages_for_parser_model):\n+                    if message.role == \"assistant\":\n+                        parser_model_response_message = message\n+                        break\n+                if parser_model_response_message is not None:\n+                    run_messages.messages.append(parser_model_response_message)\n+                    model_response.parsed = parser_model_response.parsed\n+                    model_response.content = parser_model_response.content\n+                else:\n+                    log_warning(\"Unable to parse response with parser model\")\n+            else:\n+                log_warning(\"A response model is required to parse the response with a parser model\")\n+\n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n         # 3. Add the run to memory\n@@ -932,7 +960,7 @@ class Agent:\n \n         # Prepare arguments for the model\n         self.set_default_model()\n-        response_format = self._get_response_format()\n+        response_format = self._get_response_format() if self.parser_model is None else None\n         self.model = cast(Model, self.model)\n \n         self.determine_tools_for_model(\n@@ -958,7 +986,7 @@ class Agent:\n                 run_response.model = self.model.id if self.model is not None else None\n                 run_response.model_provider = self.model.provider if self.model is not None else None\n \n-                # for backward compatibility, set self.run_response\n+                # For backward compatibility, set self.run_response\n                 self.run_response = run_response\n                 self.run_id = run_id\n \n@@ -983,6 +1011,7 @@ class Agent:\n                     videos=videos,\n                     files=files,\n                     messages=messages,\n+                    knowledge_filters=effective_filters,\n                     **kwargs,\n                 )\n                 if len(run_messages.messages) == 0:\n@@ -1080,13 +1109,36 @@ class Agent:\n         # 2. Generate a response from the Model (includes running function calls)\n         model_response: ModelResponse = await self.model.aresponse(\n             messages=run_messages.messages,\n-            response_format=response_format,\n             tools=self._tools_for_model,\n             functions=self._functions_for_model,\n             tool_choice=self.tool_choice,\n             tool_call_limit=self.tool_call_limit,\n+            response_format=response_format,\n         )\n \n+        # If a parser model is provided, structure the response separately\n+        if self.parser_model is not None:\n+            if self.response_model is not None:\n+                parser_response_format = self._get_response_format(self.parser_model)\n+                messages_for_parser_model = self.get_messages_for_parser_model(model_response, parser_response_format)\n+                parser_model_response: ModelResponse = await self.parser_model.aresponse(\n+                    messages=messages_for_parser_model,\n+                    response_format=parser_response_format,\n+                )\n+                parser_model_response_message: Optional[Message] = None\n+                for message in reversed(messages_for_parser_model):\n+                    if message.role == \"assistant\":\n+                        parser_model_response_message = message\n+                        break\n+                if parser_model_response_message is not None:\n+                    run_messages.messages.append(parser_model_response_message)\n+                    model_response.parsed = parser_model_response.parsed\n+                    model_response.content = parser_model_response.content\n+                else:\n+                    log_warning(\"Unable to parse response with parser model\")\n+            else:\n+                log_warning(\"A response model is required to parse the response with a parser model\")\n+\n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n         # 3. Add the run to memory\n@@ -1336,7 +1388,7 @@ class Agent:\n \n         # Prepare arguments for the model\n         self.set_default_model()\n-        response_format = self._get_response_format()\n+        response_format = self._get_response_format() if self.parser_model is None else None\n         self.model = cast(Model, self.model)\n \n         self.determine_tools_for_model(\n@@ -1386,6 +1438,7 @@ class Agent:\n                     videos=videos,\n                     files=files,\n                     messages=messages,\n+                    knowledge_filters=effective_filters,\n                     **kwargs,\n                 )\n                 if len(run_messages.messages) == 0:\n@@ -3586,8 +3639,8 @@ class Agent:\n             and (not self.use_json_mode or self.structured_outputs)\n         )\n \n-    def _get_response_format(self) -> Optional[Union[Dict, Type[BaseModel]]]:\n-        self.model = cast(Model, self.model)\n+    def _get_response_format(self, model: Optional[Model] = None) -> Optional[Union[Dict, Type[BaseModel]]]:\n+        self.model = cast(Model, model or self.model)\n         if self.response_model is None:\n             return None\n         else:\n@@ -4078,6 +4131,7 @@ class Agent:\n             # or if use_json_mode is True\n             if (\n                 self.model is not None\n+                and self.parser_model is None\n                 and self.response_model is not None\n                 and not (\n                     (self.model.supports_native_structured_outputs or self.model.supports_json_schema_outputs)\n@@ -4320,12 +4374,20 @@ class Agent:\n \n         # 3.3.13 Add the JSON output prompt if response_model is provided and the model does not support native structured outputs or JSON schema outputs\n         # or if use_json_mode is True\n-        if self.response_model is not None and not (\n-            (self.model.supports_native_structured_outputs or self.model.supports_json_schema_outputs)\n-            and (not self.use_json_mode or self.structured_outputs is True)\n+        if (\n+            self.response_model is not None\n+            and self.parser_model is None\n+            and not (\n+                (self.model.supports_native_structured_outputs or self.model.supports_json_schema_outputs)\n+                and (not self.use_json_mode or self.structured_outputs is True)\n+            )\n         ):\n             system_message_content += f\"{get_json_output_prompt(self.response_model)}\"  # type: ignore\n \n+        # 3.3.14 Add the response model format prompt if response_model is provided\n+        if self.response_model is not None and self.parser_model is not None:\n+            system_message_content += f\"{get_response_model_format_prompt(self.response_model)}\"\n+\n         # Return the system message\n         return (\n             Message(role=self.system_message_role, content=system_message_content.strip())  # type: ignore\n@@ -4341,6 +4403,7 @@ class Agent:\n         images: Optional[Sequence[Image]] = None,\n         videos: Optional[Sequence[Video]] = None,\n         files: Optional[Sequence[File]] = None,\n+        knowledge_filters: Optional[Dict[str, Any]] = None,\n         **kwargs: Any,\n     ) -> Optional[Message]:\n         \"\"\"Return the user message for the Agent.\n@@ -4363,7 +4426,9 @@ class Agent:\n \n             retrieval_timer = Timer()\n             retrieval_timer.start()\n-            docs_from_knowledge = self.get_relevant_docs_from_knowledge(query=message_str, **kwargs)\n+            docs_from_knowledge = self.get_relevant_docs_from_knowledge(\n+                query=message_str, filters=knowledge_filters, **kwargs\n+            )\n             if docs_from_knowledge is not None:\n                 references = MessageReferences(\n                     query=message_str, references=docs_from_knowledge, time=round(retrieval_timer.elapsed, 4)\n@@ -4474,6 +4539,7 @@ class Agent:\n         videos: Optional[Sequence[Video]] = None,\n         files: Optional[Sequence[File]] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n+        knowledge_filters: Optional[Dict[str, Any]] = None,\n         **kwargs: Any,\n     ) -> RunMessages:\n         \"\"\"This function returns a RunMessages object with the following attributes:\n@@ -4571,7 +4637,13 @@ class Agent:\n         # 4.1 Build user message if message is None, str or list\n         if message is None or isinstance(message, str) or isinstance(message, list):\n             user_message = self.get_user_message(\n-                message=message, audio=audio, images=images, videos=videos, files=files, **kwargs\n+                message=message,\n+                audio=audio,\n+                images=images,\n+                videos=videos,\n+                files=files,\n+                knowledge_filters=knowledge_filters,\n+                **kwargs,\n             )\n         # 4.2 If message is provided as a Message, use it directly\n         elif isinstance(message, Message):\n@@ -4724,6 +4796,24 @@ class Agent:\n \n         return run_messages\n \n+    def get_messages_for_parser_model(\n+        self, model_response: ModelResponse, response_format: Optional[Union[Dict, Type[BaseModel]]]\n+    ) -> List[Message]:\n+        \"\"\"Get the messages for the parser model.\"\"\"\n+        system_content = (\n+            self.parser_model_prompt\n+            if self.parser_model_prompt is not None\n+            else \"You are tasked with creating a structured output from the provided data.\"\n+        )\n+\n+        if response_format == {\"type\": \"json_object\"} and self.response_model is not None:\n+            system_content += f\"{get_json_output_prompt(self.response_model)}\"  # type: ignore\n+\n+        return [\n+            Message(role=\"system\", content=system_content),\n+            Message(role=\"user\", content=model_response.content),\n+        ]\n+\n     def get_session_summary(self, session_id: Optional[str] = None, user_id: Optional[str] = None):\n         \"\"\"Get the session summary for the given session ID and user ID.\"\"\"\n         if self.memory is None:\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/agui/__init__.py",
            "diff": "diff --git a/libs/agno/agno/app/agui/__init__.py b/libs/agno/agno/app/agui/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/agui/app.py",
            "diff": "diff --git a/libs/agno/agno/app/agui/app.py b/libs/agno/agno/app/agui/app.py\nnew file mode 100644\nindex 000000000..62db4c732\n--- /dev/null\n+++ b/libs/agno/agno/app/agui/app.py\n@@ -0,0 +1,17 @@\n+\"\"\"Main class for the AG-UI app, used to expose an Agno Agent or Team in an AG-UI compatible format.\"\"\"\n+\n+from fastapi.routing import APIRouter\n+\n+from agno.app.agui.async_router import get_async_agui_router\n+from agno.app.agui.sync_router import get_sync_agui_router\n+from agno.app.base import BaseAPIApp\n+\n+\n+class AGUIApp(BaseAPIApp):\n+    type = \"agui\"\n+\n+    def get_router(self) -> APIRouter:\n+        return get_sync_agui_router(agent=self.agent, team=self.team)\n+\n+    def get_async_router(self) -> APIRouter:\n+        return get_async_agui_router(agent=self.agent, team=self.team)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/agui/async_router.py",
            "diff": "diff --git a/libs/agno/agno/app/agui/async_router.py b/libs/agno/agno/app/agui/async_router.py\nnew file mode 100644\nindex 000000000..bb87b73f6\n--- /dev/null\n+++ b/libs/agno/agno/app/agui/async_router.py\n@@ -0,0 +1,120 @@\n+\"\"\"Async router handling exposing an Agno Agent or Team in an AG-UI compatible format.\"\"\"\n+\n+import logging\n+import uuid\n+from typing import AsyncIterator, Optional\n+\n+from ag_ui.core import (\n+    BaseEvent,\n+    EventType,\n+    RunAgentInput,\n+    RunErrorEvent,\n+    RunStartedEvent,\n+)\n+from ag_ui.encoder import EventEncoder\n+from fastapi import APIRouter\n+from fastapi.responses import StreamingResponse\n+\n+from agno.agent.agent import Agent\n+from agno.app.agui.utils import async_stream_agno_response_as_agui_events, get_last_user_message\n+from agno.team.team import Team\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+async def run_agent(agent: Agent, run_input: RunAgentInput) -> AsyncIterator[BaseEvent]:\n+    \"\"\"Run the contextual Agent, mapping AG-UI input messages to Agno format, and streaming the response in AG-UI format.\"\"\"\n+    run_id = run_input.run_id or str(uuid.uuid4())\n+\n+    try:\n+        # Preparing the input for the Agent and emitting the run started event\n+        message = get_last_user_message(run_input.messages)\n+        yield RunStartedEvent(type=EventType.RUN_STARTED, thread_id=run_input.thread_id, run_id=run_id)\n+\n+        # Request streaming response from agent\n+        response_stream = await agent.arun(\n+            message=message,\n+            session_id=run_input.thread_id,\n+            stream=True,\n+            stream_intermediate_steps=True,\n+        )\n+\n+        # Stream the response content in AG-UI format\n+        async for event in async_stream_agno_response_as_agui_events(\n+            response_stream=response_stream, thread_id=run_input.thread_id, run_id=run_id\n+        ):\n+            yield event\n+\n+    # Emit a RunErrorEvent if any error occurs\n+    except Exception as e:\n+        logger.error(f\"Error running agent: {e}\", exc_info=True)\n+        yield RunErrorEvent(type=EventType.RUN_ERROR, message=str(e))\n+\n+\n+async def run_team(team: Team, input: RunAgentInput) -> AsyncIterator[BaseEvent]:\n+    \"\"\"Run the contextual Team, mapping AG-UI input messages to Agno format, and streaming the response in AG-UI format.\"\"\"\n+    run_id = input.run_id or str(uuid.uuid4())\n+    try:\n+        # Extract the last user message for team execution\n+        user_message = get_last_user_message(input.messages) if input.messages else \"\"\n+        yield RunStartedEvent(type=EventType.RUN_STARTED, thread_id=input.thread_id, run_id=run_id)\n+\n+        # Request streaming response from team\n+        response_stream = await team.arun(\n+            message=user_message,\n+            session_id=input.thread_id,\n+            stream=True,\n+            stream_intermediate_steps=True,\n+        )\n+\n+        # Stream the response content in AG-UI format\n+        async for event in async_stream_agno_response_as_agui_events(\n+            response_stream=response_stream, thread_id=input.thread_id, run_id=run_id\n+        ):\n+            yield event\n+\n+    except Exception as e:\n+        logger.error(f\"Error running team: {e}\", exc_info=True)\n+        yield RunErrorEvent(type=EventType.RUN_ERROR, message=str(e))\n+\n+\n+def get_async_agui_router(agent: Optional[Agent] = None, team: Optional[Team] = None) -> APIRouter:\n+    \"\"\"Return an AG-UI compatible FastAPI router.\"\"\"\n+    if (agent is None and team is None) or (agent is not None and team is not None):\n+        raise ValueError(\"One of 'agent' or 'team' must be provided.\")\n+\n+    router = APIRouter()\n+    encoder = EventEncoder()\n+\n+    async def _run(run_input: RunAgentInput):\n+        async def event_generator():\n+            if agent:\n+                async for event in run_agent(agent, run_input):\n+                    encoded_event = encoder.encode(event)\n+                    yield encoded_event\n+            elif team:\n+                async for event in run_team(team, run_input):\n+                    encoded_event = encoder.encode(event)\n+                    yield encoded_event\n+\n+        return StreamingResponse(\n+            event_generator(),\n+            media_type=\"text/event-stream\",\n+            headers={\n+                \"Cache-Control\": \"no-cache\",\n+                \"Connection\": \"keep-alive\",\n+                \"Access-Control-Allow-Origin\": \"*\",\n+                \"Access-Control-Allow-Methods\": \"POST, GET, OPTIONS\",\n+                \"Access-Control-Allow-Headers\": \"*\",\n+            },\n+        )\n+\n+    @router.post(\"/agui\")\n+    async def run_agent_agui(run_input: RunAgentInput):\n+        return await _run(run_input)\n+\n+    @router.get(\"/status\")\n+    async def get_status():\n+        return {\"status\": \"available\"}\n+\n+    return router\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/agui/sync_router.py",
            "diff": "diff --git a/libs/agno/agno/app/agui/sync_router.py b/libs/agno/agno/app/agui/sync_router.py\nnew file mode 100644\nindex 000000000..d50aec939\n--- /dev/null\n+++ b/libs/agno/agno/app/agui/sync_router.py\n@@ -0,0 +1,120 @@\n+\"\"\"Async router handling exposing an Agno Agent or Team in an AG-UI compatible format.\"\"\"\n+\n+import logging\n+import uuid\n+from typing import Iterator, Optional\n+\n+from ag_ui.core import (\n+    BaseEvent,\n+    EventType,\n+    RunAgentInput,\n+    RunErrorEvent,\n+    RunStartedEvent,\n+)\n+from ag_ui.encoder import EventEncoder\n+from fastapi import APIRouter\n+from fastapi.responses import StreamingResponse\n+\n+from agno.agent.agent import Agent\n+from agno.app.agui.utils import get_last_user_message, stream_agno_response_as_agui_events\n+from agno.team.team import Team\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def run_agent(agent: Agent, run_input: RunAgentInput) -> Iterator[BaseEvent]:\n+    \"\"\"Run the contextual Agent, mapping AG-UI input messages to Agno format, and streaming the response in AG-UI format.\"\"\"\n+    run_id = run_input.run_id or str(uuid.uuid4())\n+\n+    try:\n+        # Preparing the input for the Agent and emitting the run started event\n+        message = get_last_user_message(run_input.messages)\n+        yield RunStartedEvent(type=EventType.RUN_STARTED, thread_id=run_input.thread_id, run_id=run_id)\n+\n+        # Request streaming response from agent\n+        response_stream = agent.run(\n+            message=message,\n+            session_id=run_input.thread_id,\n+            stream=True,\n+            stream_intermediate_steps=True,\n+        )\n+\n+        # Stream the response content in AG-UI format\n+        for event in stream_agno_response_as_agui_events(\n+            response_stream=response_stream, thread_id=run_input.thread_id, run_id=run_id\n+        ):\n+            yield event\n+\n+    # Emit a RunErrorEvent if any error occurs\n+    except Exception as e:\n+        logger.error(f\"Error running agent: {e}\", exc_info=True)\n+        yield RunErrorEvent(type=EventType.RUN_ERROR, message=str(e))\n+\n+\n+def run_team(team: Team, input: RunAgentInput) -> Iterator[BaseEvent]:\n+    \"\"\"Run the contextual Team, mapping AG-UI input messages to Agno format, and streaming the response in AG-UI format.\"\"\"\n+    run_id = input.run_id or str(uuid.uuid4())\n+    try:\n+        # Extract the last user message for team execution\n+        user_message = get_last_user_message(input.messages) if input.messages else \"\"\n+        yield RunStartedEvent(type=EventType.RUN_STARTED, thread_id=input.thread_id, run_id=run_id)\n+\n+        # Request streaming response from team\n+        response_stream = team.run(\n+            message=user_message,\n+            session_id=input.thread_id,\n+            stream=True,\n+            stream_intermediate_steps=True,\n+        )\n+\n+        # Stream the response content in AG-UI format\n+        for event in stream_agno_response_as_agui_events(\n+            response_stream=response_stream, thread_id=input.thread_id, run_id=run_id\n+        ):\n+            yield event\n+\n+    except Exception as e:\n+        logger.error(f\"Error running team: {e}\", exc_info=True)\n+        yield RunErrorEvent(type=EventType.RUN_ERROR, message=str(e))\n+\n+\n+def get_sync_agui_router(agent: Optional[Agent] = None, team: Optional[Team] = None) -> APIRouter:\n+    \"\"\"Return an AG-UI compatible FastAPI router.\"\"\"\n+    if (agent is None and team is None) or (agent is not None and team is not None):\n+        raise ValueError(\"One of 'agent' or 'team' must be provided.\")\n+\n+    router = APIRouter()\n+    encoder = EventEncoder()\n+\n+    def _run(run_input: RunAgentInput):\n+        def event_generator():\n+            if agent:\n+                for event in run_agent(agent, run_input):\n+                    encoded_event = encoder.encode(event)\n+                    yield encoded_event\n+            elif team:\n+                for event in run_team(team, run_input):\n+                    encoded_event = encoder.encode(event)\n+                    yield encoded_event\n+\n+        return StreamingResponse(\n+            event_generator(),\n+            media_type=\"text/event-stream\",\n+            headers={\n+                \"Cache-Control\": \"no-cache\",\n+                \"Connection\": \"keep-alive\",\n+                \"Access-Control-Allow-Origin\": \"*\",\n+                \"Access-Control-Allow-Methods\": \"POST, GET, OPTIONS\",\n+                \"Access-Control-Allow-Headers\": \"*\",\n+            },\n+        )\n+\n+    @router.post(\"/agui\")\n+    def run_agent_agui(run_input: RunAgentInput):\n+        return _run(run_input)\n+\n+    @router.get(\"/status\")\n+    def get_status():\n+        return {\"status\": \"available\"}\n+\n+    return router\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/agui/utils.py",
            "diff": "diff --git a/libs/agno/agno/app/agui/utils.py b/libs/agno/agno/app/agui/utils.py\nnew file mode 100644\nindex 000000000..0e90defe8\n--- /dev/null\n+++ b/libs/agno/agno/app/agui/utils.py\n@@ -0,0 +1,314 @@\n+\"\"\"Logic used by the AG-UI router.\"\"\"\n+\n+import uuid\n+from collections import deque\n+from collections.abc import Iterator\n+from dataclasses import dataclass\n+from typing import AsyncIterator, Deque, List, Optional, Set, Tuple, Union\n+\n+from ag_ui.core import (\n+    BaseEvent,\n+    EventType,\n+    RunFinishedEvent,\n+    StepFinishedEvent,\n+    StepStartedEvent,\n+    TextMessageContentEvent,\n+    TextMessageEndEvent,\n+    TextMessageStartEvent,\n+    ToolCallArgsEvent,\n+    ToolCallEndEvent,\n+    ToolCallStartEvent,\n+)\n+from ag_ui.core.types import Message as AGUIMessage\n+\n+from agno.run.response import RunEvent, RunResponse\n+from agno.run.team import TeamRunResponse\n+\n+\n+@dataclass\n+class EventBuffer:\n+    \"\"\"Buffer to manage event ordering constraints, relevant when mapping Agno responses to AG-UI events.\"\"\"\n+\n+    buffer: Deque[BaseEvent]\n+    blocking_tool_call_id: Optional[str]  # The tool call that's currently blocking the buffer\n+    active_tool_call_ids: Set[str]  # All currently active tool calls\n+    ended_tool_call_ids: Set[str]  # All tool calls that have ended\n+\n+    def __init__(self):\n+        self.buffer = deque()\n+        self.blocking_tool_call_id = None\n+        self.active_tool_call_ids = set()\n+        self.ended_tool_call_ids = set()\n+\n+    def is_blocked(self) -> bool:\n+        \"\"\"Check if the buffer is currently blocked by an active tool call.\"\"\"\n+        return self.blocking_tool_call_id is not None\n+\n+    def start_tool_call(self, tool_call_id: str) -> None:\n+        \"\"\"Start a new tool call, marking it the current blocking tool call if needed.\"\"\"\n+        self.active_tool_call_ids.add(tool_call_id)\n+        if self.blocking_tool_call_id is None:\n+            self.blocking_tool_call_id = tool_call_id\n+\n+    def end_tool_call(self, tool_call_id: str) -> bool:\n+        \"\"\"End a tool call, marking it as ended and unblocking the buffer if needed.\"\"\"\n+        self.active_tool_call_ids.discard(tool_call_id)\n+        self.ended_tool_call_ids.add(tool_call_id)\n+\n+        # Unblock the buffer if the current blocking tool call is the one ending\n+        if tool_call_id == self.blocking_tool_call_id:\n+            self.blocking_tool_call_id = None\n+            return True\n+\n+        return False\n+\n+\n+def get_last_user_message(messages: Optional[List[AGUIMessage]]) -> str:\n+    if not messages:\n+        return \"\"\n+    for msg in reversed(messages):\n+        if msg.role == \"user\" and msg.content:\n+            return msg.content\n+    return \"\"\n+\n+\n+def extract_team_response_chunk_content(response: TeamRunResponse) -> str:\n+    \"\"\"Given a response stream chunk, find and extract the content.\"\"\"\n+\n+    # Handle Team members' responses\n+    members_content = []\n+    if hasattr(response, \"member_responses\") and response.member_responses:\n+        for member_resp in response.member_responses:\n+            if isinstance(member_resp, RunResponse):\n+                member_content = extract_response_chunk_content(member_resp)\n+                if member_content:\n+                    members_content.append(f\"Team member: {member_content}\")\n+            elif isinstance(member_resp, TeamRunResponse):\n+                member_content = extract_team_response_chunk_content(member_resp)\n+                if member_content:\n+                    members_content.append(f\"Team member: {member_content}\")\n+    members_response = \"\\n\".join(members_content) if members_content else \"\"\n+\n+    return str(response.content) + members_response\n+\n+\n+def extract_response_chunk_content(response: RunResponse) -> str:\n+    \"\"\"Given a response stream chunk, find and extract the content.\"\"\"\n+    if hasattr(response, \"messages\") and response.messages:\n+        for msg in reversed(response.messages):\n+            if hasattr(msg, \"role\") and msg.role == \"assistant\" and hasattr(msg, \"content\") and msg.content:\n+                return str(msg.content)\n+\n+    return str(response.content) if response.content else \"\"\n+\n+\n+def _create_events_from_chunk(\n+    chunk: Union[RunResponse, TeamRunResponse], message_id: str, message_started: bool, event_buffer: EventBuffer\n+) -> Tuple[List[BaseEvent], bool]:\n+    \"\"\"\n+    Process a single chunk and return events to emit + updated message_started state.\n+    Returns: (events_to_emit, new_message_started_state)\n+    \"\"\"\n+    events_to_emit = []\n+\n+    # Extract content\n+    if isinstance(chunk, RunResponse):\n+        content = extract_response_chunk_content(chunk)\n+    elif isinstance(chunk, TeamRunResponse):\n+        content = extract_team_response_chunk_content(chunk)\n+    else:\n+        content = None\n+\n+    # Handle text responses\n+    if chunk.event == RunEvent.run_response:\n+        # Handle the message start event, emitted once per message\n+        if not message_started:\n+            message_started = True\n+            start_event = TextMessageStartEvent(\n+                type=EventType.TEXT_MESSAGE_START,\n+                message_id=message_id,\n+                role=\"assistant\",\n+            )\n+            events_to_emit.append(start_event)\n+\n+        # Handle the text content event, emitted once per text chunk\n+        if content is not None and content != \"\":\n+            content_event = TextMessageContentEvent(\n+                type=EventType.TEXT_MESSAGE_CONTENT,\n+                message_id=message_id,\n+                delta=content,\n+            )\n+            events_to_emit.append(content_event)\n+\n+    # Handle starting a new tool call\n+    elif chunk.event == RunEvent.tool_call_started:\n+        if chunk.tools is not None and len(chunk.tools) != 0:\n+            tool_call = chunk.tools[0]\n+            start_event = ToolCallStartEvent(\n+                type=EventType.TOOL_CALL_START,\n+                tool_call_id=tool_call.tool_call_id,  # type: ignore\n+                tool_call_name=tool_call.tool_name,  # type: ignore\n+                parent_message_id=message_id,\n+            )\n+            events_to_emit.append(start_event)\n+\n+            args_event = ToolCallArgsEvent(\n+                type=EventType.TOOL_CALL_ARGS,\n+                tool_call_id=tool_call.tool_call_id,  # type: ignore\n+                delta=str(tool_call.tool_args),\n+            )\n+            events_to_emit.append(args_event)\n+\n+    # Handle tool call completion\n+    elif chunk.event == RunEvent.tool_call_completed:\n+        if chunk.tools is not None and len(chunk.tools) != 0:\n+            tool_call = chunk.tools[0]\n+            if tool_call.tool_call_id not in event_buffer.ended_tool_call_ids:\n+                end_event = ToolCallEndEvent(\n+                    type=EventType.TOOL_CALL_END,\n+                    tool_call_id=tool_call.tool_call_id,  # type: ignore\n+                )\n+                events_to_emit.append(end_event)\n+\n+    # Handle reasoning\n+    elif chunk.event == RunEvent.reasoning_started:\n+        step_event = StepStartedEvent(type=EventType.STEP_STARTED, step_name=\"reasoning\")\n+        events_to_emit.append(step_event)\n+    elif chunk.event == RunEvent.reasoning_completed:\n+        step_event = StepFinishedEvent(type=EventType.STEP_FINISHED, step_name=\"reasoning\")\n+        events_to_emit.append(step_event)\n+\n+    return events_to_emit, message_started\n+\n+\n+def _create_completion_events(\n+    event_buffer: EventBuffer, message_started: bool, message_id: str, thread_id: str, run_id: str\n+) -> List[BaseEvent]:\n+    \"\"\"Create events for run completion.\"\"\"\n+    events_to_emit = []\n+\n+    # End remaining active tool calls if needed\n+    for tool_call_id in list(event_buffer.active_tool_call_ids):\n+        if tool_call_id not in event_buffer.ended_tool_call_ids:\n+            end_event = ToolCallEndEvent(\n+                type=EventType.TOOL_CALL_END,\n+                tool_call_id=tool_call_id,\n+            )\n+            events_to_emit.append(end_event)\n+\n+    # End the message and run, denoting the end of the session\n+    if message_started:\n+        end_message_event = TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=message_id)\n+        events_to_emit.append(end_message_event)\n+\n+    run_finished_event = RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id=thread_id, run_id=run_id)\n+    events_to_emit.append(run_finished_event)\n+\n+    return events_to_emit\n+\n+\n+def _emit_event_logic(event: BaseEvent, event_buffer: EventBuffer) -> List[BaseEvent]:\n+    \"\"\"Process an event through the buffer and return events to actually emit.\"\"\"\n+    events_to_emit = []\n+\n+    if event_buffer.is_blocked():\n+        # Handle events related to the current blocking tool call\n+        if event.type == EventType.TOOL_CALL_ARGS:\n+            if hasattr(event, \"tool_call_id\") and event.tool_call_id in event_buffer.active_tool_call_ids:  # type: ignore\n+                events_to_emit.append(event)\n+            else:\n+                event_buffer.buffer.append(event)\n+        elif event.type == EventType.TOOL_CALL_END:\n+            tool_call_id = getattr(event, \"tool_call_id\", None)\n+            if tool_call_id and tool_call_id == event_buffer.blocking_tool_call_id:\n+                events_to_emit.append(event)\n+                event_buffer.end_tool_call(tool_call_id)\n+                # Flush buffered events after ending the blocking tool call\n+                while event_buffer.buffer:\n+                    buffered_event = event_buffer.buffer.popleft()\n+                    # Recursively process buffered events\n+                    nested_events = _emit_event_logic(buffered_event, event_buffer)\n+                    events_to_emit.extend(nested_events)\n+            elif tool_call_id and tool_call_id in event_buffer.active_tool_call_ids:\n+                event_buffer.buffer.append(event)\n+                event_buffer.end_tool_call(tool_call_id)\n+            else:\n+                event_buffer.buffer.append(event)\n+        # Handle all other events\n+        elif event.type == EventType.TOOL_CALL_START:\n+            event_buffer.buffer.append(event)\n+        else:\n+            event_buffer.buffer.append(event)\n+    # If the buffer is not blocked, emit the events normally\n+    else:\n+        if event.type == EventType.TOOL_CALL_START:\n+            tool_call_id = getattr(event, \"tool_call_id\", None)\n+            if tool_call_id:\n+                event_buffer.start_tool_call(tool_call_id)\n+            events_to_emit.append(event)\n+        elif event.type == EventType.TOOL_CALL_END:\n+            tool_call_id = getattr(event, \"tool_call_id\", None)\n+            if tool_call_id:\n+                event_buffer.end_tool_call(tool_call_id)\n+            events_to_emit.append(event)\n+        else:\n+            events_to_emit.append(event)\n+\n+    return events_to_emit\n+\n+\n+def stream_agno_response_as_agui_events(\n+    response_stream: Union[Iterator[RunResponse], Iterator[TeamRunResponse]], thread_id: str, run_id: str\n+) -> Iterator[BaseEvent]:\n+    \"\"\"Map the Agno response stream to AG-UI format, handling event ordering constraints.\"\"\"\n+    message_id = str(uuid.uuid4())\n+    message_started = False\n+    event_buffer = EventBuffer()\n+\n+    for chunk in response_stream:\n+        # Handle the lifecycle end event\n+        if chunk.event == RunEvent.run_completed:\n+            completion_events = _create_completion_events(event_buffer, message_started, message_id, thread_id, run_id)\n+            for event in completion_events:\n+                events_to_emit = _emit_event_logic(event_buffer=event_buffer, event=event)\n+                for emit_event in events_to_emit:\n+                    yield emit_event\n+        else:\n+            # Process regular chunk\n+            events_from_chunk, message_started = _create_events_from_chunk(\n+                chunk, message_id, message_started, event_buffer\n+            )\n+\n+            for event in events_from_chunk:\n+                events_to_emit = _emit_event_logic(event_buffer=event_buffer, event=event)\n+                for emit_event in events_to_emit:\n+                    yield emit_event\n+\n+\n+# Async version - thin wrapper\n+async def async_stream_agno_response_as_agui_events(\n+    response_stream: Union[AsyncIterator[RunResponse], AsyncIterator[TeamRunResponse]], thread_id: str, run_id: str\n+) -> AsyncIterator[BaseEvent]:\n+    \"\"\"Map the Agno response stream to AG-UI format, handling event ordering constraints.\"\"\"\n+    message_id = str(uuid.uuid4())\n+    message_started = False\n+    event_buffer = EventBuffer()\n+\n+    async for chunk in response_stream:\n+        # Handle the lifecycle end event\n+        if chunk.event == RunEvent.run_completed:\n+            completion_events = _create_completion_events(event_buffer, message_started, message_id, thread_id, run_id)\n+            for event in completion_events:\n+                events_to_emit = _emit_event_logic(event_buffer=event_buffer, event=event)\n+                for emit_event in events_to_emit:\n+                    yield emit_event\n+        else:\n+            # Process regular chunk\n+            events_from_chunk, message_started = _create_events_from_chunk(\n+                chunk, message_id, message_started, event_buffer\n+            )\n+\n+            for event in events_from_chunk:\n+                events_to_emit = _emit_event_logic(event_buffer=event_buffer, event=event)\n+                for emit_event in events_to_emit:\n+                    yield emit_event\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/base.py",
            "diff": "diff --git a/libs/agno/agno/app/base.py b/libs/agno/agno/app/base.py\nindex 482cfb352..59adf37a0 100644\n--- a/libs/agno/agno/app/base.py\n+++ b/libs/agno/agno/app/base.py\n@@ -17,6 +17,8 @@ from agno.utils.log import log_debug, log_info\n \n \n class BaseAPIApp(ABC):\n+    type: Optional[str] = None\n+\n     def __init__(\n         self,\n         agent: Optional[Agent] = None,\n@@ -190,7 +192,7 @@ class BaseAPIApp(ABC):\n             ]\n             if self.team\n             else None,\n-            \"type\": \"fastapi\",\n+            \"type\": self.type,\n             \"description\": self.description,\n         }\n         payload = {k: v for k, v in payload.items() if v is not None}\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/fastapi/app.py",
            "diff": "diff --git a/libs/agno/agno/app/fastapi/app.py b/libs/agno/agno/app/fastapi/app.py\nindex f9ca97370..cf153da54 100644\n--- a/libs/agno/agno/app/fastapi/app.py\n+++ b/libs/agno/agno/app/fastapi/app.py\n@@ -1,17 +1,113 @@\n import logging\n+from typing import List, Optional, Union\n \n+import uvicorn\n+from fastapi import FastAPI\n from fastapi.routing import APIRouter\n \n+from agno.agent.agent import Agent\n from agno.app.base import BaseAPIApp\n from agno.app.fastapi.async_router import get_async_router\n from agno.app.fastapi.sync_router import get_sync_router\n+from agno.app.settings import APIAppSettings\n+from agno.app.utils import generate_id\n+from agno.team.team import Team\n+from agno.utils.log import log_info\n+from agno.workflow.workflow import Workflow\n \n logger = logging.getLogger(__name__)\n \n \n class FastAPIApp(BaseAPIApp):\n+    type = \"fastapi\"\n+\n+    def __init__(\n+        self,\n+        agents: Optional[List[Agent]] = None,\n+        teams: Optional[List[Team]] = None,\n+        workflows: Optional[List[Workflow]] = None,\n+        settings: Optional[APIAppSettings] = None,\n+        api_app: Optional[FastAPI] = None,\n+        router: Optional[APIRouter] = None,\n+        app_id: Optional[str] = None,\n+        name: Optional[str] = None,\n+        description: Optional[str] = None,\n+        monitoring: bool = True,\n+    ):\n+        if not agents and not teams and not workflows:\n+            raise ValueError(\"Either agents, teams or workflows must be provided.\")\n+\n+        self.agents: Optional[List[Agent]] = agents\n+        self.teams: Optional[List[Team]] = teams\n+        self.workflows: Optional[List[Workflow]] = workflows\n+\n+        self.settings: APIAppSettings = settings or APIAppSettings()\n+        self.api_app: Optional[FastAPI] = api_app\n+        self.router: Optional[APIRouter] = router\n+\n+        self.app_id: Optional[str] = app_id\n+        self.name: Optional[str] = name\n+        self.monitoring = monitoring\n+        self.description = description\n+        self.set_app_id()\n+\n+        if self.agents:\n+            for agent in self.agents:\n+                if not agent.app_id:\n+                    agent.app_id = self.app_id\n+                agent.initialize_agent()\n+\n+        if self.teams:\n+            for team in self.teams:\n+                if not team.app_id:\n+                    team.app_id = self.app_id\n+                team.initialize_team()\n+                for member in team.members:\n+                    if isinstance(member, Agent):\n+                        if not member.app_id:\n+                            member.app_id = self.app_id\n+\n+                        member.team_id = None\n+                        member.initialize_agent()\n+                    elif isinstance(member, Team):\n+                        member.initialize_team()\n+\n+        if self.workflows:\n+            for workflow in self.workflows:\n+                if not workflow.app_id:\n+                    workflow.app_id = self.app_id\n+                if not workflow.workflow_id:\n+                    workflow.workflow_id = generate_id(workflow.name)\n+\n     def get_router(self) -> APIRouter:\n-        return get_sync_router(agent=self.agent, team=self.team)\n+        return get_sync_router(agents=self.agents, teams=self.teams, workflows=self.workflows)\n \n     def get_async_router(self) -> APIRouter:\n-        return get_async_router(agent=self.agent, team=self.team)\n+        return get_async_router(agents=self.agents, teams=self.teams, workflows=self.workflows)\n+\n+    def serve(\n+        self,\n+        app: Union[str, FastAPI],\n+        *,\n+        host: str = \"localhost\",\n+        port: int = 7777,\n+        reload: bool = False,\n+        **kwargs,\n+    ):\n+        self.set_app_id()\n+        self.register_app_on_platform()\n+\n+        if self.agents:\n+            for agent in self.agents:\n+                agent.register_agent()\n+\n+        if self.teams:\n+            for team in self.teams:\n+                team.register_team()\n+\n+        if self.workflows:\n+            for workflow in self.workflows:\n+                workflow.register_workflow()\n+        log_info(f\"Starting API on {host}:{port}\")\n+\n+        uvicorn.run(app=app, host=host, port=port, reload=reload, **kwargs)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/fastapi/async_router.py",
            "diff": "diff --git a/libs/agno/agno/app/fastapi/async_router.py b/libs/agno/agno/app/fastapi/async_router.py\nindex 3c4b7a0ce..1d42463f4 100644\n--- a/libs/agno/agno/app/fastapi/async_router.py\n+++ b/libs/agno/agno/app/fastapi/async_router.py\n@@ -1,8 +1,10 @@\n+import json\n+from dataclasses import asdict\n from io import BytesIO\n-from typing import AsyncGenerator, List, Optional, cast\n+from typing import Any, AsyncGenerator, Dict, List, Optional, cast\n from uuid import uuid4\n \n-from fastapi import APIRouter, File, Form, HTTPException, UploadFile\n+from fastapi import APIRouter, File, Form, HTTPException, Query, UploadFile\n from fastapi.responses import StreamingResponse\n \n from agno.agent.agent import Agent, RunResponse\n@@ -13,6 +15,7 @@ from agno.run.response import RunEvent\n from agno.run.team import TeamRunResponse\n from agno.team.team import Team\n from agno.utils.log import logger\n+from agno.workflow.workflow import Workflow\n \n \n async def agent_chat_response_streamer(\n@@ -81,11 +84,13 @@ async def team_chat_response_streamer(\n         return\n \n \n-def get_async_router(agent: Optional[Agent] = None, team: Optional[Team] = None) -> APIRouter:\n+def get_async_router(\n+    agents: Optional[List[Agent]] = None, teams: Optional[List[Team]] = None, workflows: Optional[List[Workflow]] = None\n+) -> APIRouter:\n     router = APIRouter()\n \n-    if agent is None and team is None:\n-        raise ValueError(\"Either agent or team must be provided.\")\n+    if agents is None and teams is None and workflows is None:\n+        raise ValueError(\"Either agents, teams or workflows must be provided.\")\n \n     @router.get(\"/status\")\n     async def status():\n@@ -246,13 +251,17 @@ def get_async_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n         return base64_images, base64_audios, base64_videos, document_files\n \n     @router.post(\"/runs\")\n-    async def run_agent_or_team(\n-        message: str = Form(...),\n+    async def run_agent_or_team_or_workflow(\n+        message: str = Form(None),\n         stream: bool = Form(False),\n         monitor: bool = Form(False),\n         session_id: Optional[str] = Form(None),\n         user_id: Optional[str] = Form(None),\n         files: Optional[List[UploadFile]] = File(None),\n+        agent_id: Optional[str] = Query(None),\n+        team_id: Optional[str] = Query(None),\n+        workflow_id: Optional[str] = Query(None),\n+        workflow_input: Optional[Dict[str, Any]] = Form(None),\n     ):\n         if session_id is not None and session_id != \"\":\n             logger.debug(f\"Continuing session: {session_id}\")\n@@ -260,16 +269,42 @@ def get_async_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n             logger.debug(\"Creating new session\")\n             session_id = str(uuid4())\n \n+        agent = None\n+        team = None\n+        workflow = None\n+\n+        # Only one of agent_id, team_id or workflow_id can be provided\n+        if agent_id and team_id or agent_id and workflow_id or team_id and workflow_id:\n+            raise HTTPException(status_code=400, detail=\"Only one of agent_id, team_id or workflow_id can be provided\")\n+\n+        if not agent_id and not team_id and not workflow_id:\n+            raise HTTPException(status_code=400, detail=\"One of agent_id, team_id or workflow_id must be provided\")\n+\n+        if agent_id and agents:\n+            agent = next((agent for agent in agents if agent.agent_id == agent_id), None)\n+            if agent is None:\n+                raise HTTPException(status_code=404, detail=\"Agent not found\")\n+            if not message:\n+                raise HTTPException(status_code=400, detail=\"Message is required\")\n+        if team_id and teams:\n+            team = next((team for team in teams if team.team_id == team_id), None)\n+            if team is None:\n+                raise HTTPException(status_code=404, detail=\"Team not found\")\n+            if not message:\n+                raise HTTPException(status_code=400, detail=\"Message is required\")\n+        if workflow_id and workflows:\n+            workflow = next((workflow for workflow in workflows if workflow.workflow_id == workflow_id), None)\n+            if workflow is None:\n+                raise HTTPException(status_code=404, detail=\"Workflow not found\")\n+            if not workflow_input:\n+                raise HTTPException(status_code=400, detail=\"Workflow input is required\")\n+\n         if agent:\n-            if monitor:\n-                agent.monitoring = True\n-            else:\n-                agent.monitoring = False\n+            agent.monitoring = bool(monitor)\n         elif team:\n-            if monitor:\n-                team.monitoring = True\n-            else:\n-                team.monitoring = False\n+            team.monitoring = bool(monitor)\n+        elif workflow:\n+            workflow.monitoring = bool(monitor)\n \n         base64_images: List[Image] = []\n         base64_audios: List[Audio] = []\n@@ -309,6 +344,14 @@ def get_async_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n                     ),\n                     media_type=\"text/event-stream\",\n                 )\n+            elif workflow:\n+                workflow_instance = workflow.deep_copy(update={\"workflow_id\": workflow_id})\n+                workflow_instance.user_id = user_id\n+                workflow_instance.session_name = None\n+                return StreamingResponse(\n+                    (json.dumps(asdict(result)) for result in await workflow_instance.arun(**(workflow_input or {}))),\n+                    media_type=\"text/event-stream\",\n+                )\n         else:\n             if agent:\n                 run_response = cast(\n@@ -336,5 +379,10 @@ def get_async_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n                     stream=False,\n                 )\n                 return team_run_response.to_dict()\n+            elif workflow:\n+                workflow_instance = workflow.deep_copy(update={\"workflow_id\": workflow_id})\n+                workflow_instance.user_id = user_id\n+                workflow_instance.session_name = None\n+                return (await workflow_instance.arun(**(workflow_input or {}))).to_dict()\n \n     return router\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/fastapi/sync_router.py",
            "diff": "diff --git a/libs/agno/agno/app/fastapi/sync_router.py b/libs/agno/agno/app/fastapi/sync_router.py\nindex 2398cd27c..f74437c7a 100644\n--- a/libs/agno/agno/app/fastapi/sync_router.py\n+++ b/libs/agno/agno/app/fastapi/sync_router.py\n@@ -1,8 +1,10 @@\n+import json\n+from dataclasses import asdict\n from io import BytesIO\n-from typing import Generator, List, Optional, cast\n+from typing import Any, Dict, Generator, List, Optional, cast\n from uuid import uuid4\n \n-from fastapi import APIRouter, File, Form, HTTPException, UploadFile\n+from fastapi import APIRouter, File, Form, HTTPException, Query, UploadFile\n from fastapi.responses import StreamingResponse\n \n from agno.agent.agent import Agent, RunResponse\n@@ -13,6 +15,7 @@ from agno.run.response import RunEvent\n from agno.run.team import TeamRunResponse\n from agno.team.team import Team\n from agno.utils.log import logger\n+from agno.workflow.workflow import Workflow\n \n \n def agent_chat_response_streamer(\n@@ -81,11 +84,13 @@ def team_chat_response_streamer(\n         return\n \n \n-def get_sync_router(agent: Optional[Agent] = None, team: Optional[Team] = None) -> APIRouter:\n+def get_sync_router(\n+    agents: Optional[List[Agent]] = None, teams: Optional[List[Team]] = None, workflows: Optional[List[Workflow]] = None\n+) -> APIRouter:\n     router = APIRouter()\n \n-    if agent is None and team is None:\n-        raise ValueError(\"Either agent or team must be provided.\")\n+    if agents is None and teams is None and workflows is None:\n+        raise ValueError(\"Either agents, teams or workflows must be provided.\")\n \n     @router.get(\"/status\")\n     def status():\n@@ -246,10 +251,14 @@ def get_sync_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n         return base64_images, base64_audios, base64_videos, document_files\n \n     @router.post(\"/runs\")\n-    def run_agent_or_team(\n-        message: str = Form(...),\n+    def run_agent_or_team_or_workflow(\n+        message: str = Form(None),\n         stream: bool = Form(True),\n         monitor: bool = Form(False),\n+        agent_id: Optional[str] = Query(None),\n+        team_id: Optional[str] = Query(None),\n+        workflow_id: Optional[str] = Query(None),\n+        workflow_input: Optional[Dict[str, Any]] = Form(None),\n         session_id: Optional[str] = Form(None),\n         user_id: Optional[str] = Form(None),\n         files: Optional[List[UploadFile]] = File(None),\n@@ -260,16 +269,42 @@ def get_sync_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n             logger.debug(\"Creating new session\")\n             session_id = str(uuid4())\n \n+        # Only one of agent_id, team_id or workflow_id can be provided\n+        if agent_id and team_id or agent_id and workflow_id or team_id and workflow_id:\n+            raise HTTPException(status_code=400, detail=\"Only one of agent_id, team_id or workflow_id can be provided\")\n+\n+        if not agent_id and not team_id and not workflow_id:\n+            raise HTTPException(status_code=400, detail=\"One of agent_id, team_id or workflow_id must be provided\")\n+\n+        agent = None\n+        team = None\n+        workflow = None\n+\n+        if agent_id and agents:\n+            agent = next((agent for agent in agents if agent.agent_id == agent_id), None)\n+            if agent is None:\n+                raise HTTPException(status_code=404, detail=\"Agent not found\")\n+            if not message:\n+                raise HTTPException(status_code=400, detail=\"Message is required\")\n+        if team_id and teams:\n+            team = next((team for team in teams if team.team_id == team_id), None)\n+            if team is None:\n+                raise HTTPException(status_code=404, detail=\"Team not found\")\n+            if not message:\n+                raise HTTPException(status_code=400, detail=\"Message is required\")\n+        if workflow_id and workflows:\n+            workflow = next((workflow for workflow in workflows if workflow.workflow_id == workflow_id), None)\n+            if workflow is None:\n+                raise HTTPException(status_code=404, detail=\"Workflow not found\")\n+            if not workflow_input:\n+                raise HTTPException(status_code=400, detail=\"Workflow input is required\")\n+\n         if agent:\n-            if monitor:\n-                agent.monitoring = True\n-            else:\n-                agent.monitoring = False\n+            agent.monitoring = bool(monitor)\n         elif team:\n-            if monitor:\n-                team.monitoring = True\n-            else:\n-                team.monitoring = False\n+            team.monitoring = bool(monitor)\n+        elif workflow:\n+            workflow.monitoring = bool(monitor)\n \n         if files:\n             if agent:\n@@ -305,6 +340,14 @@ def get_sync_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n                     ),\n                     media_type=\"text/event-stream\",\n                 )\n+            elif workflow:\n+                workflow_instance = workflow.deep_copy(update={\"workflow_id\": workflow_id})\n+                workflow_instance.user_id = user_id\n+                workflow_instance.session_name = None\n+                return StreamingResponse(\n+                    (json.dumps(asdict(result)) for result in workflow_instance.run(**(workflow_input or {}))),\n+                    media_type=\"text/event-stream\",\n+                )\n         else:\n             if agent:\n                 run_response = cast(\n@@ -332,5 +375,10 @@ def get_sync_router(agent: Optional[Agent] = None, team: Optional[Team] = None)\n                     stream=False,\n                 )\n                 return team_run_response.to_dict()\n+            elif workflow:\n+                workflow_instance = workflow.deep_copy(update={\"workflow_id\": workflow_id})\n+                workflow_instance.user_id = user_id\n+                workflow_instance.session_name = None\n+                return workflow_instance.run(**(workflow_input or {})).to_dict()\n \n     return router\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/playground/app.py",
            "diff": "diff --git a/libs/agno/agno/app/playground/app.py b/libs/agno/agno/app/playground/app.py\nindex 461cb02e9..4dc72a11c 100644\n--- a/libs/agno/agno/app/playground/app.py\n+++ b/libs/agno/agno/app/playground/app.py\n@@ -15,6 +15,7 @@ from agno.agent.agent import Agent\n from agno.api.playground import PlaygroundEndpointCreate\n from agno.app.playground.async_router import get_async_playground_router\n from agno.app.playground.sync_router import get_sync_playground_router\n+from agno.app.utils import generate_id\n from agno.cli.console import console\n from agno.cli.settings import agno_cli_settings\n from agno.playground.settings import PlaygroundSettings\n@@ -43,10 +44,13 @@ class Playground:\n         self.agents: Optional[List[Agent]] = agents\n         self.workflows: Optional[List[Workflow]] = workflows\n         self.teams: Optional[List[Team]] = teams\n+\n         self.settings: PlaygroundSettings = settings or PlaygroundSettings()\n         self.api_app: Optional[FastAPI] = api_app\n         self.router: Optional[APIRouter] = router\n+\n         self.endpoints_created: Optional[PlaygroundEndpointCreate] = None\n+\n         self.app_id: Optional[str] = app_id\n         self.name: Optional[str] = name\n         self.monitoring = monitoring\n@@ -237,10 +241,3 @@ class Playground:\n         }\n         payload = {k: v for k, v in payload.items() if v is not None}\n         return payload\n-\n-\n-def generate_id(name: Optional[str] = None) -> str:\n-    if name:\n-        return name.lower().replace(\" \", \"-\").replace(\"_\", \"-\")\n-    else:\n-        return str(uuid4())\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/playground/async_router.py",
            "diff": "diff --git a/libs/agno/agno/app/playground/async_router.py b/libs/agno/agno/app/playground/async_router.py\nindex af66cccd7..9316ab936 100644\n--- a/libs/agno/agno/app/playground/async_router.py\n+++ b/libs/agno/agno/app/playground/async_router.py\n@@ -392,7 +392,7 @@ def get_async_playground_router(\n         logger.debug(f\"AgentSessionsRequest: {agent_id} {user_id} {session_id}\")\n         agent = get_agent_by_id(agent_id, agents)\n         if agent is None:\n-            return JSONResponse(status_code=404, content=\"Agent not found.\")\n+            raise HTTPException(status_code=404, detail=\"Agent not found\")\n \n         if agent.storage is None:\n             return JSONResponse(status_code=404, content=\"Agent does not have storage enabled.\")\n@@ -538,7 +538,7 @@ def get_async_playground_router(\n             # Handle unexpected runtime errors\n             raise HTTPException(status_code=500, detail=f\"Error running workflow: {str(e)}\")\n \n-    @playground_router.get(\"/workflows/{workflow_id}/sessions\", response_model=List[WorkflowSessionResponse])\n+    @playground_router.get(\"/workflows/{workflow_id}/sessions\")\n     async def get_all_workflow_sessions(workflow_id: str, user_id: Optional[str] = Query(None, min_length=1)):\n         # Retrieve the workflow by ID\n         workflow = get_workflow_by_id(workflow_id, workflows)\n@@ -558,17 +558,20 @@ def get_async_playground_router(\n             raise HTTPException(status_code=500, detail=f\"Error retrieving sessions: {str(e)}\")\n \n         # Return the sessions\n-        return [\n-            WorkflowSessionResponse(\n-                title=get_session_title_from_workflow_session(session),\n-                session_id=session.session_id,\n-                session_name=session.session_data.get(\"session_name\") if session.session_data else None,\n-                created_at=session.created_at,\n+        workflow_sessions: List[WorkflowSessionResponse] = []\n+        for session in all_workflow_sessions:\n+            title = get_session_title_from_workflow_session(session)\n+            workflow_sessions.append(\n+                {\n+                    \"title\": title,\n+                    \"session_id\": session.session_id,\n+                    \"session_name\": session.session_data.get(\"session_name\") if session.session_data else None,\n+                    \"created_at\": session.created_at,\n+                }\n             )\n-            for session in all_workflow_sessions\n-        ]\n+        return workflow_sessions\n \n-    @playground_router.get(\"/workflows/{workflow_id}/sessions/{session_id}\")\n+    @playground_router.get(\"/workflows/{workflow_id}/sessions/{session_id}\", response_model=WorkflowSession)\n     async def get_workflow_session(\n         workflow_id: str, session_id: str, user_id: Optional[str] = Query(None, min_length=1)\n     ):\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/playground/operator.py",
            "diff": "diff --git a/libs/agno/agno/app/playground/operator.py b/libs/agno/agno/app/playground/operator.py\nindex 5f8913ed9..4e1efdf5f 100644\n--- a/libs/agno/agno/app/playground/operator.py\n+++ b/libs/agno/agno/app/playground/operator.py\n@@ -94,11 +94,24 @@ def get_session_title_from_workflow_session(workflow_session: WorkflowSession) -\n         runs = cast(List[Any], runs)\n         for _run in runs:\n             try:\n+                # Try to get content directly from the run first (workflow structure)\n+                content = _run.get(\"content\")\n+                if content:\n+                    # Split content by newlines and take first line, but limit to 100 chars\n+                    first_line = content.split(\"\\n\")[0]\n+                    return first_line[:100] + \"...\" if len(first_line) > 100 else first_line\n+\n+                # Fallback to response.content structure (if it exists)\n                 response = _run.get(\"response\")\n-                content = response.get(\"content\") if response else None\n-                return content.split(\"\\n\")[0] if content else \"No title\"\n+                if response:\n+                    content = response.get(\"content\")\n+                    if content:\n+                        # Split content by newlines and take first line, but limit to 100 chars\n+                        first_line = content.split(\"\\n\")[0]\n+                        return first_line[:100] + \"...\" if len(first_line) > 100 else first_line\n+\n             except Exception as e:\n-                logger.error(f\"Error parsing chat: {e}\")\n+                logger.error(f\"Error parsing workflow session: {e}\")\n     return \"Unnamed session\"\n \n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/playground/sync_router.py",
            "diff": "diff --git a/libs/agno/agno/app/playground/sync_router.py b/libs/agno/agno/app/playground/sync_router.py\nindex dae277ecf..41cb018ba 100644\n--- a/libs/agno/agno/app/playground/sync_router.py\n+++ b/libs/agno/agno/app/playground/sync_router.py\n@@ -529,16 +529,16 @@ def get_sync_playground_router(\n             # Handle unexpected runtime errors\n             raise HTTPException(status_code=500, detail=f\"Error running workflow: {str(e)}\")\n \n-    @playground_router.get(\"/workflows/{workflow_id}/sessions\", response_model=List[WorkflowSessionResponse])\n+    @playground_router.get(\"/workflows/{workflow_id}/sessions\")\n     def get_all_workflow_sessions(workflow_id: str, user_id: Optional[str] = Query(None, min_length=1)):\n         # Retrieve the workflow by ID\n         workflow = get_workflow_by_id(workflow_id, workflows)\n         if not workflow:\n-            raise HTTPException(status_code=404, detail=\"Workflow not found\")\n+            return JSONResponse(status_code=404, content=\"Workflow not found.\")\n \n         # Ensure storage is enabled for the workflow\n         if not workflow.storage:\n-            raise HTTPException(status_code=404, detail=\"Workflow does not have storage enabled\")\n+            return JSONResponse(status_code=404, content=\"Workflow does not have storage enabled.\")\n \n         # Retrieve all sessions for the given workflow and user\n         try:\n@@ -546,18 +546,21 @@ def get_sync_playground_router(\n                 user_id=user_id, entity_id=workflow_id\n             )  # type: ignore\n         except Exception as e:\n-            raise HTTPException(status_code=500, detail=f\"Error retrieving sessions: {str(e)}\")\n+            return JSONResponse(status_code=500, content=f\"Error retrieving sessions: {str(e)}\")\n \n         # Return the sessions\n-        return [\n-            WorkflowSessionResponse(\n-                title=get_session_title_from_workflow_session(session),\n-                session_id=session.session_id,\n-                session_name=session.session_data.get(\"session_name\") if session.session_data else None,\n-                created_at=session.created_at,\n+        workflow_sessions: List[WorkflowSessionResponse] = []\n+        for session in all_workflow_sessions:\n+            title = get_session_title_from_workflow_session(session)\n+            workflow_sessions.append(\n+                {\n+                    \"title\": title,\n+                    \"session_id\": session.session_id,\n+                    \"session_name\": session.session_data.get(\"session_name\") if session.session_data else None,\n+                    \"created_at\": session.created_at,\n+                }\n             )\n-            for session in all_workflow_sessions\n-        ]\n+        return workflow_sessions\n \n     @playground_router.get(\"/workflows/{workflow_id}/sessions/{session_id}\", response_model=WorkflowSession)\n     def get_workflow_session(workflow_id: str, session_id: str, user_id: Optional[str] = Query(None, min_length=1)):\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/slack/app.py",
            "diff": "diff --git a/libs/agno/agno/app/slack/app.py b/libs/agno/agno/app/slack/app.py\nindex 93a1ca993..5ce6495bc 100644\n--- a/libs/agno/agno/app/slack/app.py\n+++ b/libs/agno/agno/app/slack/app.py\n@@ -10,6 +10,8 @@ logger = logging.getLogger(__name__)\n \n \n class SlackAPI(BaseAPIApp):\n+    type = \"slack\"\n+\n     def get_router(self) -> APIRouter:\n         return get_sync_router(agent=self.agent, team=self.team)\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/app/whatsapp/app.py",
            "diff": "diff --git a/libs/agno/agno/app/whatsapp/app.py b/libs/agno/agno/app/whatsapp/app.py\nindex 8f22a6305..976de2bb7 100644\n--- a/libs/agno/agno/app/whatsapp/app.py\n+++ b/libs/agno/agno/app/whatsapp/app.py\n@@ -6,6 +6,8 @@ from agno.app.whatsapp.sync_router import get_sync_router\n \n \n class WhatsappAPI(BaseAPIApp):\n+    type = \"whatsapp\"\n+\n     def get_router(self) -> APIRouter:\n         return get_sync_router(agent=self.agent, team=self.team)\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/document/reader/url_reader.py",
            "diff": "diff --git a/libs/agno/agno/document/reader/url_reader.py b/libs/agno/agno/document/reader/url_reader.py\nindex 2b49e5a8a..a1bae419a 100644\n--- a/libs/agno/agno/document/reader/url_reader.py\n+++ b/libs/agno/agno/document/reader/url_reader.py\n@@ -1,5 +1,3 @@\n-import asyncio\n-from time import sleep\n from typing import List, Optional\n from urllib.parse import urlparse\n \n@@ -7,7 +5,8 @@ import httpx\n \n from agno.document.base import Document\n from agno.document.reader.base import Reader\n-from agno.utils.log import log_debug, log_info, logger\n+from agno.utils.http import async_fetch_with_retry, fetch_with_retry\n+from agno.utils.log import log_debug\n \n \n class URLReader(Reader):\n@@ -21,31 +20,9 @@ class URLReader(Reader):\n         if not url:\n             raise ValueError(\"No url provided\")\n \n-        log_info(f\"Reading: {url}\")\n+        log_debug(f\"Reading: {url}\")\n         # Retry the request up to 3 times with exponential backoff\n-        for attempt in range(3):\n-            try:\n-                response = httpx.get(url, proxy=self.proxy) if self.proxy else httpx.get(url)\n-                break\n-            except httpx.RequestError as e:\n-                if attempt == 2:  # Last attempt\n-                    logger.error(f\"Failed to fetch URL after 3 attempts: {e}\")\n-                    raise\n-                wait_time = 2**attempt  # Exponential backoff: 1, 2, 4 seconds\n-                logger.warning(f\"Request failed, retrying in {wait_time} seconds...\")\n-                sleep(wait_time)\n-\n-        try:\n-            log_debug(f\"Status: {response.status_code}\")\n-            log_debug(f\"Content size: {len(response.content)} bytes\")\n-        except Exception:\n-            pass\n-\n-        try:\n-            response.raise_for_status()\n-        except httpx.HTTPStatusError as e:\n-            logger.error(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n-            raise\n+        response = fetch_with_retry(url, proxy=self.proxy)\n \n         document = self._create_document(url, response.text)\n         if self.chunk:\n@@ -57,37 +34,15 @@ class URLReader(Reader):\n         if not url:\n             raise ValueError(\"No url provided\")\n \n-        log_info(f\"Reading async: {url}\")\n+        log_debug(f\"Reading async: {url}\")\n         client_args = {\"proxy\": self.proxy} if self.proxy else {}\n         async with httpx.AsyncClient(**client_args) as client:  # type: ignore\n-            for attempt in range(3):\n-                try:\n-                    response = await client.get(url)\n-                    break\n-                except httpx.RequestError as e:\n-                    if attempt == 2:  # Last attempt\n-                        logger.error(f\"Failed to fetch URL after 3 attempts: {e}\")\n-                        raise\n-                    wait_time = 2**attempt\n-                    logger.warning(f\"Request failed, retrying in {wait_time} seconds...\")\n-                    await asyncio.sleep(wait_time)\n-\n-            try:\n-                log_debug(f\"Status: {response.status_code}\")\n-                log_debug(f\"Content size: {len(response.content)} bytes\")\n-            except Exception:\n-                pass\n-\n-            try:\n-                response.raise_for_status()\n-            except httpx.HTTPStatusError as e:\n-                logger.error(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n-                raise\n+            response = await async_fetch_with_retry(url, client=client)\n \n-            document = self._create_document(url, response.text)\n-            if self.chunk:\n-                return await self.chunk_documents_async([document])\n-            return [document]\n+        document = self._create_document(url, response.text)\n+        if self.chunk:\n+            return await self.chunk_documents_async([document])\n+        return [document]\n \n     def _create_document(self, url: str, content: str) -> Document:\n         \"\"\"Helper method to create a document from URL content\"\"\"\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/embedder/langdb.py",
            "diff": "diff --git a/libs/agno/agno/embedder/langdb.py b/libs/agno/agno/embedder/langdb.py\nnew file mode 100644\nindex 000000000..9599eabce\n--- /dev/null\n+++ b/libs/agno/agno/embedder/langdb.py\n@@ -0,0 +1,76 @@\n+from os import getenv\n+from typing import Any, Dict, List, Optional, Tuple\n+\n+from typing_extensions import Literal\n+\n+from agno.embedder.base import Embedder\n+from agno.utils.log import logger\n+\n+try:\n+    from openai import OpenAI as OpenAIClient\n+    from openai.types.create_embedding_response import CreateEmbeddingResponse\n+except ImportError:\n+    raise ImportError(\"`openai` not installed\")\n+\n+\n+class LangDBEmbedder(Embedder):\n+    model: str = \"text-embedding-ada-002\"\n+    dimensions: int = 1536\n+    encoding_format: Literal[\"float\", \"base64\"] = \"float\"\n+    user: Optional[str] = None\n+    api_key: Optional[str] = getenv(\"LANGDB_API_KEY\")\n+    project_id: Optional[str] = getenv(\"LANGDB_PROJECT_ID\")\n+    if not project_id:\n+        logger.error(\"LANGDB_PROJECT_ID not set in the environment\")\n+    organization: Optional[str] = None\n+    base_url: Optional[str] = f\"https://api.us-east-1.langdb.ai/{project_id}/v1\"\n+    request_params: Optional[Dict[str, Any]] = None\n+    client_params: Optional[Dict[str, Any]] = None\n+    openai_client: Optional[OpenAIClient] = None\n+\n+    @property\n+    def client(self) -> OpenAIClient:\n+        if self.openai_client:\n+            return self.openai_client\n+\n+        _client_params: Dict[str, Any] = {}\n+        if self.api_key:\n+            _client_params[\"api_key\"] = self.api_key\n+        if self.organization:\n+            _client_params[\"organization\"] = self.organization\n+        if self.base_url:\n+            _client_params[\"base_url\"] = self.base_url\n+        if self.client_params:\n+            _client_params.update(self.client_params)\n+        return OpenAIClient(**_client_params)\n+\n+    def response(self, text: str) -> CreateEmbeddingResponse:\n+        _request_params: Dict[str, Any] = {\n+            \"input\": text,\n+            \"model\": self.model,\n+            \"encoding_format\": self.encoding_format,\n+        }\n+        if self.user is not None:\n+            _request_params[\"user\"] = self.user\n+        if self.model.startswith(\"text-embedding-3\"):\n+            _request_params[\"dimensions\"] = self.dimensions\n+        if self.request_params:\n+            _request_params.update(self.request_params)\n+        return self.client.embeddings.create(**_request_params)\n+\n+    def get_embedding(self, text: str) -> List[float]:\n+        response: CreateEmbeddingResponse = self.response(text=text)\n+        try:\n+            return response.data[0].embedding\n+        except Exception as e:\n+            logger.warning(e)\n+            return []\n+\n+    def get_embedding_and_usage(self, text: str) -> Tuple[List[float], Optional[Dict]]:\n+        response: CreateEmbeddingResponse = self.response(text=text)\n+\n+        embedding = response.data[0].embedding\n+        usage = response.usage\n+        if usage:\n+            return embedding, usage.model_dump()\n+        return embedding, None\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/eval/accuracy.py",
            "diff": "diff --git a/libs/agno/agno/eval/accuracy.py b/libs/agno/agno/eval/accuracy.py\nindex 233cb9c38..226a8c5c4 100644\n--- a/libs/agno/agno/eval/accuracy.py\n+++ b/libs/agno/agno/eval/accuracy.py\n@@ -399,18 +399,30 @@ Remember: You must only compare the agent_output to the expected_output. The exp\n             self.result.print_summary(console)\n \n         # Log results to the Agno platform if requested\n+        if self.agent is not None:\n+            agent_id = self.agent.agent_id\n+            team_id = None\n+            model_id = self.agent.model.id if self.agent.model is not None else None\n+            model_provider = self.agent.model.provider if self.agent.model is not None else None\n+            evaluated_entity_name = self.agent.name\n+        elif self.team is not None:\n+            agent_id = None\n+            team_id = self.team.team_id\n+            model_id = self.team.model.id if self.team.model is not None else None\n+            model_provider = self.team.model.provider if self.team.model is not None else None\n+            evaluated_entity_name = self.team.name\n+\n         if self.monitoring:\n             log_eval_run(\n                 run_id=self.eval_id,  # type: ignore\n                 run_data=asdict(self.result),\n                 eval_type=EvalType.ACCURACY,\n-                agent_id=self.agent.agent_id if self.agent is not None else None,\n-                model_id=self.agent.model.id if self.agent is not None and self.agent.model is not None else None,\n-                model_provider=self.agent.model.provider\n-                if self.agent is not None and self.agent.model is not None\n-                else None,\n+                agent_id=agent_id,\n+                team_id=team_id,\n+                model_id=model_id,\n+                model_provider=model_provider,\n                 name=self.name if self.name is not None else None,\n-                evaluated_entity_name=self.agent.name if self.agent is not None else None,\n+                evaluated_entity_name=evaluated_entity_name,\n             )\n \n         logger.debug(f\"*********** Evaluation {self.eval_id} Finished ***********\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/knowledge/agent.py",
            "diff": "diff --git a/libs/agno/agno/knowledge/agent.py b/libs/agno/agno/knowledge/agent.py\nindex 972b96653..6892c5cb1 100644\n--- a/libs/agno/agno/knowledge/agent.py\n+++ b/libs/agno/agno/knowledge/agent.py\n@@ -167,8 +167,8 @@ class AgentKnowledge(BaseModel):\n \n         log_info(\"Loading knowledge base\")\n         num_documents = 0\n-        document_iterator = await self.async_document_lists\n-        async for document_list in document_iterator:\n+        document_iterator = self.async_document_lists\n+        async for document_list in document_iterator:  # type: ignore\n             documents_to_load = document_list\n             # Track metadata for filtering capabilities\n             for doc in document_list:\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/knowledge/light_rag.py",
            "diff": "diff --git a/libs/agno/agno/knowledge/light_rag.py b/libs/agno/agno/knowledge/light_rag.py\nnew file mode 100644\nindex 000000000..308e0b125\n--- /dev/null\n+++ b/libs/agno/agno/knowledge/light_rag.py\n@@ -0,0 +1,273 @@\n+from __future__ import annotations\n+\n+from pathlib import Path\n+from typing import Any, ClassVar, Dict, Iterator, List, Optional, Union\n+\n+import textract\n+from pydantic import Field\n+\n+from agno.document import Document\n+from agno.document.reader.markdown_reader import MarkdownReader\n+from agno.document.reader.pdf_reader import PDFUrlReader\n+from agno.document.reader.url_reader import URLReader\n+from agno.knowledge.agent import AgentKnowledge\n+from agno.utils.log import log_debug, log_info, logger\n+\n+\n+class LightRagKnowledgeBase(AgentKnowledge):\n+    \"\"\"LightRAG-based knowledge base for document processing and retrieval.\"\"\"\n+\n+    # Constants\n+    DEFAULT_SERVER_URL: ClassVar[str] = \"http://localhost:9621\"\n+    SUPPORTED_EXTENSIONS: ClassVar[List[str]] = [\".pdf\", \".md\", \".txt\"]\n+\n+    lightrag_server_url: str = DEFAULT_SERVER_URL\n+    path: Optional[Union[str, Path, List[Dict[str, Union[str, Dict[str, Any]]]]]] = None\n+    urls: Optional[Union[List[str], List[Dict[str, Union[str, Dict[str, Any]]]]]] = None\n+    exclude_files: List[str] = Field(default_factory=list)\n+\n+    pdf_url_reader: PDFUrlReader = PDFUrlReader()\n+    markdown_reader: MarkdownReader = MarkdownReader()\n+    url_reader: URLReader = URLReader()\n+\n+    @property\n+    def document_lists(self) -> Iterator[List[Document]]:\n+        \"\"\"Iterate over documents and yield lists of Document objects.\"\"\"\n+        # Convert text lists to Document objects to match parent class signature\n+        for text_list in self._text_document_lists():\n+            documents = [Document(content=text) for text in text_list]\n+            yield documents\n+\n+    def _text_document_lists(self) -> Iterator[List[str]]:\n+        \"\"\"Internal method to iterate over documents and yield lists of text content.\"\"\"\n+        if self.path is not None:\n+            yield from self._process_paths()\n+\n+        if self.urls is not None:\n+            yield from self._process_urls()\n+\n+        if self.urls is None and self.path is None:\n+            raise ValueError(\"Path or URLs are not set\")\n+\n+    def _process_paths(self) -> Iterator[List[str]]:\n+        \"\"\"Process path-based documents.\"\"\"\n+        if self.path is None:\n+            return\n+\n+        if isinstance(self.path, list):\n+            for item in self.path:\n+                if isinstance(item, dict) and \"path\" in item:\n+                    path_value = item[\"path\"]\n+                    if isinstance(path_value, (str, Path)):\n+                        yield from self._process_single_path(Path(path_value))\n+        else:\n+            yield from self._process_single_path(Path(self.path))\n+\n+    def _process_single_path(self, path: Path) -> Iterator[List[str]]:\n+        \"\"\"Process a single path (file or directory).\"\"\"\n+        if path.is_dir():\n+            for file_path in path.glob(\"**/*\"):\n+                if file_path.is_file():\n+                    text_str = textract.process(str(file_path)).decode(\"utf-8\")\n+                    yield [text_str]\n+        elif path.exists() and path.is_file():\n+            if path.suffix == \".md\":\n+                documents = self.markdown_reader.read(file=path)\n+                text_contents = [doc.content for doc in documents]\n+                yield text_contents\n+            elif path.suffix == \".pdf\":\n+                text_str = textract.process(str(path)).decode(\"utf-8\")\n+                yield [text_str]\n+            else:\n+                text_str = textract.process(str(path)).decode(\"utf-8\")\n+                yield [text_str]\n+\n+    def _process_urls(self) -> Iterator[List[str]]:\n+        \"\"\"Process URL-based documents.\"\"\"\n+        if self.urls is None:\n+            return\n+\n+        log_info(f\"Processing URLs: {self.urls}\")\n+        for item in self.urls:\n+            if isinstance(item, dict) and \"url\" in item:\n+                url = item[\"url\"]\n+                config = item.get(\"metadata\", {})\n+                if isinstance(url, str) and isinstance(config, dict):\n+                    yield from self._process_url_with_metadata(url, config)\n+            elif isinstance(item, str):\n+                yield from self._process_simple_url(item)\n+\n+    def _process_url_with_metadata(self, url: str, config: Dict[str, Any]) -> Iterator[List[str]]:\n+        \"\"\"Process URL with metadata configuration.\"\"\"\n+        log_debug(f\"Processing URL with metadata - URL: {url}, Config: {config}\")\n+        if self._is_valid_url(url):\n+            if url.endswith(\".pdf\"):\n+                log_info(f\"READING PDF URL: {url}\")\n+                documents = self.pdf_url_reader.read(url=url)\n+                text_contents = [doc.content for doc in documents]\n+                yield text_contents\n+            else:\n+                log_debug(f\"URL is valid, reading documents from: {url}\")\n+                documents = self.url_reader.read(url=url)\n+                text_contents = []\n+                for doc in documents:\n+                    if config:\n+                        log_debug(f\"Adding metadata {config} to document from URL: {url}\")\n+                        doc.meta_data.update(config)\n+                    text_contents.append(doc.content)\n+                yield text_contents\n+\n+    def _process_simple_url(self, url: str) -> Iterator[List[str]]:\n+        \"\"\"Process a simple URL without metadata.\"\"\"\n+        log_info(f\"Processing simple URL: {url}\")\n+        if self._is_valid_url(url):\n+            log_info(f\"Simple URL is valid, reading documents from: {url}\")\n+            if url.endswith(\".pdf\"):\n+                documents = self.pdf_url_reader.read(url=url)\n+                text_contents = [doc.content for doc in documents]\n+                yield text_contents\n+            else:\n+                documents = self.url_reader.read(url=url)\n+                text_contents = [doc.content for doc in documents]\n+                yield text_contents\n+\n+    async def load(\n+        self,\n+        recreate: bool = False,\n+        upsert: bool = False,\n+        skip_existing: bool = True,\n+    ) -> None:\n+        \"\"\"Load the knowledge base to the LightRAG server asynchronously.\n+\n+        Note: The LightRAG implementation is inherently async.\n+        \"\"\"\n+        logger.debug(\"Loading LightRagKnowledgeBase\")\n+        for text_list in self._text_document_lists():\n+            for text in text_list:\n+                await self._insert_text(text)\n+\n+    async def aload(\n+        self,\n+        recreate: bool = False,\n+        upsert: bool = False,\n+        skip_existing: bool = True,\n+    ) -> None:\n+        \"\"\"Load all documents into the LightRAG server asynchronously.\"\"\"\n+        # Delegate to load() since both are async for LightRAG\n+        await self.load(recreate=recreate, upsert=upsert, skip_existing=skip_existing)\n+\n+    async def load_text(\n+        self, text: str, upsert: bool = False, skip_existing: bool = True, filters: Optional[Dict[str, Any]] = None\n+    ) -> None:\n+        \"\"\"Load a single text into the LightRAG server asynchronously.\"\"\"\n+        await self._insert_text(text)\n+\n+    async def async_search(\n+        self, query: str, num_documents: Optional[int] = None, filters: Optional[Dict[str, Any]] = None\n+    ) -> List[Document]:\n+        \"\"\"Override the async_search method from AgentKnowledge to query the LightRAG server.\"\"\"\n+        import httpx\n+\n+        logger.info(f\"Querying LightRAG server with query: {query}\")\n+        mode = \"hybrid\"  # Default mode, can be \"local\", \"global\", or \"hybrid\"\n+\n+        async with httpx.AsyncClient() as client:\n+            response = await client.post(\n+                f\"{self.lightrag_server_url}/query\",\n+                json={\"query\": query, \"mode\": mode},\n+                headers={\"Content-Type\": \"application/json\"},\n+            )\n+            response.raise_for_status()\n+            result = response.json()\n+            logger.info(f\"Query result: {result}\")\n+\n+            # Convert result to Document objects to match parent class signature\n+            if isinstance(result, dict) and \"response\" in result:\n+                return [Document(content=result[\"response\"], meta_data={\"query\": query, \"mode\": mode})]\n+            elif isinstance(result, list):\n+                return [Document(content=str(item), meta_data={\"query\": query, \"mode\": mode}) for item in result]\n+            else:\n+                return [Document(content=str(result), meta_data={\"query\": query, \"mode\": mode})]\n+\n+    async def _insert_text(self, text: str) -> Dict[str, Any]:\n+        \"\"\"Insert text into the LightRAG server.\"\"\"\n+        import httpx\n+\n+        async with httpx.AsyncClient() as client:\n+            response = await client.post(\n+                f\"{self.lightrag_server_url}/documents/text\",\n+                json={\"text\": text},\n+                headers={\"Content-Type\": \"application/json\"},\n+            )\n+            response.raise_for_status()\n+            result = response.json()\n+            logger.debug(f\"Text insertion result: {result}\")\n+            return result\n+\n+    def _is_valid_url(self, url: str) -> bool:\n+        \"\"\"Helper to check if URL is valid.\"\"\"\n+        if not any(url.endswith(ext) for ext in self.SUPPORTED_EXTENSIONS):\n+            logger.error(f\"Unsupported URL: {url}. Supported file types: {', '.join(self.SUPPORTED_EXTENSIONS)}\")\n+            return False\n+        return True\n+\n+\n+async def lightrag_retriever(\n+    query: str,\n+    num_documents: int = 5,\n+    mode: str = \"hybrid\",  # Default mode, can be \"local\", \"global\", or \"hybrid\"\n+    lightrag_server_url: str = \"http://localhost:9621\",\n+) -> Optional[List[Dict[str, Any]]]:\n+    \"\"\"\n+    Custom retriever function to search the LightRAG server for relevant documents.\n+\n+    Args:\n+        query: The search query string\n+        num_documents: Number of documents to retrieve (currently unused by LightRAG)\n+        mode: Query mode - \"local\", \"global\", or \"hybrid\"\n+        lightrag_server_url: URL of the LightRAG server\n+\n+    Returns:\n+        List of retrieved documents or None if search fails\n+    \"\"\"\n+    try:\n+        import httpx\n+\n+        async with httpx.AsyncClient(timeout=30.0) as client:\n+            response = await client.post(\n+                f\"{lightrag_server_url}/query\",\n+                json={\"query\": query, \"mode\": mode},\n+                headers={\"Content-Type\": \"application/json\"},\n+            )\n+\n+            response.raise_for_status()\n+            result = response.json()\n+\n+            return _format_lightrag_response(result, query, mode)\n+\n+    except httpx.RequestError as e:\n+        logger.error(f\"HTTP Request Error: {type(e).__name__}: {str(e)}\")\n+        return None\n+    except httpx.HTTPStatusError as e:\n+        logger.error(f\"HTTP Status Error: {e.response.status_code} - {e.response.text}\")\n+        return None\n+    except Exception as e:\n+        logger.error(f\"Unexpected error during LightRAG server search: {type(e).__name__}: {str(e)}\")\n+        import traceback\n+\n+        logger.error(f\"Full traceback: {traceback.format_exc()}\")\n+        return None\n+\n+\n+def _format_lightrag_response(result: Any, query: str, mode: str) -> List[Dict[str, Any]]:\n+    \"\"\"Format LightRAG server response to expected document format.\"\"\"\n+    # LightRAG server returns a dict with 'response' key, but we expect a list of documents\n+    # Convert the response to the expected format\n+    if isinstance(result, dict) and \"response\" in result:\n+        # Wrap the response in a document-like structure\n+        return [{\"content\": result[\"response\"], \"source\": \"lightrag\", \"metadata\": {\"query\": query, \"mode\": mode}}]\n+    elif isinstance(result, list):\n+        return result\n+    else:\n+        # If it's a string or other format, wrap it\n+        return [{\"content\": str(result), \"source\": \"lightrag\", \"metadata\": {\"query\": query, \"mode\": mode}}]\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/knowledge/pdf_bytes.py",
            "diff": "diff --git a/libs/agno/agno/knowledge/pdf_bytes.py b/libs/agno/agno/knowledge/pdf_bytes.py\nnew file mode 100644\nindex 000000000..e70e5aca6\n--- /dev/null\n+++ b/libs/agno/agno/knowledge/pdf_bytes.py\n@@ -0,0 +1,42 @@\n+import io\n+from typing import IO, AsyncIterator, Iterator, List, Union\n+\n+from pydantic import Field\n+\n+from agno.document import Document\n+from agno.document.reader.pdf_reader import PDFImageReader, PDFReader\n+from agno.knowledge.agent import AgentKnowledge\n+\n+\n+class PDFBytesKnowledgeBase(AgentKnowledge):\n+    pdfs: Union[List[bytes], List[IO]]\n+\n+    exclude_files: List[str] = Field(default_factory=list)\n+\n+    reader: Union[PDFReader, PDFImageReader] = PDFReader()\n+\n+    @property\n+    def document_lists(self) -> Iterator[List[Document]]:\n+        \"\"\"Iterate over PDFs bytes and yield lists of documents.\n+        Each object yielded by the iterator is a list of documents.\n+\n+        Returns:\n+            Iterator[List[Document]]: Iterator yielding list of documents\n+        \"\"\"\n+\n+        for pdf in self.pdfs:\n+            _pdf = io.BytesIO(pdf) if isinstance(pdf, bytes) else pdf\n+            yield self.reader.read(pdf=_pdf)\n+\n+    @property\n+    async def async_document_lists(self) -> AsyncIterator[List[Document]]:\n+        \"\"\"Iterate over PDFs bytes and yield lists of documents.\n+        Each object yielded by the iterator is a list of documents.\n+\n+        Returns:\n+            Iterator[List[Document]]: Iterator yielding list of documents\n+        \"\"\"\n+\n+        for pdf in self.pdfs:\n+            _pdf = io.BytesIO(pdf) if isinstance(pdf, bytes) else pdf\n+            yield await self.reader.async_read(pdf=_pdf)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/knowledge/pdf_url.py",
            "diff": "diff --git a/libs/agno/agno/knowledge/pdf_url.py b/libs/agno/agno/knowledge/pdf_url.py\nindex 5a7302cf2..09c7a7331 100644\n--- a/libs/agno/agno/knowledge/pdf_url.py\n+++ b/libs/agno/agno/knowledge/pdf_url.py\n@@ -14,7 +14,7 @@ class PDFUrlKnowledgeBase(AgentKnowledge):\n     @property\n     def document_lists(self) -> Iterator[List[Document]]:\n         \"\"\"Iterate over PDF URLs and yield lists of documents.\"\"\"\n-        if not self.urls:\n+        if self.urls is None:\n             raise ValueError(\"URLs are not set\")\n \n         for item in self.urls:\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/anthropic/claude.py",
            "diff": "diff --git a/libs/agno/agno/models/anthropic/claude.py b/libs/agno/agno/models/anthropic/claude.py\nindex eee874764..83abd4774 100644\n--- a/libs/agno/agno/models/anthropic/claude.py\n+++ b/libs/agno/agno/models/anthropic/claude.py\n@@ -526,12 +526,19 @@ class Claude(Model):\n \n         # Add usage metrics\n         if response.usage is not None:\n-            model_response.response_usage = {\n-                \"cache_write_tokens\": response.usage.cache_creation_input_tokens,\n-                \"cached_tokens\": response.usage.cache_read_input_tokens,\n+            usage_dict = {\n                 \"input_tokens\": response.usage.input_tokens,\n                 \"output_tokens\": response.usage.output_tokens,\n             }\n+\n+            if hasattr(response.usage, \"cache_creation_input_tokens\") and response.usage.cache_creation_input_tokens:\n+                usage_dict[\"cache_write_tokens\"] = response.usage.cache_creation_input_tokens\n+\n+            if hasattr(response.usage, \"cache_read_input_tokens\") and response.usage.cache_read_input_tokens:\n+                usage_dict[\"cached_tokens\"] = response.usage.cache_read_input_tokens\n+\n+            model_response.response_usage = usage_dict\n+\n         return model_response\n \n     def parse_provider_response_delta(\n@@ -606,13 +613,19 @@ class Claude(Model):\n                         )\n \n         if hasattr(response, \"usage\") and response.usage is not None:\n-            model_response.response_usage = {\n-                \"cache_write_tokens\": response.usage.cache_creation_input_tokens or 0,\n-                \"cached_tokens\": response.usage.cache_read_input_tokens or 0,\n+            usage_dict = {\n                 \"input_tokens\": response.usage.input_tokens or 0,\n                 \"output_tokens\": response.usage.output_tokens or 0,\n             }\n \n+            if hasattr(response.usage, \"cache_creation_input_tokens\") and response.usage.cache_creation_input_tokens:\n+                usage_dict[\"cache_write_tokens\"] = response.usage.cache_creation_input_tokens\n+\n+            if hasattr(response.usage, \"cache_read_input_tokens\") and response.usage.cache_read_input_tokens:\n+                usage_dict[\"cached_tokens\"] = response.usage.cache_read_input_tokens\n+\n+            model_response.response_usage = usage_dict\n+\n         # Capture the Beta response\n         try:\n             if (\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/langdb/__init__.py",
            "diff": "diff --git a/libs/agno/agno/models/langdb/__init__.py b/libs/agno/agno/models/langdb/__init__.py\nnew file mode 100644\nindex 000000000..76f4652c8\n--- /dev/null\n+++ b/libs/agno/agno/models/langdb/__init__.py\n@@ -0,0 +1 @@\n+from agno.models.langdb.langdb import LangDB\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/langdb/langdb.py",
            "diff": "diff --git a/libs/agno/agno/models/langdb/langdb.py b/libs/agno/agno/models/langdb/langdb.py\nnew file mode 100644\nindex 000000000..cab3fe058\n--- /dev/null\n+++ b/libs/agno/agno/models/langdb/langdb.py\n@@ -0,0 +1,42 @@\n+from dataclasses import dataclass\n+from os import getenv\n+from typing import Any, Dict, Optional\n+\n+from agno.models.openai.like import OpenAILike\n+from agno.utils.log import logger\n+\n+\n+@dataclass\n+class LangDB(OpenAILike):\n+    \"\"\"\n+    A class for using models hosted on LangDB.\n+\n+    Attributes:\n+        id (str): The model id. Defaults to \"gpt-4o\".\n+        name (str): The model name. Defaults to \"LangDB\".\n+        provider (str): The provider name. Defaults to \"LangDB\".\n+        api_key (Optional[str]): The API key. Defaults to getenv(\"LANGDB_API_KEY\").\n+        project_id (Optional[str]): The project id. Defaults to None.\n+    \"\"\"\n+\n+    id: str = \"gpt-4o\"\n+    name: str = \"LangDB\"\n+    provider: str = \"LangDB\"\n+\n+    api_key: Optional[str] = getenv(\"LANGDB_API_KEY\")\n+    project_id: Optional[str] = getenv(\"LANGDB_PROJECT_ID\")\n+    if not project_id:\n+        logger.warning(\"LANGDB_PROJECT_ID not set in the environment\")\n+    base_url: str = f\"https://api.us-east-1.langdb.ai/{project_id}/v1\"\n+    label: Optional[str] = None\n+    default_headers: Optional[dict] = None\n+\n+    def _get_client_params(self) -> Dict[str, Any]:\n+        # Initialize headers with label if present\n+        if self.label and not self.default_headers:\n+            self.default_headers = {\n+                \"x-label\": self.label,\n+            }\n+        client_params = super()._get_client_params()\n+\n+        return client_params\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/ollama/chat.py",
            "diff": "diff --git a/libs/agno/agno/models/ollama/chat.py b/libs/agno/agno/models/ollama/chat.py\nindex 48e544008..d2868eda6 100644\n--- a/libs/agno/agno/models/ollama/chat.py\n+++ b/libs/agno/agno/models/ollama/chat.py\n@@ -265,19 +265,6 @@ class Ollama(Model):\n         # Get response message\n         response_message: OllamaMessage = response.get(\"message\")\n \n-        # Parse structured outputs if enabled\n-        try:\n-            if (\n-                response_format is not None\n-                and isinstance(response_format, type)\n-                and issubclass(response_format, BaseModel)\n-            ):\n-                parsed_object = response_message.content  # type: ignore\n-                if parsed_object is not None:\n-                    model_response.parsed = parsed_object\n-        except Exception as e:\n-            log_warning(f\"Error retrieving structured outputs: {e}\")\n-\n         if response_message.get(\"role\") is not None:\n             model_response.role = response_message.get(\"role\")\n \n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/openai/chat.py",
            "diff": "diff --git a/libs/agno/agno/models/openai/chat.py b/libs/agno/agno/models/openai/chat.py\nindex d9f062f47..e30ef1b3d 100644\n--- a/libs/agno/agno/models/openai/chat.py\n+++ b/libs/agno/agno/models/openai/chat.py\n@@ -25,7 +25,6 @@ try:\n         ChoiceDelta,\n         ChoiceDeltaToolCall,\n     )\n-    from openai.types.chat.parsed_chat_completion import ParsedChatCompletion\n except (ImportError, ModuleNotFoundError):\n     raise ImportError(\"`openai` not installed. Please install using `pip install openai`\")\n \n@@ -314,7 +313,7 @@ class OpenAIChat(Model):\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n         tools: Optional[List[Dict[str, Any]]] = None,\n         tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n-    ) -> Union[ChatCompletion, ParsedChatCompletion]:\n+    ) -> ChatCompletion:\n         \"\"\"\n         Send a chat completion request to the OpenAI API.\n \n@@ -375,7 +374,7 @@ class OpenAIChat(Model):\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n         tools: Optional[List[Dict[str, Any]]] = None,\n         tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n-    ) -> Union[ChatCompletion, ParsedChatCompletion]:\n+    ) -> ChatCompletion:\n         \"\"\"\n         Sends an asynchronous chat completion request to the OpenAI API.\n \n@@ -600,7 +599,7 @@ class OpenAIChat(Model):\n \n     def parse_provider_response(\n         self,\n-        response: Union[ChatCompletion, ParsedChatCompletion],\n+        response: ChatCompletion,\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n     ) -> ModelResponse:\n         \"\"\"\n@@ -618,19 +617,6 @@ class OpenAIChat(Model):\n         # Get response message\n         response_message = response.choices[0].message\n \n-        # Parse structured outputs if enabled\n-        try:\n-            if (\n-                response_format is not None\n-                and isinstance(response_format, type)\n-                and issubclass(response_format, BaseModel)\n-            ):\n-                parsed_object = response_message.parsed  # type: ignore\n-                if parsed_object is not None:\n-                    model_response.parsed = parsed_object\n-        except Exception as e:\n-            log_warning(f\"Error retrieving structured outputs: {e}\")\n-\n         # Add role\n         if response_message.role is not None:\n             model_response.role = response_message.role\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/vllm/__init__.py",
            "diff": "diff --git a/libs/agno/agno/models/vllm/__init__.py b/libs/agno/agno/models/vllm/__init__.py\nnew file mode 100644\nindex 000000000..8884df38c\n--- /dev/null\n+++ b/libs/agno/agno/models/vllm/__init__.py\n@@ -0,0 +1,3 @@\n+from agno.models.vllm.vllm import vLLM\n+\n+__all__ = [\"vLLM\"]\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/models/vllm/vllm.py",
            "diff": "diff --git a/libs/agno/agno/models/vllm/vllm.py b/libs/agno/agno/models/vllm/vllm.py\nnew file mode 100644\nindex 000000000..040df1d05\n--- /dev/null\n+++ b/libs/agno/agno/models/vllm/vllm.py\n@@ -0,0 +1,74 @@\n+from dataclasses import dataclass\n+from os import getenv\n+from typing import Any, Dict, List, Optional, Type, Union\n+\n+from pydantic import BaseModel\n+\n+from agno.models.openai.like import OpenAILike\n+\n+\n+@dataclass\n+class vLLM(OpenAILike):\n+    \"\"\"\n+    Class for interacting with vLLM models via OpenAI-compatible API.\n+\n+    Attributes:\n+        id: Model identifier\n+        name: API name\n+        provider: API provider\n+        base_url: vLLM server URL\n+        temperature: Sampling temperature\n+        top_p: Nucleus sampling probability\n+        presence_penalty: Repetition penalty\n+        top_k: Top-k sampling\n+        enable_thinking: Special mode flag\n+    \"\"\"\n+\n+    id: str = \"not-set\"\n+    name: str = \"vLLM\"\n+    provider: str = \"vLLM\"\n+\n+    api_key: Optional[str] = getenv(\"VLLM_API_KEY\") or \"EMPTY\"\n+    base_url: Optional[str] = getenv(\"VLLM_BASE_URL\", \"http://localhost:8000/v1/\")\n+\n+    temperature: float = 0.7\n+    top_p: float = 0.8\n+    presence_penalty: float = 1.5\n+    top_k: Optional[int] = None\n+    enable_thinking: Optional[bool] = None\n+\n+    def __post_init__(self):\n+        \"\"\"Validate required configuration\"\"\"\n+        if not self.base_url:\n+            raise ValueError(\"VLLM_BASE_URL must be set via environment variable or explicit initialization\")\n+        if self.id == \"not-set\":\n+            raise ValueError(\"Model ID must be set via environment variable or explicit initialization\")\n+\n+        body: Dict[str, Any] = {}\n+        if self.top_k is not None:\n+            body[\"top_k\"] = self.top_k\n+        if self.enable_thinking is not None:\n+            body[\"chat_template_kwargs\"] = {\"enable_thinking\": self.enable_thinking}\n+        self.extra_body = body or None\n+\n+    def get_request_kwargs(\n+        self,\n+        response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n+        tools: Optional[List[Dict[str, Any]]] = None,\n+        tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n+    ) -> Dict[str, Any]:\n+        request_kwargs = super().get_request_kwargs(\n+            response_format=response_format, tools=tools, tool_choice=tool_choice\n+        )\n+\n+        vllm_body: Dict[str, Any] = {}\n+        if self.top_k is not None:\n+            vllm_body[\"top_k\"] = self.top_k\n+        if self.enable_thinking is not None:\n+            vllm_body.setdefault(\"chat_template_kwargs\", {})[\"enable_thinking\"] = self.enable_thinking\n+\n+        if vllm_body:\n+            existing_body = request_kwargs.get(\"extra_body\") or {}\n+            request_kwargs[\"extra_body\"] = {**existing_body, **vllm_body}\n+\n+        return request_kwargs\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/reranker/__init__.py",
            "diff": "diff --git a/libs/agno/agno/reranker/__init__.py b/libs/agno/agno/reranker/__init__.py\nindex e69de29bb..6b1c9f0ad 100644\n--- a/libs/agno/agno/reranker/__init__.py\n+++ b/libs/agno/agno/reranker/__init__.py\n@@ -0,0 +1,5 @@\n+from agno.reranker.base import Reranker\n+from agno.reranker.cohere import CohereReranker\n+from agno.reranker.infinity import InfinityReranker\n+\n+__all__ = [\"Reranker\", \"CohereReranker\", \"InfinityReranker\"]\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/reranker/infinity.py",
            "diff": "diff --git a/libs/agno/agno/reranker/infinity.py b/libs/agno/agno/reranker/infinity.py\nnew file mode 100644\nindex 000000000..0d03997c7\n--- /dev/null\n+++ b/libs/agno/agno/reranker/infinity.py\n@@ -0,0 +1,195 @@\n+from typing import Any, List, Optional\n+from urllib.parse import urlparse\n+\n+from agno.document import Document\n+from agno.reranker.base import Reranker\n+from agno.utils.log import logger\n+\n+try:\n+    from infinity_client import AuthenticatedClient, Client\n+    from infinity_client.api.default import rerank\n+    from infinity_client.models import RerankInput\n+except ImportError:\n+    raise ImportError(\"infinity_client not installed, please run `pip install infinity_client`\")\n+\n+\n+class InfinityReranker(Reranker):\n+    model: str = \"BAAI/bge-reranker-base\"\n+    host: str = \"localhost\"\n+    port: int = 7997\n+    url: Optional[str] = None\n+    top_n: Optional[int] = None\n+    api_key: Optional[str] = None\n+    verify_ssl: bool = True\n+    _client: Optional[Any] = None\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        if self.url:\n+            self._parse_url()\n+\n+    def _parse_url(self):\n+        \"\"\"Parse URL to extract host, port and path\"\"\"\n+        if self.url:\n+            parsed = urlparse(self.url)\n+            if parsed.hostname:\n+                self.host = parsed.hostname\n+            if parsed.port:\n+                self.port = parsed.port\n+            # If no port specified in URL, keep default port\n+\n+    @property\n+    def base_url(self) -> str:\n+        \"\"\"Construct the base URL for the Infinity server\"\"\"\n+        return f\"http://{self.host}:{self.port}\"\n+\n+    @property\n+    def client(self) -> Any:\n+        \"\"\"Get or create the infinity client\"\"\"\n+        if self._client:\n+            return self._client\n+\n+        base_url = self.base_url\n+\n+        if self.api_key:\n+            self._client = AuthenticatedClient(base_url=base_url, token=self.api_key, verify_ssl=self.verify_ssl)\n+        else:\n+            self._client = Client(base_url=base_url, verify_ssl=self.verify_ssl)\n+\n+        return self._client\n+\n+    def _rerank(self, query: str, documents: List[Document]) -> List[Document]:\n+        # Validate input documents and top_n\n+        if not documents:\n+            return []\n+\n+        top_n = self.top_n\n+        if top_n and not (0 < top_n):\n+            logger.warning(f\"top_n should be a positive integer, got {self.top_n}, setting top_n to None\")\n+            top_n = None\n+\n+        compressed_docs: list[Document] = []\n+\n+        try:\n+            # Prepare the request body for Infinity reranking\n+            rerank_input = {\n+                \"model\": self.model,\n+                \"query\": query,\n+                \"documents\": [doc.content for doc in documents],\n+                \"return_documents\": False,  # We only need scores, we already have documents\n+            }\n+\n+            # Add top_n to payload if specified\n+            if top_n:\n+                rerank_input[\"top_n\"] = top_n\n+\n+            # Create the input object\n+            body = RerankInput.from_dict(rerank_input)\n+\n+            # Make request to Infinity rerank endpoint using the client\n+            with self.client as client:\n+                result = rerank.sync(client=client, body=body)\n+\n+                if result is None:\n+                    logger.error(\"Rerank request returned None\")\n+                    return documents\n+\n+                # Process the response\n+                # Infinity returns results with index and relevance_score\n+                if hasattr(result, \"results\") and result.results:\n+                    for item in result.results:\n+                        doc_index = item.index\n+                        relevance_score = item.relevance_score\n+\n+                        if doc_index < len(documents):\n+                            doc = documents[doc_index]\n+                            doc.reranking_score = relevance_score\n+                            compressed_docs.append(doc)\n+\n+                # Order by relevance score\n+                compressed_docs.sort(\n+                    key=lambda x: x.reranking_score if x.reranking_score is not None else float(\"-inf\"),\n+                    reverse=True,\n+                )\n+\n+                # Limit to top_n if specified and not already limited by the API\n+                if top_n and len(compressed_docs) > top_n:\n+                    compressed_docs = compressed_docs[:top_n]\n+\n+        except Exception as e:\n+            logger.error(f\"Error connecting to Infinity server at {self.base_url}: {e}\")\n+            return documents\n+\n+        return compressed_docs\n+\n+    def rerank(self, query: str, documents: List[Document]) -> List[Document]:\n+        try:\n+            return self._rerank(query=query, documents=documents)\n+        except Exception as e:\n+            logger.error(f\"Error reranking documents: {e}. Returning original documents\")\n+            return documents\n+\n+    async def arerank(self, query: str, documents: List[Document]) -> List[Document]:\n+        \"\"\"Async version of rerank\"\"\"\n+        # Validate input documents and top_n\n+        if not documents:\n+            return []\n+\n+        top_n = self.top_n\n+        if top_n and not (0 < top_n):\n+            logger.warning(f\"top_n should be a positive integer, got {self.top_n}, setting top_n to None\")\n+            top_n = None\n+\n+        compressed_docs: list[Document] = []\n+\n+        try:\n+            # Prepare the request body for Infinity reranking\n+            rerank_input = {\n+                \"model\": self.model,\n+                \"query\": query,\n+                \"documents\": [doc.content for doc in documents],\n+                \"return_documents\": False,  # We only need scores, we already have documents\n+            }\n+\n+            # Add top_n to payload if specified\n+            if top_n:\n+                rerank_input[\"top_n\"] = top_n\n+\n+            # Create the input object\n+            body = RerankInput.from_dict(rerank_input)\n+\n+            # Make async request to Infinity rerank endpoint using the client\n+            async with self.client as client:\n+                result = await rerank.asyncio(client=client, body=body)\n+\n+                if result is None:\n+                    logger.error(\"Async rerank request returned None\")\n+                    return documents\n+\n+                # Process the response\n+                # Infinity returns results with index and relevance_score\n+                if hasattr(result, \"results\") and result.results:\n+                    for item in result.results:\n+                        doc_index = item.index\n+                        relevance_score = item.relevance_score\n+\n+                        if doc_index < len(documents):\n+                            doc = documents[doc_index]\n+                            doc.reranking_score = relevance_score\n+                            compressed_docs.append(doc)\n+\n+                # Order by relevance score\n+                compressed_docs.sort(\n+                    key=lambda x: x.reranking_score if x.reranking_score is not None else float(\"-inf\"),\n+                    reverse=True,\n+                )\n+\n+                # Limit to top_n if specified and not already limited by the API\n+                if top_n and len(compressed_docs) > top_n:\n+                    compressed_docs = compressed_docs[:top_n]\n+\n+        except Exception as e:\n+            logger.error(f\"Error connecting to Infinity server at {self.base_url}: {e}\")\n+            return documents\n+\n+        return compressed_docs\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/run/response.py",
            "diff": "diff --git a/libs/agno/agno/run/response.py b/libs/agno/agno/run/response.py\nindex 5c233b8d0..e678f47fb 100644\n--- a/libs/agno/agno/run/response.py\n+++ b/libs/agno/agno/run/response.py\n@@ -177,7 +177,7 @@ class RunResponse:\n                 _dict[\"citations\"] = self.citations\n \n         if self.content and isinstance(self.content, BaseModel):\n-            _dict[\"content\"] = self.content.model_dump(exclude_none=True)\n+            _dict[\"content\"] = self.content.model_dump(exclude_none=True, mode=\"json\")\n \n         if self.tools is not None:\n             _dict[\"tools\"] = []\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/run/team.py",
            "diff": "diff --git a/libs/agno/agno/run/team.py b/libs/agno/agno/run/team.py\nindex d1af4ec83..58b2abb7e 100644\n--- a/libs/agno/agno/run/team.py\n+++ b/libs/agno/agno/run/team.py\n@@ -81,7 +81,7 @@ class TeamRunResponse:\n                 _dict[\"citations\"] = self.citations\n \n         if self.content and isinstance(self.content, BaseModel):\n-            _dict[\"content\"] = self.content.model_dump(exclude_none=True)\n+            _dict[\"content\"] = self.content.model_dump(exclude_none=True, mode=\"json\")\n \n         if self.tools is not None:\n             _dict[\"tools\"] = []\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/team/team.py",
            "diff": "diff --git a/libs/agno/agno/team/team.py b/libs/agno/agno/team/team.py\nindex c554c4308..1eeef1281 100644\n--- a/libs/agno/agno/team/team.py\n+++ b/libs/agno/agno/team/team.py\n@@ -209,8 +209,10 @@ class Team:\n     add_session_summary_references: Optional[bool] = None\n \n     # --- Team History ---\n-    # If True, enable the team history\n+    # If True, enable the team history (Deprecated in favor of add_history_to_messages)\n     enable_team_history: bool = False\n+    # add_history_to_messages=true adds messages from the chat history to the messages list sent to the Model.\n+    add_history_to_messages: bool = False\n     # Deprecated in favor of num_history_runs: Number of interactions from history\n     num_of_interactions_from_history: Optional[int] = None\n     # Number of historical runs to include in the messages\n@@ -287,6 +289,7 @@ class Team:\n         enable_session_summaries: bool = False,\n         add_session_summary_references: Optional[bool] = None,\n         enable_team_history: bool = False,\n+        add_history_to_messages: bool = False,\n         num_of_interactions_from_history: Optional[int] = None,\n         num_history_runs: int = 3,\n         storage: Optional[Storage] = None,\n@@ -358,6 +361,7 @@ class Team:\n         self.add_session_summary_references = add_session_summary_references\n \n         self.enable_team_history = enable_team_history\n+        self.add_history_to_messages = add_history_to_messages\n         self.num_of_interactions_from_history = num_of_interactions_from_history\n         self.num_history_runs = num_history_runs\n \n@@ -4722,7 +4726,7 @@ class Team:\n             run_messages.messages.append(system_message)\n \n         # 2. Add history to run_messages\n-        if self.enable_team_history:\n+        if self.enable_team_history or self.add_history_to_messages:\n             from copy import deepcopy\n \n             history = []\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/crawl4ai.py",
            "diff": "diff --git a/libs/agno/agno/tools/crawl4ai.py b/libs/agno/agno/tools/crawl4ai.py\nindex 8d1f4e990..687ebdf53 100644\n--- a/libs/agno/agno/tools/crawl4ai.py\n+++ b/libs/agno/agno/tools/crawl4ai.py\n@@ -1,10 +1,11 @@\n import asyncio\n-from typing import Any, List, Optional\n+from typing import Any, Dict, List, Optional, Union\n \n from agno.tools import Toolkit\n+from agno.utils.log import log_debug, log_warning\n \n try:\n-    from crawl4ai import AsyncWebCrawler, CacheMode\n+    from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n except ImportError:\n     raise ImportError(\"`crawl4ai` not installed. Please install using `pip install crawl4ai`\")\n \n@@ -12,54 +13,140 @@ except ImportError:\n class Crawl4aiTools(Toolkit):\n     def __init__(\n         self,\n-        max_length: Optional[int] = 1000,\n+        max_length: Optional[int] = 5000,\n+        timeout: int = 60,\n+        use_pruning: bool = False,\n+        pruning_threshold: float = 0.48,\n+        bm25_threshold: float = 1.0,\n+        headless: bool = True,\n+        wait_until: str = \"domcontentloaded\",\n         **kwargs,\n     ):\n+        super().__init__(name=\"crawl4ai_tools\", tools=[self.crawl], **kwargs)\n         self.max_length = max_length\n-\n-        tools: List[Any] = []\n-        tools.append(self.web_crawler)\n-\n-        # Call superclass with tools list\n-        super().__init__(name=\"crawl4ai_tools\", tools=tools, **kwargs)\n-\n-    def web_crawler(self, url: str, max_length: Optional[int] = None) -> str:\n+        self.timeout = timeout\n+        self.use_pruning = use_pruning\n+        self.pruning_threshold = pruning_threshold\n+        self.bm25_threshold = bm25_threshold\n+        self.wait_until = wait_until\n+        self.headless = headless\n+\n+    def _build_config(self, search_query: Optional[str] = None) -> Dict[str, Any]:\n+        \"\"\"Build CrawlerRunConfig parameters from toolkit settings.\"\"\"\n+        config_params = {\n+            \"page_timeout\": self.timeout * 1000,  # Convert to milliseconds\n+            \"wait_until\": self.wait_until,\n+            \"cache_mode\": \"bypass\",  # Don't use cache for fresh results\n+            \"verbose\": False,\n+        }\n+\n+        # Handle content filtering\n+        if self.use_pruning or search_query:\n+            try:\n+                from crawl4ai.content_filter_strategy import BM25ContentFilter, PruningContentFilter\n+                from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n+\n+                if search_query:\n+                    # Use BM25 for query-specific extraction\n+                    content_filter = BM25ContentFilter(user_query=search_query, bm25_threshold=self.bm25_threshold)\n+                    log_debug(f\"Using BM25ContentFilter for query: {search_query}\")\n+                else:\n+                    # Use pruning for general cleanup\n+                    content_filter = PruningContentFilter(\n+                        threshold=self.pruning_threshold, threshold_type=\"fixed\", min_word_threshold=2\n+                    )\n+                    log_debug(\"Using PruningContentFilter for general cleanup\")\n+\n+                config_params[\"markdown_generator\"] = DefaultMarkdownGenerator(content_filter=content_filter)\n+                log_debug(\"Using DefaultMarkdownGenerator with content_filter\")\n+            except ImportError:\n+                # If advanced features not available, continue without them\n+                log_warning(\"crawl4ai.content_filter_strategy or crawl4ai.markdown_generation_strategy not installed\")\n+                pass\n+\n+        return config_params\n+\n+    def crawl(self, url: Union[str, List[str]], search_query: Optional[str] = None) -> Union[str, Dict[str, str]]:\n         \"\"\"\n-        Crawls a website using crawl4ai's WebCrawler.\n+        Crawl URLs and extract their text content.\n \n-        :param url: The URL to crawl.\n-        :param max_length: The maximum length of the result.\n+        Args:\n+            url: Single URL string or list of URLs to crawl\n+            search_query: Optional query string to filter content using BM25 algorithm\n \n-        :return: The results of the crawling.\n+        Returns:\n+            The extracted text content from the URL(s)\n         \"\"\"\n-        if url is None:\n-            return \"No URL provided\"\n-\n-        # Run the async crawler function synchronously\n-        return asyncio.run(self._async_web_crawler(url, max_length))\n-\n-    async def _async_web_crawler(self, url: str, max_length: Optional[int] = None) -> str:\n-        \"\"\"\n-        Asynchronous method to crawl a website using AsyncWebCrawler.\n-\n-        :param url: The URL to crawl.\n-\n-        :return: The results of the crawling as a markdown string, or None if no result.\n-        \"\"\"\n-\n-        async with AsyncWebCrawler(thread_safe=True) as crawler:\n-            result = await crawler.arun(url=url, cache_mode=CacheMode.BYPASS)\n-\n-            # Determine the length to use\n-            length = self.max_length or max_length\n-            if not result.markdown:\n-                return \"No result\"\n-\n-            # Remove spaces and truncate if length is specified\n-            if length:\n-                result = result.markdown[:length]\n-                result = result.replace(\" \", \"\")\n-                return result\n-\n-            result = result.markdown.replace(\" \", \"\")\n-        return result\n+        if not url:\n+            return \"Error: No URL provided\"\n+\n+        # Handle single URL\n+        if isinstance(url, str):\n+            return asyncio.run(self._async_crawl(url, search_query))\n+\n+        # Handle multiple URLs\n+        results = {}\n+        for single_url in url:\n+            results[single_url] = asyncio.run(self._async_crawl(single_url, search_query))\n+        return results\n+\n+    async def _async_crawl(self, url: str, search_query: Optional[str] = None) -> str:\n+        \"\"\"Crawl a single URL and extract content.\"\"\"\n+        try:\n+            # Use BrowserConfig to suppress crawl4ai logs\n+            browser_config = BrowserConfig(\n+                headless=self.headless,\n+                verbose=False,\n+            )\n+\n+            async with AsyncWebCrawler(config=browser_config) as crawler:\n+                # Build configuration from parameters\n+                config_params = self._build_config(search_query)\n+\n+                config = CrawlerRunConfig(**config_params)\n+                log_debug(f\"Crawling {url} with config: {config}\")\n+                result = await crawler.arun(url=url, config=config)\n+\n+                # Process the result\n+                if not result:\n+                    return \"Error: No content found\"\n+\n+                log_debug(f\"Result attributes: {dir(result)}\")\n+                log_debug(f\"Result success: {getattr(result, 'success', 'N/A')}\")\n+\n+                # Try to get markdown content\n+                content = \"\"\n+                if hasattr(result, \"fit_markdown\") and result.fit_markdown:\n+                    content = result.fit_markdown\n+                    log_debug(\"Using fit_markdown\")\n+                elif hasattr(result, \"markdown\") and result.markdown:\n+                    if hasattr(result.markdown, \"raw_markdown\"):\n+                        content = result.markdown.raw_markdown\n+                        log_debug(\"Using markdown.raw_markdown\")\n+                    else:\n+                        content = str(result.markdown)\n+                        log_debug(\"Using str(markdown)\")\n+                else:\n+                    # Try to get any text content\n+                    if hasattr(result, \"text\"):\n+                        content = result.text\n+                        log_debug(\"Using text attribute\")\n+                    elif hasattr(result, \"html\"):\n+                        log_warning(\"Only HTML available, no markdown extracted\")\n+                        return \"Error: Could not extract markdown from page\"\n+\n+                if not content:\n+                    log_warning(f\"No content extracted. Result type: {type(result)}\")\n+                    return \"Error: No readable content extracted\"\n+\n+                log_debug(f\"Extracted content length: {len(content)}\")\n+\n+                # Truncate if needed\n+                if self.max_length and len(content) > self.max_length:\n+                    content = content[: self.max_length] + \"...\"\n+\n+                return content\n+\n+        except Exception as e:\n+            log_warning(f\"Exception during crawl: {str(e)}\")\n+            return f\"Error crawling {url}: {str(e)}\"\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/daytona.py",
            "diff": "diff --git a/libs/agno/agno/tools/daytona.py b/libs/agno/agno/tools/daytona.py\nnew file mode 100644\nindex 000000000..e754d237a\n--- /dev/null\n+++ b/libs/agno/agno/tools/daytona.py\n@@ -0,0 +1,130 @@\n+import json\n+from os import getenv\n+from typing import Any, Dict, List, Optional\n+\n+from agno.tools import Toolkit\n+from agno.utils.code_execution import prepare_python_code\n+from agno.utils.log import logger\n+\n+try:\n+    from daytona_sdk import (\n+        Daytona,\n+        CodeLanguage,\n+        CreateSandboxParams,\n+        DaytonaConfig,\n+        Sandbox,\n+        SandboxTargetRegion,\n+    )\n+    from daytona_sdk.common.process import ExecuteResponse\n+except ImportError:\n+    raise ImportError(\"`daytona_sdk` not installed. Please install using `pip install daytona_sdk`\")\n+\n+\n+class DaytonaTools(Toolkit):\n+    def __init__(\n+        self,\n+        api_key: Optional[str] = None,\n+        api_url: Optional[str] = None,\n+        sandbox_language: Optional[CodeLanguage] = None,\n+        sandbox_target_region: Optional[SandboxTargetRegion] = None,\n+        sandbox_os: Optional[str] = None,\n+        sandbox_os_user: Optional[str] = None,\n+        sandbox_env_vars: Optional[Dict[str, str]] = None,\n+        sandbox_labels: Optional[Dict[str, str]] = None,\n+        sandbox_public: Optional[bool] = None,\n+        sandbox_auto_stop_interval: Optional[int] = None,\n+        organization_id: Optional[str] = None,\n+        timeout: int = 300,  # 5 minutes default timeout\n+        **kwargs,\n+    ):\n+        \"\"\"Daytona Toolkit for remote code execution.\n+\n+        Args:\n+            api_key: Daytona API key (defaults to DAYTONA_API_KEY environment variable)\n+            api_url: Daytona API URL (defaults to DAYTONA_API_URL environment variable)\n+            sandbox_language: The programming language to run on the sandbox (default: python)\n+            sandbox_target_region: The region where the sandbox will be created\n+            sandbox_os: The operating system to run on the sandbox (default: ubuntu)\n+            sandbox_os_user: The user to run the sandbox as (default: root)\n+            sandbox_env_vars: The environment variables to set in the sandbox\n+            sandbox_labels: The labels to set in the sandbox\n+            sandbox_public: Whether the sandbox should be public\n+            sandbox_auto_stop_interval: The interval in minutes after which the sandbox will be stopped if no activity occurs\n+            organization_id: The contextual Daytona organization ID for the sandbox\n+            timeout: Timeout in seconds for communication with the sandbox (default: 5 minutes)\n+        \"\"\"\n+\n+        self.api_key = api_key or getenv(\"DAYTONA_API_KEY\")\n+        if not self.api_key:\n+            raise ValueError(\"DAYTONA_API_KEY not set. Please set the DAYTONA_API_KEY environment variable.\")\n+\n+        self.api_url = api_url or getenv(\"DAYTONA_API_URL\")\n+        self.sandbox_target_region = sandbox_target_region\n+        self.organization_id = organization_id\n+        self.sandbox_language = sandbox_language\n+        self.sandbox_os = sandbox_os\n+        self.sandbox_os_user = sandbox_os_user\n+        self.sandbox_env_vars = sandbox_env_vars\n+        self.sandbox_labels = sandbox_labels\n+        self.sandbox_public = sandbox_public\n+        self.sandbox_auto_stop_interval = sandbox_auto_stop_interval\n+        self.timeout = timeout\n+\n+        self.config = DaytonaConfig(\n+            api_key=self.api_key,\n+            api_url=self.api_url,\n+            target=self.sandbox_target_region,\n+            organization_id=self.organization_id,\n+        )  # type: ignore\n+\n+        try:\n+            params = CreateSandboxParams(\n+                language=self.sandbox_language,\n+                os_user=self.sandbox_os_user,\n+                env_vars=self.sandbox_env_vars,\n+                labels=self.sandbox_labels,\n+                public=self.sandbox_public,\n+                auto_stop_interval=self.sandbox_auto_stop_interval,\n+                timeout=self.timeout,\n+            )\n+            daytona = Daytona(self.config)\n+            self.sandbox: Sandbox = daytona.create(params)\n+        except Exception as e:\n+            logger.error(f\"Error creating Daytona sandbox: {e}\")\n+            raise e\n+\n+        # Last execution result for reference\n+        self.last_execution: Optional[ExecuteResponse] = None\n+\n+        tools: List[Any] = []\n+\n+        if self.sandbox_language == CodeLanguage.PYTHON:\n+            tools.append(self.run_python_code)\n+        else:\n+            tools.append(self.run_code)\n+\n+        super().__init__(name=\"daytona_tools\", tools=tools, **kwargs)\n+\n+    def run_python_code(self, code: str) -> str:\n+        \"\"\"Prepare and run Python code in the contextual Daytona sandbox.\"\"\"\n+        try:\n+            executable_code = prepare_python_code(code)\n+\n+            execution = self.sandbox.process.code_run(executable_code)\n+\n+            self.last_execution = execution\n+            self.result = execution.result\n+            return self.result\n+        except Exception as e:\n+            return json.dumps({\"status\": \"error\", \"message\": f\"Error executing code: {str(e)}\"})\n+\n+    def run_code(self, code: str) -> str:\n+        \"\"\"General function to run non-Python code in the contextual Daytona sandbox.\"\"\"\n+        try:\n+            response = self.sandbox.process.code_run(code)\n+\n+            self.last_execution = response\n+            self.result = response.result\n+            return self.result\n+        except Exception as e:\n+            return json.dumps({\"status\": \"error\", \"message\": f\"Error executing code: {str(e)}\"})\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/e2b.py",
            "diff": "diff --git a/libs/agno/agno/tools/e2b.py b/libs/agno/agno/tools/e2b.py\nindex 3809c9217..184979b55 100644\n--- a/libs/agno/agno/tools/e2b.py\n+++ b/libs/agno/agno/tools/e2b.py\n@@ -1,6 +1,5 @@\n import base64\n import json\n-import re\n import tempfile\n import time\n from os import fdopen, getenv\n@@ -12,6 +11,7 @@ from agno.agent import Agent\n from agno.media import ImageArtifact\n from agno.team.team import Team\n from agno.tools import Toolkit\n+from agno.utils.code_execution import prepare_python_code\n from agno.utils.log import logger\n \n try:\n@@ -102,16 +102,9 @@ class E2BTools(Toolkit):\n             str: Execution results or error message\n         \"\"\"\n         try:\n-            # Execute the code in the sandbox using the correct method name for Python SDK\n-            # Fix common Python keywords that require capitalized first letters\n-            # This is necessary because users or LLMs sometimes use lowercase versions\n-            # of Python keywords that should be capitalized (True, False, None)\n-            python_keywords = {\"true\": \"True\", \"false\": \"False\", \"none\": \"None\"}\n+            executable_code = prepare_python_code(code)\n \n-            for lowercase, capitalized in python_keywords.items():\n-                code = re.sub(rf\"\\b({lowercase})\\b\", capitalized, code)\n-\n-            execution = self.sandbox.run_code(code)\n+            execution = self.sandbox.run_code(executable_code)\n             self.last_execution = execution\n \n             # Check for errors\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/gmail.py",
            "diff": "diff --git a/libs/agno/agno/tools/gmail.py b/libs/agno/agno/tools/gmail.py\nindex e4bf3613a..0a495b00c 100644\n--- a/libs/agno/agno/tools/gmail.py\n+++ b/libs/agno/agno/tools/gmail.py\n@@ -27,13 +27,16 @@ How to Get These Credentials:\n      * Client Secret (GOOGLE_CLIENT_SECRET)\n    - The Project ID (GOOGLE_PROJECT_ID) is visible in the project dropdown at the top of the page\n \n-5. Set up environment variables:\n+5. Add auth redirect URI:\n+   - Go to https://console.cloud.google.com/auth/clients and add the redirect URI as http://127.0.0.1/\n+\n+6. Set up environment variables:\n    Create a .envrc file in your project root with:\n    ```\n    export GOOGLE_CLIENT_ID=your_client_id_here\n    export GOOGLE_CLIENT_SECRET=your_client_secret_here\n    export GOOGLE_PROJECT_ID=your_project_id_here\n-   export GOOGLE_REDIRECT_URI=http://localhost  # Default value\n+   export GOOGLE_REDIRECT_URI=http://127.0.0.1/  # Default value\n    ```\n \n Note: The first time you run the application, it will open a browser window for OAuth authentication.\n@@ -41,16 +44,19 @@ A token.json file will be created to store the authentication credentials for fu\n \"\"\"\n \n import base64\n+import mimetypes\n import re\n from datetime import datetime, timedelta\n from functools import wraps\n from os import getenv\n from pathlib import Path\n-from typing import Any, List, Optional\n+from typing import Any, List, Optional, Union\n \n from agno.tools import Toolkit\n \n try:\n+    from email.mime.application import MIMEApplication\n+    from email.mime.multipart import MIMEMultipart\n     from email.mime.text import MIMEText\n \n     from google.auth.transport.requests import Request\n@@ -397,7 +403,14 @@ class GmailTools(Toolkit):\n             return f\"Unexpected error retrieving emails by date: {type(error).__name__}: {error}\"\n \n     @authenticate\n-    def create_draft_email(self, to: str, subject: str, body: str, cc: Optional[str] = None) -> str:\n+    def create_draft_email(\n+        self,\n+        to: str,\n+        subject: str,\n+        body: str,\n+        cc: Optional[str] = None,\n+        attachments: Optional[Union[str, List[str]]] = None,\n+    ) -> str:\n         \"\"\"\n         Create and save a draft email. to and cc are comma separated string of email ids\n         Args:\n@@ -405,18 +418,42 @@ class GmailTools(Toolkit):\n             subject (str): Email subject\n             body (str): Email body content\n             cc (Optional[str]): Comma separated string of CC email addresses (optional)\n+            attachments (Optional[Union[str, List[str]]]): File path(s) for attachments (optional)\n \n         Returns:\n             str: Stringified dictionary containing draft email details including id\n         \"\"\"\n         self._validate_email_params(to, subject, body)\n-        message = self._create_message(to.split(\",\"), subject, body, cc.split(\",\") if cc else None)\n+\n+        # Process attachments\n+        attachment_files = []\n+        if attachments:\n+            if isinstance(attachments, str):\n+                attachment_files = [attachments]\n+            else:\n+                attachment_files = attachments\n+\n+            # Validate attachment files\n+            for file_path in attachment_files:\n+                if not Path(file_path).exists():\n+                    raise ValueError(f\"Attachment file not found: {file_path}\")\n+\n+        message = self._create_message(\n+            to.split(\",\"), subject, body, cc.split(\",\") if cc else None, attachments=attachment_files\n+        )\n         draft = {\"message\": message}\n         draft = self.service.users().drafts().create(userId=\"me\", body=draft).execute()  # type: ignore\n         return str(draft)\n \n     @authenticate\n-    def send_email(self, to: str, subject: str, body: str, cc: Optional[str] = None) -> str:\n+    def send_email(\n+        self,\n+        to: str,\n+        subject: str,\n+        body: str,\n+        cc: Optional[str] = None,\n+        attachments: Optional[Union[str, List[str]]] = None,\n+    ) -> str:\n         \"\"\"\n         Send an email immediately. to and cc are comma separated string of email ids\n         Args:\n@@ -424,19 +461,43 @@ class GmailTools(Toolkit):\n             subject (str): Email subject\n             body (str): Email body content\n             cc (Optional[str]): Comma separated string of CC email addresses (optional)\n+            attachments (Optional[Union[str, List[str]]]): File path(s) for attachments (optional)\n \n         Returns:\n             str: Stringified dictionary containing sent email details including id\n         \"\"\"\n         self._validate_email_params(to, subject, body)\n+\n+        # Process attachments\n+        attachment_files = []\n+        if attachments:\n+            if isinstance(attachments, str):\n+                attachment_files = [attachments]\n+            else:\n+                attachment_files = attachments\n+\n+            # Validate attachment files\n+            for file_path in attachment_files:\n+                if not Path(file_path).exists():\n+                    raise ValueError(f\"Attachment file not found: {file_path}\")\n+\n         body = body.replace(\"\\n\", \"<br>\")\n-        message = self._create_message(to.split(\",\"), subject, body, cc.split(\",\") if cc else None)\n+        message = self._create_message(\n+            to.split(\",\"), subject, body, cc.split(\",\") if cc else None, attachments=attachment_files\n+        )\n         message = self.service.users().messages().send(userId=\"me\", body=message).execute()  # type: ignore\n         return str(message)\n \n     @authenticate\n     def send_email_reply(\n-        self, thread_id: str, message_id: str, to: str, subject: str, body: str, cc: Optional[str] = None\n+        self,\n+        thread_id: str,\n+        message_id: str,\n+        to: str,\n+        subject: str,\n+        body: str,\n+        cc: Optional[str] = None,\n+        attachments: Optional[Union[str, List[str]]] = None,\n     ) -> str:\n         \"\"\"\n         Respond to an existing email thread.\n@@ -448,6 +509,7 @@ class GmailTools(Toolkit):\n             subject (str): Email subject (prefixed with \"Re:\" if not already).\n             body (str): Email body content.\n             cc (Optional[str]): Comma-separated CC email addresses (optional).\n+            attachments (Optional[Union[str, List[str]]]): File path(s) for attachments (optional)\n \n         Returns:\n             str: Stringified dictionary containing sent email details including id.\n@@ -458,9 +520,28 @@ class GmailTools(Toolkit):\n         if not subject.lower().startswith(\"re:\"):\n             subject = f\"Re: {subject}\"\n \n+        # Process attachments\n+        attachment_files = []\n+        if attachments:\n+            if isinstance(attachments, str):\n+                attachment_files = [attachments]\n+            else:\n+                attachment_files = attachments\n+\n+            # Validate attachment files\n+            for file_path in attachment_files:\n+                if not Path(file_path).exists():\n+                    raise ValueError(f\"Attachment file not found: {file_path}\")\n+\n         body = body.replace(\"\\n\", \"<br>\")\n         message = self._create_message(\n-            to.split(\",\"), subject, body, cc.split(\",\") if cc else None, thread_id, message_id\n+            to.split(\",\"),\n+            subject,\n+            body,\n+            cc.split(\",\") if cc else None,\n+            thread_id,\n+            message_id,\n+            attachments=attachment_files,\n         )\n         message = self.service.users().messages().send(userId=\"me\", body=message).execute()  # type: ignore\n         return str(message)\n@@ -511,9 +592,43 @@ class GmailTools(Toolkit):\n         cc: Optional[List[str]] = None,\n         thread_id: Optional[str] = None,\n         message_id: Optional[str] = None,\n+        attachments: Optional[List[str]] = None,\n     ) -> dict:\n         body = body.replace(\"\\\\n\", \"\\n\")\n-        message = MIMEText(body, \"html\")\n+\n+        # Create multipart message if attachments exist, otherwise simple text message\n+        message: Union[MIMEMultipart, MIMEText]\n+        if attachments:\n+            message = MIMEMultipart()\n+\n+            # Add the text body\n+            text_part = MIMEText(body, \"html\")\n+            message.attach(text_part)\n+\n+            # Add attachments\n+            for file_path in attachments:\n+                file_path_obj = Path(file_path)\n+                if not file_path_obj.exists():\n+                    continue\n+\n+                # Guess the content type based on the file extension\n+                content_type, encoding = mimetypes.guess_type(file_path)\n+                if content_type is None or encoding is not None:\n+                    content_type = \"application/octet-stream\"\n+\n+                main_type, sub_type = content_type.split(\"/\", 1)\n+\n+                # Read file and create attachment\n+                with open(file_path, \"rb\") as file:\n+                    attachment_data = file.read()\n+\n+                attachment = MIMEApplication(attachment_data, _subtype=sub_type)\n+                attachment.add_header(\"Content-Disposition\", \"attachment\", filename=file_path_obj.name)\n+                message.attach(attachment)\n+        else:\n+            message = MIMEText(body, \"html\")\n+\n+        # Set headers\n         message[\"to\"] = \", \".join(to)\n         message[\"from\"] = \"me\"\n         message[\"subject\"] = subject\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/serperapi.py",
            "diff": "diff --git a/libs/agno/agno/tools/serperapi.py b/libs/agno/agno/tools/serperapi.py\nnew file mode 100644\nindex 000000000..eeae65337\n--- /dev/null\n+++ b/libs/agno/agno/tools/serperapi.py\n@@ -0,0 +1,80 @@\n+import json\n+from os import getenv\n+from typing import Optional\n+\n+import requests\n+\n+from agno.tools import Toolkit\n+from agno.utils.log import log_debug\n+\n+\n+class SerperApiTools(Toolkit):\n+    \"\"\"\n+    A class to interact with the Serper API for Google search functionality. Go to serper.dev for more information.\n+\n+    Attributes:\n+        api_key (str): The API key for accessing the Serper API.\n+        location (str): The Google search location to be used for the search (default is \"us\").\n+        num_results (int): The number of search results to return (default is 10).\n+\n+    Methods:\n+        search_google(query: str, gl: Optional[str] = None) -> str:\n+            Performs a Google search using the Serper API and returns the results.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        api_key: Optional[str] = None,\n+        location: str = \"us\",\n+        num_results: int = 10,\n+    ):\n+        \"\"\"\n+        Initializes the SerperApiTools instance.\n+\n+        Args:\n+            api_key (str, optional): The Serper API key. If not provided, will be fetched from the environment variable \"SERPER_API_KEY\".\n+            gl (str, optional): The Google location code for search results (default is \"us\").\n+            num_results (int, optional): The number of search results to retrieve (default is 10).\n+        \"\"\"\n+        super().__init__(name=\"serper_api_tools\")\n+\n+        self.api_key = api_key or getenv(\"SERPER_API_KEY\")\n+        if not self.api_key:\n+            log_debug(\"No Serper API key provided\")\n+\n+        self.location = location\n+        self.num_results = num_results\n+        self.register(self.search_google)\n+\n+    def search_google(self, query: str, location: Optional[str] = None) -> str:\n+        \"\"\"\n+        Searches Google for the provided query using the Serper API.\n+\n+        Args:\n+            query (str): The search query to search for on Google.\n+            location (str, optional): The Google location code for search results. If not provided, the default class attribute is used.\n+\n+        Returns:\n+            str: The search results in JSON format or an error message if the search fails.\n+        \"\"\"\n+        try:\n+            if not self.api_key:\n+                return \"Please provide an API key\"\n+            if not query:\n+                return \"Please provide a query to search for\"\n+\n+            log_debug(f\"Searching Google for: {query}\")\n+\n+            url = \"https://google.serper.dev/search\"\n+            headers = {\"X-API-KEY\": self.api_key, \"Content-Type\": \"application/json\"}\n+            # Use the gl parameter from the method if provided, otherwise use the class attribute\n+            search_gl = location if location is not None else self.location\n+            params = {\"q\": query, \"num\": self.num_results, \"gl\": search_gl}\n+            payload = json.dumps(params)\n+            response = requests.request(\"POST\", url, headers=headers, data=payload)\n+            results = response.text\n+\n+            return results\n+\n+        except Exception as e:\n+            return f\"Error searching for the query {query}: {e}\"\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/webtools.py",
            "diff": "diff --git a/libs/agno/agno/tools/webtools.py b/libs/agno/agno/tools/webtools.py\nnew file mode 100644\nindex 000000000..e72244d9c\n--- /dev/null\n+++ b/libs/agno/agno/tools/webtools.py\n@@ -0,0 +1,37 @@\n+import httpx\n+\n+from agno.tools import Toolkit\n+from agno.utils.log import logger\n+\n+\n+class WebTools(Toolkit):\n+    \"\"\"\n+    A toolkit for working with web-related tools.\n+    \"\"\"\n+\n+    def __init__(self, retries: int = 3):\n+        super().__init__(name=\"web_tools\")\n+\n+        self.retries = retries\n+\n+        self.register(self.expand_url)\n+\n+    def expand_url(self, url: str) -> str:\n+        \"\"\"\n+        Expands a shortened URL to its final destination using HTTP HEAD requests with retries.\n+\n+        :param url: The URL to expand.\n+\n+        :return: The final destination URL if successful; otherwise, returns the original URL.\n+        \"\"\"\n+        timeout = 5\n+        for attempt in range(1, self.retries + 1):\n+            try:\n+                response = httpx.head(url, follow_redirects=True, timeout=timeout)\n+                final_url = response.url\n+                logger.info(f\"expand_url: {url} expanded to {final_url} on attempt {attempt}\")\n+                return str(final_url)\n+            except Exception as e:\n+                logger.error(f\"Error expanding URL {url} on attempt {attempt}: {e}\")\n+\n+        return url\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/x.py",
            "diff": "diff --git a/libs/agno/agno/tools/x.py b/libs/agno/agno/tools/x.py\nindex 144d9440d..a1d51e0a6 100644\n--- a/libs/agno/agno/tools/x.py\n+++ b/libs/agno/agno/tools/x.py\n@@ -19,6 +19,8 @@ class XTools(Toolkit):\n         consumer_secret: Optional[str] = None,\n         access_token: Optional[str] = None,\n         access_token_secret: Optional[str] = None,\n+        include_post_metrics: bool = False,\n+        wait_on_rate_limit: bool = False,\n         **kwargs,\n     ):\n         \"\"\"\n@@ -30,20 +32,24 @@ class XTools(Toolkit):\n             consumer_secret Optional[str]: The consumer secret for Twitter API.\n             access_token Optional[str]: The access token for Twitter API.\n             access_token_secret Optional[str]: The access token secret for Twitter API.\n+            include_post_metrics Optional[bool]: Whether to include post metrics in the search results.\n+            wait_on_rate_limit Optional[bool]: Whether to wait on rate limit.\n         \"\"\"\n         self.bearer_token = bearer_token or os.getenv(\"X_BEARER_TOKEN\")\n         self.consumer_key = consumer_key or os.getenv(\"X_CONSUMER_KEY\")\n         self.consumer_secret = consumer_secret or os.getenv(\"X_CONSUMER_SECRET\")\n         self.access_token = access_token or os.getenv(\"X_ACCESS_TOKEN\")\n         self.access_token_secret = access_token_secret or os.getenv(\"X_ACCESS_TOKEN_SECRET\")\n-\n+        self.wait_on_rate_limit = wait_on_rate_limit\n         self.client = tweepy.Client(\n             bearer_token=self.bearer_token,\n             consumer_key=self.consumer_key,\n             consumer_secret=self.consumer_secret,\n             access_token=self.access_token,\n             access_token_secret=self.access_token_secret,\n+            wait_on_rate_limit=self.wait_on_rate_limit,\n         )\n+        self.include_post_metrics = include_post_metrics\n \n         tools: List[Any] = []\n         tools.append(self.create_post)\n@@ -51,6 +57,7 @@ class XTools(Toolkit):\n         tools.append(self.send_dm)\n         tools.append(self.get_user_info)\n         tools.append(self.get_home_timeline)\n+        tools.append(self.search_posts)\n \n         super().__init__(name=\"x\", tools=tools, **kwargs)\n \n@@ -238,3 +245,90 @@ class XTools(Toolkit):\n         except tweepy.TweepyException as e:\n             logger.error(f\"Error fetching home timeline: {e}\")\n             return json.dumps({\"error\": str(e)})\n+\n+    def search_posts(self, query: str, max_results: int = 10) -> str:\n+        \"\"\"\n+        Search for tweets based on a search query.\n+\n+        Args:\n+            query (str): The search query.\n+            max_results (int): The maximum number of posts to retrieve.\n+\n+        Returns:\n+            A list of posts matching the search query\n+        \"\"\"\n+        try:\n+            max_results = max(10, min(max_results, 100))  # range 10 - 100\n+\n+            log_debug(f\"Searching for posts with query: {query}, bounded max results: {max_results}\")\n+            results = self.client.search_recent_tweets(\n+                query=query,\n+                max_results=max_results,\n+                tweet_fields=[\n+                    \"author_id\",\n+                    \"created_at\",\n+                    \"id\",\n+                    \"public_metrics\",\n+                    \"text\",\n+                ],\n+                user_fields=[\"name\", \"username\", \"verified\"],\n+            )\n+\n+            users_data = {}\n+            if hasattr(results, \"includes\") and \"users\" in results.includes:\n+                for user in results.includes[\"users\"]:\n+                    users_data[user.id] = {\n+                        \"id\": user.id,\n+                        \"name\": user.name,\n+                        \"username\": user.username,\n+                        \"verified\": getattr(user, \"verified\", False),\n+                    }\n+            tweets = []\n+\n+            if results.data:\n+                for tweet in results.data:\n+                    author_info = users_data.get(\n+                        tweet.author_id, {\"id\": tweet.author_id, \"name\": \"Unknown\", \"username\": \"unknown\"}\n+                    )\n+\n+                    post_url = f\"https://x.com/{author_info.get('username', 'unknown')}/status/{tweet.id}\"\n+\n+                    post_data = {\n+                        \"id\": tweet.id,\n+                        \"text\": tweet.text,\n+                        \"created_at\": tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n+                        if hasattr(tweet, \"created_at\")\n+                        else None,\n+                        \"author\": author_info,\n+                        \"url\": post_url,\n+                    }\n+                    if self.include_post_metrics:\n+                        post_data[\"metrics\"] = {\n+                            \"retweet_count\": tweet.public_metrics.get(\"retweet_count\", 0)\n+                            if hasattr(tweet, \"public_metrics\")\n+                            else 0,\n+                            \"reply_count\": tweet.public_metrics.get(\"reply_count\", 0)\n+                            if hasattr(tweet, \"public_metrics\")\n+                            else 0,\n+                            \"like_count\": tweet.public_metrics.get(\"like_count\", 0)\n+                            if hasattr(tweet, \"public_metrics\")\n+                            else 0,\n+                            \"quote_count\": tweet.public_metrics.get(\"quote_count\", 0)\n+                            if hasattr(tweet, \"public_metrics\")\n+                            else 0,\n+                        }\n+                    tweets.append(post_data)\n+\n+                log_info(f\"Successfully found {len(tweets)} posts for query: {query}\")\n+                result = {\"query\": query, \"count\": len(tweets), \"posts\": tweets}\n+            else:\n+                log_info(f\"No posts found for query: {query}\")\n+                result = {}\n+            return json.dumps(result, indent=2)\n+\n+        except tweepy.TweepyException as e:\n+            logger.error(f\"Error searching posts: {e}\")\n+            return json.dumps({\"error\": str(e), \"query\": query})\n+        except Exception as e:\n+            logger.error(f\"Unexpected error searching posts: {e}\")\n+            return json.dumps({\"error\": f\"An unexpected error occurred: {str(e)}\", \"query\": query})\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/tools/zep.py",
            "diff": "diff --git a/libs/agno/agno/tools/zep.py b/libs/agno/agno/tools/zep.py\nindex deb691154..a26bc99bf 100644\n--- a/libs/agno/agno/tools/zep.py\n+++ b/libs/agno/agno/tools/zep.py\n@@ -7,10 +7,14 @@ from agno.tools import Toolkit\n from agno.utils.log import log_debug, log_error, log_warning\n \n try:\n-    from zep_cloud import BadRequestError, NotFoundError\n+    from zep_cloud import (\n+        BadRequestError,\n+        NotFoundError,\n+    )\n+    from zep_cloud import (\n+        Message as ZepMessage,\n+    )\n     from zep_cloud.client import AsyncZep, Zep\n-    from zep_cloud.types import MemorySearchResult\n-    from zep_cloud.types import Message as ZepMessage\n except ImportError:\n     raise ImportError(\"`zep-cloud` package not found. Please install it with `pip install zep-cloud`\")\n \n@@ -23,7 +27,7 @@ DEFAULT_INSTRUCTIONS = dedent(\n \n     Guidelines:\n     - Use `add_zep_message` tool to add relevant messages to the users memories. You can use this tool multiple times to add multiple messages.\n-    - Use `get_zep_memory` tool to get the memory for the current Zep session for additional context. This will give you a summary of the users memories.\n+    - Use `get_zep_memory` tool to get the memory for the current Zep session for additional context. This will give you a entire context of the user's memories with relevant facts.\n     - Use `search_zep_memory` tool to search the Zep user memories for relevant facts. This will give you a list of relevant facts.\n     \"\"\"\n )\n@@ -112,6 +116,13 @@ class ZepTools(Toolkit):\n                         self.zep_client = None  # Reset client on failure\n                         return False  # Initialization failed\n \n+            # Create session associated with the user\n+            try:\n+                self.zep_client.memory.add_session(session_id=self.session_id, user_id=self.user_id)\n+                log_debug(f\"Created session {self.session_id} for user {self.user_id}\")\n+            except Exception as e:\n+                log_debug(f\"Session may already exist: {e}\")\n+\n             self._initialized = True\n             return True\n \n@@ -160,7 +171,7 @@ class ZepTools(Toolkit):\n         \"\"\"\n         Retrieves the memory for the current Zep session.\n         Args:\n-            memory_type: The type of memory to retrieve ('context', 'summary', 'messages').\n+            memory_type: The type of memory to retrieve ('context', 'messages', 'relevant_facts').\n         Returns:\n             The requested memory content as a string, or an error string.\n         \"\"\"\n@@ -175,16 +186,16 @@ class ZepTools(Toolkit):\n             if memory_type == \"context\":\n                 # Ensure context is a string\n                 return memory_data.context or \"No context available.\"\n-            elif memory_type == \"summary\":\n-                # Ensure summary content is a string, checking both summary and its content\n-                return (\n-                    (memory_data.summary.content or \"Summary content not available.\")\n-                    if memory_data.summary\n-                    else \"No summary available.\"\n-                )\n             elif memory_type == \"messages\":\n                 # Ensure messages string representation is returned\n                 return str(memory_data.messages) if memory_data.messages else \"No messages available.\"\n+            elif memory_type == \"relevant_facts\":\n+                # Return all relevant facts from memory\n+                if memory_data.relevant_facts:\n+                    facts_str = \"\\n\".join([f\"- {fact.fact}\" for fact in memory_data.relevant_facts])\n+                    return f\"Relevant facts:\\n{facts_str}\"\n+                else:\n+                    return \"No relevant facts available.\"\n             else:\n                 warning_msg = f\"Unsupported memory_type requested: {memory_type}. Returning empty string.\"\n                 log_warning(warning_msg)\n@@ -194,59 +205,41 @@ class ZepTools(Toolkit):\n             log_error(f\"Failed to get Zep memory for session {self.session_id}: {e}\")\n             return f\"Error getting memory for session {self.session_id}\"\n \n-    def search_zep_memory(self, query: str, search_scope: str = \"messages\") -> str:\n+    def search_zep_memory(self, query: str, search_scope: str = \"edges\") -> str:\n         \"\"\"\n-        Searches the Zep memory store for relevant messages or summaries associated with the configured user_id.\n+        Searches the Zep knowledge graph for relevant facts or nodes.\n         Args:\n-            query: The search term to find relevant facts.\n-            search_scope: The scope of the search to perform. Can be \"messages\" or \"summary\".\n+            query: The search term to find relevant facts or nodes.\n+            search_scope: The scope of the search to perform. Can be \"edges\" (for facts) or \"nodes\".\n         Returns:\n             A string of the search result\n         \"\"\"\n-        results: List = []\n-        search_result = \"\"\n-        if not self.zep_client or not self.user_id or not self.session_id:\n-            log_error(\"Zep client or user ID or session ID not initialized. Cannot search memory.\")\n-            return \"Error: Zep client/user/session not initialized.\"\n+        # Graph search is built on user_id not on session_id\n+        if not self.zep_client or not self.user_id:\n+            log_error(\"Zep client or user ID not initialized. Cannot search graph.\")\n+            return \"Error: Zep client/user not initialized.\"\n \n         try:\n-            search_response: List[MemorySearchResult] = self.zep_client.memory.search(\n-                text=query, session_id=self.session_id, search_scope=search_scope\n+            search_response = self.zep_client.graph.search(\n+                query=query,\n+                user_id=self.user_id,\n+                scope=search_scope,  # Can be \"edges\" or \"nodes\"\n             )\n-            results = [\n-                {\n-                    \"content\": response.message.content,\n-                    \"created_at\": response.message.created_at,\n-                    \"uuid\": response.message.uuid_,\n-                    \"score\": response.score,\n-                    \"summary\": response.summary,\n-                }\n-                for response in search_response\n-                if response.message is not None\n-            ]\n-            log_debug(f\"Memory search found {len(results)} relevant messages.\")\n-        except Exception as e:\n-            log_error(f\"Failed to search Zep graph memory for user {self.user_id}: {e}\")\n-\n-        if results is not None and results != []:\n-            if search_scope == \"summary\":\n-                search_result = \" \".join(\n-                    [result.get(\"summary\", \"\") for result in results if result.get(\"summary\") is not None]\n-                )\n-                if search_result == \"\":\n-                    return \"No relevant summary found.\"\n-                else:\n-                    return search_result\n+\n+            if search_scope == \"edges\" and search_response.edges:\n+                # Return facts from edges\n+                facts_str = \"\\n\".join([f\"- {edge.fact}\" for edge in search_response.edges])\n+                return f\"Found {len(search_response.edges)} facts:\\n{facts_str}\"\n+            elif search_scope == \"nodes\" and search_response.nodes:\n+                # Return node summaries\n+                nodes_str = \"\\n\".join([f\"- {node.name}: {node.summary}\" for node in search_response.nodes])\n+                return f\"Found {len(search_response.nodes)} nodes:\\n{nodes_str}\"\n             else:\n-                search_result = \" \".join(\n-                    [result.get(\"content\", \"\") for result in results if result.get(\"content\") is not None]\n-                )\n-                if search_result == \"\":\n-                    return \"No relevant content found.\"\n-                else:\n-                    return search_result\n-        else:\n-            return \"No relevant messages found.\"\n+                return f\"No {search_scope} found for query: {query}\"\n+\n+        except Exception as e:\n+            log_error(f\"Failed to search Zep graph for user {self.user_id}: {e}\")\n+            return f\"Error searching graph: {e}\"\n \n \n class ZepAsyncTools(Toolkit):\n@@ -333,6 +326,13 @@ class ZepAsyncTools(Toolkit):\n                         self.zep_client = None  # Reset client on failure\n                         return False  # Initialization failed\n \n+            # Create session associated with the user\n+            try:\n+                await self.zep_client.memory.add_session(session_id=self.session_id, user_id=self.user_id)  # type: ignore\n+                log_debug(f\"Created session {self.session_id} for user {self.user_id}\")\n+            except Exception as e:\n+                log_debug(f\"Session may already exist: {e}\")\n+\n             self._initialized = True\n             return True\n \n@@ -384,7 +384,7 @@ class ZepAsyncTools(Toolkit):\n         \"\"\"\n         Retrieves the memory for the current Zep session.\n         Args:\n-            memory_type: The type of memory to retrieve ('context', 'summary', 'messages').\n+            memory_type: The type of memory to retrieve ('context', 'messages', 'relevant_facts').\n         Returns:\n             The requested memory content as a string, or an error string.\n         \"\"\"\n@@ -401,82 +401,62 @@ class ZepAsyncTools(Toolkit):\n             if memory_type == \"context\":\n                 # Ensure context is a string\n                 return memory_data.context or \"No context available.\"\n-            elif memory_type == \"summary\":\n-                # Ensure summary content is a string, checking both summary and its content\n-                return (\n-                    (memory_data.summary.content or \"Summary content not available.\")\n-                    if memory_data.summary\n-                    else \"No summary available.\"\n-                )\n             elif memory_type == \"messages\":\n                 # Ensure messages string representation is returned\n                 return str(memory_data.messages) if memory_data.messages else \"No messages available.\"\n+            elif memory_type == \"relevant_facts\":\n+                # Return relevant facts from memory\n+                if memory_data.relevant_facts:\n+                    facts_str = \"\\n\".join([f\"- {fact.fact}\" for fact in memory_data.relevant_facts])\n+                    return f\"Relevant facts:\\n{facts_str}\"\n+                else:\n+                    return \"No relevant facts available.\"\n             else:\n-                warning_msg = f\"Unsupported memory_type requested: {memory_type}. Returning empty string.\"\n+                warning_msg = f\"Unsupported memory_type requested: {memory_type}. Returning context.\"\n                 log_warning(warning_msg)\n-                return warning_msg\n+                return memory_data.context or \"No context available.\"\n \n         except Exception as e:\n             error_msg = f\"Failed to get Zep memory for session {self.session_id}: {e}\"\n             log_error(error_msg)\n             return f\"Error getting memory: {e}\"\n \n-    async def search_zep_memory(self, query: str, search_scope: str = \"messages\") -> str:\n+    async def search_zep_memory(self, query: str, scope: str = \"edges\", limit: int = 5) -> str:\n         \"\"\"\n-        Searches the Zep memory store for relevant messages or summaries associated with the configured user_id.\n+        Searches the Zep knowledge graph for relevant facts or nodes.\n         Args:\n-            query: The search term to find relevant facts.\n-            search_scope: The scope of the search to perform. Can be \"messages\" or \"summary\".\n+            query: The search term to find relevant facts or nodes.\n+            scope: The scope of the search to perform. Can be \"edges\" (for facts) or \"nodes\".\n+            limit: The maximum number of results to return.\n         Returns:\n             A string of the search result\n         \"\"\"\n         if not self._initialized:\n             await self.initialize()\n \n-        results: List = []\n-        search_result = \"\"\n-\n-        if not self.zep_client or not self.user_id or not self.session_id:\n-            log_error(\"Zep client or user ID or session ID not initialized. Cannot search memory.\")\n-            return \"Error: Zep client/user/session not initialized.\"\n+        if not self.zep_client or not self.user_id:\n+            log_error(\"Zep client or user ID not initialized. Cannot search graph.\")\n+            return \"Error: Zep client/user not initialized.\"\n \n         try:\n-            search_response: List[MemorySearchResult] = await self.zep_client.memory.search(\n-                text=query, session_id=self.session_id, search_scope=search_scope\n+            search_response = await self.zep_client.graph.search(  # type: ignore\n+                query=query,\n+                user_id=self.user_id,\n+                scope=scope,  # Can be \"edges\" or \"nodes\"\n+                limit=limit,\n             )\n \n-            results = [\n-                {\n-                    \"content\": response.message.content,\n-                    \"created_at\": response.message.created_at,\n-                    \"uuid\": response.message.uuid_,\n-                    \"score\": response.score,\n-                    \"summary\": response.summary,\n-                }\n-                for response in search_response\n-                if response.message is not None\n-            ]\n-\n-            log_debug(f\"Memory search found {len(results)} relevant messages.\")\n-        except Exception as e:\n-            log_error(f\"Failed to search Zep graph memory for user {self.user_id}: {e}\")\n-\n-        if results is not None and results != []:\n-            if search_scope == \"summary\":\n-                search_result = \" \".join(\n-                    [result.get(\"summary\", \"\") for result in results if result.get(\"summary\") is not None]\n-                )\n-                if search_result == \"\":\n-                    return \"No relevant summary found.\"\n-                else:\n-                    return search_result\n+            if scope == \"edges\" and search_response.edges:\n+                # Return facts from edges\n+                facts_str = \"\\n\".join([f\"- {edge.fact}\" for edge in search_response.edges])\n+                return f\"Found {len(search_response.edges)} facts:\\n{facts_str}\"\n+            elif scope == \"nodes\" and search_response.nodes:\n+                # Return node summaries\n+                nodes_str = \"\\n\".join([f\"- {node.name}: {node.summary}\" for node in search_response.nodes])\n+                return f\"Found {len(search_response.nodes)} nodes:\\n{nodes_str}\"\n             else:\n-                search_result = \" \".join(\n-                    [result.get(\"content\", \"\") for result in results if result.get(\"content\") is not None]\n-                )\n-                if search_result == \"\":\n-                    return \"No relevant content found.\"\n-                else:\n-                    return search_result\n-        else:\n-            return \"No relevant messages found.\"\n+                return f\"No {scope} found for query: {query}\"\n+\n+        except Exception as e:\n+            log_error(f\"Failed to search Zep graph for user {self.user_id}: {e}\")\n+            return f\"Error searching graph: {e}\"\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/utils/code_execution.py",
            "diff": "diff --git a/libs/agno/agno/utils/code_execution.py b/libs/agno/agno/utils/code_execution.py\nnew file mode 100644\nindex 000000000..f62121bea\n--- /dev/null\n+++ b/libs/agno/agno/utils/code_execution.py\n@@ -0,0 +1,11 @@\n+\"\"\"Utils for our multiple integrations with external code execution environments.\"\"\"\n+\n+import re\n+\n+\n+def prepare_python_code(code: str) -> str:\n+    \"\"\"Fix common problems with LLM-generated Python code.\"\"\"\n+    python_keywords = {\"true\": \"True\", \"false\": \"False\", \"none\": \"None\"}\n+    for lowercase, capitalized in python_keywords.items():\n+        code = re.sub(rf\"\\b({lowercase})\\b\", capitalized, code)\n+    return code\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/agno/utils/prompts.py",
            "diff": "diff --git a/libs/agno/agno/utils/prompts.py b/libs/agno/agno/utils/prompts.py\nindex 79feac500..a59a8b17a 100644\n--- a/libs/agno/agno/utils/prompts.py\n+++ b/libs/agno/agno/utils/prompts.py\n@@ -1,5 +1,5 @@\n import json\n-from typing import Union\n+from typing import Type, Union\n \n from pydantic import BaseModel\n \n@@ -93,3 +93,19 @@ def get_json_output_prompt(response_model: Union[str, list, BaseModel]) -> str:\n     json_output_prompt += \"\\nYour output will be passed to json.loads() to convert it to a Python object.\"\n     json_output_prompt += \"\\nMake sure it only contains valid JSON.\"\n     return json_output_prompt\n+\n+\n+def get_response_model_format_prompt(response_model: Type[BaseModel]) -> str:\n+    \"\"\"Return the format prompt for the response model.\"\"\"\n+\n+    message = \"Make sure your response is a valid string (NOT JSON) that mentions the following topics:\"\n+\n+    # Extract field names and descriptions\n+    for field_name, field_info in response_model.model_fields.items():\n+        description = field_info.description or \"\"\n+        if description:\n+            message += f\"\\n- {field_name}: {description}\"\n+        else:\n+            message += f\"\\n- {field_name}\"\n+\n+    return message\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py",
            "diff": "diff --git a/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py b/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\nindex 56690dab2..37506c505 100644\n--- a/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\n+++ b/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\n@@ -143,7 +143,9 @@ async def test_multi_user_multi_session_chat(memory_agent, agent_storage, memory\n \n     # Chat with user 2\n     await memory_agent.arun(\"Hi my name is John Doe.\", user_id=user_2_id, session_id=user_2_session_1_id)\n-    await memory_agent.arun(\"I'm planning to hike this weekend.\", user_id=user_2_id, session_id=user_2_session_1_id)\n+    await memory_agent.arun(\n+        \"I love hiking and go hiking every weekend.\", user_id=user_2_id, session_id=user_2_session_1_id\n+    )\n \n     # Chat with user 3\n     await memory_agent.arun(\"Hi my name is Jane Smith.\", user_id=user_3_id, session_id=user_3_session_1_id)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/agent/test_parser_model.py",
            "diff": "diff --git a/libs/agno/tests/integration/agent/test_parser_model.py b/libs/agno/tests/integration/agent/test_parser_model.py\nnew file mode 100644\nindex 000000000..d02eeb508\n--- /dev/null\n+++ b/libs/agno/tests/integration/agent/test_parser_model.py\n@@ -0,0 +1,93 @@\n+from typing import List\n+\n+from pydantic import BaseModel, Field\n+\n+from agno.agent import Agent\n+from agno.models.anthropic import Claude\n+from agno.models.google import Gemini\n+from agno.models.openai import OpenAIChat\n+\n+\n+class ParkGuide(BaseModel):\n+    park_name: str = Field(..., description=\"The official name of the national park.\")\n+    activities: List[str] = Field(\n+        ..., description=\"A list of popular activities to do in the park. Provide at least three.\"\n+    )\n+    best_season_to_visit: str = Field(\n+        ..., description=\"The best season to visit the park (e.g., Spring, Summer, Autumn, Winter).\"\n+    )\n+\n+\n+def test_claude_with_openai_parser_model():\n+    park_agent = Agent(\n+        model=Claude(id=\"claude-sonnet-4-20250514\"),  # Main model to generate the content\n+        description=\"You are an expert on national parks and provide concise guides.\",\n+        response_model=ParkGuide,\n+        parser_model=OpenAIChat(id=\"gpt-4o\"),  # Model to parse the output\n+    )\n+\n+    response = park_agent.run(\"Tell me about Yosemite National Park.\")\n+\n+    assert response.content is not None\n+    assert isinstance(response.content, ParkGuide)\n+    assert isinstance(response.content.park_name, str)\n+    assert len(response.content.park_name) > 0\n+\n+    assert isinstance(response.content.activities, list)\n+    assert len(response.content.activities) >= 2\n+    for activity in response.content.activities:\n+        assert isinstance(activity, str)\n+        assert len(activity) > 0\n+\n+    assert isinstance(response.content.best_season_to_visit, str)\n+    assert len(response.content.best_season_to_visit) > 0\n+\n+\n+def test_openai_with_claude_parser_model():\n+    park_agent = Agent(\n+        model=OpenAIChat(id=\"gpt-4o\"),  # Main model to generate the content\n+        description=\"You are an expert on national parks and provide concise guides.\",\n+        response_model=ParkGuide,\n+        parser_model=Claude(id=\"claude-sonnet-4-20250514\"),  # Model to parse the output\n+    )\n+\n+    response = park_agent.run(\"Tell me about Yosemite National Park.\")\n+\n+    assert response.content is not None\n+    assert isinstance(response.content, ParkGuide)\n+    assert isinstance(response.content.park_name, str)\n+    assert len(response.content.park_name) > 0\n+\n+    assert isinstance(response.content.activities, list)\n+    assert len(response.content.activities) >= 2\n+    for activity in response.content.activities:\n+        assert isinstance(activity, str)\n+        assert len(activity) > 0\n+\n+    assert isinstance(response.content.best_season_to_visit, str)\n+    assert len(response.content.best_season_to_visit) > 0\n+\n+\n+def test_gemini_with_openai_parser_model():\n+    park_agent = Agent(\n+        model=Gemini(id=\"gemini-2.0-flash-001\"),  # Main model to generate the content\n+        description=\"You are an expert on national parks and provide concise guides.\",\n+        response_model=ParkGuide,\n+        parser_model=OpenAIChat(id=\"gpt-4o\"),  # Model to parse the output\n+    )\n+\n+    response = park_agent.run(\"Tell me about Yosemite National Park.\")\n+\n+    assert response.content is not None\n+    assert isinstance(response.content, ParkGuide)\n+    assert isinstance(response.content.park_name, str)\n+    assert len(response.content.park_name) > 0\n+\n+    assert isinstance(response.content.activities, list)\n+    assert len(response.content.activities) >= 2\n+    for activity in response.content.activities:\n+        assert isinstance(activity, str)\n+        assert len(activity) > 0\n+\n+    assert isinstance(response.content.best_season_to_visit, str)\n+    assert len(response.content.best_season_to_visit) > 0\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/knowledge/test_pdf_bytes_knowledge_base.py",
            "diff": "diff --git a/libs/agno/tests/integration/knowledge/test_pdf_bytes_knowledge_base.py b/libs/agno/tests/integration/knowledge/test_pdf_bytes_knowledge_base.py\nnew file mode 100644\nindex 000000000..0c978759e\n--- /dev/null\n+++ b/libs/agno/tests/integration/knowledge/test_pdf_bytes_knowledge_base.py\n@@ -0,0 +1,87 @@\n+from pathlib import Path\n+\n+import pytest\n+\n+from agno.agent import Agent\n+from agno.knowledge.pdf_bytes import PDFBytesKnowledgeBase\n+from agno.vectordb.lancedb.lance_db import LanceDb\n+\n+\n+def test_pdf_knowledge_base():\n+    vector_db = LanceDb(\n+        table_name=\"recipes\",\n+        uri=\"tmp/lancedb\",\n+    )\n+\n+    # Read the PDF file as bytes\n+    file_path = Path(__file__).parent / \"data\" / \"thai_recipes_short.pdf\"\n+    with open(file_path, \"rb\") as file:\n+        pdf_bytes = file.read()\n+\n+    # Create knowledge base\n+    knowledge_base = PDFBytesKnowledgeBase(\n+        pdfs=[pdf_bytes],\n+        vector_db=vector_db,\n+    )\n+\n+    knowledge_base.load(recreate=True)\n+\n+    assert vector_db.exists()\n+\n+    assert vector_db.get_count() == 10\n+\n+    # Create and use the agent\n+    agent = Agent(knowledge=knowledge_base)\n+    response = agent.run(\"Show me how to make Tom Kha Gai\", markdown=True)\n+\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    for call in tool_calls:\n+        if call.get(\"type\", \"\") == \"function\":\n+            assert call[\"function\"][\"name\"] == \"search_knowledge_base\"\n+\n+    # Clean up\n+    vector_db.drop()\n+\n+\n+@pytest.mark.asyncio\n+async def test_pdf_knowledge_base_async():\n+    vector_db = LanceDb(\n+        table_name=\"recipes_async\",\n+        uri=\"tmp/lancedb\",\n+    )\n+\n+    # Read the PDF file as bytes\n+    file_path = Path(__file__).parent / \"data\" / \"thai_recipes_short.pdf\"\n+    with open(file_path, \"rb\") as file:\n+        pdf_bytes = file.read()\n+\n+    # Create knowledge base\n+    knowledge_base = PDFBytesKnowledgeBase(\n+        pdfs=[pdf_bytes],\n+        vector_db=vector_db,\n+    )\n+\n+    await knowledge_base.aload(recreate=True)\n+\n+    assert await vector_db.async_exists()\n+    assert await vector_db.async_get_count() == 10\n+\n+    # Create and use the agent\n+    agent = Agent(knowledge=knowledge_base)\n+    response = await agent.arun(\"What ingredients do I need for Tom Kha Gai?\", markdown=True)\n+\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    for call in tool_calls:\n+        if call.get(\"type\", \"\") == \"function\":\n+            assert call[\"function\"][\"name\"] == \"async_search_knowledge_base\"\n+\n+    assert any(ingredient in response.content.lower() for ingredient in [\"coconut\", \"chicken\", \"galangal\"])\n+\n+    # Clean up\n+    await vector_db.async_drop()\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/knowledge/test_website_knowledge_base.py",
            "diff": "diff --git a/libs/agno/tests/integration/knowledge/test_website_knowledge_base.py b/libs/agno/tests/integration/knowledge/test_website_knowledge_base.py\nindex 70c7a640f..662ebccdc 100644\n--- a/libs/agno/tests/integration/knowledge/test_website_knowledge_base.py\n+++ b/libs/agno/tests/integration/knowledge/test_website_knowledge_base.py\n@@ -25,7 +25,7 @@ def test_website_knowledge_base_directory(setup_vector_db):\n     kb.load(recreate=True)\n \n     assert setup_vector_db.exists()\n-    assert setup_vector_db.get_count() == 5\n+    assert setup_vector_db.get_count() == 3\n \n     agent = Agent(knowledge=kb)\n     response = agent.run(\"What are agents in Agno and what levels are there?\", markdown=True)\n@@ -47,7 +47,7 @@ def test_website_knowledge_base_single_url(setup_vector_db):\n     kb.load(recreate=True)\n \n     assert setup_vector_db.exists()\n-    assert setup_vector_db.get_count() == 4\n+    assert setup_vector_db.get_count() == 2\n \n     agent = Agent(knowledge=kb)\n     response = agent.run(\"How do I create a basic agent in Agno?\", markdown=True)\n@@ -70,7 +70,7 @@ async def test_website_knowledge_base_async_directory(setup_vector_db):\n     await kb.aload(recreate=True)\n \n     assert await setup_vector_db.async_exists()\n-    assert await setup_vector_db.async_get_count() == 5\n+    assert await setup_vector_db.async_get_count() == 3\n \n     agent = Agent(\n         knowledge=kb,\n@@ -97,7 +97,7 @@ async def test_website_knowledge_base_async_single_url(setup_vector_db):\n     await kb.aload(recreate=True)\n \n     assert await setup_vector_db.async_exists()\n-    assert await setup_vector_db.async_get_count() == 4\n+    assert await setup_vector_db.async_get_count() == 2\n \n     agent = Agent(\n         knowledge=kb,\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/anthropic/test_prompt_caching.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/anthropic/test_prompt_caching.py b/libs/agno/tests/integration/models/anthropic/test_prompt_caching.py\nnew file mode 100644\nindex 000000000..3db340b9b\n--- /dev/null\n+++ b/libs/agno/tests/integration/models/anthropic/test_prompt_caching.py\n@@ -0,0 +1,161 @@\n+\"\"\"\n+Integration tests for Claude model prompt caching functionality.\n+\n+Tests the basic caching features including:\n+- System message caching with real API calls\n+- Cache performance tracking\n+- Usage metrics with standard field names\n+\"\"\"\n+\n+from pathlib import Path\n+from unittest.mock import Mock\n+\n+import pytest\n+\n+from agno.agent import Agent, RunResponse\n+from agno.models.anthropic import Claude\n+from agno.utils.media import download_file\n+\n+\n+def _get_large_system_prompt() -> str:\n+    \"\"\"Load an example large system message from S3\"\"\"\n+    txt_path = Path(__file__).parent.joinpath(\"system_prompt.txt\")\n+    download_file(\n+        \"https://agno-public.s3.amazonaws.com/prompts/system_promt.txt\",\n+        str(txt_path),\n+    )\n+    return txt_path.read_text()\n+\n+\n+def _assert_cache_metrics(response: RunResponse, expect_cache_write: bool = False, expect_cache_read: bool = False):\n+    \"\"\"Assert cache-related metrics in response.\"\"\"\n+    if response.metrics is None:\n+        pytest.fail(\"Response metrics is None\")\n+\n+    cache_write_tokens = response.metrics.get(\"cache_write_tokens\", [0])\n+    cache_read_tokens = response.metrics.get(\"cached_tokens\", [0])\n+\n+    if expect_cache_write:\n+        assert sum(cache_write_tokens) > 0, \"Expected cache write tokens but found none\"\n+\n+    if expect_cache_read:\n+        assert sum(cache_read_tokens) > 0, \"Expected cache read tokens but found none\"\n+\n+\n+def test_system_message_caching_basic():\n+    \"\"\"Test basic system message caching functionality.\"\"\"\n+    claude = Claude(cache_system_prompt=True)\n+    system_message = \"You are a helpful assistant.\"\n+    kwargs = claude._prepare_request_kwargs(system_message)\n+\n+    expected_system = [{\"text\": system_message, \"type\": \"text\", \"cache_control\": {\"type\": \"ephemeral\"}}]\n+    assert kwargs[\"system\"] == expected_system\n+\n+\n+def test_extended_cache_time():\n+    \"\"\"Test extended cache time configuration.\"\"\"\n+    claude = Claude(cache_system_prompt=True, extended_cache_time=True)\n+    system_message = \"You are a helpful assistant.\"\n+    kwargs = claude._prepare_request_kwargs(system_message)\n+\n+    expected_system = [{\"text\": system_message, \"type\": \"text\", \"cache_control\": {\"type\": \"ephemeral\", \"ttl\": \"1h\"}}]\n+    assert kwargs[\"system\"] == expected_system\n+\n+\n+def test_usage_metrics_parsing():\n+    \"\"\"Test parsing enhanced usage metrics with standard field names.\"\"\"\n+    claude = Claude()\n+\n+    mock_response = Mock()\n+    mock_response.role = \"assistant\"\n+    mock_response.content = [Mock(type=\"text\", text=\"Test response\", citations=None)]\n+    mock_response.stop_reason = None\n+\n+    mock_usage = Mock()\n+    mock_usage.input_tokens = 100\n+    mock_usage.output_tokens = 50\n+    mock_usage.cache_creation_input_tokens = 80\n+    mock_usage.cache_read_input_tokens = 20\n+\n+    if hasattr(mock_usage, \"cache_creation\"):\n+        del mock_usage.cache_creation\n+    if hasattr(mock_usage, \"cache_read\"):\n+        del mock_usage.cache_read\n+\n+    mock_response.usage = mock_usage\n+\n+    model_response = claude.parse_provider_response(mock_response)\n+\n+    expected_usage = {\n+        \"input_tokens\": 100,\n+        \"output_tokens\": 50,\n+        \"cache_write_tokens\": 80,\n+        \"cached_tokens\": 20,\n+    }\n+    assert model_response.response_usage == expected_usage\n+\n+\n+def test_prompt_caching_with_agent():\n+    \"\"\"Test prompt caching using Agent with a large system prompt.\"\"\"\n+    large_system_prompt = _get_large_system_prompt()\n+\n+    print(f\"System prompt length: {len(large_system_prompt)} characters\")\n+\n+    agent = Agent(\n+        model=Claude(id=\"claude-3-5-sonnet-20241022\", cache_system_prompt=True),\n+        system_message=large_system_prompt,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"Explain the key principles of microservices architecture\")\n+\n+    print(f\"First response metrics: {response.metrics}\")\n+\n+    if response.metrics is None:\n+        pytest.fail(\"Response metrics is None\")\n+\n+    cache_creation_tokens = response.metrics.get(\"cache_write_tokens\", [0])[0]\n+    cache_hit_tokens = response.metrics.get(\"cached_tokens\", [0])[0]\n+\n+    print(f\"Cache creation tokens: {cache_creation_tokens}\")\n+    print(f\"Cache hit tokens: {cache_hit_tokens}\")\n+\n+    cache_activity = cache_creation_tokens > 0 or cache_hit_tokens > 0\n+    if not cache_activity:\n+        print(\"No cache activity detected. This might be due to:\")\n+        print(\"1. System prompt being below Anthropic's minimum caching threshold\")\n+        print(\"2. Cache already existing from previous runs\")\n+        print(\"Skipping cache assertions...\")\n+        return\n+\n+    assert response.content is not None\n+\n+    if cache_creation_tokens > 0:\n+        print(f\"\u2705 Cache was created with {cache_creation_tokens} tokens\")\n+        response2 = agent.run(\"How would you implement monitoring for this architecture?\")\n+        if response2.metrics is None:\n+            pytest.fail(\"Response2 metrics is None\")\n+        cache_read_tokens = response2.metrics.get(\"cached_tokens\", [0])[0]\n+        assert cache_read_tokens > 0, f\"Expected cache read tokens but found {cache_read_tokens}\"\n+    else:\n+        print(f\"\u2705 Cache was used with {cache_hit_tokens} tokens from previous run\")\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_prompt_caching():\n+    \"\"\"Test async prompt caching functionality.\"\"\"\n+    large_system_prompt = _get_large_system_prompt()\n+\n+    agent = Agent(\n+        model=Claude(id=\"claude-3-5-haiku-20241022\", cache_system_prompt=True),\n+        system_message=large_system_prompt,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = await agent.arun(\"Explain REST API design patterns\")\n+\n+    assert response.content is not None\n+    assert len(response.messages) == 3\n+    assert [m.role for m in response.messages] == [\"system\", \"user\", \"assistant\"]\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/langdb/__init__.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/langdb/__init__.py b/libs/agno/tests/integration/models/langdb/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/langdb/test_basic.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/langdb/test_basic.py b/libs/agno/tests/integration/models/langdb/test_basic.py\nnew file mode 100644\nindex 000000000..99840ec63\n--- /dev/null\n+++ b/libs/agno/tests/integration/models/langdb/test_basic.py\n@@ -0,0 +1,161 @@\n+import pytest\n+from pydantic import BaseModel, Field\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+from agno.storage.sqlite import SqliteStorage\n+\n+\n+def _assert_metrics(response: RunResponse):\n+    input_tokens = response.metrics.get(\"input_tokens\", [])\n+    output_tokens = response.metrics.get(\"output_tokens\", [])\n+    total_tokens = response.metrics.get(\"total_tokens\", [])\n+\n+    assert sum(input_tokens) > 0\n+    assert sum(output_tokens) > 0\n+    assert sum(total_tokens) > 0\n+    assert sum(total_tokens) == sum(input_tokens) + sum(output_tokens)\n+\n+\n+def test_basic():\n+    agent = Agent(model=LangDB(id=\"gemini-1.5-pro-latest\"), markdown=True, telemetry=False, monitoring=False)\n+\n+    # Print the response in the terminal\n+    response: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n+\n+    assert response.content is not None\n+    assert len(response.messages) == 3\n+    assert [m.role for m in response.messages] == [\"system\", \"user\", \"assistant\"]\n+\n+    _assert_metrics(response)\n+\n+\n+def test_basic_stream():\n+    agent = Agent(model=LangDB(id=\"gemini-1.5-pro-latest\"), markdown=True, telemetry=False, monitoring=False)\n+\n+    response_stream = agent.run(\"Share a 2 sentence horror story\", stream=True)\n+\n+    # Verify it's an iterator\n+    assert hasattr(response_stream, \"__iter__\")\n+\n+    responses = list(response_stream)\n+    assert len(responses) > 0\n+    for response in responses:\n+        assert isinstance(response, RunResponse)\n+        assert response.content is not None\n+\n+    # Broken at the moment\n+    # _assert_metrics(agent.run_response)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_basic():\n+    agent = Agent(model=LangDB(id=\"gemini-1.5-pro-latest\"), markdown=True, telemetry=False, monitoring=False)\n+\n+    response = await agent.arun(\"Share a 2 sentence horror story\")\n+\n+    assert response.content is not None\n+    assert len(response.messages) == 3\n+    assert [m.role for m in response.messages] == [\"system\", \"user\", \"assistant\"]\n+    _assert_metrics(response)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_basic_stream():\n+    agent = Agent(model=LangDB(id=\"gemini-1.5-pro-latest\"), markdown=True, telemetry=False, monitoring=False)\n+\n+    response_stream = await agent.arun(\"Share a 2 sentence horror story\", stream=True)\n+\n+    async for response in response_stream:\n+        assert isinstance(response, RunResponse)\n+        assert response.content is not None\n+\n+    # Broken at the moment\n+    # _assert_metrics(agent.run_response)\n+\n+\n+def test_with_memory():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        add_history_to_messages=True,\n+        num_history_responses=5,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    # First interaction\n+    response1 = agent.run(\"My name is John Smith\")\n+    assert response1.content is not None\n+\n+    # Second interaction should remember the name\n+    response2 = agent.run(\"What's my name?\")\n+    assert \"John Smith\" in response2.content\n+\n+    # Verify memories were created\n+    messages = agent.get_messages_for_session()\n+    assert len(messages) == 5\n+    assert [m.role for m in messages] == [\"system\", \"user\", \"assistant\", \"user\", \"assistant\"]\n+\n+    # Test metrics structure and types\n+    _assert_metrics(response2)\n+\n+\n+def test_structured_output():\n+    class MovieScript(BaseModel):\n+        title: str = Field(..., description=\"Movie title\")\n+        genre: str = Field(..., description=\"Movie genre\")\n+        plot: str = Field(..., description=\"Brief plot summary\")\n+\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"), response_model=MovieScript, telemetry=False, monitoring=False\n+    )\n+\n+    response = agent.run(\"Create a movie about time travel\")\n+\n+    # Verify structured output\n+    assert isinstance(response.content, MovieScript)\n+    assert response.content.title is not None\n+    assert response.content.genre is not None\n+    assert response.content.plot is not None\n+\n+\n+def test_json_response_mode():\n+    class MovieScript(BaseModel):\n+        title: str = Field(..., description=\"Movie title\")\n+        genre: str = Field(..., description=\"Movie genre\")\n+        plot: str = Field(..., description=\"Brief plot summary\")\n+\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        response_model=MovieScript,\n+        use_json_mode=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"Create a movie about time travel\")\n+\n+    # Verify structured output\n+    assert isinstance(response.content, MovieScript)\n+    assert response.content.title is not None\n+    assert response.content.genre is not None\n+    assert response.content.plot is not None\n+\n+\n+def test_history():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        storage=SqliteStorage(table_name=\"agent_sessions\", db_file=\"tmp/agent_storage.db\"),\n+        add_history_to_messages=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+    agent.run(\"Hello\")\n+    assert len(agent.run_response.messages) == 2\n+    agent.run(\"Hello 2\")\n+    assert len(agent.run_response.messages) == 4\n+    agent.run(\"Hello 3\")\n+    assert len(agent.run_response.messages) == 6\n+    agent.run(\"Hello 4\")\n+    assert len(agent.run_response.messages) == 8\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/langdb/test_tool_use.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/langdb/test_tool_use.py b/libs/agno/tests/integration/models/langdb/test_tool_use.py\nnew file mode 100644\nindex 000000000..4c6ee3ccb\n--- /dev/null\n+++ b/libs/agno/tests/integration/models/langdb/test_tool_use.py\n@@ -0,0 +1,256 @@\n+from typing import Optional\n+\n+import pytest\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.langdb import LangDB\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+from agno.tools.exa import ExaTools\n+from agno.tools.yfinance import YFinanceTools\n+\n+\n+def test_tool_use():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content\n+\n+\n+def test_tool_use_stream():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response_stream = agent.run(\"What is the current price of TSLA?\", stream=True, stream_intermediate_steps=True)\n+\n+    responses = []\n+    tool_call_seen = False\n+\n+    for chunk in response_stream:\n+        assert isinstance(chunk, RunResponse)\n+        responses.append(chunk)\n+        if chunk.tools:\n+            if any(tc.tool_name for tc in chunk.tools):\n+                tool_call_seen = True\n+\n+    assert len(responses) > 0\n+    assert tool_call_seen, \"No tool calls observed in stream\"\n+    assert any(\"TSLA\" in r.content for r in responses if r.content)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_tool_use():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = await agent.arun(\"What is the current price of TSLA?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages if msg.role == \"assistant\")\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_tool_use_stream():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response_stream = await agent.arun(\n+        \"What is the current price of TSLA?\", stream=True, stream_intermediate_steps=True\n+    )\n+\n+    responses = []\n+    tool_call_seen = False\n+\n+    async for chunk in response_stream:\n+        assert isinstance(chunk, RunResponse)\n+        responses.append(chunk)\n+        if chunk.tools:\n+            if any(tc.tool_name for tc in chunk.tools):\n+                tool_call_seen = True\n+\n+    assert len(responses) > 0\n+    assert tool_call_seen, \"No tool calls observed in stream\"\n+    assert any(\"TSLA\" in r.content for r in responses if r.content)\n+\n+\n+def test_tool_use_tool_call_limit():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(company_news=True, cache_results=True)],\n+        tool_call_limit=1,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"Find me the current price of TSLA, then after that find me the latest news about Tesla.\")\n+\n+    # Verify tool usage, should only call the first tool\n+    assert len(response.tools) == 1\n+    assert response.tools[0].tool_name == \"get_current_stock_price\"\n+    assert response.tools[0].tool_args == {\"symbol\": \"TSLA\"}\n+    assert response.tools[0].result is not None\n+    assert response.content is not None\n+\n+\n+def test_tool_use_with_content():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA? What does the ticker stand for?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content or \"Tesla\" in response.content\n+\n+\n+def test_parallel_tool_calls():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA and AAPL?\")\n+\n+    # Verify tool usage\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    assert len([call for call in tool_calls if call.get(\"type\", \"\") == \"function\"]) == 2  # Total of 2 tool calls made\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content and \"AAPL\" in response.content\n+\n+\n+def test_multiple_tool_calls():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[YFinanceTools(cache_results=True), DuckDuckGoTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA and what is the latest news about it?\")\n+\n+    # Verify tool usage\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    assert len([call for call in tool_calls if call.get(\"type\", \"\") == \"function\"]) == 2  # Total of 2 tool calls made\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content\n+\n+\n+def test_tool_call_custom_tool_no_parameters():\n+    def get_the_weather_in_tokyo():\n+        \"\"\"\n+        Get the weather in Tokyo\n+        \"\"\"\n+        return \"It is currently 70 degrees and cloudy in Tokyo\"\n+\n+    agent = Agent(\n+        model=LangDB(id=\"gpt-4o\"),\n+        tools=[get_the_weather_in_tokyo],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the weather in Tokyo?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"Tokyo\" in response.content\n+\n+\n+def test_tool_call_custom_tool_optional_parameters():\n+    def get_the_weather(city: Optional[str] = None):\n+        \"\"\"\n+        Get the weather in a city\n+\n+        Args:\n+            city: The city to get the weather for\n+        \"\"\"\n+        if city is None:\n+            return \"It is currently 70 degrees and cloudy in Tokyo\"\n+        else:\n+            return f\"It is currently 70 degrees and cloudy in {city}\"\n+\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[get_the_weather],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the weather in Paris?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"70\" in response.content\n+\n+\n+def test_tool_call_list_parameters():\n+    agent = Agent(\n+        model=LangDB(id=\"gemini-1.5-pro-latest\"),\n+        tools=[ExaTools()],\n+        instructions=\"Use a single tool call if possible\",\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\n+        \"What are the papers at https://arxiv.org/pdf/2307.06435 and https://arxiv.org/pdf/2502.09601 about?\"\n+    )\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    for call in tool_calls:\n+        if call.get(\"type\", \"\") == \"function\":\n+            assert call[\"function\"][\"name\"] in [\"get_contents\", \"exa_answer\", \"search_exa\"]\n+    assert response.content is not None\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/vllm/test_basic.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/vllm/test_basic.py b/libs/agno/tests/integration/models/vllm/test_basic.py\nnew file mode 100644\nindex 000000000..f56535acf\n--- /dev/null\n+++ b/libs/agno/tests/integration/models/vllm/test_basic.py\n@@ -0,0 +1,172 @@\n+import pytest\n+from pydantic import BaseModel, Field\n+\n+from agno.agent import Agent, RunResponse\n+from agno.exceptions import ModelProviderError\n+from agno.models.vllm import vLLM\n+from agno.storage.sqlite import SqliteStorage\n+\n+# Use default model id or override via env var\n+VLLM_MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n+\n+\n+def _assert_metrics(response: RunResponse):\n+    input_tokens = response.metrics.get(\"input_tokens\", [])\n+    output_tokens = response.metrics.get(\"output_tokens\", [])\n+    total_tokens = response.metrics.get(\"total_tokens\", [])\n+\n+    assert sum(input_tokens) > 0\n+    assert sum(output_tokens) > 0\n+    assert sum(total_tokens) > 0\n+    assert sum(total_tokens) == sum(input_tokens) + sum(output_tokens)\n+\n+\n+def test_basic():\n+    agent = Agent(model=vLLM(id=VLLM_MODEL_ID), markdown=True, telemetry=False, monitoring=False)\n+\n+    # Print the response in the terminal\n+    response: RunResponse = agent.run(\"Share a 2 sentence comedy story\")\n+\n+    assert response.content is not None\n+    assert len(response.messages) == 3\n+    assert [m.role for m in response.messages] == [\"system\", \"user\", \"assistant\"]\n+\n+    _assert_metrics(response)\n+\n+\n+def test_basic_stream():\n+    agent = Agent(model=vLLM(id=VLLM_MODEL_ID), markdown=True, telemetry=False, monitoring=False)\n+\n+    response_stream = agent.run(\"Share a 2 sentence horror story\", stream=True)\n+\n+    # Verify it's an iterator\n+    assert hasattr(response_stream, \"__iter__\")\n+\n+    responses = list(response_stream)\n+    assert len(responses) > 0\n+    for response in responses:\n+        assert isinstance(response, RunResponse)\n+        assert response.content is not None\n+\n+    _assert_metrics(agent.run_response)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_basic():\n+    agent = Agent(model=vLLM(id=VLLM_MODEL_ID), markdown=True, telemetry=False, monitoring=False)\n+\n+    response = await agent.arun(\"Share a 2 sentence horror story\")\n+\n+    assert response.content is not None\n+    assert len(response.messages) == 3\n+    assert [m.role for m in response.messages] == [\"system\", \"user\", \"assistant\"]\n+    _assert_metrics(response)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_basic_stream():\n+    agent = Agent(model=vLLM(id=VLLM_MODEL_ID), markdown=True, telemetry=False, monitoring=False)\n+\n+    response_stream = await agent.arun(\"Share a 2 sentence horror story\", stream=True)\n+\n+    async for response in response_stream:\n+        assert isinstance(response, RunResponse)\n+        assert response.content is not None\n+\n+    _assert_metrics(agent.run_response)\n+\n+\n+def test_with_memory():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        add_history_to_messages=True,\n+        num_history_responses=5,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    # First interaction\n+    response1 = agent.run(\"My name is John Smith\")\n+    assert response1.content is not None\n+\n+    # Second interaction should remember the name\n+    response2 = agent.run(\"What's my name?\")\n+    assert \"John Smith\" in response2.content\n+\n+    # Verify memories were created\n+    messages = agent.get_messages_for_session()\n+    assert len(messages) == 5\n+    assert [m.role for m in messages] == [\"system\", \"user\", \"assistant\", \"user\", \"assistant\"]\n+\n+    # Test metrics structure and types\n+    _assert_metrics(response2)\n+\n+\n+def test_response_model():\n+    class MovieScript(BaseModel):\n+        title: str = Field(..., description=\"Movie title\")\n+        genre: str = Field(..., description=\"Movie genre\")\n+        plot: str = Field(..., description=\"Brief plot summary\")\n+\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        response_model=MovieScript,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"Create a movie about time travel\")\n+\n+    # Verify structured output\n+    assert isinstance(response.content, MovieScript)\n+    assert response.content.title is not None\n+    assert response.content.genre is not None\n+    assert response.content.plot is not None\n+\n+\n+def test_json_response_mode():\n+    class MovieScript(BaseModel):\n+        title: str = Field(..., description=\"Movie title\")\n+        genre: str = Field(..., description=\"Movie genre\")\n+        plot: str = Field(..., description=\"Brief plot summary\")\n+\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        response_model=MovieScript,\n+        use_json_mode=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"Create a movie about time travel\")\n+\n+    # Verify structured output\n+    assert isinstance(response.content, MovieScript)\n+    assert response.content.title is not None\n+    assert response.content.genre is not None\n+    assert response.content.plot is not None\n+\n+\n+def test_history():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        storage=SqliteStorage(table_name=\"agent_sessions\", db_file=\"tmp/agent_storage.db\"),\n+        add_history_to_messages=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+    agent.run(\"Hello\")\n+    assert len(agent.run_response.messages) == 2\n+    agent.run(\"Hello 2\")\n+    assert len(agent.run_response.messages) == 4\n+    agent.run(\"Hello 3\")\n+    assert len(agent.run_response.messages) == 6\n+    agent.run(\"Hello 4\")\n+    assert len(agent.run_response.messages) == 8\n+\n+\n+def test_exception():\n+    agent = Agent(model=vLLM(id=\"invalid-model-id\"), markdown=True, telemetry=False, monitoring=False)\n+    with pytest.raises(ModelProviderError):\n+        agent.run(\"Test vLLM exception\")\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/models/vllm/test_tool_use.py",
            "diff": "diff --git a/libs/agno/tests/integration/models/vllm/test_tool_use.py b/libs/agno/tests/integration/models/vllm/test_tool_use.py\nnew file mode 100644\nindex 000000000..06dc7e79f\n--- /dev/null\n+++ b/libs/agno/tests/integration/models/vllm/test_tool_use.py\n@@ -0,0 +1,221 @@\n+from typing import Optional\n+\n+import pytest\n+\n+from agno.agent import Agent, RunResponse\n+from agno.models.vllm import vLLM\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+from agno.tools.exa import ExaTools\n+from agno.tools.yfinance import YFinanceTools\n+\n+VLLM_MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n+\n+\n+def test_tool_use():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content\n+\n+\n+def test_tool_use_stream():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response_stream = agent.run(\"What is the current price of TSLA?\", stream=True, stream_intermediate_steps=True)\n+\n+    responses = []\n+    tool_call_seen = False\n+\n+    for chunk in response_stream:\n+        assert isinstance(chunk, RunResponse)\n+        responses.append(chunk)\n+        if chunk.tools:\n+            if any(tc.tool_name for tc in chunk.tools):\n+                tool_call_seen = True\n+\n+    assert len(responses) > 0\n+    assert tool_call_seen, \"No tool calls observed in stream\"\n+    assert any(\"TSLA\" in r.content for r in responses if r.content)\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_tool_use():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = await agent.arun(\"What is the current price of TSLA?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages if msg.role == \"assistant\")\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content\n+\n+\n+@pytest.mark.asyncio\n+async def test_async_tool_use_stream():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response_stream = await agent.arun(\n+        \"What is the current price of TSLA?\", stream=True, stream_intermediate_steps=True\n+    )\n+\n+    responses = []\n+    tool_call_seen = False\n+\n+    async for chunk in response_stream:\n+        assert isinstance(chunk, RunResponse)\n+        responses.append(chunk)\n+        if chunk.tools:\n+            if any(tc.tool_name for tc in chunk.tools):\n+                tool_call_seen = True\n+\n+    assert len(responses) > 0\n+    assert tool_call_seen, \"No tool calls observed in stream\"\n+    assert any(\"TSLA\" in r.content for r in responses if r.content)\n+\n+\n+def test_parallel_tool_calls():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA and AAPL?\")\n+\n+    # Verify tool usage\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    assert len([call for call in tool_calls if call.get(\"type\", \"\") == \"function\"]) == 2  # Total of 2 tool calls made\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content and \"AAPL\" in response.content\n+\n+\n+def test_multiple_tool_calls():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[YFinanceTools(cache_results=True), DuckDuckGoTools(cache_results=True)],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the current price of TSLA and what is the latest news about it?\")\n+\n+    # Verify tool usage\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    assert len([call for call in tool_calls if call.get(\"type\", \"\") == \"function\"]) == 2  # Total of 2 tool calls made\n+    assert response.content is not None\n+    assert \"TSLA\" in response.content and \"latest news\" in response.content.lower()\n+\n+\n+def test_tool_call_custom_tool_no_parameters():\n+    def get_the_weather_in_tokyo():\n+        \"\"\"\n+        Get the weather in Tokyo\n+        \"\"\"\n+        return \"It is currently 70 degrees and cloudy in Tokyo\"\n+\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[get_the_weather_in_tokyo],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the weather in Tokyo?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"70\" in response.content\n+\n+\n+def test_tool_call_custom_tool_optional_parameters():\n+    def get_the_weather(city: Optional[str] = None):\n+        \"\"\"\n+        Get the weather in a city\n+\n+        Args:\n+            city: The city to get the weather for\n+        \"\"\"\n+        if city is None:\n+            return \"It is currently 70 degrees and cloudy in Tokyo\"\n+        else:\n+            return f\"It is currently 70 degrees and cloudy in {city}\"\n+\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[get_the_weather],\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the weather in Paris?\")\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    assert response.content is not None\n+    assert \"70\" in response.content\n+\n+\n+def test_tool_call_list_parameters():\n+    agent = Agent(\n+        model=vLLM(id=VLLM_MODEL_ID),\n+        tools=[ExaTools()],\n+        instructions=\"Use a single tool call if possible\",\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\n+        \"What are the papers at https://arxiv.org/pdf/2307.06435 and https://arxiv.org/pdf/2502.09601 about?\"\n+    )\n+\n+    # Verify tool usage\n+    assert any(msg.tool_calls for msg in response.messages)\n+    tool_calls = []\n+    for msg in response.messages:\n+        if msg.tool_calls:\n+            tool_calls.extend(msg.tool_calls)\n+    for call in tool_calls:\n+        if call.get(\"type\", \"\") == \"function\":\n+            assert call[\"function\"][\"name\"] in [\"get_contents\", \"exa_answer\", \"search_exa\"]\n+    assert response.content is not None\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/integration/teams/test_team_with_storage_and_memory.py",
            "diff": "diff --git a/libs/agno/tests/integration/teams/test_team_with_storage_and_memory.py b/libs/agno/tests/integration/teams/test_team_with_storage_and_memory.py\nindex 312598de6..a9fa652e8 100644\n--- a/libs/agno/tests/integration/teams/test_team_with_storage_and_memory.py\n+++ b/libs/agno/tests/integration/teams/test_team_with_storage_and_memory.py\n@@ -113,6 +113,34 @@ async def test_run_history_persistence(route_team, team_storage, memory):\n     assert first_user_message_content == conversation_messages[0]\n \n \n+@pytest.mark.asyncio\n+async def test_run_session_summary(route_team, team_storage, memory):\n+    \"\"\"Test that the session summary is persisted in storage.\"\"\"\n+    session_id = \"session_123\"\n+    user_id = \"john@example.com\"\n+\n+    # Enable session summaries\n+    route_team.enable_user_memories = False\n+    route_team.enable_session_summaries = True\n+\n+    # Clear memory for this specific test case\n+    memory.clear()\n+\n+    await route_team.arun(\"Where is New York?\", user_id=user_id, session_id=session_id)\n+\n+    assert route_team.get_session_summary(user_id=user_id, session_id=session_id).summary is not None\n+\n+    team_session = team_storage.read(session_id=session_id)\n+    assert len(team_session.memory[\"summaries\"][user_id][session_id]) > 0\n+\n+    await route_team.arun(\"Where is Tokyo?\", user_id=user_id, session_id=session_id)\n+\n+    assert route_team.get_session_summary(user_id=user_id, session_id=session_id).summary is not None\n+\n+    team_session = team_storage.read(session_id=session_id)\n+    assert len(team_session.memory[\"summaries\"][user_id][session_id]) > 0\n+\n+\n @pytest.mark.asyncio\n async def test_multi_user_multi_session_route_team(route_team, team_storage, memory):\n     \"\"\"Test multi-user multi-session route team with storage and memory.\"\"\"\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/app/__init__.py",
            "diff": "diff --git a/libs/agno/tests/unit/app/__init__.py b/libs/agno/tests/unit/app/__init__.py\nnew file mode 100644\nindex 000000000..e69de29bb\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/app/test_agui_app.py",
            "diff": "diff --git a/libs/agno/tests/unit/app/test_agui_app.py b/libs/agno/tests/unit/app/test_agui_app.py\nnew file mode 100644\nindex 000000000..761e09e98\n--- /dev/null\n+++ b/libs/agno/tests/unit/app/test_agui_app.py\n@@ -0,0 +1,244 @@\n+from unittest.mock import MagicMock\n+\n+import pytest\n+from ag_ui.core import EventType\n+\n+from agno.app.agui.utils import EventBuffer, async_stream_agno_response_as_agui_events\n+from agno.run.response import RunResponse\n+\n+\n+def test_event_buffer_initial_state():\n+    \"\"\"Test EventBuffer initial state\"\"\"\n+    buffer = EventBuffer()\n+\n+    assert not buffer.is_blocked()\n+    assert buffer.blocking_tool_call_id is None\n+    assert len(buffer.active_tool_call_ids) == 0\n+    assert len(buffer.ended_tool_call_ids) == 0\n+    assert len(buffer.buffer) == 0\n+\n+\n+def test_event_buffer_tool_call_lifecycle():\n+    \"\"\"Test complete tool call lifecycle in EventBuffer\"\"\"\n+    buffer = EventBuffer()\n+\n+    # Initial state\n+    assert not buffer.is_blocked()\n+    assert len(buffer.active_tool_call_ids) == 0\n+\n+    # Start tool call\n+    buffer.start_tool_call(\"tool_1\")\n+    assert buffer.is_blocked()\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+    assert \"tool_1\" in buffer.active_tool_call_ids\n+\n+    # End tool call\n+    unblocked = buffer.end_tool_call(\"tool_1\")\n+    assert unblocked is True\n+    assert not buffer.is_blocked()\n+    assert \"tool_1\" in buffer.ended_tool_call_ids\n+    assert \"tool_1\" not in buffer.active_tool_call_ids\n+\n+\n+def test_event_buffer_multiple_tool_calls():\n+    \"\"\"Test multiple concurrent tool calls\"\"\"\n+    buffer = EventBuffer()\n+\n+    # Start first tool call (becomes blocking)\n+    buffer.start_tool_call(\"tool_1\")\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+\n+    # Start second tool call (doesn't change blocking)\n+    buffer.start_tool_call(\"tool_2\")\n+    assert buffer.blocking_tool_call_id == \"tool_1\"  # Still blocked by first\n+    assert len(buffer.active_tool_call_ids) == 2\n+\n+    # End non-blocking tool call\n+    unblocked = buffer.end_tool_call(\"tool_2\")\n+    assert unblocked is False\n+    assert buffer.is_blocked()  # Still blocked by tool_1\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+\n+    # End blocking tool call\n+    unblocked = buffer.end_tool_call(\"tool_1\")\n+    assert unblocked is True\n+    assert not buffer.is_blocked()\n+    assert buffer.blocking_tool_call_id is None\n+\n+\n+def test_event_buffer_end_nonexistent_tool_call():\n+    \"\"\"Test ending a tool call that was never started\"\"\"\n+    buffer = EventBuffer()\n+\n+    # End tool call that was never started\n+    unblocked = buffer.end_tool_call(\"nonexistent_tool\")\n+    assert unblocked is False\n+    assert not buffer.is_blocked()\n+    assert \"nonexistent_tool\" in buffer.ended_tool_call_ids\n+\n+\n+def test_event_buffer_duplicate_start_tool_call():\n+    \"\"\"Test starting the same tool call multiple times\"\"\"\n+    buffer = EventBuffer()\n+\n+    # Start same tool call twice\n+    buffer.start_tool_call(\"tool_1\")\n+    buffer.start_tool_call(\"tool_1\")  # Should not cause issues\n+\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+    assert len(buffer.active_tool_call_ids) == 1  # Should still be 1\n+    assert \"tool_1\" in buffer.active_tool_call_ids\n+\n+\n+def test_event_buffer_duplicate_end_tool_call():\n+    \"\"\"Test ending the same tool call multiple times\"\"\"\n+    buffer = EventBuffer()\n+\n+    buffer.start_tool_call(\"tool_1\")\n+\n+    # End same tool call twice\n+    unblocked_1 = buffer.end_tool_call(\"tool_1\")\n+    unblocked_2 = buffer.end_tool_call(\"tool_1\")\n+\n+    assert unblocked_1 is True\n+    assert unblocked_2 is False  # Second end should not unblock\n+    assert not buffer.is_blocked()\n+    assert \"tool_1\" in buffer.ended_tool_call_ids\n+\n+\n+def test_event_buffer_complex_sequence():\n+    \"\"\"Test complex sequence of tool call operations\"\"\"\n+    buffer = EventBuffer()\n+\n+    # Start multiple tool calls\n+    buffer.start_tool_call(\"tool_1\")  # This becomes blocking\n+    buffer.start_tool_call(\"tool_2\")\n+    buffer.start_tool_call(\"tool_3\")\n+\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+    assert len(buffer.active_tool_call_ids) == 3\n+\n+    # End middle tool call (should not unblock)\n+    unblocked = buffer.end_tool_call(\"tool_2\")\n+    assert unblocked is False\n+    assert buffer.is_blocked()\n+    assert buffer.blocking_tool_call_id == \"tool_1\"\n+\n+    # End blocking tool call (should unblock)\n+    unblocked = buffer.end_tool_call(\"tool_1\")\n+    assert unblocked is True\n+    assert not buffer.is_blocked()\n+\n+    # End remaining tool call\n+    unblocked = buffer.end_tool_call(\"tool_3\")\n+    assert unblocked is False  # Already unblocked\n+\n+    # Check final state\n+    assert len(buffer.active_tool_call_ids) == 0\n+    assert len(buffer.ended_tool_call_ids) == 3\n+\n+\n+def test_event_buffer_blocking_behavior_edge_cases():\n+    \"\"\"Test edge cases in blocking behavior\"\"\"\n+    buffer = EventBuffer()\n+\n+    # Test that empty string tool_call_id is handled gracefully\n+    buffer.start_tool_call(\"\")  # Empty string\n+    assert buffer.is_blocked()\n+    assert buffer.blocking_tool_call_id == \"\"\n+\n+    # End with empty string\n+    unblocked = buffer.end_tool_call(\"\")\n+    assert unblocked is True\n+    assert not buffer.is_blocked()\n+\n+\n+@pytest.mark.asyncio\n+async def test_stream_basic():\n+    \"\"\"Test the async_stream_agno_response_as_agui_events function emits all expected events in a basic case.\"\"\"\n+    from agno.run.response import RunEvent\n+\n+    async def mock_stream():\n+        text_response = RunResponse()\n+        text_response.event = RunEvent.run_response\n+        text_response.content = \"Hello world\"\n+        text_response.messages = []\n+        yield text_response\n+        completed_response = RunResponse()\n+        completed_response.event = RunEvent.run_completed\n+        completed_response.content = \"\"\n+        completed_response.messages = []\n+        yield completed_response\n+\n+    events = []\n+    async for event in async_stream_agno_response_as_agui_events(mock_stream(), \"thread_1\", \"run_1\"):\n+        events.append(event)\n+\n+    assert len(events) == 4\n+    assert events[0].type == EventType.TEXT_MESSAGE_START\n+    assert events[1].type == EventType.TEXT_MESSAGE_CONTENT\n+    assert events[1].delta == \"Hello world\"\n+    assert events[2].type == EventType.TEXT_MESSAGE_END\n+    assert events[3].type == EventType.RUN_FINISHED\n+\n+\n+@pytest.mark.asyncio\n+async def test_stream_with_tool_call_blocking():\n+    \"\"\"Test that events are properly buffered during tool calls\"\"\"\n+    from agno.run.response import RunEvent\n+\n+    async def mock_stream_with_tool_calls():\n+        # Start with a text response\n+        text_response = RunResponse()\n+        text_response.event = RunEvent.run_response\n+        text_response.content = \"I'll help you\"\n+        text_response.messages = []\n+        yield text_response\n+\n+        # Start a tool call\n+        tool_start_response = RunResponse()\n+        tool_start_response.event = RunEvent.tool_call_started\n+        tool_start_response.content = \"\"\n+        tool_start_response.messages = []\n+        tool_call = MagicMock()\n+        tool_call.tool_call_id = \"tool_1\"\n+        tool_call.tool_name = \"search\"\n+        tool_call.tool_args = {\"query\": \"test\"}\n+        tool_start_response.tools = [tool_call]\n+        yield tool_start_response\n+\n+        buffered_text_response = RunResponse()\n+        buffered_text_response.event = RunEvent.run_response\n+        buffered_text_response.content = \"Searching...\"\n+        buffered_text_response.messages = []\n+        yield buffered_text_response\n+        tool_end_response = RunResponse()\n+        tool_end_response.event = RunEvent.tool_call_completed\n+        tool_end_response.content = \"\"\n+        tool_end_response.messages = []\n+        tool_end_response.tools = [tool_call]\n+        yield tool_end_response\n+        completed_response = RunResponse()\n+        completed_response.event = RunEvent.run_completed\n+        completed_response.content = \"\"\n+        completed_response.messages = []\n+        yield completed_response\n+\n+    events = []\n+    async for event in async_stream_agno_response_as_agui_events(mock_stream_with_tool_calls(), \"thread_1\", \"run_1\"):\n+        events.append(event)\n+\n+    # Asserting all expected events are present\n+    event_types = [event.type for event in events]\n+    assert EventType.TEXT_MESSAGE_START in event_types\n+    assert EventType.TEXT_MESSAGE_CONTENT in event_types\n+    assert EventType.TOOL_CALL_START in event_types\n+    assert EventType.TOOL_CALL_ARGS in event_types\n+    assert EventType.TOOL_CALL_END in event_types\n+    assert EventType.TEXT_MESSAGE_END in event_types\n+    assert EventType.RUN_FINISHED in event_types\n+\n+    # Verify tool call ordering\n+    tool_start_idx = event_types.index(EventType.TOOL_CALL_START)\n+    tool_end_idx = event_types.index(EventType.TOOL_CALL_END)\n+    assert tool_start_idx < tool_end_idx\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/reader/test_url_reader.py",
            "diff": "diff --git a/libs/agno/tests/unit/reader/test_url_reader.py b/libs/agno/tests/unit/reader/test_url_reader.py\nindex 655daf7eb..d6bedcf6f 100644\n--- a/libs/agno/tests/unit/reader/test_url_reader.py\n+++ b/libs/agno/tests/unit/reader/test_url_reader.py\n@@ -1,4 +1,4 @@\n-from unittest.mock import AsyncMock, Mock, patch\n+from unittest.mock import Mock, patch\n \n import httpx\n import pytest\n@@ -21,7 +21,7 @@ def test_read_url_success(mock_response):\n     \"\"\"Test successful URL reading\"\"\"\n     url = \"https://example.com\"\n \n-    with patch(\"httpx.get\", return_value=mock_response):\n+    with patch(\"agno.document.reader.url_reader.fetch_with_retry\", return_value=mock_response):\n         reader = URLReader()\n         reader.chunk = False\n         documents = reader.read(url)\n@@ -36,7 +36,7 @@ def test_read_url_with_path(mock_response):\n     \"\"\"Test URL reading with path components\"\"\"\n     url = \"https://example.com/blog/post-1\"\n \n-    with patch(\"httpx.get\", return_value=mock_response):\n+    with patch(\"agno.document.reader.url_reader.fetch_with_retry\", return_value=mock_response):\n         reader = URLReader()\n         reader.chunk = False\n         documents = reader.read(url)\n@@ -53,38 +53,40 @@ def test_read_empty_url():\n         reader.read(\"\")\n \n \n-def test_read_url_with_retry(mock_response):\n-    \"\"\"Test URL reading with retry mechanism\"\"\"\n+def test_read_url_with_proxy(mock_response):\n+    \"\"\"Test URL reading with proxy\"\"\"\n     url = \"https://example.com\"\n+    proxy = \"http://proxy.example.com:8080\"\n \n-    with patch(\"httpx.get\", side_effect=[httpx.RequestError(\"Connection error\"), mock_response]):\n-        reader = URLReader()\n+    with patch(\"agno.document.reader.url_reader.fetch_with_retry\", return_value=mock_response) as mock_fetch:\n+        reader = URLReader(proxy=proxy)\n         reader.chunk = False\n         documents = reader.read(url)\n \n+        # Verify the proxy was passed to fetch_with_retry\n+        mock_fetch.assert_called_once_with(url, proxy=proxy)\n         assert len(documents) == 1\n         assert documents[0].content == \"Hello, World!\"\n \n \n-def test_read_url_max_retries():\n-    \"\"\"Test URL reading with max retries exceeded\"\"\"\n+def test_read_url_request_error():\n+    \"\"\"Test URL reading when fetch_with_retry raises RequestError\"\"\"\n     url = \"https://example.com\"\n \n-    with patch(\"httpx.get\", side_effect=httpx.RequestError(\"Connection error\")):\n+    with patch(\"agno.document.reader.url_reader.fetch_with_retry\", side_effect=httpx.RequestError(\"Connection failed\")):\n         reader = URLReader()\n         with pytest.raises(httpx.RequestError):\n             reader.read(url)\n \n \n-def test_read_url_http_error(mock_response):\n-    \"\"\"Test URL reading with HTTP error\"\"\"\n+def test_read_url_http_error():\n+    \"\"\"Test URL reading when fetch_with_retry raises HTTPStatusError\"\"\"\n     url = \"https://example.com\"\n-    mock_response.status_code = 404\n-    mock_response.raise_for_status.side_effect = httpx.HTTPStatusError(\n-        \"404 Not Found\", request=Mock(), response=mock_response\n-    )\n \n-    with patch(\"httpx.get\", return_value=mock_response):\n+    with patch(\n+        \"agno.document.reader.url_reader.fetch_with_retry\",\n+        side_effect=httpx.HTTPStatusError(\"404 Not Found\", request=Mock(), response=Mock()),\n+    ):\n         reader = URLReader()\n         with pytest.raises(httpx.HTTPStatusError):\n             reader.read(url)\n@@ -95,7 +97,7 @@ def test_chunking(mock_response):\n     url = \"https://example.com\"\n     mock_response.text = \"Hello, world! \" * 1000\n \n-    with patch(\"httpx.get\", return_value=mock_response):\n+    with patch(\"agno.document.reader.url_reader.fetch_with_retry\", return_value=mock_response):\n         reader = URLReader()\n         reader.chunk = True\n         reader.chunking_strategy = FixedSizeChunking(chunk_size=100)\n@@ -107,18 +109,11 @@ def test_chunking(mock_response):\n \n \n @pytest.mark.asyncio\n-async def test_async_read_url_success():\n+async def test_async_read_url_success(mock_response):\n     \"\"\"Test successful async URL reading\"\"\"\n     url = \"https://example.com\"\n \n-    mock_response = Mock(spec=httpx.Response)\n-    mock_response.status_code = 200\n-    mock_response.text = \"Hello, World!\"\n-\n-    mock_client = AsyncMock(spec=httpx.AsyncClient)\n-    mock_client.__aenter__.return_value.get.return_value = mock_response\n-\n-    with patch(\"httpx.AsyncClient\", return_value=mock_client):\n+    with patch(\"agno.document.reader.url_reader.async_fetch_with_retry\", return_value=mock_response):\n         reader = URLReader()\n         reader.chunk = False  # Disable chunking for this test\n         documents = await reader.async_read(url)\n@@ -130,35 +125,42 @@ async def test_async_read_url_success():\n \n \n @pytest.mark.asyncio\n-async def test_async_read_url_with_retry():\n-    \"\"\"Test async URL reading with retry mechanism\"\"\"\n-    url = \"https://example.com\"\n+async def test_async_read_empty_url():\n+    \"\"\"Test async reading with empty URL\"\"\"\n+    reader = URLReader()\n+    with pytest.raises(ValueError, match=\"No url provided\"):\n+        await reader.async_read(\"\")\n \n-    mock_response = Mock(spec=httpx.Response)\n-    mock_response.status_code = 200\n-    mock_response.text = \"Hello, World!\"\n \n-    mock_client = AsyncMock(spec=httpx.AsyncClient)\n-    mock_client.__aenter__.return_value.get.side_effect = [httpx.RequestError(\"Connection error\"), mock_response]\n+@pytest.mark.asyncio\n+async def test_async_read_url_with_proxy(mock_response):\n+    \"\"\"Test async URL reading with proxy\"\"\"\n+    url = \"https://example.com\"\n+    proxy = \"http://proxy.example.com:8080\"\n \n-    with patch(\"httpx.AsyncClient\", return_value=mock_client):\n-        reader = URLReader()\n-        reader.chunk = False  # Disable chunking for this test\n+    with patch(\"agno.document.reader.url_reader.async_fetch_with_retry\", return_value=mock_response) as mock_fetch:\n+        reader = URLReader(proxy=proxy)\n+        reader.chunk = False\n         documents = await reader.async_read(url)\n \n+        # Verify the client was passed to async_fetch_with_retry\n+        mock_fetch.assert_called_once()\n+        call_args = mock_fetch.call_args\n+        assert call_args[0][0] == url  # First positional arg is url\n+        assert \"client\" in call_args[1]  # client should be in kwargs\n+\n         assert len(documents) == 1\n         assert documents[0].content == \"Hello, World!\"\n \n \n @pytest.mark.asyncio\n-async def test_async_read_url_max_retries():\n-    \"\"\"Test async URL reading with max retries exceeded\"\"\"\n+async def test_async_read_url_request_error():\n+    \"\"\"Test async URL reading when async_fetch_with_retry raises RequestError\"\"\"\n     url = \"https://example.com\"\n \n-    mock_client = AsyncMock(spec=httpx.AsyncClient)\n-    mock_client.__aenter__.return_value.get.side_effect = httpx.RequestError(\"Connection error\")\n-\n-    with patch(\"httpx.AsyncClient\", return_value=mock_client):\n+    with patch(\n+        \"agno.document.reader.url_reader.async_fetch_with_retry\", side_effect=httpx.RequestError(\"Connection failed\")\n+    ):\n         reader = URLReader()\n         with pytest.raises(httpx.RequestError):\n             await reader.async_read(url)\n@@ -166,37 +168,25 @@ async def test_async_read_url_max_retries():\n \n @pytest.mark.asyncio\n async def test_async_read_url_http_error():\n-    \"\"\"Test async URL reading with HTTP error\"\"\"\n+    \"\"\"Test async URL reading when async_fetch_with_retry raises HTTPStatusError\"\"\"\n     url = \"https://example.com\"\n \n-    mock_response = Mock(spec=httpx.Response)\n-    mock_response.status_code = 404\n-    mock_response.raise_for_status.side_effect = httpx.HTTPStatusError(\n-        \"404 Not Found\", request=Mock(), response=mock_response\n-    )\n-\n-    mock_client = AsyncMock(spec=httpx.AsyncClient)\n-    mock_client.__aenter__.return_value.get.return_value = mock_response\n-\n-    with patch(\"httpx.AsyncClient\", return_value=mock_client):\n+    with patch(\n+        \"agno.document.reader.url_reader.async_fetch_with_retry\",\n+        side_effect=httpx.HTTPStatusError(\"404 Not Found\", request=Mock(), response=Mock()),\n+    ):\n         reader = URLReader()\n         with pytest.raises(httpx.HTTPStatusError):\n             await reader.async_read(url)\n \n \n @pytest.mark.asyncio\n-async def test_async_chunking():\n+async def test_async_chunking(mock_response):\n     \"\"\"Test async document chunking functionality\"\"\"\n     url = \"https://example.com\"\n-\n-    mock_response = Mock(spec=httpx.Response)\n-    mock_response.status_code = 200\n     mock_response.text = \"Hello, world! \" * 1000\n \n-    mock_client = AsyncMock(spec=httpx.AsyncClient)\n-    mock_client.__aenter__.return_value.get.return_value = mock_response\n-\n-    with patch(\"httpx.AsyncClient\", return_value=mock_client):\n+    with patch(\"agno.document.reader.url_reader.async_fetch_with_retry\", return_value=mock_response):\n         reader = URLReader()\n         reader.chunk = True\n         reader.chunking_strategy = FixedSizeChunking(chunk_size=100)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/tools/test_crawl4ai.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_crawl4ai.py b/libs/agno/tests/unit/tools/test_crawl4ai.py\nnew file mode 100644\nindex 000000000..865fd76ef\n--- /dev/null\n+++ b/libs/agno/tests/unit/tools/test_crawl4ai.py\n@@ -0,0 +1,347 @@\n+\"\"\"Unit tests for Crawl4aiTools class.\"\"\"\n+\n+from unittest.mock import AsyncMock, MagicMock, patch\n+\n+import pytest\n+\n+from agno.tools.crawl4ai import Crawl4aiTools\n+\n+\n+@pytest.fixture\n+def mock_async_crawler():\n+    \"\"\"Create a mock AsyncWebCrawler.\"\"\"\n+    with patch(\"agno.tools.crawl4ai.AsyncWebCrawler\") as mock_crawler:\n+        mock_instance = AsyncMock()\n+        mock_crawler.return_value.__aenter__.return_value = mock_instance\n+        yield mock_instance\n+\n+\n+@pytest.fixture\n+def mock_browser_config():\n+    \"\"\"Create a mock BrowserConfig.\"\"\"\n+    with patch(\"agno.tools.crawl4ai.BrowserConfig\") as mock_config:\n+        mock_instance = MagicMock()\n+        mock_config.return_value = mock_instance\n+        yield mock_config\n+\n+\n+@pytest.fixture\n+def mock_crawler_run_config():\n+    \"\"\"Create a mock CrawlerRunConfig.\"\"\"\n+    with patch(\"agno.tools.crawl4ai.CrawlerRunConfig\") as mock_config:\n+        yield mock_config\n+\n+\n+@pytest.fixture\n+def crawl4ai_tools():\n+    \"\"\"Create a Crawl4aiTools instance with default settings.\"\"\"\n+    with patch(\"agno.tools.crawl4ai.AsyncWebCrawler\"), patch(\"agno.tools.crawl4ai.BrowserConfig\"), patch(\n+        \"agno.tools.crawl4ai.CrawlerRunConfig\"\n+    ):\n+        return Crawl4aiTools()\n+\n+\n+@pytest.fixture\n+def custom_crawl4ai_tools():\n+    \"\"\"Create a Crawl4aiTools instance with custom settings.\"\"\"\n+    with patch(\"agno.tools.crawl4ai.AsyncWebCrawler\"), patch(\"agno.tools.crawl4ai.BrowserConfig\"), patch(\n+        \"agno.tools.crawl4ai.CrawlerRunConfig\"\n+    ):\n+        return Crawl4aiTools(\n+            max_length=2000,\n+            timeout=30,\n+            use_pruning=True,\n+            pruning_threshold=0.6,\n+            bm25_threshold=2.0,\n+            wait_until=\"networkidle\",\n+            headless=False,\n+        )\n+\n+\n+def create_mock_crawler_result(\n+    raw_markdown: str = \"This is the extracted content from the webpage.\",\n+    fit_markdown: str = None,\n+    html: str = \"<html><body>Test content</body></html>\",\n+    text: str = \"Test text content\",\n+    success: bool = True,\n+):\n+    \"\"\"Helper function to create mock crawler result.\"\"\"\n+    result = MagicMock()\n+    if raw_markdown:\n+        result.markdown = MagicMock()\n+        result.markdown.raw_markdown = raw_markdown\n+    else:\n+        result.markdown = None\n+    result.fit_markdown = fit_markdown\n+    result.html = html\n+    result.text = text\n+    result.success = success\n+    return result\n+\n+\n+def test_initialization_default(crawl4ai_tools):\n+    \"\"\"Test initialization with default values.\"\"\"\n+    assert crawl4ai_tools.name == \"crawl4ai_tools\"\n+    assert crawl4ai_tools.max_length == 5000\n+    assert crawl4ai_tools.timeout == 60\n+    assert crawl4ai_tools.use_pruning is False\n+    assert crawl4ai_tools.pruning_threshold == 0.48\n+    assert crawl4ai_tools.bm25_threshold == 1.0\n+    assert crawl4ai_tools.wait_until == \"domcontentloaded\"\n+    assert crawl4ai_tools.headless is True\n+\n+    # Check registered functions\n+    function_names = [func.name for func in crawl4ai_tools.functions.values()]\n+    assert \"crawl\" in function_names\n+    assert len(crawl4ai_tools.functions) == 1\n+\n+\n+def test_initialization_custom(custom_crawl4ai_tools):\n+    \"\"\"Test initialization with custom values.\"\"\"\n+    assert custom_crawl4ai_tools.max_length == 2000\n+    assert custom_crawl4ai_tools.timeout == 30\n+    assert custom_crawl4ai_tools.use_pruning is True\n+    assert custom_crawl4ai_tools.pruning_threshold == 0.6\n+    assert custom_crawl4ai_tools.bm25_threshold == 2.0\n+    assert custom_crawl4ai_tools.wait_until == \"networkidle\"\n+    assert custom_crawl4ai_tools.headless is False\n+\n+\n+def test_crawl_no_url(crawl4ai_tools):\n+    \"\"\"Test crawl with no URL provided.\"\"\"\n+    result = crawl4ai_tools.crawl(\"\")\n+    assert result == \"Error: No URL provided\"\n+\n+    result = crawl4ai_tools.crawl([])\n+    assert result == \"Error: No URL provided\"\n+\n+\n+def test_crawl_single_url_success(crawl4ai_tools, mock_async_crawler, mock_browser_config, mock_crawler_run_config):\n+    \"\"\"Test successful crawling of a single URL.\"\"\"\n+    # Setup mock result\n+    mock_result = create_mock_crawler_result()\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Assert\n+    assert result == \"This is the extracted content from the webpage.\"\n+    mock_browser_config.assert_called_once_with(headless=True, verbose=False)\n+    mock_crawler_run_config.assert_called_once()\n+\n+    # Check config parameters\n+    config_call_args = mock_crawler_run_config.call_args[1]\n+    assert config_call_args[\"page_timeout\"] == 60000  # 60 seconds in milliseconds\n+    assert config_call_args[\"wait_until\"] == \"domcontentloaded\"\n+    assert config_call_args[\"cache_mode\"] == \"bypass\"\n+    assert config_call_args[\"verbose\"] is False\n+\n+\n+def test_crawl_with_search_query(crawl4ai_tools, mock_async_crawler, mock_browser_config, mock_crawler_run_config):\n+    \"\"\"Test crawling with search query for content filtering.\"\"\"\n+    # Setup mock result\n+    mock_result = create_mock_crawler_result()\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Mock the imports that happen inside _build_config\n+    with patch(\"crawl4ai.content_filter_strategy.BM25ContentFilter\") as mock_bm25, patch(\n+        \"crawl4ai.markdown_generation_strategy.DefaultMarkdownGenerator\"\n+    ) as mock_markdown_gen:\n+        # Execute with search query\n+        result = crawl4ai_tools.crawl(\"https://example.com\", search_query=\"machine learning\")\n+\n+        # Assert\n+        assert result == \"This is the extracted content from the webpage.\"\n+\n+        # Verify BM25 content filter is used\n+        mock_bm25.assert_called_once_with(user_query=\"machine learning\", bm25_threshold=1.0)\n+        mock_markdown_gen.assert_called_once()\n+\n+\n+def test_crawl_with_fit_markdown(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test crawling when fit_markdown is available.\"\"\"\n+    # Setup mock result with fit_markdown\n+    mock_result = create_mock_crawler_result(\n+        raw_markdown=\"This is the raw content.\", fit_markdown=\"This is the filtered content.\"\n+    )\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Should return fit_markdown when available\n+    assert result == \"This is the filtered content.\"\n+\n+\n+def test_crawl_length_truncation(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test content truncation when exceeding max_length.\"\"\"\n+    # Setup mock with long content\n+    mock_result = create_mock_crawler_result(raw_markdown=\"A\" * 10000)\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Assert truncation\n+    assert len(result) == 5003  # 5000 + \"...\"\n+    assert result.endswith(\"...\")\n+    assert result[:5000] == \"A\" * 5000\n+\n+\n+def test_crawl_multiple_urls(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test crawling multiple URLs.\"\"\"\n+    # Setup different results for each URL\n+    results = [\n+        create_mock_crawler_result(raw_markdown=\"Content from site 1\"),\n+        create_mock_crawler_result(raw_markdown=\"Content from site 2\"),\n+    ]\n+\n+    # Configure arun to return different results\n+    call_count = 0\n+\n+    async def mock_arun(url, config):\n+        nonlocal call_count\n+        result = results[call_count]\n+        call_count += 1\n+        return result\n+\n+    mock_async_crawler.arun = mock_arun\n+\n+    # Execute\n+    urls = [\"https://site1.com\", \"https://site2.com\"]\n+    result = crawl4ai_tools.crawl(urls)\n+\n+    # Assert\n+    assert isinstance(result, dict)\n+    assert len(result) == 2\n+    assert result[\"https://site1.com\"] == \"Content from site 1\"\n+    assert result[\"https://site2.com\"] == \"Content from site 2\"\n+\n+\n+def test_crawl_error_handling(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test error handling during crawl.\"\"\"\n+    mock_async_crawler.arun = AsyncMock(side_effect=Exception(\"Network error\"))\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Assert error message\n+    assert \"Error crawling https://example.com: Network error\" in result\n+\n+\n+def test_crawl_no_content(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test handling of empty results.\"\"\"\n+    mock_async_crawler.arun = AsyncMock(return_value=None)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Assert\n+    assert result == \"Error: No content found\"\n+\n+\n+def test_crawl_text_fallback(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test fallback to text when markdown is not available.\"\"\"\n+    # Create result with only text\n+    mock_result = create_mock_crawler_result(raw_markdown=None, text=\"Plain text content\")\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Should fall back to text\n+    assert result == \"Plain text content\"\n+\n+\n+def test_crawl_no_readable_content(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test error when no readable content is available.\"\"\"\n+    # Create result with only HTML\n+    mock_result = create_mock_crawler_result(raw_markdown=None, text=None, html=\"<html><body>Test</body></html>\")\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Should return error\n+    assert result == \"Error: No readable content extracted\"\n+\n+\n+def test_pruning_configuration(mock_async_crawler, mock_browser_config, mock_crawler_run_config):\n+    \"\"\"Test pruning filter configuration.\"\"\"\n+    # Mock the imports that happen inside _build_config\n+    with patch(\"crawl4ai.content_filter_strategy.PruningContentFilter\") as mock_pruning, patch(\n+        \"crawl4ai.markdown_generation_strategy.DefaultMarkdownGenerator\"\n+    ) as mock_markdown_gen:\n+        # Create toolkit with pruning enabled\n+        toolkit = Crawl4aiTools(use_pruning=True, pruning_threshold=0.6)\n+\n+        # Setup mock result\n+        mock_result = create_mock_crawler_result()\n+        mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+        # Execute\n+        result = toolkit.crawl(\"https://example.com\")\n+\n+        # Assert\n+        assert result == \"This is the extracted content from the webpage.\"\n+\n+        # Verify pruning filter is used\n+        mock_pruning.assert_called_once_with(threshold=0.6, threshold_type=\"fixed\", min_word_threshold=2)\n+        mock_markdown_gen.assert_called_once()\n+\n+\n+def test_crawl_with_multiple_urls_and_errors(crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test crawling multiple URLs with some failures.\"\"\"\n+    # Configure arun to fail for second URL\n+    call_count = 0\n+\n+    async def mock_arun(url, config):\n+        nonlocal call_count\n+        call_count += 1\n+        if call_count == 2:\n+            raise Exception(\"Connection failed\")\n+        return create_mock_crawler_result(raw_markdown=f\"Content from {url}\")\n+\n+    mock_async_crawler.arun = mock_arun\n+\n+    # Execute\n+    urls = [\"https://success.com\", \"https://fail.com\"]\n+    result = crawl4ai_tools.crawl(urls)\n+\n+    # Assert\n+    assert \"Content from https://success.com\" in result[\"https://success.com\"]\n+    assert \"Error crawling https://fail.com: Connection failed\" in result[\"https://fail.com\"]\n+\n+\n+@patch(\"agno.tools.crawl4ai.log_warning\")\n+def test_crawl_logging(mock_log_warning, crawl4ai_tools, mock_async_crawler):\n+    \"\"\"Test logging during crawl operations.\"\"\"\n+    # Setup result with only HTML (no markdown, no text)\n+    mock_result = create_mock_crawler_result(raw_markdown=None, text=None, html=\"<html><body>Test</body></html>\")\n+    # Make sure result has html attribute but not text attribute\n+    mock_result.text = None\n+    delattr(mock_result, \"text\")  # Remove the text attribute entirely\n+    mock_result.html = \"<html><body>Test</body></html>\"\n+\n+    mock_async_crawler.arun = AsyncMock(return_value=mock_result)\n+\n+    # Execute\n+    result = crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    # Check that error is returned and log was called\n+    assert result == \"Error: Could not extract markdown from page\"\n+\n+    # Check warning was logged\n+    mock_log_warning.assert_called_once_with(\"Only HTML available, no markdown extracted\")\n+\n+\n+@patch(\"agno.tools.crawl4ai.asyncio.run\")\n+def test_asyncio_run_error(mock_asyncio_run, crawl4ai_tools):\n+    \"\"\"Test handling of asyncio.run errors.\"\"\"\n+    mock_asyncio_run.side_effect = RuntimeError(\"Event loop error\")\n+\n+    with pytest.raises(RuntimeError) as excinfo:\n+        crawl4ai_tools.crawl(\"https://example.com\")\n+\n+    assert \"Event loop error\" in str(excinfo.value)\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/tools/test_gmail_tools.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_gmail_tools.py b/libs/agno/tests/unit/tools/test_gmail_tools.py\nindex c686ce1ee..c829e1019 100644\n--- a/libs/agno/tests/unit/tools/test_gmail_tools.py\n+++ b/libs/agno/tests/unit/tools/test_gmail_tools.py\n@@ -3,7 +3,7 @@\n import base64\n from datetime import datetime\n from typing import Any, Dict\n-from unittest.mock import MagicMock, Mock, patch\n+from unittest.mock import MagicMock, Mock, mock_open, patch\n \n import pytest\n from google.oauth2.credentials import Credentials\n@@ -488,3 +488,228 @@ def test_service_initialization():\n         with patch.object(tools, \"_auth\"):\n             tools.get_latest_emails(count=1)\n             mock_build.assert_called_once_with(\"gmail\", \"v1\", credentials=mock_creds)\n+\n+\n+def test_send_email_with_single_attachment(gmail_tools, mock_gmail_service):\n+    \"\"\"Test sending email with a single attachment.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"application/pdf\", None)):\n+                result = gmail_tools.send_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"With Attachment\",\n+                    body=\"Email with attachment\",\n+                    attachments=\"test.pdf\",\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_send_email_with_multiple_attachments(gmail_tools, mock_gmail_service):\n+    \"\"\"Test sending email with multiple attachments.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"application/pdf\", None)):\n+                result = gmail_tools.send_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"Multiple Attachments\",\n+                    body=\"Email with multiple attachments\",\n+                    attachments=[\"test1.pdf\", \"test2.pdf\"],\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_create_draft_with_attachment(gmail_tools, mock_gmail_service):\n+    \"\"\"Test creating draft email with attachment.\"\"\"\n+    mock_draft_response = {\"id\": \"draft123\", \"message\": {\"id\": \"msg123\"}}\n+    mock_gmail_service.users().drafts().create().execute.return_value = mock_draft_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"text/plain\", None)):\n+                result = gmail_tools.create_draft_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"Draft with Attachment\",\n+                    body=\"Draft with attachment\",\n+                    attachments=\"document.txt\",\n+                )\n+\n+    assert \"draft123\" in result\n+    mock_gmail_service.users().drafts().create.assert_called_once()\n+\n+\n+def test_send_email_reply_with_attachment(gmail_tools, mock_gmail_service):\n+    \"\"\"Test sending email reply with attachment.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"image/jpeg\", None)):\n+                result = gmail_tools.send_email_reply(\n+                    thread_id=\"thread123\",\n+                    message_id=\"msg456\",\n+                    to=\"recipient@test.com\",\n+                    subject=\"Reply with Attachment\",\n+                    body=\"Reply with attachment\",\n+                    attachments=\"image.jpg\",\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_send_email_attachment_file_not_found(gmail_tools, mock_gmail_service):\n+    \"\"\"Test error handling when attachment file doesn't exist.\"\"\"\n+    with patch(\"pathlib.Path.exists\", return_value=False):\n+        with pytest.raises(ValueError, match=\"Attachment file not found\"):\n+            gmail_tools.send_email(\n+                to=\"recipient@test.com\", subject=\"Test\", body=\"Test body\", attachments=\"nonexistent.pdf\"\n+            )\n+\n+\n+def test_create_draft_attachment_file_not_found(gmail_tools, mock_gmail_service):\n+    \"\"\"Test error handling when draft attachment file doesn't exist.\"\"\"\n+    with patch(\"pathlib.Path.exists\", return_value=False):\n+        with pytest.raises(ValueError, match=\"Attachment file not found\"):\n+            gmail_tools.create_draft_email(\n+                to=\"recipient@test.com\", subject=\"Test\", body=\"Test body\", attachments=\"nonexistent.pdf\"\n+            )\n+\n+\n+def test_send_reply_attachment_file_not_found(gmail_tools, mock_gmail_service):\n+    \"\"\"Test error handling when reply attachment file doesn't exist.\"\"\"\n+    with patch(\"pathlib.Path.exists\", return_value=False):\n+        with pytest.raises(ValueError, match=\"Attachment file not found\"):\n+            gmail_tools.send_email_reply(\n+                thread_id=\"thread123\",\n+                message_id=\"msg456\",\n+                to=\"recipient@test.com\",\n+                subject=\"Test\",\n+                body=\"Test body\",\n+                attachments=\"nonexistent.pdf\",\n+            )\n+\n+\n+def test_send_email_mixed_attachment_existence(gmail_tools, mock_gmail_service):\n+    \"\"\"Test error handling when some attachments exist and others don't.\"\"\"\n+\n+    # Create a mock Path class\n+    class MockPath:\n+        def __init__(self, path):\n+            self.path = str(path)\n+\n+        def exists(self):\n+            return self.path.endswith(\"exists.pdf\")\n+\n+    with patch(\"agno.tools.gmail.Path\", MockPath):\n+        with pytest.raises(ValueError, match=\"Attachment file not found\"):\n+            gmail_tools.send_email(\n+                to=\"recipient@test.com\", subject=\"Test\", body=\"Test body\", attachments=[\"exists.pdf\", \"missing.pdf\"]\n+            )\n+\n+\n+def test_attachment_mime_type_guessing(gmail_tools, mock_gmail_service):\n+    \"\"\"Test MIME type guessing for different file types.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    # Test with unknown MIME type (should default to application/octet-stream)\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(None, None)):\n+                result = gmail_tools.send_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"Unknown File Type\",\n+                    body=\"Email with unknown file type\",\n+                    attachments=\"unknown.xyz\",\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_attachment_with_encoding(gmail_tools, mock_gmail_service):\n+    \"\"\"Test attachment handling when MIME type has encoding.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    # Test with encoding present (should default to application/octet-stream)\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"text/plain\", \"gzip\")):\n+                result = gmail_tools.send_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"Encoded File\",\n+                    body=\"Email with encoded file\",\n+                    attachments=\"file.txt.gz\",\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_empty_attachments_list(gmail_tools, mock_gmail_service):\n+    \"\"\"Test sending email with empty attachments list.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    result = gmail_tools.send_email(\n+        to=\"recipient@test.com\", subject=\"No Attachments\", body=\"Email without attachments\", attachments=[]\n+    )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n+\n+\n+def test_attachment_filename_extraction(gmail_tools, mock_gmail_service):\n+    \"\"\"Test that attachment filenames are properly extracted from paths.\"\"\"\n+    mock_send_response = {\"id\": \"msg123\", \"labelIds\": [\"SENT\"]}\n+    mock_gmail_service.users().messages().send().execute.return_value = mock_send_response\n+\n+    # Reset mock to clear any setup calls\n+    mock_gmail_service.reset_mock()\n+\n+    with patch(\"pathlib.Path.exists\", return_value=True):\n+        with patch(\"builtins.open\", mock_open(read_data=b\"fake file content\")):\n+            with patch(\"mimetypes.guess_type\", return_value=(\"application/pdf\", None)):\n+                # Test with full path - should extract just the filename\n+                result = gmail_tools.send_email(\n+                    to=\"recipient@test.com\",\n+                    subject=\"Path Test\",\n+                    body=\"Email with full path attachment\",\n+                    attachments=\"/full/path/to/document.pdf\",\n+                )\n+\n+    assert \"msg123\" in result\n+    mock_gmail_service.users().messages().send.assert_called_once()\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/tools/test_serperdev.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_serperdev.py b/libs/agno/tests/unit/tools/test_serperdev.py\nnew file mode 100644\nindex 000000000..134014964\n--- /dev/null\n+++ b/libs/agno/tests/unit/tools/test_serperdev.py\n@@ -0,0 +1,88 @@\n+import json\n+from unittest.mock import Mock, patch\n+\n+import pytest\n+import requests\n+\n+from agno.tools.serperapi import SerperApiTools\n+\n+\n+@pytest.fixture(autouse=True)\n+def clear_env(monkeypatch):\n+    \"\"\"Ensure SERPER_API_KEY is unset unless explicitly needed.\"\"\"\n+    monkeypatch.delenv(\"SERPER_API_KEY\", raising=False)\n+\n+\n+@pytest.fixture\n+def api_tools():\n+    \"\"\"SerperApiTools with a known API key, custom location, and fewer results for testing.\"\"\"\n+    return SerperApiTools(api_key=\"test_key\", location=\"us\", num_results=5)\n+\n+\n+@pytest.fixture\n+def mock_search_response():\n+    \"\"\"Mock a successful Serper API HTTP response.\"\"\"\n+    mock = Mock(spec=requests.Response)\n+    mock.text = '{\"results\": [{\"title\": \"Test Result\", \"link\": \"http://example.com\"}]}'\n+    return mock\n+\n+\n+def test_init_without_api_key_and_env(monkeypatch):\n+    \"\"\"If no api_key argument and no SERPER_API_KEY in env, api_key should be None.\"\"\"\n+    # Ensure environment has no key\n+    monkeypatch.delenv(\"SERPER_API_KEY\", raising=False)\n+    tools = SerperApiTools()\n+    assert tools.api_key is None\n+\n+\n+def test_init_with_env_var(monkeypatch):\n+    \"\"\"If SERPER_API_KEY is set in the environment, it is picked up.\"\"\"\n+    monkeypatch.setenv(\"SERPER_API_KEY\", \"env_key\")\n+    tools = SerperApiTools(api_key=None)\n+    assert tools.api_key == \"env_key\"\n+\n+\n+def test_search_google_no_api_key():\n+    \"\"\"Calling search_google without any API key returns an error message.\"\"\"\n+    tools = SerperApiTools(api_key=None)\n+    assert tools.search_google(\"anything\") == \"Please provide an API key\"\n+\n+\n+def test_search_google_empty_query(api_tools):\n+    \"\"\"Calling search_google with an empty query returns an error message.\"\"\"\n+    assert api_tools.search_google(\"\") == \"Please provide a query to search for\"\n+\n+\n+def test_search_google_success_default_location(api_tools, mock_search_response):\n+    \"\"\"A successful search should return the raw response.text and call requests.request correctly.\"\"\"\n+    with patch(\"requests.request\", return_value=mock_search_response) as mock_req:\n+        result = api_tools.search_google(\"pytest testing\")\n+        assert result == mock_search_response.text\n+\n+        mock_req.assert_called_once_with(\n+            \"POST\",\n+            \"https://google.serper.dev/search\",\n+            headers={\"X-API-KEY\": \"test_key\", \"Content-Type\": \"application/json\"},\n+            data=json.dumps({\"q\": \"pytest testing\", \"num\": 5, \"gl\": \"us\"}),\n+        )\n+\n+\n+def test_search_google_success_override_location(api_tools, mock_search_response):\n+    \"\"\"Overriding the location parameter should be respected in the request payload.\"\"\"\n+    with patch(\"requests.request\", return_value=mock_search_response) as mock_req:\n+        result = api_tools.search_google(\"pytest testing\", location=\"uk\")\n+        assert result == mock_search_response.text\n+\n+        mock_req.assert_called_once_with(\n+            \"POST\",\n+            \"https://google.serper.dev/search\",\n+            headers={\"X-API-KEY\": \"test_key\", \"Content-Type\": \"application/json\"},\n+            data=json.dumps({\"q\": \"pytest testing\", \"num\": 5, \"gl\": \"uk\"}),\n+        )\n+\n+\n+def test_search_google_exception(api_tools):\n+    \"\"\"If requests.request raises, search_google should catch and return an error string.\"\"\"\n+    with patch(\"requests.request\", side_effect=Exception(\"Network failure\")):\n+        result = api_tools.search_google(\"failure test\")\n+        assert \"Error searching for the query failure test: Network failure\" in result\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/tools/test_webtools.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_webtools.py b/libs/agno/tests/unit/tools/test_webtools.py\nnew file mode 100644\nindex 000000000..80015a623\n--- /dev/null\n+++ b/libs/agno/tests/unit/tools/test_webtools.py\n@@ -0,0 +1,33 @@\n+\"\"\"Unit tests for WebTools class.\"\"\"\n+\n+from unittest.mock import Mock, patch\n+\n+import pytest\n+\n+from agno.tools.webtools import WebTools\n+\n+\n+@pytest.fixture\n+def web_tools():\n+    \"\"\"Fixture to create a WebTools instance.\"\"\"\n+    return WebTools(retries=3)\n+\n+\n+def test_expand_url_success(web_tools):\n+    \"\"\"Test successful expansion of a URL.\"\"\"\n+    mock_url = \"https://tinyurl.com/k2fkfxra.\"\n+    final_url = \"https://github.com/agno-agi/agno\"\n+\n+    mock_response = Mock()\n+    mock_response.url = final_url\n+\n+    with patch(\"httpx.head\", return_value=mock_response) as mock_head:\n+        result = web_tools.expand_url(mock_url)\n+\n+    assert result == final_url\n+    mock_head.assert_called_once_with(mock_url, follow_redirects=True, timeout=5)\n+\n+\n+def test_toolkit_registration(web_tools):\n+    \"\"\"Test that the expand_url method is registered correctly.\"\"\"\n+    assert \"expand_url\" in [func.name for func in web_tools.functions.values()]\n"
        },
        {
            "commit": "dc07b7a4e5314d29edb7e9c30d36e12a6dec3dd7",
            "file_path": "libs/agno/tests/unit/tools/test_zep.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_zep.py b/libs/agno/tests/unit/tools/test_zep.py\nindex c1409497d..ec1a9482d 100644\n--- a/libs/agno/tests/unit/tools/test_zep.py\n+++ b/libs/agno/tests/unit/tools/test_zep.py\n@@ -61,6 +61,7 @@ def test_add_zep_message(zep_tools):\n \n def test_add_zep_message_not_initialized():\n     tools = ZepTools(api_key=MOCK_API_KEY)  # Don't initialize\n+    tools.zep_client = None  # Ensure client is None\n     result = tools.add_zep_message(\"user\", \"test message\")\n     assert result == \"Error: Zep client/session not initialized.\"\n \n@@ -68,6 +69,8 @@ def test_add_zep_message_not_initialized():\n def test_get_zep_memory_context(zep_tools):\n     mock_memory = Mock()\n     mock_memory.context = \"test context\"\n+    mock_memory.relevant_facts = None\n+    mock_memory.messages = None\n     zep_tools.zep_client.memory.get.return_value = mock_memory\n \n     result = zep_tools.get_zep_memory(\"context\")\n@@ -75,51 +78,98 @@ def test_get_zep_memory_context(zep_tools):\n     zep_tools.zep_client.memory.get.assert_called_once()\n \n \n-def test_get_zep_memory_summary(zep_tools):\n+def test_get_zep_memory_messages(zep_tools):\n     mock_memory = Mock()\n-    mock_memory.summary = Mock(content=\"test summary\")\n+    mock_memory.messages = [\"msg1\", \"msg2\"]\n     zep_tools.zep_client.memory.get.return_value = mock_memory\n \n-    result = zep_tools.get_zep_memory(\"summary\")\n-    assert result == \"test summary\"\n+    result = zep_tools.get_zep_memory(\"messages\")\n+    assert result == \"['msg1', 'msg2']\"\n+\n+\n+def test_get_zep_memory_relevant_facts(zep_tools):\n+    mock_fact1 = Mock()\n+    mock_fact1.fact = \"fact 1\"\n+    mock_fact2 = Mock()\n+    mock_fact2.fact = \"fact 2\"\n+\n+    mock_memory = Mock()\n+    mock_memory.relevant_facts = [mock_fact1, mock_fact2]\n+    zep_tools.zep_client.memory.get.return_value = mock_memory\n+\n+    result = zep_tools.get_zep_memory(\"relevant_facts\")\n+    assert result == \"Relevant facts:\\n- fact 1\\n- fact 2\"\n+\n+\n+def test_get_zep_memory_unsupported_type(zep_tools):\n+    mock_memory = Mock()\n+    mock_memory.context = \"fallback context\"\n+    zep_tools.zep_client.memory.get.return_value = mock_memory\n+\n+    result = zep_tools.get_zep_memory(\"unsupported\")\n+    assert \"Unsupported memory_type requested: unsupported\" in result\n \n \n def test_get_zep_memory_not_initialized():\n     tools = ZepTools(api_key=MOCK_API_KEY)  # Don't initialize\n+    tools.zep_client = None  # Ensure client is None\n     result = tools.get_zep_memory()\n     assert result == \"Error: Zep client/session not initialized.\"\n \n \n-def test_search_zep_memory(zep_tools):\n-    # Setup mock search response\n-    mock_message = Mock()\n-    mock_message.content = \"test content\"\n-    mock_message.created_at = \"2024-01-01\"\n-    mock_message.uuid_ = \"123\"\n+def test_search_zep_memory_edges(zep_tools):\n+    # Setup mock search response for edges (facts)\n+    mock_edge1 = Mock()\n+    mock_edge1.fact = \"User likes pizza\"\n+    mock_edge2 = Mock()\n+    mock_edge2.fact = \"User lives in NYC\"\n \n     mock_response = Mock()\n-    mock_response.message = mock_message\n-    mock_response.score = 0.9\n+    mock_response.edges = [mock_edge1, mock_edge2]\n+    mock_response.nodes = None\n \n-    zep_tools.zep_client.memory.search.return_value = [mock_response]\n+    zep_tools.zep_client.graph.search.return_value = mock_response\n \n-    result = zep_tools.search_zep_memory(\"test query\")\n-    assert result == \"test content\"\n-    zep_tools.zep_client.memory.search.assert_called_once_with(\n-        text=\"test query\", session_id=MOCK_SESSION_ID, search_scope=\"messages\"\n-    )\n+    result = zep_tools.search_zep_memory(\"test query\", search_scope=\"edges\")\n+    assert result == \"Found 2 facts:\\n- User likes pizza\\n- User lives in NYC\"\n+    zep_tools.zep_client.graph.search.assert_called_once_with(query=\"test query\", user_id=MOCK_USER_ID, scope=\"edges\")\n+\n+\n+def test_search_zep_memory_nodes(zep_tools):\n+    # Setup mock search response for nodes\n+    mock_node1 = Mock()\n+    mock_node1.name = \"John\"\n+    mock_node1.summary = \"Software engineer\"\n+    mock_node2 = Mock()\n+    mock_node2.name = \"NYC\"\n+    mock_node2.summary = \"Major city in New York\"\n+\n+    mock_response = Mock()\n+    mock_response.edges = None\n+    mock_response.nodes = [mock_node1, mock_node2]\n+\n+    zep_tools.zep_client.graph.search.return_value = mock_response\n+\n+    result = zep_tools.search_zep_memory(\"test query\", search_scope=\"nodes\")\n+    assert result == \"Found 2 nodes:\\n- John: Software engineer\\n- NYC: Major city in New York\"\n+    zep_tools.zep_client.graph.search.assert_called_once_with(query=\"test query\", user_id=MOCK_USER_ID, scope=\"nodes\")\n \n \n def test_search_zep_memory_no_results(zep_tools):\n-    zep_tools.zep_client.memory.search.return_value = []\n+    mock_response = Mock()\n+    mock_response.edges = []\n+    mock_response.nodes = []\n+\n+    zep_tools.zep_client.graph.search.return_value = mock_response\n     result = zep_tools.search_zep_memory(\"test query\")\n-    assert result == \"No relevant messages found.\"\n+    assert result == \"No edges found for query: test query\"\n \n \n def test_search_zep_memory_not_initialized():\n     tools = ZepTools(api_key=MOCK_API_KEY)  # Don't initialize\n+    tools.zep_client = None  # Ensure client is None\n     result = tools.search_zep_memory(\"test query\")\n-    assert result == \"Error: Zep client/user/session not initialized.\"\n+    assert result == \"Error: Zep client/user not initialized.\"\n \n \n # Async Tests\n@@ -179,20 +229,21 @@ async def test_async_get_zep_memory(async_zep_tools):\n \n \n @pytest.mark.asyncio\n-async def test_async_search_zep_memory(async_zep_tools):\n-    mock_message = Mock()\n-    mock_message.content = \"test content\"\n-    mock_message.created_at = \"2024-01-01\"\n-    mock_message.uuid_ = \"123\"\n+async def test_async_search_zep_memory_edges(async_zep_tools):\n+    # Setup mock search response for edges (facts)\n+    mock_edge1 = Mock()\n+    mock_edge1.fact = \"User likes pizza\"\n+    mock_edge2 = Mock()\n+    mock_edge2.fact = \"User lives in NYC\"\n \n     mock_response = Mock()\n-    mock_response.message = mock_message\n-    mock_response.score = 0.9\n+    mock_response.edges = [mock_edge1, mock_edge2]\n+    mock_response.nodes = None\n \n-    async_zep_tools.zep_client.memory.search.return_value = [mock_response]\n+    async_zep_tools.zep_client.graph.search.return_value = mock_response\n \n-    result = await async_zep_tools.search_zep_memory(\"test query\")\n-    assert result == \"test content\"\n-    async_zep_tools.zep_client.memory.search.assert_called_once_with(\n-        text=\"test query\", session_id=MOCK_SESSION_ID, search_scope=\"messages\"\n+    result = await async_zep_tools.search_zep_memory(\"test query\", scope=\"edges\")\n+    assert result == \"Found 2 facts:\\n- User likes pizza\\n- User lives in NYC\"\n+    async_zep_tools.zep_client.graph.search.assert_called_once_with(\n+        query=\"test query\", user_id=MOCK_USER_ID, scope=\"edges\", limit=5\n     )\n"
        }
    ]
}