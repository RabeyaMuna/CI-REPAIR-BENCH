{
    "sha_fail": "df5e9e422993a051ab7e2fc7b1dc70485a40c7d3",
    "changed_files": [
        {
            "commit": "df5e9e422993a051ab7e2fc7b1dc70485a40c7d3",
            "file_path": "facefusion/workflows/audio_to_image.py",
            "diff": "diff --git a/facefusion/workflows/audio_to_image.py b/facefusion/workflows/audio_to_image.py\nindex 785781a..f7168b7 100644\n--- a/facefusion/workflows/audio_to_image.py\n+++ b/facefusion/workflows/audio_to_image.py\n@@ -2,20 +2,19 @@ import os\n from concurrent.futures import ThreadPoolExecutor, as_completed\n from functools import partial\n \n-import numpy\n from tqdm import tqdm\n \n from facefusion import ffmpeg, logger, process_manager, state_manager, translator\n-from facefusion.audio import count_audio_frame_total, create_empty_audio_frame, get_audio_frame, get_voice_frame\n+from facefusion.audio import count_audio_frame_total\n from facefusion.common_helper import get_first\n from facefusion.content_analyser import analyse_image\n from facefusion.filesystem import filter_audio_paths, is_video, move_file\n from facefusion.processors.core import get_processors_modules\n-from facefusion.temp_helper import clear_temp_directory, create_temp_directory, get_temp_file_path, get_temp_frame_sequence_paths\n+from facefusion.temp_helper import clear_temp_directory, get_temp_file_path, get_temp_frame_sequence_paths\n from facefusion.time_helper import calculate_end_time\n from facefusion.types import ErrorCode\n-from facefusion.vision import conditional_merge_vision_mask, detect_image_resolution, extract_vision_mask, pack_resolution, read_static_image, read_static_images, restrict_image_resolution, scale_resolution, write_image\n-from facefusion.workflows.core import is_process_stopping\n+from facefusion.vision import detect_image_resolution, pack_resolution, restrict_image_resolution, scale_resolution\n+from facefusion.workflows.core import conditional_process_temp_frame, is_process_stopping, prepare_temp\n \n \n def process(start_time : float) -> ErrorCode:\n@@ -45,10 +44,7 @@ def setup() -> ErrorCode:\n \tif analyse_image(state_manager.get_item('target_path')):\n \t\treturn 3\n \n-\tlogger.debug(translator.get('clearing_temp'), __name__)\n-\tclear_temp_directory(state_manager.get_item('target_path'))\n-\tlogger.debug(translator.get('creating_temp'), __name__)\n-\tcreate_temp_directory(state_manager.get_item('target_path'))\n+\tprepare_temp()\n \treturn 0\n \n \n@@ -80,7 +76,7 @@ def process_frames() -> ErrorCode:\n \t\t\t\tfutures = []\n \n \t\t\t\tfor frame_number, temp_frame_path in enumerate(temp_frame_paths):\n-\t\t\t\t\tfuture = executor.submit(process_temp_frame, temp_frame_path, frame_number, output_video_fps)\n+\t\t\t\t\tfuture = executor.submit(conditional_process_temp_frame, temp_frame_path, frame_number, output_video_fps)\n \t\t\t\t\tfutures.append(future)\n \n \t\t\t\tfor future in as_completed(futures):\n@@ -103,38 +99,6 @@ def process_frames() -> ErrorCode:\n \treturn 0\n \n \n-def process_temp_frame(temp_frame_path : str, frame_number : int, output_video_fps : float) -> bool:\n-\ttemp_image_path = get_temp_file_path(state_manager.get_item('target_path'))\n-\treference_vision_frame = read_static_image(temp_image_path)\n-\tsource_vision_frames = read_static_images(state_manager.get_item('source_paths'))\n-\tsource_audio_path = get_first(filter_audio_paths(state_manager.get_item('source_paths')))\n-\ttarget_vision_frame = read_static_image(temp_image_path, 'rgba')\n-\ttemp_vision_frame = target_vision_frame.copy()\n-\ttemp_vision_mask = extract_vision_mask(temp_vision_frame)\n-\tsource_audio_frame = get_audio_frame(source_audio_path, output_video_fps, frame_number)\n-\tsource_voice_frame = get_voice_frame(source_audio_path, output_video_fps, frame_number)\n-\n-\tif not numpy.any(source_audio_frame):\n-\t\tsource_audio_frame = create_empty_audio_frame()\n-\tif not numpy.any(source_voice_frame):\n-\t\tsource_voice_frame = create_empty_audio_frame()\n-\n-\tfor processor_module in get_processors_modules(state_manager.get_item('processors')):\n-\t\ttemp_vision_frame, temp_vision_mask = processor_module.process_frame(\n-\t\t{\n-\t\t\t'reference_vision_frame': reference_vision_frame,\n-\t\t\t'source_vision_frames': source_vision_frames,\n-\t\t\t'source_audio_frame': source_audio_frame,\n-\t\t\t'source_voice_frame': source_voice_frame,\n-\t\t\t'target_vision_frame': target_vision_frame[:, :, :3],\n-\t\t\t'temp_vision_frame': temp_vision_frame[:, :, :3],\n-\t\t\t'temp_vision_mask': temp_vision_mask\n-\t\t})\n-\n-\ttemp_vision_frame = conditional_merge_vision_mask(temp_vision_frame, temp_vision_mask)\n-\treturn write_image(temp_frame_path, temp_vision_frame)\n-\n-\n def merge_video() -> ErrorCode:\n \ttarget_path = state_manager.get_item('target_path')\n \toutput_video_fps = state_manager.get_item('output_video_fps')\n"
        },
        {
            "commit": "df5e9e422993a051ab7e2fc7b1dc70485a40c7d3",
            "file_path": "facefusion/workflows/core.py",
            "diff": "diff --git a/facefusion/workflows/core.py b/facefusion/workflows/core.py\nindex 003c7e2..e91501e 100644\n--- a/facefusion/workflows/core.py\n+++ b/facefusion/workflows/core.py\n@@ -1,4 +1,13 @@\n-from facefusion import logger, process_manager, translator\n+import numpy\n+\n+from facefusion import logger, process_manager, state_manager, translator\n+from facefusion.audio import create_empty_audio_frame, get_audio_frame, get_voice_frame\n+from facefusion.common_helper import get_first\n+from facefusion.filesystem import filter_audio_paths, is_video\n+from facefusion.processors.core import get_processors_modules\n+from facefusion.temp_helper import clear_temp_directory, create_temp_directory\n+from facefusion.temp_helper import get_temp_file_path\n+from facefusion.vision import conditional_merge_vision_mask, extract_vision_mask, read_static_image, read_static_images, read_static_video_frame, write_image\n \n \n def is_process_stopping() -> bool:\n@@ -6,3 +15,47 @@ def is_process_stopping() -> bool:\n \t\tprocess_manager.end()\n \t\tlogger.info(translator.get('processing_stopped'), __name__)\n \treturn process_manager.is_pending()\n+\n+\n+def conditional_process_temp_frame(temp_frame_path : str, frame_number : int, output_video_fps : float) -> bool:\n+\tsource_vision_frames = read_static_images(state_manager.get_item('source_paths'))\n+\tsource_audio_path = get_first(filter_audio_paths(state_manager.get_item('source_paths')))\n+\ttarget_vision_frame = read_static_image(temp_frame_path, 'rgba')\n+\ttemp_vision_frame = target_vision_frame.copy()\n+\ttemp_vision_mask = extract_vision_mask(temp_vision_frame)\n+\n+\tif is_video(state_manager.get_item('target_path')):\n+\t\treference_vision_frame = read_static_video_frame(state_manager.get_item('target_path'), state_manager.get_item('reference_frame_number'))\n+\telse:\n+\t\ttemp_image_path = get_temp_file_path(state_manager.get_item('target_path'))\n+\t\treference_vision_frame = read_static_image(temp_image_path)\n+\n+\tsource_audio_frame = get_audio_frame(source_audio_path, output_video_fps, frame_number)\n+\tsource_voice_frame = get_voice_frame(source_audio_path, output_video_fps, frame_number)\n+\n+\tif not numpy.any(source_audio_frame):\n+\t\tsource_audio_frame = create_empty_audio_frame()\n+\tif not numpy.any(source_voice_frame):\n+\t\tsource_voice_frame = create_empty_audio_frame()\n+\n+\tfor processor_module in get_processors_modules(state_manager.get_item('processors')):\n+\t\ttemp_vision_frame, temp_vision_mask = processor_module.process_frame(\n+\t\t{\n+\t\t\t'reference_vision_frame': reference_vision_frame,\n+\t\t\t'source_vision_frames': source_vision_frames,\n+\t\t\t'source_audio_frame': source_audio_frame,\n+\t\t\t'source_voice_frame': source_voice_frame,\n+\t\t\t'target_vision_frame': target_vision_frame[:, :, :3],\n+\t\t\t'temp_vision_frame': temp_vision_frame[:, :, :3],\n+\t\t\t'temp_vision_mask': temp_vision_mask\n+\t\t})\n+\n+\ttemp_vision_frame = conditional_merge_vision_mask(temp_vision_frame, temp_vision_mask)\n+\treturn write_image(temp_frame_path, temp_vision_frame)\n+\n+\n+def prepare_temp() -> None:\n+\tlogger.debug(translator.get('clearing_temp'), __name__)\n+\tclear_temp_directory(state_manager.get_item('target_path'))\n+\tlogger.debug(translator.get('creating_temp'), __name__)\n+\tcreate_temp_directory(state_manager.get_item('target_path'))\n"
        },
        {
            "commit": "df5e9e422993a051ab7e2fc7b1dc70485a40c7d3",
            "file_path": "facefusion/workflows/image_to_image.py",
            "diff": "diff --git a/facefusion/workflows/image_to_image.py b/facefusion/workflows/image_to_image.py\nindex f1df279..479aad9 100644\n--- a/facefusion/workflows/image_to_image.py\n+++ b/facefusion/workflows/image_to_image.py\n@@ -6,11 +6,11 @@ from facefusion.audio import create_empty_audio_frame\n from facefusion.content_analyser import analyse_image\n from facefusion.filesystem import is_image\n from facefusion.processors.core import get_processors_modules\n-from facefusion.temp_helper import clear_temp_directory, create_temp_directory, get_temp_file_path\n+from facefusion.temp_helper import clear_temp_directory, get_temp_file_path\n from facefusion.time_helper import calculate_end_time\n from facefusion.types import ErrorCode\n from facefusion.vision import conditional_merge_vision_mask, detect_image_resolution, extract_vision_mask, pack_resolution, read_static_image, read_static_images, restrict_image_resolution, scale_resolution, write_image\n-from facefusion.workflows.core import is_process_stopping\n+from facefusion.workflows.core import is_process_stopping, prepare_temp\n \n \n def process(start_time : float) -> ErrorCode:\n@@ -38,10 +38,7 @@ def setup() -> ErrorCode:\n \tif analyse_image(state_manager.get_item('target_path')):\n \t\treturn 3\n \n-\tlogger.debug(translator.get('clearing_temp'), __name__)\n-\tclear_temp_directory(state_manager.get_item('target_path'))\n-\tlogger.debug(translator.get('creating_temp'), __name__)\n-\tcreate_temp_directory(state_manager.get_item('target_path'))\n+\tprepare_temp()\n \treturn 0\n \n \n"
        },
        {
            "commit": "df5e9e422993a051ab7e2fc7b1dc70485a40c7d3",
            "file_path": "facefusion/workflows/image_to_video.py",
            "diff": "diff --git a/facefusion/workflows/image_to_video.py b/facefusion/workflows/image_to_video.py\nindex f247854..a9f0e24 100644\n--- a/facefusion/workflows/image_to_video.py\n+++ b/facefusion/workflows/image_to_video.py\n@@ -1,21 +1,19 @@\n from concurrent.futures import ThreadPoolExecutor, as_completed\n from functools import partial\n \n-import numpy\n from tqdm import tqdm\n \n from facefusion import ffmpeg\n from facefusion import logger, process_manager, state_manager, translator, video_manager\n-from facefusion.audio import create_empty_audio_frame, get_audio_frame, get_voice_frame\n from facefusion.common_helper import get_first\n from facefusion.content_analyser import analyse_video\n from facefusion.filesystem import filter_audio_paths, is_video\n from facefusion.processors.core import get_processors_modules\n-from facefusion.temp_helper import clear_temp_directory, create_temp_directory, move_temp_file, resolve_temp_frame_paths\n+from facefusion.temp_helper import clear_temp_directory, move_temp_file, resolve_temp_frame_paths\n from facefusion.time_helper import calculate_end_time\n from facefusion.types import ErrorCode\n-from facefusion.vision import conditional_merge_vision_mask, detect_video_resolution, extract_vision_mask, pack_resolution, read_static_image, read_static_images, read_static_video_frame, restrict_trim_frame, restrict_video_fps, restrict_video_resolution, scale_resolution, write_image\n-from facefusion.workflows.core import is_process_stopping\n+from facefusion.vision import detect_video_resolution, pack_resolution, restrict_trim_frame, restrict_video_fps, restrict_video_resolution, scale_resolution\n+from facefusion.workflows.core import conditional_process_temp_frame, is_process_stopping, prepare_temp\n \n \n def process(start_time : float) -> ErrorCode:\n@@ -47,10 +45,7 @@ def setup() -> ErrorCode:\n \tif analyse_video(state_manager.get_item('target_path'), trim_frame_start, trim_frame_end):\n \t\treturn 3\n \n-\tlogger.debug(translator.get('clearing_temp'), __name__)\n-\tclear_temp_directory(state_manager.get_item('target_path'))\n-\tlogger.debug(translator.get('creating_temp'), __name__)\n-\tcreate_temp_directory(state_manager.get_item('target_path'))\n+\tprepare_temp()\n \treturn 0\n \n \n@@ -73,6 +68,7 @@ def extract_frames() -> ErrorCode:\n \n def process_video() -> ErrorCode:\n \ttemp_frame_paths = resolve_temp_frame_paths(state_manager.get_item('target_path'))\n+\toutput_video_fps = restrict_video_fps(state_manager.get_item('target_path'), state_manager.get_item('output_video_fps'))\n \n \tif temp_frame_paths:\n \t\twith tqdm(total = len(temp_frame_paths), desc = translator.get('processing'), unit = 'frame', ascii = ' =', disable = state_manager.get_item('log_level') in [ 'warn', 'error' ]) as progress:\n@@ -82,7 +78,7 @@ def process_video() -> ErrorCode:\n \t\t\t\tfutures = []\n \n \t\t\t\tfor frame_number, temp_frame_path in enumerate(temp_frame_paths):\n-\t\t\t\t\tfuture = executor.submit(process_temp_frame, temp_frame_path, frame_number)\n+\t\t\t\t\tfuture = executor.submit(conditional_process_temp_frame, temp_frame_path, frame_number, output_video_fps)\n \t\t\t\t\tfutures.append(future)\n \n \t\t\t\tfor future in as_completed(futures):\n@@ -162,36 +158,3 @@ def finalize_video(start_time : float) -> ErrorCode:\n \t\tlogger.error(translator.get('processing_video_failed'), __name__)\n \t\treturn 1\n \treturn 0\n-\n-\n-def process_temp_frame(temp_frame_path : str, frame_number : int) -> bool:\n-\treference_vision_frame = read_static_video_frame(state_manager.get_item('target_path'), state_manager.get_item('reference_frame_number'))\n-\tsource_vision_frames = read_static_images(state_manager.get_item('source_paths'))\n-\tsource_audio_path = get_first(filter_audio_paths(state_manager.get_item('source_paths')))\n-\ttemp_video_fps = restrict_video_fps(state_manager.get_item('target_path'), state_manager.get_item('output_video_fps'))\n-\ttarget_vision_frame = read_static_image(temp_frame_path, 'rgba')\n-\ttemp_vision_frame = target_vision_frame.copy()\n-\ttemp_vision_mask = extract_vision_mask(temp_vision_frame)\n-\n-\tsource_audio_frame = get_audio_frame(source_audio_path, temp_video_fps, frame_number)\n-\tsource_voice_frame = get_voice_frame(source_audio_path, temp_video_fps, frame_number)\n-\n-\tif not numpy.any(source_audio_frame):\n-\t\tsource_audio_frame = create_empty_audio_frame()\n-\tif not numpy.any(source_voice_frame):\n-\t\tsource_voice_frame = create_empty_audio_frame()\n-\n-\tfor processor_module in get_processors_modules(state_manager.get_item('processors')):\n-\t\ttemp_vision_frame, temp_vision_mask = processor_module.process_frame(\n-\t\t{\n-\t\t\t'reference_vision_frame': reference_vision_frame,\n-\t\t\t'source_vision_frames': source_vision_frames,\n-\t\t\t'source_audio_frame': source_audio_frame,\n-\t\t\t'source_voice_frame': source_voice_frame,\n-\t\t\t'target_vision_frame': target_vision_frame[:, :, :3],\n-\t\t\t'temp_vision_frame': temp_vision_frame[:, :, :3],\n-\t\t\t'temp_vision_mask': temp_vision_mask\n-\t\t})\n-\n-\ttemp_vision_frame = conditional_merge_vision_mask(temp_vision_frame, temp_vision_mask)\n-\treturn write_image(temp_frame_path, temp_vision_frame)\n"
        }
    ]
}