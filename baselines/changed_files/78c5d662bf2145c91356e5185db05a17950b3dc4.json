{
    "sha_fail": "78c5d662bf2145c91356e5185db05a17950b3dc4",
    "changed_files": [
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/agent_concepts/knowledge/chunking/csv_row_chunking.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/chunking/csv_row_chunking.py b/cookbook/agent_concepts/knowledge/chunking/csv_row_chunking.py\nnew file mode 100644\nindex 000000000..b51653ff2\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/chunking/csv_row_chunking.py\n@@ -0,0 +1,30 @@\n+from pathlib import Path\n+\n+from agno.agent import Agent\n+from agno.document.chunking.row import RowChunking\n+from agno.knowledge.csv_url import CSVUrlKnowledgeBase\n+from agno.vectordb.pgvector import PgVector\n+\n+db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n+\n+knowledge_base = CSVUrlKnowledgeBase(\n+    urls=[\n+        \"https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n+    ],\n+    vector_db=PgVector(\n+        table_name=\"imdb_movies_row_chunking\",\n+        db_url=db_url,\n+    ),\n+    chunking_strategy=RowChunking(),\n+)\n+# Load the knowledge base\n+knowledge_base.load(recreate=False)\n+\n+# Initialize the Agent with the knowledge_base\n+agent = Agent(\n+    knowledge=knowledge_base,\n+    search_knowledge=True,\n+)\n+\n+# Use the agent\n+agent.print_response(\"Tell me about the movie Guardians of the Galaxy\", markdown=True)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/agent_concepts/knowledge/embedders/jina_embedder.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/embedders/jina_embedder.py b/cookbook/agent_concepts/knowledge/embedders/jina_embedder.py\nnew file mode 100644\nindex 000000000..17b50aeef\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/embedders/jina_embedder.py\n@@ -0,0 +1,39 @@\n+from agno.agent import AgentKnowledge\n+from agno.embedder.jina import JinaEmbedder\n+from agno.vectordb.pgvector import PgVector\n+\n+# Basic usage - automatically loads from JINA_API_KEY environment variable\n+embeddings = JinaEmbedder().get_embedding(\n+    \"The quick brown fox jumps over the lazy dog.\"\n+)\n+\n+# Print the embeddings and their dimensions\n+print(f\"Embeddings: {embeddings[:5]}\")\n+print(f\"Dimensions: {len(embeddings)}\")\n+\n+custom_embedder = JinaEmbedder(\n+    dimensions=1024,\n+    late_chunking=True,  # Improved processing for long documents\n+    timeout=30.0,  # Request timeout in seconds\n+)\n+\n+# Get embedding with usage information\n+embedding, usage = custom_embedder.get_embedding_and_usage(\n+    \"Advanced text processing with Jina embeddings and late chunking.\"\n+)\n+print(f\"Embedding dimensions: {len(embedding)}\")\n+if usage:\n+    print(f\"Usage info: {usage}\")\n+\n+# Example usage with AgentKnowledge\n+knowledge_base = AgentKnowledge(\n+    vector_db=PgVector(\n+        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n+        table_name=\"jina_embeddings\",\n+        embedder=JinaEmbedder(\n+            late_chunking=True,  # Better handling of long documents\n+            timeout=30.0,  # Configure request timeout\n+        ),\n+    ),\n+    num_documents=2,\n+)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/async_basic.py",
            "diff": "diff --git a/cookbook/models/portkey/async_basic.py b/cookbook/models/portkey/async_basic.py\nnew file mode 100644\nindex 000000000..5ec0af0be\n--- /dev/null\n+++ b/cookbook/models/portkey/async_basic.py\n@@ -0,0 +1,14 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+asyncio.run(\n+    agent.aprint_response(\"What is Portkey and why would I use it as an AI gateway?\")\n+)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/async_basic_stream.py",
            "diff": "diff --git a/cookbook/models/portkey/async_basic_stream.py b/cookbook/models/portkey/async_basic_stream.py\nnew file mode 100644\nindex 000000000..9f901f481\n--- /dev/null\n+++ b/cookbook/models/portkey/async_basic_stream.py\n@@ -0,0 +1,14 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    description=\"You help people with their health and fitness goals.\",\n+    instructions=[\"Recipes should be under 5 ingredients\"],\n+)\n+# -*- Print a response to the terminal\n+asyncio.run(\n+    agent.aprint_response(\"Share a breakfast recipe.\", markdown=True, stream=True)\n+)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/async_tool_use.py",
            "diff": "diff --git a/cookbook/models/portkey/async_tool_use.py b/cookbook/models/portkey/async_tool_use.py\nnew file mode 100644\nindex 000000000..534541f64\n--- /dev/null\n+++ b/cookbook/models/portkey/async_tool_use.py\n@@ -0,0 +1,15 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+asyncio.run(agent.aprint_response(\"What are the latest developments in AI gateways?\"))\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/async_tool_use_stream.py",
            "diff": "diff --git a/cookbook/models/portkey/async_tool_use_stream.py b/cookbook/models/portkey/async_tool_use_stream.py\nnew file mode 100644\nindex 000000000..c744c2577\n--- /dev/null\n+++ b/cookbook/models/portkey/async_tool_use_stream.py\n@@ -0,0 +1,19 @@\n+import asyncio\n+\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+asyncio.run(\n+    agent.aprint_response(\n+        \"What are the latest developments in AI gateways?\", stream=True\n+    )\n+)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/basic.py",
            "diff": "diff --git a/cookbook/models/portkey/basic.py b/cookbook/models/portkey/basic.py\nnew file mode 100644\nindex 000000000..3c5298eaa\n--- /dev/null\n+++ b/cookbook/models/portkey/basic.py\n@@ -0,0 +1,16 @@\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.portkey import Portkey\n+\n+# Create model using Portkey\n+model = Portkey(\n+    id=\"gpt-4o-mini\",\n+)\n+\n+agent = Agent(model=model, markdown=True)\n+\n+# Get the response in a variable\n+# run: RunResponse = agent.run(\"What is Portkey and why would I use it as an AI gateway?\")\n+# print(run.content)\n+\n+# Print the response in the terminal\n+agent.print_response(\"What is Portkey and why would I use it as an AI gateway?\")\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/basic_stream.py",
            "diff": "diff --git a/cookbook/models/portkey/basic_stream.py b/cookbook/models/portkey/basic_stream.py\nnew file mode 100644\nindex 000000000..977e8265c\n--- /dev/null\n+++ b/cookbook/models/portkey/basic_stream.py\n@@ -0,0 +1,14 @@\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+\n+agent = Agent(\n+    model=Portkey(\n+        id=\"gpt-4o-mini\",\n+    ),\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+agent.print_response(\n+    \"What is Portkey and why would I use it as an AI gateway?\", stream=True\n+)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/structured_output.py",
            "diff": "diff --git a/cookbook/models/portkey/structured_output.py b/cookbook/models/portkey/structured_output.py\nnew file mode 100644\nindex 000000000..76035dee1\n--- /dev/null\n+++ b/cookbook/models/portkey/structured_output.py\n@@ -0,0 +1,37 @@\n+from typing import List\n+\n+from agno.agent import Agent, RunResponse  # noqa\n+from agno.models.portkey import Portkey\n+from pydantic import BaseModel, Field\n+\n+\n+class MovieScript(BaseModel):\n+    setting: str = Field(\n+        ..., description=\"Provide a nice setting for a blockbuster movie.\"\n+    )\n+    ending: str = Field(\n+        ...,\n+        description=\"Ending of the movie. If not available, provide a happy ending.\",\n+    )\n+    genre: str = Field(\n+        ...,\n+        description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\",\n+    )\n+    name: str = Field(..., description=\"Give a name to this movie\")\n+    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n+    storyline: str = Field(\n+        ..., description=\"3 sentence storyline for the movie. Make it exciting!\"\n+    )\n+\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    response_model=MovieScript,\n+    markdown=True,\n+)\n+\n+# Get the response in a variable\n+# run: RunResponse = agent.run(\"New York\")\n+# print(run.content)\n+\n+agent.print_response(\"New York\")\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/tool_use.py",
            "diff": "diff --git a/cookbook/models/portkey/tool_use.py b/cookbook/models/portkey/tool_use.py\nnew file mode 100644\nindex 000000000..cf16988a2\n--- /dev/null\n+++ b/cookbook/models/portkey/tool_use.py\n@@ -0,0 +1,13 @@\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+agent.print_response(\"What are the latest developments in AI gateways?\")\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/models/portkey/tool_use_stream.py",
            "diff": "diff --git a/cookbook/models/portkey/tool_use_stream.py b/cookbook/models/portkey/tool_use_stream.py\nnew file mode 100644\nindex 000000000..c69ffec5c\n--- /dev/null\n+++ b/cookbook/models/portkey/tool_use_stream.py\n@@ -0,0 +1,13 @@\n+from agno.agent import Agent\n+from agno.models.portkey import Portkey\n+from agno.tools.duckduckgo import DuckDuckGoTools\n+\n+agent = Agent(\n+    model=Portkey(id=\"gpt-4o-mini\"),\n+    tools=[DuckDuckGoTools()],\n+    show_tool_calls=True,\n+    markdown=True,\n+)\n+\n+# Print the response in the terminal\n+agent.print_response(\"What are the latest developments in AI gateways?\", stream=True)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/tools/bitbucket_tools.py",
            "diff": "diff --git a/cookbook/tools/bitbucket_tools.py b/cookbook/tools/bitbucket_tools.py\nnew file mode 100644\nindex 000000000..42716532d\n--- /dev/null\n+++ b/cookbook/tools/bitbucket_tools.py\n@@ -0,0 +1,35 @@\n+\"\"\"\n+Setup:\n+1. Generate an App Password:\n+   - Go to \"Personal Bitbucket settings\" -> \"App passwords\"\n+   - Create a new App password with the appropriate permissions\n+\n+2. Set environment variables:\n+   - BITBUCKET_USERNAME: Your Bitbucket username\n+   - BITBUCKET_PASSWORD: Your generated App password\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.tools.bitbucket import BitbucketTools\n+\n+repo_slug = \"ai\"\n+workspace = \"MaximMFP\"\n+\n+agent = Agent(\n+    tools=[BitbucketTools(workspace=workspace, repo_slug=repo_slug)],\n+    show_tool_calls=True,\n+)\n+\n+agent.print_response(\"List open pull requests\", markdown=True)\n+\n+# Example 1: Get specific pull request details\n+# agent.print_response(\"Get details of pull request #23\", markdown=True)\n+\n+# Example 2: Get the repo details\n+# agent.print_response(\"Get details of the repository\", markdown=True)\n+\n+# Example 3: List repositories\n+# agent.print_response(\"List 5 repositories for this workspace\", markdown=True)\n+\n+# Example 4: List commits\n+# agent.print_response(\"List the last 20 commits\", markdown=True)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "cookbook/tools/mcp/gibsonai.py",
            "diff": "diff --git a/cookbook/tools/mcp/gibsonai.py b/cookbook/tools/mcp/gibsonai.py\nnew file mode 100644\nindex 000000000..88de55234\n--- /dev/null\n+++ b/cookbook/tools/mcp/gibsonai.py\n@@ -0,0 +1,84 @@\n+\"\"\"\ud83d\udee2 GibsonAI MCP Server - Create and manage databases with prompts\n+\n+This example shows how to connect a local GibsonAI MCP to Agno agent.\n+You can instantly generate, modify database schemas\n+and chat with your relational database using natural language.\n+From prompt to a serverless database (MySQL, PostgresQL, etc.), auto-generated REST APIs for your data.\n+\n+Example prompts to try:\n+- \"Create a new GibsonAI project for my e-commerce app\"\n+- \"Show me the current schema for my project\"\n+- \"Add a 'products' table with name, price, and description fields\"\n+- \"Create a 'users' table with authentication fields\"\n+- \"Deploy my schema changes to production\"\n+\n+How to setup and run:\n+\n+1. Install [UV](https://docs.astral.sh/uv/) package manager.\n+2. Install the GibsonAI CLI:\n+    ```bash\n+    uvx --from gibson-cli@latest gibson auth login\n+    ```\n+3. Install the required dependencies:\n+    ```bash\n+    pip install agno mcp openai\n+    ```\n+4. Export your API key:\n+    ```bash\n+    export OPENAI_API_KEY=\"your_openai_api_key\"\n+    ```\n+5. Run the GibsonAI agent by running this file.\n+6. Check created database and schema on GibsonAI dashboard: https://app.gibsonai.com\n+\n+This logs you into the [GibsonAI CLI](https://docs.gibsonai.com/reference/cli-quickstart)\n+so you can access all the features directly from your agent.\n+\n+\"\"\"\n+\n+import asyncio\n+from textwrap import dedent\n+\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.tools.mcp import MCPTools\n+\n+\n+async def run_gibsonai_agent(message: str) -> None:\n+    \"\"\"Run the GibsonAI agent with the given message.\"\"\"\n+    async with MCPTools(\n+        \"uvx --from gibson-cli@latest gibson mcp run\",\n+        timeout_seconds=300,  # Extended timeout for GibsonAI operations\n+    ) as mcp_tools:\n+        agent = Agent(\n+            name=\"GibsonAIAgent\",\n+            model=OpenAIChat(id=\"gpt-4o\"),\n+            tools=[mcp_tools],\n+            description=\"Agent for managing database projects and schemas\",\n+            instructions=dedent(\"\"\"\\\n+                You are a GibsonAI database assistant. Help users manage their database projects and schemas.\n+\n+                Your capabilities include:\n+                - Creating new GibsonAI projects\n+                - Managing database schemas (tables, columns, relationships)\n+                - Deploying schema changes to hosted databases\n+                - Querying database schemas and data\n+                - Providing insights about database structure and best practices\n+            \"\"\"),\n+            markdown=True,\n+            show_tool_calls=True,\n+        )\n+\n+        # Run the agent\n+        await agent.aprint_response(message, stream=True)\n+\n+\n+# Example usage\n+if __name__ == \"__main__\":\n+    asyncio.run(\n+        run_gibsonai_agent(\n+            \"\"\"\n+            Create a database for blog posts platform with users and posts tables.\n+            You can decide the schema of the tables without double checking with me.\n+            \"\"\"\n+        )\n+    )\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/document/chunking/row.py",
            "diff": "diff --git a/libs/agno/agno/document/chunking/row.py b/libs/agno/agno/document/chunking/row.py\nnew file mode 100644\nindex 000000000..206ec1767\n--- /dev/null\n+++ b/libs/agno/agno/document/chunking/row.py\n@@ -0,0 +1,39 @@\n+from typing import List\n+\n+from agno.document.base import Document\n+from agno.document.chunking.strategy import ChunkingStrategy\n+\n+\n+class RowChunking(ChunkingStrategy):\n+    def __init__(self, skip_header: bool = False, clean_rows: bool = True):\n+        self.skip_header = skip_header\n+        self.clean_rows = clean_rows\n+\n+    def chunk(self, document: Document) -> List[Document]:\n+        if not document or not document.content:\n+            return []\n+\n+        if not isinstance(document.content, str):\n+            raise ValueError(\"Document content must be a string\")\n+\n+        rows = document.content.splitlines()\n+\n+        if self.skip_header and rows:\n+            rows = rows[1:]\n+            start_index = 2\n+        else:\n+            start_index = 1\n+\n+        chunks = []\n+        for i, row in enumerate(rows):\n+            if self.clean_rows:\n+                chunk_content = \" \".join(row.split())  # Normalize internal whitespace\n+            else:\n+                chunk_content = row.strip()\n+\n+            if chunk_content:  # Skip empty rows\n+                meta_data = document.meta_data.copy()\n+                meta_data[\"row_number\"] = start_index + i  # Preserve logical row numbering\n+                chunk_id = f\"{document.id}_row_{start_index + i}\" if document.id else None\n+                chunks.append(Document(id=chunk_id, name=document.name, meta_data=meta_data, content=chunk_content))\n+        return chunks\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/embedder/jina.py",
            "diff": "diff --git a/libs/agno/agno/embedder/jina.py b/libs/agno/agno/embedder/jina.py\nnew file mode 100644\nindex 000000000..ae478d315\n--- /dev/null\n+++ b/libs/agno/agno/embedder/jina.py\n@@ -0,0 +1,73 @@\n+from dataclasses import dataclass\n+from os import getenv\n+from typing import Any, Dict, List, Optional, Tuple\n+\n+from typing_extensions import Literal\n+\n+from agno.embedder.base import Embedder\n+from agno.utils.log import logger\n+\n+try:\n+    import requests\n+except ImportError:\n+    raise ImportError(\"requests not installed, use pip install requests\")\n+\n+\n+@dataclass\n+class JinaEmbedder(Embedder):\n+    id: str = \"jina-embeddings-v3\"\n+    dimensions: int = 1024\n+    embedding_type: Literal[\"float\", \"base64\", \"int8\"] = \"float\"\n+    late_chunking: bool = False\n+    user: Optional[str] = None\n+    api_key: Optional[str] = getenv(\"JINA_API_KEY\")\n+    base_url: str = \"https://api.jina.ai/v1/embeddings\"\n+    headers: Optional[Dict[str, str]] = None\n+    request_params: Optional[Dict[str, Any]] = None\n+    timeout: Optional[float] = None\n+\n+    def _get_headers(self) -> Dict[str, str]:\n+        if not self.api_key:\n+            raise ValueError(\n+                \"API key is required for Jina embedder. Set JINA_API_KEY environment variable or pass api_key parameter.\"\n+            )\n+\n+        headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {self.api_key}\"}\n+        if self.headers:\n+            headers.update(self.headers)\n+        return headers\n+\n+    def _response(self, text: str) -> Dict[str, Any]:\n+        data = {\n+            \"model\": self.id,\n+            \"late_chunking\": self.late_chunking,\n+            \"dimensions\": self.dimensions,\n+            \"embedding_type\": self.embedding_type,\n+            \"input\": [text],  # Jina API expects a list\n+        }\n+        if self.user is not None:\n+            data[\"user\"] = self.user\n+        if self.request_params:\n+            data.update(self.request_params)\n+\n+        response = requests.post(self.base_url, headers=self._get_headers(), json=data, timeout=self.timeout)\n+        response.raise_for_status()\n+        return response.json()\n+\n+    def get_embedding(self, text: str) -> List[float]:\n+        try:\n+            result = self._response(text)\n+            return result[\"data\"][0][\"embedding\"]\n+        except Exception as e:\n+            logger.warning(f\"Failed to get embedding: {e}\")\n+            return []\n+\n+    def get_embedding_and_usage(self, text: str) -> Tuple[List[float], Optional[Dict]]:\n+        try:\n+            result = self._response(text)\n+            embedding = result[\"data\"][0][\"embedding\"]\n+            usage = result.get(\"usage\")\n+            return embedding, usage\n+        except Exception as e:\n+            logger.warning(f\"Failed to get embedding and usage: {e}\")\n+            return [], None\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/memory/agent.py",
            "diff": "diff --git a/libs/agno/agno/memory/agent.py b/libs/agno/agno/memory/agent.py\nindex e3192abd0..470228de4 100644\n--- a/libs/agno/agno/memory/agent.py\n+++ b/libs/agno/agno/memory/agent.py\n@@ -273,7 +273,7 @@ class AgentMemory(BaseModel):\n \n         self.classifier.existing_memories = self.memories\n         classifier_response = self.classifier.run(input)\n-        if classifier_response == \"yes\":\n+        if classifier_response and classifier_response.lower() == \"yes\":\n             return True\n         return False\n \n@@ -286,7 +286,7 @@ class AgentMemory(BaseModel):\n \n         self.classifier.existing_memories = self.memories\n         classifier_response = await self.classifier.arun(input)\n-        if classifier_response == \"yes\":\n+        if classifier_response and classifier_response.lower() == \"yes\":\n             return True\n         return False\n \n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/memory/team.py",
            "diff": "diff --git a/libs/agno/agno/memory/team.py b/libs/agno/agno/memory/team.py\nindex a21c6fbdf..8ac73ffe5 100644\n--- a/libs/agno/agno/memory/team.py\n+++ b/libs/agno/agno/memory/team.py\n@@ -313,7 +313,7 @@ class TeamMemory:\n \n         self.classifier.existing_memories = self.memories\n         classifier_response = self.classifier.run(input)\n-        if classifier_response == \"yes\":\n+        if classifier_response and classifier_response.lower() == \"yes\":\n             return True\n         return False\n \n@@ -326,7 +326,7 @@ class TeamMemory:\n \n         self.classifier.existing_memories = self.memories\n         classifier_response = await self.classifier.arun(input)\n-        if classifier_response == \"yes\":\n+        if classifier_response and classifier_response.lower() == \"yes\":\n             return True\n         return False\n \n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/models/portkey/__init__.py",
            "diff": "diff --git a/libs/agno/agno/models/portkey/__init__.py b/libs/agno/agno/models/portkey/__init__.py\nnew file mode 100644\nindex 000000000..51312d2ab\n--- /dev/null\n+++ b/libs/agno/agno/models/portkey/__init__.py\n@@ -0,0 +1,3 @@\n+from agno.models.portkey.portkey import Portkey\n+\n+__all__ = [\"Portkey\"]\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/models/portkey/portkey.py",
            "diff": "diff --git a/libs/agno/agno/models/portkey/portkey.py b/libs/agno/agno/models/portkey/portkey.py\nnew file mode 100644\nindex 000000000..10b301545\n--- /dev/null\n+++ b/libs/agno/agno/models/portkey/portkey.py\n@@ -0,0 +1,88 @@\n+from dataclasses import dataclass\n+from os import getenv\n+from typing import Any, Dict, Optional, cast\n+\n+from agno.exceptions import ModelProviderError\n+from agno.models.openai.like import OpenAILike\n+\n+try:\n+    from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n+except ImportError:\n+    raise ImportError(\"`portkey-ai` not installed. Please install using `pip install portkey-ai`\")\n+\n+\n+@dataclass\n+class Portkey(OpenAILike):\n+    \"\"\"\n+    A class for using models through the Portkey AI Gateway.\n+\n+    Attributes:\n+        id (str): The model id. Defaults to \"gpt-4o-mini\".\n+        name (str): The model name. Defaults to \"Portkey\".\n+        provider (str): The provider name. Defaults to \"Portkey\".\n+        portkey_api_key (Optional[str]): The Portkey API key.\n+        virtual_key (Optional[str]): The virtual key for model routing.\n+        config (Optional[Dict[str, Any]]): Portkey configuration for routing, retries, etc.\n+        base_url (str): The Portkey gateway URL.\n+    \"\"\"\n+\n+    id: str = \"gpt-4o-mini\"\n+    name: str = \"Portkey\"\n+    provider: str = \"Portkey\"\n+\n+    portkey_api_key: Optional[str] = getenv(\"PORTKEY_API_KEY\")\n+    virtual_key: Optional[str] = getenv(\"PORTKEY_VIRTUAL_KEY\")\n+    config: Optional[Dict[str, Any]] = None\n+    base_url: str = PORTKEY_GATEWAY_URL\n+\n+    def _get_client_params(self) -> Dict[str, Any]:\n+        # Check for required keys\n+        if not self.portkey_api_key:\n+            raise ModelProviderError(\n+                message=\"PORTKEY_API_KEY not set. Please set the PORTKEY_API_KEY environment variable.\",\n+                model_name=self.name,\n+                model_id=self.id,\n+            )\n+\n+        if not self.virtual_key:\n+            raise ModelProviderError(\n+                message=\"PORTKEY_VIRTUAL_KEY not set. Please set the PORTKEY_VIRTUAL_KEY environment variable.\",\n+                model_name=self.name,\n+                model_id=self.id,\n+            )\n+\n+        # Create headers using Portkey's createHeaders function\n+        header_params: Dict[str, Any] = {\n+            \"api_key\": self.portkey_api_key,\n+            \"virtual_key\": self.virtual_key,\n+        }\n+\n+        if self.config is not None:\n+            header_params[\"config\"] = self.config\n+\n+        portkey_headers = cast(Dict[str, Any], createHeaders(**header_params))\n+\n+        # Merge with any existing default headers\n+        default_headers: Dict[str, Any] = {}\n+        if self.default_headers and isinstance(self.default_headers, dict):\n+            default_headers.update(self.default_headers)\n+        default_headers.update(portkey_headers)\n+\n+        # Define base client params\n+        base_params = {\n+            \"api_key\": \"not-needed\",  # We use virtual keys instead\n+            \"organization\": self.organization,\n+            \"base_url\": self.base_url,\n+            \"timeout\": self.timeout,\n+            \"max_retries\": self.max_retries,\n+            \"default_headers\": default_headers,\n+            \"default_query\": self.default_query,\n+        }\n+\n+        # Create client_params dict with non-None values\n+        client_params = {k: v for k, v in base_params.items() if v is not None}\n+\n+        # Add additional client params if provided\n+        if self.client_params:\n+            client_params.update(self.client_params)\n+        return client_params\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/agno/tools/bitbucket.py",
            "diff": "diff --git a/libs/agno/agno/tools/bitbucket.py b/libs/agno/agno/tools/bitbucket.py\nnew file mode 100644\nindex 000000000..1e5184355\n--- /dev/null\n+++ b/libs/agno/agno/tools/bitbucket.py\n@@ -0,0 +1,292 @@\n+import base64\n+import json\n+import os\n+from typing import Any, Dict, Optional, Union\n+\n+import requests\n+\n+from agno.tools import Toolkit\n+from agno.utils.log import logger\n+\n+\n+class BitbucketTools(Toolkit):\n+    def __init__(\n+        self,\n+        server_url: str = \"api.bitbucket.org\",\n+        username: Optional[str] = None,\n+        password: Optional[str] = None,\n+        token: Optional[str] = None,\n+        workspace: Optional[str] = None,\n+        repo_slug: Optional[str] = None,\n+        api_version: str = \"2.0\",\n+        **kwargs,\n+    ):\n+        self.username = username or os.getenv(\"BITBUCKET_USERNAME\")\n+        self.password = password or os.getenv(\"BITBUCKET_PASSWORD\")\n+        self.token = token or os.getenv(\"BITBUCKET_TOKEN\")\n+        self.auth_password = self.token or self.password\n+        self.server_url = server_url or \"api.bitbucket.org\"\n+        self.api_version = api_version or \"2.0\"\n+        self.base_url = (\n+            f\"https://{self.server_url}/{api_version}\"\n+            if not self.server_url.startswith((\"http://\", \"https://\"))\n+            else f\"{self.server_url}/{api_version}\"\n+        )\n+        self.workspace = workspace\n+        self.repo_slug = repo_slug\n+\n+        if not (self.username and self.auth_password):\n+            raise ValueError(\"Username and password or token are required\")\n+\n+        if not self.workspace:\n+            raise ValueError(\"Workspace is required\")\n+        if not self.repo_slug:\n+            raise ValueError(\"Repo slug is required\")\n+\n+        self.headers = {\"Accept\": \"application/json\", \"Authorization\": f\"Basic {self._generate_access_token()}\"}\n+\n+        super().__init__(\n+            name=\"bitbucket\",\n+            tools=[\n+                self.list_repositories,\n+                self.get_repository_details,\n+                self.create_repository,\n+                self.list_repository_commits,\n+                self.list_all_pull_requests,\n+                self.get_pull_request_details,\n+                self.get_pull_request_changes,\n+                self.list_issues,\n+            ],\n+            **kwargs,\n+        )\n+\n+    def _generate_access_token(self) -> str:\n+        auth_str = f\"{self.username}:{self.auth_password}\"\n+        auth_bytes = auth_str.encode(\"ascii\")\n+        auth_base64 = base64.b64encode(auth_bytes).decode(\"ascii\")\n+        return auth_base64\n+\n+    def _make_request(\n+        self,\n+        method: str,\n+        endpoint: str,\n+        params: Optional[Dict[str, Any]] = None,\n+        data: Optional[Dict[str, Any]] = None,\n+    ) -> Union[str, Dict[str, Any]]:\n+        url = f\"{self.base_url}{endpoint}\"\n+        response = requests.request(method, url, headers=self.headers, json=data, params=params)\n+        response.raise_for_status()\n+        encoding_type = response.headers.get(\"Content-Type\", \"application/json\")\n+        if encoding_type.startswith(\"application/json\"):\n+            return response.json() if response.text else {}\n+        elif encoding_type == \"text/plain\":\n+            return response.text\n+\n+        logger.warning(f\"Unsupported content type: {encoding_type}\")\n+        return {}\n+\n+    def list_repositories(self, count: int = 10) -> str:\n+        \"\"\"\n+        Get all repositories in the workspace.\n+        Args:\n+            count (int, optional): The number of repositories to retrieve\n+\n+        Returns:\n+            str: A JSON string containing repository list.\n+        \"\"\"\n+        try:\n+            # Limit count to maximum of 50\n+            count = min(count, 50)\n+\n+            # Use count directly as pagelen for simplicity, max out at 50 per our limit\n+            pagelen = min(count, 50)\n+            params = {\"page\": 1, \"pagelen\": pagelen}\n+\n+            repo = self._make_request(\"GET\", f\"/repositories/{self.workspace}\", params=params)\n+\n+            return json.dumps(repo, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving repository list for workspace {self.workspace}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def get_repository_details(self) -> str:\n+        \"\"\"\n+        Retrieves repository information.\n+        API Docs: https://developer.atlassian.com/cloud/bitbucket/rest/api-group-repositories/#api-repositories-workspace-repo-slug-get\n+\n+        Returns:\n+            str: A JSON string containing repository information.\n+        \"\"\"\n+        try:\n+            repo = self._make_request(\"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}\")\n+            return json.dumps(repo, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving repository information for {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def create_repository(\n+        self,\n+        name: str,\n+        project: Optional[str] = None,\n+        is_private: bool = False,\n+        description: Optional[str] = None,\n+        language: Optional[str] = None,\n+        has_issues: bool = False,\n+        has_wiki: bool = False,\n+    ) -> str:\n+        \"\"\"\n+        Creates a new repository in Bitbucket for the given workspace.\n+\n+        Args:\n+            name (str): The name of the new repository.\n+            project (str, optional): The key of the project to create the repository in.\n+            is_private (bool, optional): Whether the repository is private.\n+            description (str, optional): A short description of the repository.\n+            language (str, optional): The primary language of the repository\n+            has_issues (bool, optional): Whether the repository has issues enabled.\n+            has_wiki (bool, optional): Whether the repository has a wiki enabled.\n+\n+        Returns:\n+            str: A JSON string containing repository information.\n+        \"\"\"\n+        try:\n+            payload: Dict[str, Any] = {\n+                \"name\": name,\n+                \"scm\": \"git\",\n+                \"is_private\": is_private,\n+                \"description\": description,\n+                \"language\": language,\n+                \"has_issues\": has_issues,\n+                \"has_wiki\": has_wiki,\n+            }\n+            if project:\n+                payload[\"project\"] = {\"key\": project}\n+            repo = self._make_request(\"POST\", f\"/repositories/{self.workspace}/{self.repo_slug}\", data=payload)\n+            return json.dumps(repo, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error creating repository {self.repo_slug} for {self.workspace}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def list_repository_commits(self, count: int = 10) -> str:\n+        \"\"\"\n+        Retrieves all commits in a repository.\n+\n+        Args:\n+            count (int, optional): The number of commits to retrieve. Defaults to 10. Maximum 50.\n+\n+        Returns:\n+            str: A JSON string containing all commits.\n+        \"\"\"\n+        try:\n+            count = min(count, 50)\n+            params = {\"pagelen\": count}\n+\n+            commits = self._make_request(\n+                \"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/commits\", params=params\n+            )\n+\n+            if isinstance(commits, dict) and commits.get(\"next\"):\n+                collected_commits = commits.get(\"values\", [])\n+\n+                while len(collected_commits) < count and isinstance(commits, dict) and commits.get(\"next\"):\n+                    next_url = commits[\"next\"]  # type: ignore\n+                    query_param = next_url.split(\"?\")[1] if \"?\" in next_url else \"\"\n+                    commits = self._make_request(\n+                        \"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/commits?{query_param}\"\n+                    )\n+                    if isinstance(commits, dict):\n+                        collected_commits.extend(commits.get(\"values\", []))\n+\n+                if isinstance(commits, dict):\n+                    commits[\"values\"] = collected_commits[:count]\n+\n+            return json.dumps(commits, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving commits for {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def list_all_pull_requests(self, state: str = \"OPEN\") -> str:\n+        \"\"\"\n+        Retrieves all pull requests for a repository.\n+\n+        Args:\n+            state (str, optional): The state of the pull requests to retrieve.\n+\n+        Returns:\n+            str: A JSON string containing all pull requests.\n+        \"\"\"\n+        try:\n+            if state not in [\"OPEN\", \"MERGED\", \"DECLINED\", \"SUPERSEDED\"]:\n+                logger.debug(f\"Invalid pull request state: {state}. Defaulting to OPEN\")\n+                state = \"OPEN\"\n+\n+            params = {\"state\": state}\n+\n+            pull_requests = self._make_request(\n+                \"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/pullrequests\", params=params\n+            )\n+\n+            return json.dumps(pull_requests, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving pull requests for {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def get_pull_request_details(self, pull_request_id: int) -> str:\n+        \"\"\"\n+        Retrieves a pull request for a repository.\n+        Args:\n+            pull_request_id (int): The ID of the pull request to retrieve.\n+\n+        Returns:\n+            str: A JSON string containing the pull request.\n+        \"\"\"\n+        try:\n+            pull_request = self._make_request(\n+                \"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/pullrequests/{pull_request_id}\"\n+            )\n+            return json.dumps(pull_request, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving pull requests for {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def get_pull_request_changes(self, pull_request_id: int) -> str:\n+        \"\"\"\n+        Retrieves changes for a pull request in a repository.\n+\n+        Args:\n+            pull_request_id (int): The ID of the pull request to retrieve.\n+\n+        Returns:\n+            str: A markdown string containing the pull request diff.\n+        \"\"\"\n+        try:\n+            diff = self._make_request(\n+                \"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/pullrequests/{pull_request_id}/diff\"\n+            )\n+            if isinstance(diff, dict):\n+                return json.dumps(diff, indent=2)\n+            return diff\n+        except Exception as e:\n+            logger.error(f\"Error retrieving changes for pull request {pull_request_id} in {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n+\n+    def list_issues(self, count: int = 10) -> str:\n+        \"\"\"\n+        Retrieves all issues for a repository.\n+\n+        Args:\n+            count (int, optional): The number of issues to retrieve. Defaults to 10. Maximum 50.\n+\n+        Returns:\n+            str: A JSON string containing all issues.\n+        \"\"\"\n+        try:\n+            count = min(count, 50)\n+            params = {\"pagelen\": count}\n+\n+            issues = self._make_request(\"GET\", f\"/repositories/{self.workspace}/{self.repo_slug}/issues\", params=params)\n+\n+            return json.dumps(issues, indent=2)\n+        except Exception as e:\n+            logger.error(f\"Error retrieving issues for {self.repo_slug}: {str(e)}\")\n+            return json.dumps({\"error\": str(e)})\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/tests/integration/embedder/test_jina_embedder.py",
            "diff": "diff --git a/libs/agno/tests/integration/embedder/test_jina_embedder.py b/libs/agno/tests/integration/embedder/test_jina_embedder.py\nnew file mode 100644\nindex 000000000..f3d104b2b\n--- /dev/null\n+++ b/libs/agno/tests/integration/embedder/test_jina_embedder.py\n@@ -0,0 +1,132 @@\n+import pytest\n+\n+from agno.embedder.jina import JinaEmbedder\n+\n+\n+@pytest.fixture\n+def embedder():\n+    return JinaEmbedder()\n+\n+\n+def test_embedder_initialization(embedder):\n+    \"\"\"Test that the embedder initializes correctly\"\"\"\n+    assert embedder is not None\n+    assert embedder.id == \"jina-embeddings-v3\"  # Field is 'id' not 'model'\n+    assert embedder.dimensions == 1024\n+    assert embedder.embedding_type == \"float\"\n+    assert not embedder.late_chunking\n+    assert embedder.api_key is not None  # Should load from environment\n+\n+\n+def test_get_embedding(embedder):\n+    \"\"\"Test that we can get embeddings for a simple text\"\"\"\n+    text = \"The quick brown fox jumps over the lazy dog.\"\n+    embeddings = embedder.get_embedding(text)\n+\n+    # Basic checks on the embeddings\n+    assert isinstance(embeddings, list)\n+    assert len(embeddings) > 0\n+    assert all(isinstance(x, float) for x in embeddings)\n+    assert len(embeddings) == embedder.dimensions\n+\n+\n+def test_get_embedding_and_usage(embedder):\n+    \"\"\"Test that we can get embeddings with usage information\"\"\"\n+    text = \"Test embedding with usage information.\"\n+    embedding, usage = embedder.get_embedding_and_usage(text)\n+\n+    # Check embedding\n+    assert isinstance(embedding, list)\n+    assert len(embedding) > 0\n+    assert all(isinstance(x, float) for x in embedding)\n+    assert len(embedding) == embedder.dimensions\n+\n+    # Check usage (may be None if not provided by API)\n+    assert usage is None or isinstance(usage, dict)\n+\n+\n+def test_special_characters(embedder):\n+    \"\"\"Test that special characters are handled correctly\"\"\"\n+    text = \"Hello, world! \u3053\u3093\u306b\u3061\u306f 123 @#$%\"\n+    embeddings = embedder.get_embedding(text)\n+    assert isinstance(embeddings, list)\n+    assert len(embeddings) > 0\n+    assert len(embeddings) == embedder.dimensions\n+\n+\n+def test_long_text(embedder):\n+    \"\"\"Test that long text is handled correctly\"\"\"\n+    text = \" \".join([\"word\"] * 1000)  # Create a long text\n+    embeddings = embedder.get_embedding(text)\n+    assert isinstance(embeddings, list)\n+    assert len(embeddings) > 0\n+    assert len(embeddings) == embedder.dimensions\n+\n+\n+def test_embedding_consistency(embedder):\n+    \"\"\"Test that embeddings for the same text are consistent\"\"\"\n+    text = \"Consistency test\"\n+    embeddings1 = embedder.get_embedding(text)\n+    embeddings2 = embedder.get_embedding(text)\n+\n+    assert len(embeddings1) == len(embeddings2)\n+    assert all(abs(a - b) < 1e-6 for a, b in zip(embeddings1, embeddings2))\n+\n+\n+def test_custom_configuration():\n+    \"\"\"Test embedder with custom configuration\"\"\"\n+    custom_embedder = JinaEmbedder(\n+        id=\"jina-embeddings-v3\",  # Field is 'id' not 'model'\n+        dimensions=512,  # Different dimensions\n+        embedding_type=\"float\",\n+        late_chunking=True,\n+        timeout=30.0,\n+    )\n+\n+    text = \"Test with custom configuration\"\n+    embeddings = custom_embedder.get_embedding(text)\n+\n+    assert isinstance(embeddings, list)\n+    assert len(embeddings) > 0\n+    # Note: dimensions might still be 1024 if the API doesn't support 512 for this model\n+\n+\n+def test_different_embedding_types():\n+    \"\"\"Test different embedding output types\"\"\"\n+    # Test with float type (default)\n+    float_embedder = JinaEmbedder(embedding_type=\"float\")\n+    text = \"Test different embedding types\"\n+\n+    embeddings = float_embedder.get_embedding(text)\n+    assert isinstance(embeddings, list)\n+    assert all(isinstance(x, float) for x in embeddings)\n+\n+\n+def test_late_chunking_feature():\n+    \"\"\"Test the late chunking feature for better long document processing\"\"\"\n+    chunking_embedder = JinaEmbedder(late_chunking=True)\n+\n+    # Test with a longer document\n+    long_text = \"This is a longer document that would benefit from late chunking. \" * 50\n+    embeddings = chunking_embedder.get_embedding(long_text)\n+\n+    assert isinstance(embeddings, list)\n+    assert len(embeddings) > 0\n+    assert len(embeddings) == chunking_embedder.dimensions\n+\n+\n+def test_api_key_validation():\n+    \"\"\"Test that missing API key is handled gracefully\"\"\"\n+    embedder_no_key = JinaEmbedder(api_key=None)\n+\n+    # The embedder should return empty list when API key is missing\n+    # (since the error is caught and logged as warning)\n+    embeddings = embedder_no_key.get_embedding(\"Test text\")\n+    assert embeddings == []\n+\n+\n+def test_empty_text_handling(embedder):\n+    \"\"\"Test handling of empty text\"\"\"\n+    embeddings = embedder.get_embedding(\"\")\n+    # Should return empty list or handle gracefully\n+    assert isinstance(embeddings, list)\n"
        },
        {
            "commit": "78c5d662bf2145c91356e5185db05a17950b3dc4",
            "file_path": "libs/agno/tests/unit/tools/test_bitbucket.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_bitbucket.py b/libs/agno/tests/unit/tools/test_bitbucket.py\nnew file mode 100644\nindex 000000000..dc0f97c9f\n--- /dev/null\n+++ b/libs/agno/tests/unit/tools/test_bitbucket.py\n@@ -0,0 +1,409 @@\n+import json\n+import os\n+from unittest.mock import MagicMock, patch\n+\n+import pytest\n+import requests\n+\n+from agno.tools.bitbucket import BitbucketTools\n+\n+\n+class TestBitbucketTools:\n+    \"\"\"Test suite for BitbucketTools class.\"\"\"\n+\n+    @pytest.fixture\n+    def mock_env_vars(self):\n+        \"\"\"Mock environment variables for testing.\"\"\"\n+        with patch.dict(\n+            os.environ,\n+            {\n+                \"BITBUCKET_USERNAME\": \"test_user\",\n+                \"BITBUCKET_PASSWORD\": \"test_password\",\n+            },\n+        ):\n+            yield\n+\n+    @pytest.fixture\n+    def bitbucket_tools(self, mock_env_vars):\n+        \"\"\"Create BitbucketTools instance for testing.\"\"\"\n+        return BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\")\n+\n+    @pytest.fixture\n+    def bitbucket_tools_with_token(self, mock_env_vars):\n+        \"\"\"Create BitbucketTools instance with token for testing.\"\"\"\n+        with patch.dict(os.environ, {\"BITBUCKET_TOKEN\": \"test_token\"}):\n+            return BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\")\n+\n+    def test_init_with_required_params(self, mock_env_vars):\n+        \"\"\"Test successful initialization with required parameters.\"\"\"\n+        tools = BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\")\n+\n+        assert tools.workspace == \"test_workspace\"\n+        assert tools.repo_slug == \"test_repo\"\n+        assert tools.username == \"test_user\"\n+        assert tools.auth_password == \"test_password\"\n+        assert tools.server_url == \"api.bitbucket.org\"\n+        assert tools.api_version == \"2.0\"\n+        assert \"Basic\" in tools.headers[\"Authorization\"]\n+\n+    def test_init_with_custom_params(self, mock_env_vars):\n+        \"\"\"Test initialization with custom parameters.\"\"\"\n+        tools = BitbucketTools(\n+            workspace=\"custom_workspace\",\n+            repo_slug=\"custom_repo\",\n+            server_url=\"custom.bitbucket.com\",\n+            username=\"custom_user\",\n+            password=\"custom_password\",\n+            api_version=\"2.1\",\n+        )\n+\n+        assert tools.workspace == \"custom_workspace\"\n+        assert tools.repo_slug == \"custom_repo\"\n+        assert tools.username == \"custom_user\"\n+        assert tools.auth_password == \"custom_password\"\n+        assert tools.server_url == \"custom.bitbucket.com\"\n+        assert tools.api_version == \"2.1\"\n+\n+    def test_init_with_token_priority(self, mock_env_vars):\n+        \"\"\"Test that token takes priority over password.\"\"\"\n+        tools = BitbucketTools(\n+            workspace=\"test_workspace\", repo_slug=\"test_repo\", token=\"test_token\", password=\"test_password\"\n+        )\n+\n+        assert tools.auth_password == \"test_token\"\n+        assert tools.token == \"test_token\"\n+        assert tools.password == \"test_password\"\n+\n+    def test_init_missing_credentials(self):\n+        \"\"\"Test initialization fails without credentials.\"\"\"\n+        with patch.dict(os.environ, {}, clear=True):  # Clear all environment variables\n+            with pytest.raises(ValueError, match=\"Username and password or token are required\"):\n+                BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\")\n+\n+    def test_init_missing_workspace(self, mock_env_vars):\n+        \"\"\"Test initialization fails without workspace.\"\"\"\n+        with pytest.raises(ValueError, match=\"Workspace is required\"):\n+            BitbucketTools(repo_slug=\"test_repo\")\n+\n+    def test_init_missing_repo_slug(self, mock_env_vars):\n+        \"\"\"Test initialization fails without repo_slug.\"\"\"\n+        with pytest.raises(ValueError, match=\"Repo slug is required\"):\n+            BitbucketTools(workspace=\"test_workspace\")\n+\n+    def test_generate_access_token(self, bitbucket_tools):\n+        \"\"\"Test access token generation.\"\"\"\n+        token = bitbucket_tools._generate_access_token()\n+        assert isinstance(token, str)\n+        assert len(token) > 0\n+\n+    @patch(\"requests.request\")\n+    def test_make_request_json_response(self, mock_request, bitbucket_tools):\n+        \"\"\"Test _make_request with JSON response.\"\"\"\n+        mock_response = MagicMock()\n+        mock_response.headers = {\"Content-Type\": \"application/json\"}\n+        mock_response.json.return_value = {\"test\": \"data\"}\n+        mock_response.text = '{\"test\": \"data\"}'\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools._make_request(\"GET\", \"/test\")\n+\n+        assert result == {\"test\": \"data\"}\n+        mock_request.assert_called_once()\n+\n+    @patch(\"requests.request\")\n+    def test_make_request_text_response(self, mock_request, bitbucket_tools):\n+        \"\"\"Test _make_request with text response.\"\"\"\n+        mock_response = MagicMock()\n+        mock_response.headers = {\"Content-Type\": \"text/plain\"}\n+        mock_response.text = \"test data\"\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools._make_request(\"GET\", \"/test\")\n+\n+        assert result == \"test data\"\n+\n+    @patch(\"requests.request\")\n+    def test_make_request_empty_json_response(self, mock_request, bitbucket_tools):\n+        \"\"\"Test _make_request with empty JSON response.\"\"\"\n+        mock_response = MagicMock()\n+        mock_response.headers = {\"Content-Type\": \"application/json\"}\n+        mock_response.text = \"\"\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools._make_request(\"GET\", \"/test\")\n+\n+        assert result == {}\n+\n+    @patch(\"requests.request\")\n+    def test_make_request_unsupported_content_type(self, mock_request, bitbucket_tools):\n+        \"\"\"Test _make_request with unsupported content type.\"\"\"\n+        mock_response = MagicMock()\n+        mock_response.headers = {\"Content-Type\": \"application/xml\"}\n+        mock_request.return_value = mock_response\n+\n+        with patch(\"agno.tools.bitbucket.logger.warning\") as mock_logger:\n+            result = bitbucket_tools._make_request(\"GET\", \"/test\")\n+\n+            assert result == {}\n+            mock_logger.assert_called_once()\n+\n+    @patch(\"requests.request\")\n+    def test_make_request_http_error(self, mock_request, bitbucket_tools):\n+        \"\"\"Test _make_request with HTTP error.\"\"\"\n+        mock_request.side_effect = requests.exceptions.HTTPError(\"HTTP Error\")\n+\n+        with pytest.raises(requests.exceptions.HTTPError):\n+            bitbucket_tools._make_request(\"GET\", \"/test\")\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_repositories_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_repositories method success.\"\"\"\n+        mock_response = {\"values\": [{\"name\": \"repo1\"}, {\"name\": \"repo2\"}], \"page\": 1, \"size\": 2}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.list_repositories(count=5)\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\"GET\", \"/repositories/test_workspace\", params={\"page\": 1, \"pagelen\": 5})\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_repositories_max_count(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_repositories respects maximum count of 50.\"\"\"\n+        mock_response = {\"values\": []}\n+        mock_request.return_value = mock_response\n+\n+        bitbucket_tools.list_repositories(count=100)\n+\n+        # Should be limited to 50\n+        mock_request.assert_called_once_with(\"GET\", \"/repositories/test_workspace\", params={\"page\": 1, \"pagelen\": 50})\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_repositories_error(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_repositories error handling.\"\"\"\n+        mock_request.side_effect = Exception(\"API Error\")\n+\n+        with patch(\"agno.tools.bitbucket.logger.error\") as mock_logger:\n+            result = bitbucket_tools.list_repositories()\n+\n+            result_data = json.loads(result)\n+            assert \"error\" in result_data\n+            mock_logger.assert_called_once()\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_get_repository_details_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test get_repository_details method success.\"\"\"\n+        mock_response = {\"name\": \"test_repo\", \"full_name\": \"test_workspace/test_repo\"}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.get_repository_details()\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\"GET\", \"/repositories/test_workspace/test_repo\")\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_create_repository_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test create_repository method success.\"\"\"\n+        mock_response = {\"name\": \"new_repo\", \"is_private\": False}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.create_repository(name=\"new_repo\", description=\"Test repository\", is_private=False)\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+\n+        expected_payload = {\n+            \"name\": \"new_repo\",\n+            \"scm\": \"git\",\n+            \"is_private\": False,\n+            \"description\": \"Test repository\",\n+            \"language\": None,\n+            \"has_issues\": False,\n+            \"has_wiki\": False,\n+        }\n+        mock_request.assert_called_once_with(\"POST\", \"/repositories/test_workspace/test_repo\", data=expected_payload)\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_create_repository_with_project(self, mock_request, bitbucket_tools):\n+        \"\"\"Test create_repository with project parameter.\"\"\"\n+        mock_response = {\"name\": \"new_repo\"}\n+        mock_request.return_value = mock_response\n+\n+        bitbucket_tools.create_repository(name=\"new_repo\", project=\"TEST\")\n+\n+        call_args = mock_request.call_args\n+        payload = call_args[1][\"data\"]\n+        assert payload[\"project\"] == {\"key\": \"TEST\"}\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_repository_commits_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_repository_commits method success.\"\"\"\n+        mock_response = {\"values\": [{\"hash\": \"abc123\"}, {\"hash\": \"def456\"}], \"next\": None}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.list_repository_commits(count=10)\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\n+            \"GET\", \"/repositories/test_workspace/test_repo/commits\", params={\"pagelen\": 10}\n+        )\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_repository_commits_with_pagination(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_repository_commits with pagination.\"\"\"\n+        # First response with next page\n+        first_response = {\n+            \"values\": [{\"hash\": \"abc123\"}],\n+            \"next\": \"https://api.bitbucket.org/repositories/test_workspace/test_repo/commits?page=2\",\n+        }\n+        # Second response\n+        second_response = {\"values\": [{\"hash\": \"def456\"}], \"next\": None}\n+\n+        mock_request.side_effect = [first_response, second_response]\n+\n+        result = bitbucket_tools.list_repository_commits(count=10)\n+\n+        result_data = json.loads(result)\n+        assert len(result_data[\"values\"]) == 2\n+        assert result_data[\"values\"][0][\"hash\"] == \"abc123\"\n+        assert result_data[\"values\"][1][\"hash\"] == \"def456\"\n+        assert mock_request.call_count == 2\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_all_pull_requests_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_all_pull_requests method success.\"\"\"\n+        mock_response = {\"values\": [{\"id\": 1, \"title\": \"PR 1\"}, {\"id\": 2, \"title\": \"PR 2\"}]}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.list_all_pull_requests(state=\"OPEN\")\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\n+            \"GET\", \"/repositories/test_workspace/test_repo/pullrequests\", params={\"state\": \"OPEN\"}\n+        )\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_all_pull_requests_invalid_state(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_all_pull_requests with invalid state defaults to OPEN.\"\"\"\n+        mock_response = {\"values\": []}\n+        mock_request.return_value = mock_response\n+\n+        with patch(\"agno.tools.bitbucket.logger.debug\") as mock_logger:\n+            bitbucket_tools.list_all_pull_requests(state=\"INVALID\")\n+\n+            mock_logger.assert_called_once()\n+            # Should default to OPEN state\n+            mock_request.assert_called_once_with(\n+                \"GET\", \"/repositories/test_workspace/test_repo/pullrequests\", params={\"state\": \"OPEN\"}\n+            )\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_get_pull_request_details_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test get_pull_request_details method success.\"\"\"\n+        mock_response = {\"id\": 123, \"title\": \"Test PR\"}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.get_pull_request_details(pull_request_id=123)\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\"GET\", \"/repositories/test_workspace/test_repo/pullrequests/123\")\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_get_pull_request_changes_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test get_pull_request_changes method success.\"\"\"\n+        mock_diff = \"diff --git a/file.txt b/file.txt\\n+added line\"\n+        mock_request.return_value = mock_diff\n+\n+        result = bitbucket_tools.get_pull_request_changes(pull_request_id=123)\n+\n+        assert result == mock_diff\n+        mock_request.assert_called_once_with(\"GET\", \"/repositories/test_workspace/test_repo/pullrequests/123/diff\")\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_issues_success(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_issues method success.\"\"\"\n+        mock_response = {\"values\": [{\"id\": 1, \"title\": \"Issue 1\"}, {\"id\": 2, \"title\": \"Issue 2\"}]}\n+        mock_request.return_value = mock_response\n+\n+        result = bitbucket_tools.list_issues(count=10)\n+\n+        assert isinstance(result, str)\n+        result_data = json.loads(result)\n+        assert result_data == mock_response\n+        mock_request.assert_called_once_with(\n+            \"GET\", \"/repositories/test_workspace/test_repo/issues\", params={\"pagelen\": 10}\n+        )\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_list_issues_max_count(self, mock_request, bitbucket_tools):\n+        \"\"\"Test list_issues respects maximum count of 50.\"\"\"\n+        mock_response = {\"values\": []}\n+        mock_request.return_value = mock_response\n+\n+        bitbucket_tools.list_issues(count=100)\n+\n+        # Should be limited to 50\n+        mock_request.assert_called_once_with(\n+            \"GET\", \"/repositories/test_workspace/test_repo/issues\", params={\"pagelen\": 50}\n+        )\n+\n+    def test_base_url_construction_with_protocol(self, mock_env_vars):\n+        \"\"\"Test base URL construction when server_url already has protocol.\"\"\"\n+        tools = BitbucketTools(\n+            workspace=\"test_workspace\", repo_slug=\"test_repo\", server_url=\"https://custom.bitbucket.com\"\n+        )\n+\n+        assert tools.base_url == \"https://custom.bitbucket.com/2.0\"\n+\n+    def test_base_url_construction_without_protocol(self, mock_env_vars):\n+        \"\"\"Test base URL construction when server_url doesn't have protocol.\"\"\"\n+        tools = BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\", server_url=\"custom.bitbucket.com\")\n+\n+        assert tools.base_url == \"https://custom.bitbucket.com/2.0\"\n+\n+    def test_tools_registration(self, bitbucket_tools):\n+        \"\"\"Test that all expected tools are registered.\"\"\"\n+        # Check that the tools list contains the expected methods\n+        assert hasattr(bitbucket_tools, \"list_repositories\")\n+        assert hasattr(bitbucket_tools, \"get_repository_details\")\n+        assert hasattr(bitbucket_tools, \"create_repository\")\n+        assert hasattr(bitbucket_tools, \"list_repository_commits\")\n+        assert hasattr(bitbucket_tools, \"list_all_pull_requests\")\n+        assert hasattr(bitbucket_tools, \"get_pull_request_details\")\n+        assert hasattr(bitbucket_tools, \"get_pull_request_changes\")\n+        assert hasattr(bitbucket_tools, \"list_issues\")\n+\n+    @patch.object(BitbucketTools, \"_make_request\")\n+    def test_error_handling_returns_json_error(self, mock_request, bitbucket_tools):\n+        \"\"\"Test that errors are properly formatted as JSON.\"\"\"\n+        mock_request.side_effect = Exception(\"Test error\")\n+\n+        with patch(\"agno.tools.bitbucket.logger.error\"):\n+            result = bitbucket_tools.list_repositories()\n+\n+            result_data = json.loads(result)\n+            assert \"error\" in result_data\n+            assert \"Test error\" in result_data[\"error\"]\n+\n+    def test_env_var_fallbacks(self):\n+        \"\"\"Test environment variable fallbacks work correctly.\"\"\"\n+        with patch.dict(\n+            os.environ,\n+            {\"BITBUCKET_USERNAME\": \"env_user\", \"BITBUCKET_PASSWORD\": \"env_password\", \"BITBUCKET_TOKEN\": \"env_token\"},\n+        ):\n+            tools = BitbucketTools(workspace=\"test_workspace\", repo_slug=\"test_repo\")\n+\n+            assert tools.username == \"env_user\"\n+            assert tools.password == \"env_password\"\n+            assert tools.token == \"env_token\"\n+            assert tools.auth_password == \"env_token\"  # Token takes priority\n"
        }
    ]
}