{
    "sha_fail": "c434e89bee35d93f4e741c32dc36c5a9a68404df",
    "changed_files": [
        {
            "commit": "c434e89bee35d93f4e741c32dc36c5a9a68404df",
            "file_path": "cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py",
            "diff": "diff --git a/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py b/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py\nnew file mode 100644\nindex 000000000..0606a6667\n--- /dev/null\n+++ b/cookbook/agent_concepts/knowledge/filters/filtering_traditional_RAG.py\n@@ -0,0 +1,122 @@\n+\"\"\"\n+User-Level Knowledge Filtering Example\n+\n+This cookbook demonstrates how to use knowledge filters to restrict knowledge base searches to specific users, document types, or any other metadata attributes.\n+\n+Key concepts demonstrated:\n+1. Loading documents with user-specific metadata\n+2. Filtering knowledge base searches by user ID\n+3. Combining multiple filter criteria\n+4. Comparing results across different filter combinations\n+\n+You can pass filters in the following ways:\n+1. If you pass on Agent only, we use that for all runs\n+2. If you pass on run/print_response only, we use that for that run\n+3. If you pass on both, we override with the filters passed on run/print_response for that run\n+\"\"\"\n+\n+from agno.agent import Agent\n+from agno.knowledge.text import TextKnowledgeBase\n+from agno.utils.media import (\n+    SampleDataFileExtension,\n+    download_knowledge_filters_sample_data,\n+)\n+from agno.vectordb.lancedb import LanceDb\n+\n+# Download all sample CVs and get their paths\n+downloaded_cv_paths = download_knowledge_filters_sample_data(\n+    num_files=5, file_extension=SampleDataFileExtension.TXT\n+)\n+\n+# Initialize LanceDB\n+# By default, it stores data in /tmp/lancedb\n+vector_db = LanceDb(\n+    table_name=\"recipes\",\n+    uri=\"tmp/lancedb\",  # You can change this path to store data elsewhere\n+)\n+\n+# Step 1: Initialize knowledge base with documents and metadata\n+# ------------------------------------------------------------------------------\n+# When initializing the knowledge base, we can attach metadata that will be used for filtering\n+# This metadata can include user IDs, document types, dates, or any other attributes\n+\n+knowledge_base = TextKnowledgeBase(\n+    path=[\n+        {\n+            \"path\": downloaded_cv_paths[0],\n+            \"metadata\": {\n+                \"user_id\": \"jordan_mitchell\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[1],\n+            \"metadata\": {\n+                \"user_id\": \"taylor_brooks\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[2],\n+            \"metadata\": {\n+                \"user_id\": \"morgan_lee\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[3],\n+            \"metadata\": {\n+                \"user_id\": \"casey_jordan\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+        {\n+            \"path\": downloaded_cv_paths[4],\n+            \"metadata\": {\n+                \"user_id\": \"alex_rivera\",\n+                \"document_type\": \"cv\",\n+                \"year\": 2025,\n+            },\n+        },\n+    ],\n+    vector_db=vector_db,\n+)\n+\n+# Load all documents into the vector database\n+knowledge_base.load(recreate=True)\n+\n+# Step 2: Query the knowledge base with different filter combinations\n+# ------------------------------------------------------------------------------\n+\n+# Option 1: Filters on the Agent\n+# Initialize the Agent with the knowledge base and filters\n+agent = Agent(\n+    knowledge=knowledge_base,\n+    search_knowledge=False,\n+    add_references=True,\n+    knowledge_filters={\"user_id\": \"jordan_mitchell\"},\n+)\n+\n+# Query for Jordan Mitchell's experience and skills\n+agent.print_response(\n+    \"Tell me about Jordan Mitchell's experience and skills\",\n+    markdown=True,\n+)\n+\n+# # Option 2: Filters on the run/print_response\n+# agent = Agent(\n+#     knowledge=knowledge_base,\n+#     add_references=True,\n+#     search_knowledge=False,\n+# )\n+\n+# # Query for Taylor Brooks as a candidate\n+# agent.print_response(\n+#     \"Tell me about Taylor Brooks as a candidate\",\n+#     knowledge_filters={\"user_id\": \"taylor_brooks\"},\n+#     markdown=True,\n+# )\n"
        },
        {
            "commit": "c434e89bee35d93f4e741c32dc36c5a9a68404df",
            "file_path": "libs/agno/agno/agent/agent.py",
            "diff": "diff --git a/libs/agno/agno/agent/agent.py b/libs/agno/agno/agent/agent.py\nindex 0d8747580..eface6762 100644\n--- a/libs/agno/agno/agent/agent.py\n+++ b/libs/agno/agno/agent/agent.py\n@@ -983,6 +983,7 @@ class Agent:\n                     videos=videos,\n                     files=files,\n                     messages=messages,\n+                    knowledge_filters=effective_filters,\n                     **kwargs,\n                 )\n                 if len(run_messages.messages) == 0:\n@@ -1386,6 +1387,7 @@ class Agent:\n                     videos=videos,\n                     files=files,\n                     messages=messages,\n+                    knowledge_filters=effective_filters,\n                     **kwargs,\n                 )\n                 if len(run_messages.messages) == 0:\n@@ -4341,6 +4343,7 @@ class Agent:\n         images: Optional[Sequence[Image]] = None,\n         videos: Optional[Sequence[Video]] = None,\n         files: Optional[Sequence[File]] = None,\n+        knowledge_filters: Optional[Dict[str, Any]] = None,\n         **kwargs: Any,\n     ) -> Optional[Message]:\n         \"\"\"Return the user message for the Agent.\n@@ -4363,7 +4366,9 @@ class Agent:\n \n             retrieval_timer = Timer()\n             retrieval_timer.start()\n-            docs_from_knowledge = self.get_relevant_docs_from_knowledge(query=message_str, **kwargs)\n+            docs_from_knowledge = self.get_relevant_docs_from_knowledge(\n+                query=message_str, filters=knowledge_filters, **kwargs\n+            )\n             if docs_from_knowledge is not None:\n                 references = MessageReferences(\n                     query=message_str, references=docs_from_knowledge, time=round(retrieval_timer.elapsed, 4)\n@@ -4474,6 +4479,7 @@ class Agent:\n         videos: Optional[Sequence[Video]] = None,\n         files: Optional[Sequence[File]] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n+        knowledge_filters: Optional[Dict[str, Any]] = None,\n         **kwargs: Any,\n     ) -> RunMessages:\n         \"\"\"This function returns a RunMessages object with the following attributes:\n@@ -4571,7 +4577,13 @@ class Agent:\n         # 4.1 Build user message if message is None, str or list\n         if message is None or isinstance(message, str) or isinstance(message, list):\n             user_message = self.get_user_message(\n-                message=message, audio=audio, images=images, videos=videos, files=files, **kwargs\n+                message=message,\n+                audio=audio,\n+                images=images,\n+                videos=videos,\n+                files=files,\n+                knowledge_filters=knowledge_filters,\n+                **kwargs,\n             )\n         # 4.2 If message is provided as a Message, use it directly\n         elif isinstance(message, Message):\n"
        },
        {
            "commit": "c434e89bee35d93f4e741c32dc36c5a9a68404df",
            "file_path": "libs/agno/agno/models/openai/chat.py",
            "diff": "diff --git a/libs/agno/agno/models/openai/chat.py b/libs/agno/agno/models/openai/chat.py\nindex d9f062f47..e30ef1b3d 100644\n--- a/libs/agno/agno/models/openai/chat.py\n+++ b/libs/agno/agno/models/openai/chat.py\n@@ -25,7 +25,6 @@ try:\n         ChoiceDelta,\n         ChoiceDeltaToolCall,\n     )\n-    from openai.types.chat.parsed_chat_completion import ParsedChatCompletion\n except (ImportError, ModuleNotFoundError):\n     raise ImportError(\"`openai` not installed. Please install using `pip install openai`\")\n \n@@ -314,7 +313,7 @@ class OpenAIChat(Model):\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n         tools: Optional[List[Dict[str, Any]]] = None,\n         tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n-    ) -> Union[ChatCompletion, ParsedChatCompletion]:\n+    ) -> ChatCompletion:\n         \"\"\"\n         Send a chat completion request to the OpenAI API.\n \n@@ -375,7 +374,7 @@ class OpenAIChat(Model):\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n         tools: Optional[List[Dict[str, Any]]] = None,\n         tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n-    ) -> Union[ChatCompletion, ParsedChatCompletion]:\n+    ) -> ChatCompletion:\n         \"\"\"\n         Sends an asynchronous chat completion request to the OpenAI API.\n \n@@ -600,7 +599,7 @@ class OpenAIChat(Model):\n \n     def parse_provider_response(\n         self,\n-        response: Union[ChatCompletion, ParsedChatCompletion],\n+        response: ChatCompletion,\n         response_format: Optional[Union[Dict, Type[BaseModel]]] = None,\n     ) -> ModelResponse:\n         \"\"\"\n@@ -618,19 +617,6 @@ class OpenAIChat(Model):\n         # Get response message\n         response_message = response.choices[0].message\n \n-        # Parse structured outputs if enabled\n-        try:\n-            if (\n-                response_format is not None\n-                and isinstance(response_format, type)\n-                and issubclass(response_format, BaseModel)\n-            ):\n-                parsed_object = response_message.parsed  # type: ignore\n-                if parsed_object is not None:\n-                    model_response.parsed = parsed_object\n-        except Exception as e:\n-            log_warning(f\"Error retrieving structured outputs: {e}\")\n-\n         # Add role\n         if response_message.role is not None:\n             model_response.role = response_message.role\n"
        }
    ]
}