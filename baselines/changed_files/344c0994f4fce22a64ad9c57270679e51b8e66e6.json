{
    "sha_fail": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
    "changed_files": [
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/agentic_user_input.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/agentic_user_input.py b/cookbook/agent_concepts/user_control_flows/agentic_user_input.py\nindex 6117a6898..bebf2f68c 100644\n--- a/cookbook/agent_concepts/user_control_flows/agentic_user_input.py\n+++ b/cookbook/agent_concepts/user_control_flows/agentic_user_input.py\n@@ -1,6 +1,7 @@\n \"\"\"\ud83e\udd1d Human-in-the-Loop: Allowing users to provide input externally\n \n-This example shows how to use the UserControlFlowTools to allow the agent to get user input dynamically.\n+This example shows how to use the UserControlFlowTools to allow the agent to get user input dynamically.  \n+If the agent doesn't have enough information to complete a task, it will use the toolkit to get the information it needs from the user.\n \"\"\"\n \n from typing import Any, Dict\n@@ -42,7 +43,7 @@ class EmailTools(Toolkit):\n \n agent = Agent(\n     model=OpenAIChat(id=\"gpt-4o-mini\"),\n-    tools=[EmailTools(), UserControlFlowTools(get_user_input=True)],\n+    tools=[EmailTools(), UserControlFlowTools()],\n     markdown=True,\n     debug_mode=True,\n )\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required.py b/cookbook/agent_concepts/user_control_flows/confirmation_required.py\nindex c23da64c2..2ea5c930f 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required.py\n@@ -60,7 +60,7 @@ agent = Agent(\n     markdown=True,\n )\n \n-agent.run(\"Fetch the top 2 hackernews stories\")\n+agent.run(\"Fetch the top 2 hackernews stories.\")\n if agent.is_paused:  # Or agent.run_response.is_paused\n     for tool in agent.run_response.tools_requiring_confirmation:\n         # Ask for confirmation\n@@ -74,15 +74,19 @@ if agent.is_paused:  # Or agent.run_response.is_paused\n         )\n \n         if message == \"n\":\n-            break\n+            tool.confirmed = False\n         else:\n             # We update the tools in place\n             tool.confirmed = True\n \n-    run_response = (\n-        agent.continue_run()\n-    )  # or agent.continue_run(run_response=agent.run_response)\n-    pprint.pprint_run_response(run_response)\n+run_response = agent.continue_run()\n+# Or\n+# run_response = agent.continue_run(run_id=run_response.run_id)\n+# Or\n+# run_response = agent.continue_run(run_response=run_response)\n+\n+pprint.pprint_run_response(run_response)\n+\n \n # Or for simple debug flow\n # agent.print_response(\"Fetch the top 2 hackernews stories\")\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_async.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_async.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_async.py\nindex ef012c242..b0059e25b 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required_async.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_async.py\n@@ -75,13 +75,19 @@ if run_response.is_paused:\n         )\n \n         if message == \"n\":\n-            break\n+            tool.confirmed = False\n         else:\n             # We update the tools in place\n             tool.confirmed = True\n \n-    run_response = asyncio.run(agent.acontinue_run(run_response=run_response))\n-    pprint.pprint_run_response(run_response)\n+\n+run_response = asyncio.run(agent.acontinue_run(run_response=run_response))\n+# Or\n+# run_response = asyncio.run(agent.acontinue_run(run_id=run_response.run_id))\n+# Or\n+# run_response = asyncio.run(agent.acontinue_run())\n+\n+pprint.pprint_run_response(run_response)\n \n \n # Or for simple debug flow\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_mixed_tools.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_mixed_tools.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_mixed_tools.py\nnew file mode 100644\nindex 000000000..ac0779c83\n--- /dev/null\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_mixed_tools.py\n@@ -0,0 +1,99 @@\n+\"\"\"\ud83e\udd1d Human-in-the-Loop: Adding User Confirmation to Tool Calls\n+\n+This example shows how to implement human-in-the-loop functionality in your Agno tools.\n+\n+In this case we have multiple tools and only one of them requires confirmation.\n+\n+The agent should execute the tool that doesn't require confirmation and then pause for user confirmation.\n+\n+The user can then either approve or reject the tool call and the agent should continue from where it left off.\n+\"\"\"\n+\n+import json\n+\n+import httpx\n+from agno.agent import Agent\n+from agno.models.openai import OpenAIChat\n+from agno.tools import tool\n+from agno.utils import pprint\n+from rich.console import Console\n+from rich.prompt import Prompt\n+\n+console = Console()\n+\n+\n+def get_top_hackernews_stories(num_stories: int) -> str:\n+    \"\"\"Fetch top stories from Hacker News.\n+\n+    Args:\n+        num_stories (int): Number of stories to retrieve\n+\n+    Returns:\n+        str: JSON string containing story details\n+    \"\"\"\n+    # Fetch top story IDs\n+    response = httpx.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\")\n+    story_ids = response.json()\n+\n+    # Yield story details\n+    all_stories = []\n+    for story_id in story_ids[:num_stories]:\n+        story_response = httpx.get(\n+            f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\"\n+        )\n+        story = story_response.json()\n+        if \"text\" in story:\n+            story.pop(\"text\", None)\n+        all_stories.append(story)\n+    return json.dumps(all_stories)\n+\n+\n+@tool(requires_confirmation=True)\n+def send_email(to: str, subject: str, body: str) -> str:\n+    \"\"\"Send an email.\n+\n+    Args:\n+        to (str): Email address to send to\n+        subject (str): Subject of the email\n+        body (str): Body of the email\n+    \"\"\"\n+    return f\"Email sent to {to} with subject {subject} and body {body}\"\n+\n+\n+agent = Agent(\n+    model=OpenAIChat(id=\"gpt-4o-mini\"),\n+    tools=[get_top_hackernews_stories, send_email],\n+    markdown=True,\n+)\n+\n+run_response = agent.run(\n+    \"Fetch the top 2 hackernews stories and email them to john@doe.com.\"\n+)\n+if run_response.is_paused:  # Or agent.run_response.is_paused\n+    for tool in run_response.tools:\n+        if tool.requires_confirmation:\n+            # Ask for confirmation\n+            console.print(\n+                f\"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation.\"\n+            )\n+            message = (\n+                Prompt.ask(\"Do you want to continue?\", choices=[\"y\", \"n\"], default=\"y\")\n+                .strip()\n+                .lower()\n+            )\n+\n+            if message == \"n\":\n+                tool.confirmed = False\n+            else:\n+                # We update the tools in place\n+                tool.confirmed = True\n+        else:\n+            console.print(\n+                f\"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] was completed in [bold green]{tool.metrics.time:.2f}[/] seconds.\"\n+            )\n+\n+    run_response = agent.continue_run()\n+    pprint.pprint_run_response(run_response)\n+\n+# Or for simple debug flow\n+# agent.print_response(\"Fetch the top 2 hackernews stories\")\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_multiple_tools.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_multiple_tools.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_multiple_tools.py\nindex a5f999f86..fa028067b 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required_multiple_tools.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_multiple_tools.py\n@@ -1,12 +1,17 @@\n \"\"\"\ud83e\udd1d Human-in-the-Loop: Adding User Confirmation to Tool Calls\n \n This example shows how to implement human-in-the-loop functionality in your Agno tools.\n+It shows how to:\n+- Handle user confirmation during tool execution\n+- Gracefully cancel operations based on user choice\n \n-In this case we have multiple tools and only one of them requires confirmation.\n+Some practical applications:\n+- Confirming sensitive operations before execution\n+- Reviewing API calls before they're made\n+- Validating data transformations\n+- Approving automated actions in critical systems\n \n-The agent should execute the tool that doesn't require confirmation and then pause for user confirmation.\n-\n-The user can then either approve or reject the tool call and the agent should continue from where it left off.\n+Run `pip install openai httpx rich agno` to install dependencies.\n \"\"\"\n \n import json\n@@ -15,6 +20,7 @@ import httpx\n from agno.agent import Agent\n from agno.models.openai import OpenAIChat\n from agno.tools import tool\n+from agno.tools.wikipedia import WikipediaTools\n from agno.utils import pprint\n from rich.console import Console\n from rich.prompt import Prompt\n@@ -22,6 +28,7 @@ from rich.prompt import Prompt\n console = Console()\n \n \n+@tool(requires_confirmation=True)\n def get_top_hackernews_stories(num_stories: int) -> str:\n     \"\"\"Fetch top stories from Hacker News.\n \n@@ -48,52 +55,38 @@ def get_top_hackernews_stories(num_stories: int) -> str:\n     return json.dumps(all_stories)\n \n \n-@tool(requires_confirmation=True)\n-def send_email(to: str, subject: str, body: str) -> str:\n-    \"\"\"Send an email.\n-\n-    Args:\n-        to (str): Email address to send to\n-        subject (str): Subject of the email\n-        body (str): Body of the email\n-    \"\"\"\n-    return f\"Email sent to {to} with subject {subject} and body {body}\"\n-\n-\n agent = Agent(\n     model=OpenAIChat(id=\"gpt-4o-mini\"),\n-    tools=[get_top_hackernews_stories, send_email],\n+    tools=[\n+        get_top_hackernews_stories,\n+        WikipediaTools(requires_confirmation_tools=[\"search_wikipedia\"]),\n+    ],\n     markdown=True,\n+    debug_mode=True,\n )\n \n run_response = agent.run(\n-    \"Fetch the top 2 hackernews stories and email them to john@doe.com.\"\n+    \"Fetch 2 articles about the topic 'python'. You can choose which source to use, but only use one source.\"\n )\n-if run_response.is_paused:  # Or agent.run_response.is_paused\n-    for tool in run_response.tools:\n-        if tool.requires_confirmation:\n-            # Ask for confirmation\n-            console.print(\n-                f\"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation.\"\n-            )\n-            message = (\n-                Prompt.ask(\"Do you want to continue?\", choices=[\"y\", \"n\"], default=\"y\")\n-                .strip()\n-                .lower()\n-            )\n+while run_response.is_paused:  # Or agent.run_response.is_paused\n+    for tool in agent.run_response.tools_requiring_confirmation:\n+        # Ask for confirmation\n+        console.print(\n+            f\"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation.\"\n+        )\n+        message = (\n+            Prompt.ask(\"Do you want to continue?\", choices=[\"y\", \"n\"], default=\"y\")\n+            .strip()\n+            .lower()\n+        )\n \n-            if message == \"n\":\n-                break\n-            else:\n-                # We update the tools in place\n-                tool.confirmed = True\n-        else:\n-            console.print(\n-                f\"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] was completed in [bold green]{tool.metrics.time:.2f}[/] seconds.\"\n+        if message == \"n\":\n+            tool.confirmed = False\n+            tool.confirmation_note = (\n+                \"This is not the right tool to use. Use the other tool!\"\n             )\n+        else:\n+            # We update the tools in place\n+            tool.confirmed = True\n \n     run_response = agent.continue_run()\n-    pprint.pprint_run_response(run_response)\n-\n-# Or for simple debug flow\n-# agent.print_response(\"Fetch the top 2 hackernews stories\")\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_stream.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_stream.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_stream.py\nindex becd91c58..2f23325e6 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required_stream.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_stream.py\n@@ -74,7 +74,7 @@ for run_response in agent.run(\"Fetch the top 2 hackernews stories\", stream=True)\n             )\n \n             if message == \"n\":\n-                break\n+                tool.confirmed = False\n             else:\n                 # We update the tools in place\n                 tool.confirmed = True\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_stream_async.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_stream_async.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_stream_async.py\nindex e268c5ecb..9b565bc8f 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required_stream_async.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_stream_async.py\n@@ -80,7 +80,7 @@ async def main():\n                 )\n \n                 if message == \"n\":\n-                    break\n+                    tool.confirmed = False\n                 else:\n                     # We update the tools in place\n                     tool.confirmed = True\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/agent_concepts/user_control_flows/confirmation_required_toolkit.py",
            "diff": "diff --git a/cookbook/agent_concepts/user_control_flows/confirmation_required_toolkit.py b/cookbook/agent_concepts/user_control_flows/confirmation_required_toolkit.py\nindex 79753fec9..512f6bac4 100644\n--- a/cookbook/agent_concepts/user_control_flows/confirmation_required_toolkit.py\n+++ b/cookbook/agent_concepts/user_control_flows/confirmation_required_toolkit.py\n@@ -44,7 +44,7 @@ if agent.is_paused:  # Or agent.run_response.is_paused\n         )\n \n         if message == \"n\":\n-            break\n+            tool.confirmed = False\n         else:\n             # We update the tools in place\n             tool.confirmed = True\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "cookbook/tools/firecrawl_tools.py",
            "diff": "diff --git a/cookbook/tools/firecrawl_tools.py b/cookbook/tools/firecrawl_tools.py\nindex a8f158123..ec8c5f852 100644\n--- a/cookbook/tools/firecrawl_tools.py\n+++ b/cookbook/tools/firecrawl_tools.py\n@@ -1,9 +1,26 @@\n+\"\"\"\n+This is an example of how to use the FirecrawlTools.\n+\n+Prerequisites:\n+- Create a Firecrawl account and get an API key\n+- Set the API key as an environment variable:\n+    export FIRECRAWL_API_KEY=<your-api-key>\n+\"\"\"\n+\n from agno.agent import Agent\n from agno.tools.firecrawl import FirecrawlTools\n \n agent = Agent(\n-    tools=[FirecrawlTools(scrape=False, crawl=True)],\n+    tools=[FirecrawlTools(scrape=False, crawl=True, search=True, poll_interval=2)],\n     show_tool_calls=True,\n     markdown=True,\n )\n-agent.print_response(\"Summarize this https://finance.yahoo.com/\")\n+\n+# Should use search\n+agent.print_response(\n+    \"Search for the web for the latest on 'web scraping technologies'\",\n+    formats=[\"markdown\", \"links\"],\n+)\n+\n+# Should use crawl\n+agent.print_response(\"Summarize this https://docs.agno.com/introduction/\")\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/agent/agent.py",
            "diff": "diff --git a/libs/agno/agno/agent/agent.py b/libs/agno/agno/agent/agent.py\nindex a6acc4141..0e738a467 100644\n--- a/libs/agno/agno/agent/agent.py\n+++ b/libs/agno/agno/agent/agent.py\n@@ -590,10 +590,11 @@ class Agent:\n         Steps:\n         1. Reason about the task if reasoning is enabled\n         2. Generate a response from the Model (includes running function calls)\n-        3. Update Agent Memory\n-        4. Calculate session metrics\n-        5. Save session to storage\n-        6. Save output to file if save_response_to_file is set\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n         \"\"\"\n         log_debug(f\"Agent Run Start: {run_response.run_id}\", center=True)\n \n@@ -617,26 +618,36 @@ class Agent:\n \n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             return self._handle_agent_run_paused(\n                 run_response=run_response, session_id=session_id, user_id=user_id, message=message\n             )\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         self._update_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n-        # 5. Save session to storage\n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -660,6 +671,18 @@ class Agent:\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n         stream_intermediate_steps: bool = False,\n     ) -> Iterator[RunResponse]:\n+        \"\"\"Run the Agent and yield the RunResponse.\n+\n+        Steps:\n+        1. Reason about the task if reasoning is enabled\n+        2. Generate a response from the Model (includes running function calls)\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n+        \"\"\"\n+\n         log_debug(f\"Agent Run Start: {run_response.run_id}\", center=True)\n \n         # 1. Reason about the task if reasoning is enabled\n@@ -683,6 +706,15 @@ class Agent:\n         ):\n             yield event\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             yield from self._handle_agent_run_paused_stream(\n@@ -690,16 +722,17 @@ class Agent:\n             )\n             return\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         self._update_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n         # Yield UpdatingMemory event\n         if stream_intermediate_steps:\n             yield self.create_run_response(\n@@ -708,10 +741,10 @@ class Agent:\n                 event=RunEvent.updating_memory,\n             )\n \n-        # 5. Save session to storage\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -985,10 +1018,11 @@ class Agent:\n         Steps:\n         1. Reason about the task if reasoning is enabled\n         2. Generate a response from the Model (includes running function calls)\n-        3. Update Agent Memory\n-        4. Calculate session metrics\n-        5. Save session to storage\n-        6. Save output to file if save_response_to_file is set\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n         \"\"\"\n         log_debug(f\"Agent Run Start: {run_response.run_id}\", center=True)\n \n@@ -1012,26 +1046,36 @@ class Agent:\n \n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             return self._handle_agent_run_paused(\n                 run_response=run_response, session_id=session_id, user_id=user_id, message=message\n             )\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         await self._aupdate_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n-        # 5. Save session to storage\n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -1060,10 +1104,11 @@ class Agent:\n         Steps:\n         1. Reason about the task if reasoning is enabled\n         2. Generate a response from the Model (includes running function calls)\n-        3. Update Agent Memory\n-        4. Calculate session metrics\n-        5. Save session to storage\n-        6. Save output to file if save_response_to_file is set\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n         \"\"\"\n         log_debug(f\"Agent Run Start: {run_response.run_id}\", center=True)\n \n@@ -1089,6 +1134,15 @@ class Agent:\n         ):\n             yield event\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             for item in self._handle_agent_run_paused_stream(\n@@ -1097,16 +1151,17 @@ class Agent:\n                 yield item\n             return\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         await self._aupdate_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n         # Yield UpdatingMemory event\n         if stream_intermediate_steps:\n             yield self.create_run_response(\n@@ -1115,10 +1170,10 @@ class Agent:\n                 event=RunEvent.updating_memory,\n             )\n \n-        # 5. Save session to storage\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -1345,6 +1400,7 @@ class Agent:\n         self,\n         run_response: Optional[RunResponse] = None,\n         *,\n+        run_id: Optional[str] = None,\n         stream: Literal[False] = False,\n         stream_intermediate_steps: bool = False,\n         user_id: Optional[str] = None,\n@@ -1358,6 +1414,7 @@ class Agent:\n         self,\n         run_response: Optional[RunResponse] = None,\n         *,\n+        run_id: Optional[str] = None,\n         stream: Literal[True] = True,\n         stream_intermediate_steps: bool = False,\n         user_id: Optional[str] = None,\n@@ -1370,6 +1427,7 @@ class Agent:\n         self,\n         run_response: Optional[RunResponse] = None,\n         *,\n+        run_id: Optional[str] = None,\n         stream: Optional[bool] = None,\n         stream_intermediate_steps: bool = False,\n         user_id: Optional[str] = None,\n@@ -1440,6 +1498,30 @@ class Agent:\n         # Read existing session from storage\n         self.read_from_storage(session_id=session_id, user_id=user_id)\n \n+        # Run can be continued from previous run response or from passed run_response context\n+        if run_response is not None:\n+            messages = run_response.messages or []\n+            self.run_response = run_response\n+            self.run_id = run_response.run_id\n+        elif run_id is not None:\n+            if isinstance(self.memory, Memory):\n+                runs = self.memory.get_runs(session_id=session_id)\n+                run_response = next((r for r in runs if r.run_id == run_id), None)  # type: ignore\n+            else:\n+                runs = self.memory.runs  # type: ignore\n+                run_response = next((r for r in runs if r.response.run_id == run_id), None)  # type: ignore\n+            if run_response is None:\n+                raise RuntimeError(f\"No runs found for run ID {run_id}\")\n+            messages = run_response.messages or []\n+            self.run_response = run_response\n+            self.run_id = run_id\n+        else:\n+            self.run_response = cast(RunResponse, self.run_response)\n+            # We are continuing from a previous run\n+            run_response = self.run_response\n+            messages = self.run_response.messages or []\n+            self.run_id = self.run_response.run_id\n+\n         # Read existing session from storage\n         if self.context is not None:\n             self.resolve_run_context()\n@@ -1462,18 +1544,6 @@ class Agent:\n             knowledge_filters=effective_filters,\n         )\n \n-        # Run can be continued from previous run response or from passed run_response context\n-        if run_response is not None:\n-            messages = run_response.messages or []\n-            self.run_response = run_response\n-            self.run_id = run_response.run_id\n-        else:\n-            self.run_response = cast(RunResponse, self.run_response)\n-            # We are continuing from a previous run\n-            run_response = self.run_response\n-            messages = self.run_response.messages or []\n-            self.run_id = self.run_response.run_id\n-\n         # Extract original user message from messages and remove from messages\n         user_message = None\n         for m in messages:\n@@ -1575,6 +1645,17 @@ class Agent:\n         message: Optional[Union[str, List, Dict, Message]] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n     ) -> RunResponse:\n+        \"\"\"Continue a previous run.\n+\n+        Steps:\n+        1. Handle any updated tools\n+        2. Generate a response from the Model\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n+        \"\"\"\n         self.model = cast(Model, self.model)\n \n         # 1. Handle the updated tools\n@@ -1597,26 +1678,36 @@ class Agent:\n \n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             return self._handle_agent_run_paused(\n                 run_response=run_response, session_id=session_id, user_id=user_id, message=message\n             )\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         self._update_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n-        # 5. Save session to storage\n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -1640,16 +1731,16 @@ class Agent:\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n         stream_intermediate_steps: bool = False,\n     ) -> Iterator[RunResponse]:\n-        \"\"\"\n-        Continue a previous agent run\n+        \"\"\"Continue a previous run.\n \n         Steps:\n-        1. Handle tool calls as updated by the user\n+        1. Handle any updated tools\n         2. Generate a response from the Model\n-        3. Update Agent Memory\n-        4. Calculate session metrics\n-        5. Save session to storage\n-        6. Save output to file if save_response_to_file is set\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n         \"\"\"\n         # 1. Handle the updated tools\n         yield from self._handle_tool_call_updates_stream(\n@@ -1674,6 +1765,15 @@ class Agent:\n         ):\n             yield event\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             yield from self._handle_agent_run_paused_stream(\n@@ -1681,16 +1781,17 @@ class Agent:\n             )\n             return\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         self._update_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n         # Yield UpdatingMemory event\n         if stream_intermediate_steps:\n             yield self.create_run_response(\n@@ -1699,10 +1800,10 @@ class Agent:\n                 event=RunEvent.updating_memory,\n             )\n \n-        # 5. Save session to storage\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -1723,6 +1824,7 @@ class Agent:\n         self,\n         run_response: Optional[RunResponse] = None,\n         *,\n+        run_id: Optional[str] = None,\n         stream: Optional[bool] = None,\n         stream_intermediate_steps: bool = False,\n         user_id: Optional[str] = None,\n@@ -1793,6 +1895,30 @@ class Agent:\n         # Read existing session from storage\n         self.read_from_storage(session_id=session_id, user_id=user_id)\n \n+        # Run can be continued from previous run response or from passed run_response context\n+        if run_response is not None:\n+            messages = run_response.messages or []\n+            self.run_response = run_response\n+            self.run_id = run_response.run_id\n+        elif run_id is not None:\n+            if isinstance(self.memory, Memory):\n+                runs = self.memory.get_runs(session_id=session_id)\n+                run_response = next((r for r in runs if r.run_id == run_id), None)  # type: ignore\n+            else:\n+                runs = self.memory.runs  # type: ignore\n+                run_response = next((r for r in runs if r.response.run_id == run_id), None)  # type: ignore\n+            if run_response is None:\n+                raise RuntimeError(f\"No runs found for run ID {run_id}\")\n+            messages = run_response.messages or []\n+            self.run_response = run_response\n+            self.run_id = run_id\n+        else:\n+            # We are continuing from a previous run\n+            self.run_response = cast(RunResponse, self.run_response)\n+            run_response = self.run_response\n+            messages = self.run_response.messages or []\n+            self.run_id = self.run_response.run_id\n+\n         # Read existing session from storage\n         if self.context is not None:\n             self.resolve_run_context()\n@@ -1815,18 +1941,6 @@ class Agent:\n             knowledge_filters=effective_filters,\n         )\n \n-        # Run can be continued from previous run response or from passed run_response context\n-        if run_response is not None:\n-            messages = run_response.messages or []\n-            self.run_response = run_response\n-            self.run_id = run_response.run_id\n-        else:\n-            # We are continuing from a previous run\n-            self.run_response = cast(RunResponse, self.run_response)\n-            run_response = self.run_response\n-            messages = self.run_response.messages or []\n-            self.run_id = self.run_response.run_id\n-\n         # Extract original user message from messages and remove from messages\n         user_message = None\n         for m in messages:\n@@ -1927,6 +2041,18 @@ class Agent:\n         message: Optional[Union[str, List, Dict, Message]] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n     ) -> RunResponse:\n+        \"\"\"Continue a previous run.\n+\n+        Steps:\n+        1. Handle any updated tools\n+        2. Generate a response from the Model\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n+        \"\"\"\n+\n         self.model = cast(Model, self.model)\n \n         # 1. Handle the updated tools\n@@ -1948,26 +2074,36 @@ class Agent:\n \n         self._update_run_response(model_response=model_response, run_response=run_response, run_messages=run_messages)\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             return self._handle_agent_run_paused(\n                 run_response=run_response, session_id=session_id, user_id=user_id, message=message\n             )\n \n-        # 3. Update Agent Memory\n+        # 4. Update Agent Memory\n         await self._aupdate_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n-        # 5. Save session to storage\n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -1993,16 +2129,16 @@ class Agent:\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n         stream_intermediate_steps: bool = False,\n     ) -> AsyncIterator[RunResponse]:\n-        \"\"\"\n-        Continue a previous agent run\n+        \"\"\"Continue a previous run.\n \n         Steps:\n-        1. Handle tool calls as updated by the user\n+        1. Handle any updated tools\n         2. Generate a response from the Model\n-        3. Update Agent Memory\n-        4. Calculate session metrics\n-        5. Save session to storage\n-        6. Save output to file if save_response_to_file is set\n+        3. Add the run to memory\n+        4. Update Agent Memory\n+        5. Calculate session metrics\n+        6. Save session to storage\n+        7. Save output to file if save_response_to_file is set\n         \"\"\"\n         # 1. Handle the updated tools\n         async for event in self._ahandle_tool_call_updates_stream(\n@@ -2028,6 +2164,15 @@ class Agent:\n         ):\n             yield event\n \n+        # 3. Add the run to memory\n+        self._add_run_to_memory(\n+            run_response=run_response,\n+            run_messages=run_messages,\n+            session_id=session_id,\n+            messages=messages,\n+            index_of_last_user_message=index_of_last_user_message,\n+        )\n+\n         # We should break out of the run function\n         if any(tool_call.is_paused for tool_call in run_response.tools or []):\n             for item in self._handle_agent_run_paused_stream(\n@@ -2035,16 +2180,18 @@ class Agent:\n             ):\n                 yield item\n             return\n-        # 3. Update Agent Memory\n+\n+        # 4. Update Agent Memory\n         await self._aupdate_memory(\n-            run_response=run_response,\n             run_messages=run_messages,\n             session_id=session_id,\n             user_id=user_id,\n             messages=messages,\n-            index_of_last_user_message=index_of_last_user_message,\n         )\n \n+        # 5. Calculate session metrics\n+        self._set_session_metrics(run_messages)\n+\n         # Yield UpdatingMemory event\n         if stream_intermediate_steps:\n             yield self.create_run_response(\n@@ -2053,10 +2200,10 @@ class Agent:\n                 event=RunEvent.updating_memory,\n             )\n \n-        # 5. Save session to storage\n+        # 6. Save session to storage\n         self.write_to_storage(user_id=user_id, session_id=session_id)\n \n-        # 6. Save output to file if save_response_to_file is set\n+        # 7. Save output to file if save_response_to_file is set\n         self.save_run_response_to_file(message=message, session_id=session_id)\n \n         # Log Agent Run\n@@ -2217,6 +2364,17 @@ class Agent:\n         if len(function_call_results) > 0:\n             run_messages.messages.extend(function_call_results)\n \n+    def _reject_tool_call(self, run_messages: RunMessages, tool: ToolExecution):\n+        self.model = cast(Model, self.model)\n+        function_call = self.model.get_function_call_to_run_from_tool_execution(tool, self._functions_for_model)\n+        function_call.error = tool.confirmation_note or \"Function call was rejected by the user\"\n+\n+        function_call_result = self.model.create_function_call_result(\n+            function_call=function_call,\n+            success=False,\n+        )\n+        run_messages.messages.append(function_call_result)\n+\n     async def _arun_tool(\n         self, run_messages: RunMessages, tool: ToolExecution, session_id: Optional[str] = None\n     ) -> AsyncIterator[RunResponse]:\n@@ -2257,9 +2415,9 @@ class Agent:\n                 if _t.confirmed is not None and _t.confirmed is True and _t.result is None:\n                     # Consume the generator without yielding\n                     deque(self._run_tool(run_messages, _t), maxlen=0)\n-                    _t.requires_confirmation = False\n                 else:\n-                    raise ValueError(f\"Tool {_t.tool_name} requires confirmation, cannot continue run\")\n+                    self._reject_tool_call(run_messages, _t)\n+                _t.requires_confirmation = False\n \n             # Case 2: Handle external execution required tools\n             if _t.external_execution_required is not None and _t.external_execution_required is True:\n@@ -2291,10 +2449,9 @@ class Agent:\n                 # Tool is confirmed and hasn't been run before\n                 if _t.confirmed is not None and _t.confirmed is True and _t.result is None:\n                     yield from self._run_tool(run_messages, _t, session_id)\n-                    _t.requires_confirmation = False\n                 else:\n-                    raise ValueError(f\"Tool {_t.tool_name} requires confirmation, cannot continue run\")\n-\n+                    self._reject_tool_call(run_messages, _t)\n+                _t.requires_confirmation = False\n             # Case 2: Handle external execution required tools\n             if _t.external_execution_required is not None and _t.external_execution_required is True:\n                 self._handle_external_execution_update(run_messages=run_messages, tool=_t)\n@@ -2324,9 +2481,9 @@ class Agent:\n                 if _t.confirmed is not None and _t.confirmed is True and _t.result is None:\n                     async for _ in self._arun_tool(run_messages, _t):\n                         pass\n-                    _t.requires_confirmation = False\n                 else:\n-                    raise ValueError(f\"Tool {_t.tool_name} requires confirmation, cannot continue run\")\n+                    self._reject_tool_call(run_messages, _t)\n+                _t.requires_confirmation = False\n \n             # Case 2: Handle external execution required tools\n             if _t.external_execution_required is not None and _t.external_execution_required is True:\n@@ -2360,9 +2517,9 @@ class Agent:\n                 if _t.confirmed is not None and _t.confirmed is True and _t.result is None:\n                     async for event in self._arun_tool(run_messages, _t):\n                         yield event\n-                    _t.requires_confirmation = False\n                 else:\n-                    raise ValueError(f\"Tool {_t.tool_name} requires confirmation, cannot continue run\")\n+                    self._reject_tool_call(run_messages, _t)\n+                _t.requires_confirmation = False\n \n             # Case 2: Handle external execution required tools\n             if _t.external_execution_required is not None and _t.external_execution_required is True:\n@@ -2448,15 +2605,14 @@ class Agent:\n         # Update the RunResponse metrics\n         run_response.metrics = self.aggregate_metrics_from_messages(messages_for_run_response)\n \n-    def _update_memory(\n+    def _add_run_to_memory(\n         self,\n         run_response: RunResponse,\n         run_messages: RunMessages,\n         session_id: str,\n-        user_id: Optional[str] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n         index_of_last_user_message: int = 0,\n-    ) -> None:\n+    ):\n         if isinstance(self.memory, AgentMemory):\n             self.memory = cast(AgentMemory, self.memory)\n         else:\n@@ -2484,14 +2640,6 @@ class Agent:\n             agent_run = AgentRun(response=run_response)\n             agent_run.message = run_messages.user_message\n \n-            # Update the memories with the user message if needed\n-            if (\n-                self.memory.create_user_memories\n-                and self.memory.update_user_memories_after_run\n-                and run_messages.user_message is not None\n-            ):\n-                self.memory.update_memory(input=run_messages.user_message.get_content_string())\n-\n             if messages is not None and len(messages) > 0:\n                 for _im in messages:\n                     # Parse the message and convert to a Message object if possible\n@@ -2512,25 +2660,27 @@ class Agent:\n                         if agent_run.messages is None:\n                             agent_run.messages = []\n                         agent_run.messages.append(mp)\n-                        if self.memory.create_user_memories and self.memory.update_user_memories_after_run:\n-                            self.memory.update_memory(input=mp.get_content_string())\n                     else:\n                         log_warning(\"Unable to add message to memory\")\n+\n             # Add AgentRun to memory\n             self.memory.add_run(agent_run)\n-            # Update the session summary if needed\n-            if self.memory.create_session_summary and self.memory.update_session_summary_after_run:\n-                self.memory.update_summary()\n \n-            # 4. Calculate session metrics\n-            self.session_metrics = self.calculate_metrics(self.memory.messages)\n         elif isinstance(self.memory, Memory):\n             # Add AgentRun to memory\n             self.memory.add_run(session_id=session_id, run=run_response)\n \n-            self._make_memories_and_summaries(run_messages, session_id, user_id, messages)  # type: ignore\n+    def _set_session_metrics(self, run_messages: RunMessages):\n+        if isinstance(self.memory, AgentMemory):\n+            self.memory = cast(AgentMemory, self.memory)\n+        else:\n+            self.memory = cast(Memory, self.memory)\n \n-            # 4. Calculate session metrics\n+        if isinstance(self.memory, AgentMemory):\n+            # Calculate session metrics\n+            self.session_metrics = self.calculate_metrics(self.memory.messages)\n+        elif isinstance(self.memory, Memory):\n+            # Calculate session metrics\n             if self.session_metrics is None:\n                 self.session_metrics = self.calculate_metrics(run_messages.messages)  # Calculate metrics for the run\n             else:\n@@ -2538,14 +2688,12 @@ class Agent:\n                     run_messages.messages\n                 )  # Calculate metrics for the session\n \n-    async def _aupdate_memory(\n+    def _update_memory(\n         self,\n-        run_response: RunResponse,\n         run_messages: RunMessages,\n         session_id: str,\n         user_id: Optional[str] = None,\n         messages: Optional[Sequence[Union[Dict, Message]]] = None,\n-        index_of_last_user_message: int = 0,\n     ) -> None:\n         if isinstance(self.memory, AgentMemory):\n             self.memory = cast(AgentMemory, self.memory)\n@@ -2553,27 +2701,56 @@ class Agent:\n             self.memory = cast(Memory, self.memory)\n \n         if isinstance(self.memory, AgentMemory):\n-            # Add the system message to the memory\n-            if run_messages.system_message is not None:\n-                self.memory.add_system_message(\n-                    run_messages.system_message, system_message_role=self.system_message_role\n-                )\n+            # Update the memories with the user message if needed\n+            if (\n+                self.memory.create_user_memories\n+                and self.memory.update_user_memories_after_run\n+                and run_messages.user_message is not None\n+            ):\n+                self.memory.update_memory(input=run_messages.user_message.get_content_string())\n \n-            # Build a list of messages that should be added to the AgentMemory\n-            messages_for_memory: List[Message] = (\n-                [run_messages.user_message] if run_messages.user_message is not None else []\n-            )\n-            # Add messages from messages_for_run after the last user message\n-            for _rm in run_messages.messages[index_of_last_user_message:]:\n-                if _rm.add_to_agent_memory:\n-                    messages_for_memory.append(_rm)\n-            if len(messages_for_memory) > 0:\n-                self.memory.add_messages(messages=messages_for_memory)\n+            if messages is not None and len(messages) > 0:\n+                for _im in messages:\n+                    # Parse the message and convert to a Message object if possible\n+                    mp = None\n+                    if isinstance(_im, Message):\n+                        mp = _im\n+                    elif isinstance(_im, dict):\n+                        try:\n+                            mp = Message(**_im)\n+                        except Exception as e:\n+                            log_warning(f\"Failed to validate message during memory update: {e}\")\n+                    else:\n+                        log_warning(f\"Unsupported message type during memory update: {type(_im)}\")\n+                        continue\n \n-            # Create an AgentRun object to add to memory\n-            agent_run = AgentRun(response=run_response)\n-            agent_run.message = run_messages.user_message\n+                    # Add the message to the AgentRun\n+                    if mp:\n+                        if self.memory.create_user_memories and self.memory.update_user_memories_after_run:\n+                            self.memory.update_memory(input=mp.get_content_string())\n+                    else:\n+                        log_warning(\"Unable to add message to memory\")\n+\n+            # Update the session summary if needed\n+            if self.memory.create_session_summary and self.memory.update_session_summary_after_run:\n+                self.memory.update_summary()\n+\n+        elif isinstance(self.memory, Memory):\n+            self._make_memories_and_summaries(run_messages, session_id, user_id, messages)  # type: ignore\n \n+    async def _aupdate_memory(\n+        self,\n+        run_messages: RunMessages,\n+        session_id: str,\n+        user_id: Optional[str] = None,\n+        messages: Optional[Sequence[Union[Dict, Message]]] = None,\n+    ) -> None:\n+        if isinstance(self.memory, AgentMemory):\n+            self.memory = cast(AgentMemory, self.memory)\n+        else:\n+            self.memory = cast(Memory, self.memory)\n+\n+        if isinstance(self.memory, AgentMemory):\n             # Update the memories with the user message if needed\n             if (\n                 self.memory.create_user_memories\n@@ -2592,42 +2769,24 @@ class Agent:\n                         try:\n                             mp = Message(**_im)\n                         except Exception as e:\n-                            log_warning(f\"Failed to validate message: {e}\")\n+                            log_warning(f\"Failed to validate message during memory update: {e}\")\n                     else:\n                         log_warning(f\"Unsupported message type: {type(_im)}\")\n                         continue\n \n                     # Add the message to the AgentRun\n                     if mp:\n-                        if agent_run.messages is None:\n-                            agent_run.messages = []\n-                        agent_run.messages.append(mp)\n                         if self.memory.create_user_memories and self.memory.update_user_memories_after_run:\n                             await self.memory.aupdate_memory(input=mp.get_content_string())\n                     else:\n                         log_warning(\"Unable to add message to memory\")\n-            # Add AgentRun to memory\n-            self.memory.add_run(agent_run)\n             # Update the session summary if needed\n             if self.memory.create_session_summary and self.memory.update_session_summary_after_run:\n                 await self.memory.aupdate_summary()\n \n-            # 4. Calculate metrics for the run\n-            self.session_metrics = self.calculate_metrics(self.memory.messages)\n         elif isinstance(self.memory, Memory):\n-            # Add AgentRun to memory\n-            self.memory.add_run(session_id=session_id, run=run_response)\n-\n             await self._amake_memories_and_summaries(run_messages, session_id, user_id, messages)  # type: ignore\n \n-            # 4. Calculate metrics for the run\n-            if self.session_metrics is None:\n-                self.session_metrics = self.calculate_metrics(run_messages.messages)  # Calculate metrics for the run\n-            else:\n-                self.session_metrics += self.calculate_metrics(\n-                    run_messages.messages\n-                )  # Calculate metrics for the session\n-\n     def _handle_model_response_stream(\n         self,\n         run_response: RunResponse,\n@@ -3028,7 +3187,7 @@ class Agent:\n                         try:\n                             parsed_messages.append(Message(**_im))\n                         except Exception as e:\n-                            log_warning(f\"Failed to validate message: {e}\")\n+                            log_warning(f\"Failed to validate message during memory update: {e}\")\n                     else:\n                         log_warning(f\"Unsupported message type: {type(_im)}\")\n                         continue\n@@ -3072,7 +3231,7 @@ class Agent:\n                         try:\n                             parsed_messages.append(Message(**_im))\n                         except Exception as e:\n-                            log_warning(f\"Failed to validate message: {e}\")\n+                            log_warning(f\"Failed to validate message during memory update: {e}\")\n                     else:\n                         log_warning(f\"Unsupported message type: {type(_im)}\")\n                         continue\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/memory/agent.py",
            "diff": "diff --git a/libs/agno/agno/memory/agent.py b/libs/agno/agno/memory/agent.py\nindex e311f26de..c5ab8f73a 100644\n--- a/libs/agno/agno/memory/agent.py\n+++ b/libs/agno/agno/memory/agent.py\n@@ -98,8 +98,25 @@ class AgentMemory(BaseModel):\n \n     def add_run(self, agent_run: AgentRun) -> None:\n         \"\"\"Adds an AgentRun to the runs list.\"\"\"\n-        self.runs.append(agent_run)\n-        log_debug(\"Added AgentRun to AgentMemory\")\n+        # Initialize runs list if it doesn't exist\n+        if self.runs is None:\n+            self.runs = []\n+\n+        # Process run if it has a valid response with run_id\n+        if agent_run.response and agent_run.response.run_id:\n+            run_id = agent_run.response.run_id\n+\n+            # Check for existing run with same ID\n+            for i, run in enumerate(self.runs):\n+                if run.response and run.response.run_id == run_id:\n+                    # Replace existing run\n+                    self.runs[i] = agent_run\n+                    log_debug(f\"Replaced existing AgentRun with run_id {run_id} in memory\")\n+                    return\n+\n+            # Add new run if not found\n+            self.runs.append(agent_run)\n+            log_debug(\"Added AgentRun to AgentMemory\")\n \n     def add_system_message(self, message: Message, system_message_role: str = \"system\") -> None:\n         \"\"\"Add the system messages to the messages list\"\"\"\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/memory/v2/memory.py",
            "diff": "diff --git a/libs/agno/agno/memory/v2/memory.py b/libs/agno/agno/memory/v2/memory.py\nindex 96096e2b1..48a89aeb8 100644\n--- a/libs/agno/agno/memory/v2/memory.py\n+++ b/libs/agno/agno/memory/v2/memory.py\n@@ -674,7 +674,21 @@ class Memory:\n         if not self.runs:\n             self.runs = {}\n \n-        self.runs.setdefault(session_id, []).append(run)\n+        if session_id not in self.runs:\n+            self.runs[session_id] = []\n+\n+        # Check if run already exists with the same run_id\n+        if hasattr(run, \"run_id\") and run.run_id:\n+            run_id = run.run_id\n+            # Look for existing run with same ID\n+            for i, existing_run in enumerate(self.runs[session_id]):\n+                if hasattr(existing_run, \"run_id\") and existing_run.run_id == run_id:\n+                    # Replace existing run\n+                    self.runs[session_id][i] = run\n+                    log_debug(f\"Replaced existing run with run_id {run_id} in memory\")\n+                    return\n+\n+        self.runs[session_id].append(run)\n         log_debug(\"Added RunResponse to Memory\")\n \n     def get_messages_from_last_n_runs(\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/models/base.py",
            "diff": "diff --git a/libs/agno/agno/models/base.py b/libs/agno/agno/models/base.py\nindex 27a6f9fcf..02e6adbab 100644\n--- a/libs/agno/agno/models/base.py\n+++ b/libs/agno/agno/models/base.py\n@@ -1060,19 +1060,26 @@ class Model(ABC):\n                 function_calls_to_run.append(_function_call)\n         return function_calls_to_run\n \n-    def _create_function_call_result(\n-        self, fc: FunctionCall, success: bool, output: Optional[Union[List[Any], str]], timer: Timer\n+    def create_function_call_result(\n+        self,\n+        function_call: FunctionCall,\n+        success: bool,\n+        output: Optional[Union[List[Any], str]] = None,\n+        timer: Optional[Timer] = None,\n     ) -> Message:\n         \"\"\"Create a function call result message.\"\"\"\n+        kwargs = {}\n+        if timer is not None:\n+            kwargs[\"metrics\"] = MessageMetrics(time=timer.elapsed)\n         return Message(\n             role=self.tool_message_role,\n-            content=output if success else fc.error,\n-            tool_call_id=fc.call_id,\n-            tool_name=fc.function.name,\n-            tool_args=fc.arguments,\n+            content=output if success else function_call.error,\n+            tool_call_id=function_call.call_id,\n+            tool_name=function_call.function.name,\n+            tool_args=function_call.arguments,\n             tool_call_error=not success,\n-            stop_after_tool_call=fc.function.stop_after_tool_call,\n-            metrics=MessageMetrics(time=timer.elapsed),\n+            stop_after_tool_call=function_call.function.stop_after_tool_call,\n+            **kwargs,\n         )\n \n     def run_function_call(\n@@ -1128,7 +1135,7 @@ class Model(ABC):\n                 yield ModelResponse(content=function_call_output)\n \n         # Create and yield function call result\n-        function_call_result = self._create_function_call_result(\n+        function_call_result = self.create_function_call_result(\n             function_call, success=function_call_success, output=function_call_output, timer=function_call_timer\n         )\n         yield ModelResponse(\n@@ -1458,7 +1465,7 @@ class Model(ABC):\n                     yield ModelResponse(content=function_call_output)\n \n             # Create and yield function call result\n-            function_call_result = self._create_function_call_result(\n+            function_call_result = self.create_function_call_result(\n                 fc, success=function_call_success, output=function_call_output, timer=function_call_timer\n             )\n             yield ModelResponse(\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/models/ollama/tools.py",
            "diff": "diff --git a/libs/agno/agno/models/ollama/tools.py b/libs/agno/agno/models/ollama/tools.py\nindex b01c9c053..f6678ac60 100644\n--- a/libs/agno/agno/models/ollama/tools.py\n+++ b/libs/agno/agno/models/ollama/tools.py\n@@ -136,24 +136,24 @@ class OllamaTools(Ollama):\n \n         return model_response\n \n-    def _create_function_call_result(\n-        self, fc: FunctionCall, success: bool, output: Optional[Union[List[Any], str]], timer: Timer\n+    def create_function_call_result(\n+        self, function_call: FunctionCall, success: bool, output: Optional[Union[List[Any], str]], timer: Timer\n     ) -> Message:\n         \"\"\"Create a function call result message.\"\"\"\n         content = (\n             \"<tool_response>\\n\"\n-            + json.dumps({\"name\": fc.function.name, \"content\": output if success else fc.error})\n+            + json.dumps({\"name\": function_call.function.name, \"content\": output if success else function_call.error})\n             + \"\\n</tool_response>\"\n         )\n \n         return Message(\n             role=self.tool_message_role,\n             content=content,\n-            tool_call_id=fc.call_id,\n-            tool_name=fc.function.name,\n-            tool_args=fc.arguments,\n+            tool_call_id=function_call.call_id,\n+            tool_name=function_call.function.name,\n+            tool_args=function_call.arguments,\n             tool_call_error=not success,\n-            stop_after_tool_call=fc.function.stop_after_tool_call,\n+            stop_after_tool_call=function_call.function.stop_after_tool_call,\n             metrics=MessageMetrics(time=timer.elapsed),\n         )\n \n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/models/response.py",
            "diff": "diff --git a/libs/agno/agno/models/response.py b/libs/agno/agno/models/response.py\nindex 4258473e4..4f111575a 100644\n--- a/libs/agno/agno/models/response.py\n+++ b/libs/agno/agno/models/response.py\n@@ -35,6 +35,7 @@ class ToolExecution:\n \n     requires_confirmation: Optional[bool] = None\n     confirmed: Optional[bool] = None\n+    confirmation_note: Optional[str] = None\n \n     requires_user_input: Optional[bool] = None\n     user_input_schema: Optional[List[UserInputField]] = None\n@@ -52,6 +53,7 @@ class ToolExecution:\n \n         if self.user_input_schema is not None:\n             _dict[\"user_input_schema\"] = [field.to_dict() for field in self.user_input_schema]\n+            \n         return _dict\n \n \n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/tools/firecrawl.py",
            "diff": "diff --git a/libs/agno/agno/tools/firecrawl.py b/libs/agno/agno/tools/firecrawl.py\nindex f1f662ebe..9bb6870c4 100644\n--- a/libs/agno/agno/tools/firecrawl.py\n+++ b/libs/agno/agno/tools/firecrawl.py\n@@ -39,9 +39,12 @@ class FirecrawlTools(Toolkit):\n         api_key: Optional[str] = None,\n         formats: Optional[List[str]] = None,\n         limit: int = 10,\n+        poll_interval: int = 30,\n         scrape: bool = True,\n         crawl: bool = False,\n         mapping: bool = False,\n+        search: bool = False,\n+        search_params: Optional[Dict[str, Any]] = None,\n         api_url: Optional[str] = \"https://api.firecrawl.dev\",\n         **kwargs,\n     ):\n@@ -53,6 +56,7 @@ class FirecrawlTools(Toolkit):\n \n         self.formats: Optional[List[str]] = formats\n         self.limit: int = limit\n+        self.poll_interval: int = poll_interval\n         self.app: FirecrawlApp = FirecrawlApp(api_key=self.api_key, api_url=api_url)\n \n         # Start with scrape by default. But if crawl is set, then set scrape to False.\n@@ -68,6 +72,9 @@ class FirecrawlTools(Toolkit):\n             self.register(self.crawl_website)\n         if mapping:\n             self.register(self.map_website)\n+        if search:\n+            self.register(self.search)\n+        self.search_params = search_params\n \n     def scrape_website(self, url: str) -> str:\n         \"\"\"Use this function to scrape a website using Firecrawl.\n@@ -98,7 +105,7 @@ class FirecrawlTools(Toolkit):\n         if self.formats:\n             params[\"scrape_options\"] = ScrapeOptions(formats=self.formats)  # type: ignore\n \n-        params[\"poll_interval\"] = 30\n+        params[\"poll_interval\"] = self.poll_interval\n \n         crawl_result = self.app.crawl_url(url, **params)\n         return json.dumps(crawl_result.model_dump(), cls=CustomJSONEncoder)\n@@ -112,3 +119,24 @@ class FirecrawlTools(Toolkit):\n         \"\"\"\n         map_result = self.app.map_url(url)\n         return json.dumps(map_result.model_dump(), cls=CustomJSONEncoder)\n+\n+    def search(self, query: str, limit: Optional[int] = None):\n+        \"\"\"Use this function to search for the web using Firecrawl.\n+\n+        Args:\n+            query (str): The query to search for.\n+            limit (int): The maximum number of results to return.\n+        \"\"\"\n+        params: Dict[str, Any] = {}\n+        if self.limit or limit:\n+            params[\"limit\"] = self.limit or limit\n+        if self.formats:\n+            params[\"scrape_options\"] = ScrapeOptions(formats=self.formats)  # type: ignore\n+        if self.search_params:\n+            params.update(self.search_params)\n+\n+        search_result = self.app.search(query, **params)\n+        if search_result.success:\n+            return json.dumps(search_result.data, cls=CustomJSONEncoder)\n+        else:\n+            return \"Error searching with the Firecrawl tool: \" + search_result.error\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/tools/user_control_flow.py",
            "diff": "diff --git a/libs/agno/agno/tools/user_control_flow.py b/libs/agno/agno/tools/user_control_flow.py\nindex 8bd8ed10e..92ba6c3a0 100644\n--- a/libs/agno/agno/tools/user_control_flow.py\n+++ b/libs/agno/agno/tools/user_control_flow.py\n@@ -7,16 +7,13 @@ from agno.tools import Toolkit\n class UserControlFlowTools(Toolkit):\n     def __init__(\n         self,\n-        get_user_input: bool = True,\n         instructions: Optional[str] = None,\n         add_instructions: bool = True,\n         **kwargs,\n     ):\n         \"\"\"A toolkit that provides the ability for the agent to interrupt the agent run and interact with the user.\"\"\"\n \n-        tools = []\n-        if get_user_input:\n-            tools.append(self.get_user_input)\n+        tools = [self.get_user_input]\n \n         super().__init__(\n             name=\"user_control_flow_tools\",\n@@ -52,10 +49,10 @@ class UserControlFlowTools(Toolkit):\n             - Usage: Call `get_user_input` with the fields you require the user to fill in for you to continue your task.\n \n         ## IMPORTANT GUIDELINES\n-        - **Don't respond and ask the user for information:** Don't respond and ask the user for information. Just use the `get_user_input` tool to get the information you need from the user.\n-        - **Don't make up information you don't have:** Don't make up information you don't have. If you don't have the information, use the `get_user_input` tool to get the information you need from the user.\n-        - **Include only the required fields:** Include only the required fields in the `user_input_fields` parameter of the `get_user_input` tool. Don't include fields you already have the information for.\n-        - **Provide a clear and concise description of the field:** Provide a clear and concise description of the field in the `field_description` parameter of the `user_input_fields` parameter of the `get_user_input` tool.\n-        - **Provide a type for the field:** Provide a type for the field in the `field_type` parameter of the `user_input_fields` parameter of the `get_user_input` tool.\n+        - **Don't respond and ask the user for information.** Just use the `get_user_input` tool to get the information you need from the user.\n+        - **Don't make up information you don't have.** If you don't have the information, use the `get_user_input` tool to get the information you need from the user.\n+        - **Include only the required fields.** Include only the required fields in the `user_input_fields` parameter of the `get_user_input` tool. Don't include fields you already have the information for.\n+        - **Provide a clear and concise description of the field.** Clearly describe the field in the `field_description` parameter of the `user_input_fields` parameter of the `get_user_input` tool.\n+        - **Provide a type for the field.** Fill the `field_type` parameter of the `user_input_fields` parameter of the `get_user_input` tool with the type of the field.\n         \"\"\"\n     )\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/agno/tools/wikipedia.py",
            "diff": "diff --git a/libs/agno/agno/tools/wikipedia.py b/libs/agno/agno/tools/wikipedia.py\nindex c086a1e9f..c9a846b1e 100644\n--- a/libs/agno/agno/tools/wikipedia.py\n+++ b/libs/agno/agno/tools/wikipedia.py\n@@ -9,13 +9,15 @@ from agno.utils.log import log_debug, log_info\n \n class WikipediaTools(Toolkit):\n     def __init__(self, knowledge_base: Optional[WikipediaKnowledgeBase] = None, **kwargs):\n-        super().__init__(name=\"wikipedia_tools\", **kwargs)\n-        self.knowledge_base: Optional[WikipediaKnowledgeBase] = knowledge_base\n+        tools = []\n \n+        self.knowledge_base: Optional[WikipediaKnowledgeBase] = knowledge_base\n         if self.knowledge_base is not None and isinstance(self.knowledge_base, WikipediaKnowledgeBase):\n-            self.register(self.search_wikipedia_and_update_knowledge_base)\n+            tools.append(self.search_wikipedia_and_update_knowledge_base)\n         else:\n-            self.register(self.search_wikipedia)\n+            tools.append(self.search_wikipedia)  # type: ignore\n+\n+        super().__init__(name=\"wikipedia_tools\", tools=tools, **kwargs)\n \n     def search_wikipedia_and_update_knowledge_base(self, topic: str) -> str:\n         \"\"\"This function searches wikipedia for a topic, adds the results to the knowledge base and returns them.\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py",
            "diff": "diff --git a/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py b/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\nindex aea583356..8f1a44b23 100644\n--- a/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\n+++ b/libs/agno/tests/integration/agent/test_agent_with_storage_and_memory.py\n@@ -5,9 +5,11 @@ import uuid\n import pytest\n \n from agno.agent.agent import Agent\n+from agno.memory.agent import AgentMemory\n from agno.memory.v2.db.sqlite import SqliteMemoryDb\n from agno.memory.v2.memory import Memory\n from agno.models.anthropic.claude import Claude\n+from agno.models.message import Message\n from agno.models.openai.chat import OpenAIChat\n from agno.storage.sqlite import SqliteStorage\n \n@@ -65,6 +67,16 @@ def memory(memory_db):\n @pytest.fixture\n def chat_agent(agent_storage, memory):\n     \"\"\"Create an agent with storage and memory for testing.\"\"\"\n+    return Agent(\n+        model=OpenAIChat(id=\"gpt-4o-mini\"),\n+        storage=agent_storage,\n+        memory=memory,\n+    )\n+\n+\n+@pytest.fixture\n+def memory_agent(agent_storage, memory):\n+    \"\"\"Create an agent that creates memories.\"\"\"\n     return Agent(\n         model=OpenAIChat(id=\"gpt-4o-mini\"),\n         storage=agent_storage,\n@@ -73,8 +85,49 @@ def chat_agent(agent_storage, memory):\n     )\n \n \n+def test_agent_runs_in_memory(chat_agent):\n+    session_id = \"test_session\"\n+    response = chat_agent.run(\"Hello, how are you?\", session_id=session_id)\n+    assert response is not None\n+    assert response.content is not None\n+    assert response.run_id is not None\n+\n+    assert len(chat_agent.memory.runs[session_id]) == 1\n+    stored_run_response = chat_agent.memory.runs[session_id][0]\n+    assert stored_run_response.run_id == response.run_id\n+    assert len(stored_run_response.messages) == 2\n+\n+    # Check that the run is also stored in the agent session\n+    assert len(chat_agent.agent_session.memory[\"runs\"]) == 1\n+\n+\n+def test_agent_runs_in_memory_legacy(chat_agent):\n+    chat_agent.memory = AgentMemory()\n+    session_id = \"test_session\"\n+    response = chat_agent.run(\n+        \"What can you do?\",\n+        messages=[\n+            Message(role=\"user\", content=\"Hello, how are you?\"),\n+            Message(role=\"assistant\", content=\"I'm good, thank you!\"),\n+        ],\n+        session_id=session_id,\n+    )\n+    assert response is not None\n+    assert response.content is not None\n+    assert response.run_id is not None\n+\n+    assert len(chat_agent.memory.runs) == 1\n+    stored_agent_run = chat_agent.memory.runs[0]\n+    assert stored_agent_run.response.run_id == response.run_id\n+    assert len(stored_agent_run.response.messages) == 4\n+    assert len(stored_agent_run.messages) == 2\n+\n+    # Check that the run is also stored in the agent session\n+    assert len(chat_agent.agent_session.memory[\"runs\"]) == 1\n+\n+\n @pytest.mark.asyncio\n-async def test_multi_user_multi_session_chat(chat_agent, agent_storage, memory):\n+async def test_multi_user_multi_session_chat(memory_agent, agent_storage, memory):\n     \"\"\"Test multi-user multi-session chat with storage and memory.\"\"\"\n     # Define user and session IDs\n     user_1_id = \"user_1@example.com\"\n@@ -90,26 +143,26 @@ async def test_multi_user_multi_session_chat(chat_agent, agent_storage, memory):\n     memory.clear()\n \n     # Chat with user 1 - Session 1\n-    await chat_agent.arun(\n+    await memory_agent.arun(\n         \"My name is Mark Gonzales and I like anime and video games.\", user_id=user_1_id, session_id=user_1_session_1_id\n     )\n-    await chat_agent.arun(\n+    await memory_agent.arun(\n         \"I also enjoy reading manga and playing video games.\", user_id=user_1_id, session_id=user_1_session_1_id\n     )\n \n     # Chat with user 1 - Session 2\n-    await chat_agent.arun(\"I'm going to the movies tonight.\", user_id=user_1_id, session_id=user_1_session_2_id)\n+    await memory_agent.arun(\"I'm going to the movies tonight.\", user_id=user_1_id, session_id=user_1_session_2_id)\n \n     # Chat with user 2\n-    await chat_agent.arun(\"Hi my name is John Doe.\", user_id=user_2_id, session_id=user_2_session_1_id)\n-    await chat_agent.arun(\"I'm planning to hike this weekend.\", user_id=user_2_id, session_id=user_2_session_1_id)\n+    await memory_agent.arun(\"Hi my name is John Doe.\", user_id=user_2_id, session_id=user_2_session_1_id)\n+    await memory_agent.arun(\"I'm planning to hike this weekend.\", user_id=user_2_id, session_id=user_2_session_1_id)\n \n     # Chat with user 3\n-    await chat_agent.arun(\"Hi my name is Jane Smith.\", user_id=user_3_id, session_id=user_3_session_1_id)\n-    await chat_agent.arun(\"I'm going to the gym tomorrow.\", user_id=user_3_id, session_id=user_3_session_1_id)\n+    await memory_agent.arun(\"Hi my name is Jane Smith.\", user_id=user_3_id, session_id=user_3_session_1_id)\n+    await memory_agent.arun(\"I'm going to the gym tomorrow.\", user_id=user_3_id, session_id=user_3_session_1_id)\n \n     # Continue the conversation with user 1\n-    await chat_agent.arun(\"What do you suggest I do this weekend?\", user_id=user_1_id, session_id=user_1_session_1_id)\n+    await memory_agent.arun(\"What do you suggest I do this weekend?\", user_id=user_1_id, session_id=user_1_session_1_id)\n \n     # Verify storage DB has the right sessions\n     all_session_ids = agent_storage.get_all_session_ids()\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/tests/integration/agent/test_user_confirmation_flows.py",
            "diff": "diff --git a/libs/agno/tests/integration/agent/test_user_confirmation_flows.py b/libs/agno/tests/integration/agent/test_user_confirmation_flows.py\nindex 861059ba7..ea52c8dc8 100644\n--- a/libs/agno/tests/integration/agent/test_user_confirmation_flows.py\n+++ b/libs/agno/tests/integration/agent/test_user_confirmation_flows.py\n@@ -19,6 +19,35 @@ def test_tool_call_requires_confirmation():\n         monitoring=False,\n     )\n \n+    agent.run(\"What is the weather in Tokyo?\")\n+\n+    assert agent.run_response.is_paused\n+    assert agent.run_response.tools[0].requires_confirmation\n+    assert agent.run_response.tools[0].tool_name == \"get_the_weather\"\n+    assert agent.run_response.tools[0].tool_args == {\"city\": \"Tokyo\"}\n+\n+    # Mark the tool as confirmed\n+    agent.run_response.tools[0].confirmed = True\n+\n+    agent.continue_run()\n+    assert agent.run_response.is_paused is False\n+    assert agent.run_response.tools[0].result == \"It is currently 70 degrees and cloudy in Tokyo\"\n+\n+\n+def test_tool_call_requires_confirmation_continue_with_run_response():\n+    @tool(requires_confirmation=True)\n+    def get_the_weather(city: str):\n+        return f\"It is currently 70 degrees and cloudy in {city}\"\n+\n+    agent = Agent(\n+        model=OpenAIChat(id=\"gpt-4o-mini\"),\n+        tools=[get_the_weather],\n+        show_tool_calls=True,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n     response = agent.run(\"What is the weather in Tokyo?\")\n \n     assert response.is_paused\n@@ -34,6 +63,73 @@ def test_tool_call_requires_confirmation():\n     assert response.tools[0].result == \"It is currently 70 degrees and cloudy in Tokyo\"\n \n \n+def test_tool_call_requires_confirmation_continue_with_run_id():\n+    @tool(requires_confirmation=True)\n+    def get_the_weather(city: str):\n+        return f\"It is currently 70 degrees and cloudy in {city}\"\n+\n+    agent = Agent(\n+        model=OpenAIChat(id=\"gpt-4o-mini\"),\n+        tools=[get_the_weather],\n+        show_tool_calls=True,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    response = agent.run(\"What is the weather in Tokyo?\")\n+\n+    assert response.is_paused\n+    assert response.tools[0].requires_confirmation\n+    assert response.tools[0].tool_name == \"get_the_weather\"\n+    assert response.tools[0].tool_args == {\"city\": \"Tokyo\"}\n+\n+    # Mark the tool as confirmed\n+    response.tools[0].confirmed = True\n+\n+    response = agent.continue_run(run_id=response.run_id)\n+    assert response.is_paused is False\n+    assert response.tools[0].result == \"It is currently 70 degrees and cloudy in Tokyo\"\n+\n+\n+def test_tool_call_requires_confirmation_memory_footprint():\n+    @tool(requires_confirmation=True)\n+    def get_the_weather(city: str):\n+        return f\"It is currently 70 degrees and cloudy in {city}\"\n+\n+    agent = Agent(\n+        model=OpenAIChat(id=\"gpt-4o-mini\"),\n+        tools=[get_the_weather],\n+        show_tool_calls=True,\n+        markdown=True,\n+        telemetry=False,\n+        monitoring=False,\n+    )\n+\n+    session_id = \"test_session\"\n+\n+    response = agent.run(\"What is the weather in Tokyo?\", session_id=session_id)\n+\n+    assert len(agent.memory.runs[session_id]) == 1, \"There should be one run in the memory\"\n+    assert len(agent.memory.runs[session_id][0].messages) == 3, (\n+        \"There should be three messages in the run (system, user, assistant)\"\n+    )\n+\n+    assert response.is_paused\n+\n+    # Mark the tool as confirmed\n+    response.tools[0].confirmed = True\n+\n+    response = agent.continue_run(response)\n+    assert response.is_paused is False\n+    assert response.tools[0].result == \"It is currently 70 degrees and cloudy in Tokyo\"\n+\n+    assert len(agent.memory.runs[session_id]) == 1, \"There should be one run in the memory\"\n+    assert len(agent.memory.runs[session_id][0].messages) == 5, (\n+        \"There should be five messages in the run (system, user, assistant, tool call, assistant)\"\n+    )\n+\n+\n def test_tool_call_requires_confirmation_stream():\n     @tool(requires_confirmation=True)\n     def get_the_weather(city: str):\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/tests/unit/reader/test_firecrawl_reader.py",
            "diff": "diff --git a/libs/agno/tests/unit/reader/test_firecrawl_reader.py b/libs/agno/tests/unit/reader/test_firecrawl_reader.py\nindex 8a9d48471..a09a21a52 100644\n--- a/libs/agno/tests/unit/reader/test_firecrawl_reader.py\n+++ b/libs/agno/tests/unit/reader/test_firecrawl_reader.py\n@@ -78,6 +78,27 @@ def test_scrape_with_api_key_and_params():\n         mock_app.scrape_url.assert_called_once_with(\"https://example.com\", **params)\n \n \n+def test_scrape_with_api_key_and_formats_params():\n+    \"\"\"Test scraping with API key and formats parameter\"\"\"\n+    with patch(\"agno.document.reader.firecrawl_reader.FirecrawlApp\") as MockFirecrawlApp:\n+        # Set up mock\n+        mock_app = MockFirecrawlApp.return_value\n+        mock_app.scrape_url.return_value = {\"markdown\": \"Test content\"}\n+\n+        # Create reader with API key and params containing both formats and other params\n+        api_key = \"test_api_key\"\n+        params = {\n+            \"waitUntil\": \"networkidle2\",  # This should be ignored\n+            \"formats\": [\"markdown\"],\n+        }\n+        reader = FirecrawlReader(api_key=api_key, params=params)\n+        reader.scrape(\"https://example.com\")\n+\n+        # Verify FirecrawlApp was called with correct parameters\n+        MockFirecrawlApp.assert_called_once_with(api_key=api_key)\n+        mock_app.scrape_url.assert_called_once_with(\"https://example.com\", params=params)\n+\n+\n def test_scrape_empty_response():\n     \"\"\"Test handling of empty response from scrape_url\"\"\"\n     with patch(\"agno.document.reader.firecrawl_reader.FirecrawlApp\") as MockFirecrawlApp:\n"
        },
        {
            "commit": "344c0994f4fce22a64ad9c57270679e51b8e66e6",
            "file_path": "libs/agno/tests/unit/tools/test_firecrawl.py",
            "diff": "diff --git a/libs/agno/tests/unit/tools/test_firecrawl.py b/libs/agno/tests/unit/tools/test_firecrawl.py\nnew file mode 100644\nindex 000000000..43e60985c\n--- /dev/null\n+++ b/libs/agno/tests/unit/tools/test_firecrawl.py\n@@ -0,0 +1,225 @@\n+\"\"\"Unit tests for FirecrawlTools class.\"\"\"\n+\n+import json\n+import os\n+from unittest.mock import Mock, patch\n+\n+import pytest\n+from firecrawl import FirecrawlApp\n+\n+from agno.tools.firecrawl import FirecrawlTools\n+\n+TEST_API_KEY = os.environ.get(\"FIRECRAWL_API_KEY\", \"test_api_key\")\n+TEST_API_URL = \"https://api.firecrawl.dev\"\n+\n+\n+@pytest.fixture\n+def mock_firecrawl():\n+    \"\"\"Create a mock FirecrawlApp instance.\"\"\"\n+    with patch(\"agno.tools.firecrawl.FirecrawlApp\") as mock_firecrawl_cls:\n+        mock_app = Mock(spec=FirecrawlApp)\n+        mock_firecrawl_cls.return_value = mock_app\n+        return mock_app\n+\n+\n+@pytest.fixture\n+def firecrawl_tools(mock_firecrawl):\n+    \"\"\"Create a FirecrawlTools instance with mocked dependencies.\"\"\"\n+    with patch.dict(\"os.environ\", {\"FIRECRAWL_API_KEY\": TEST_API_KEY}):\n+        tools = FirecrawlTools()\n+        # Directly set the app to our mock to avoid initialization issues\n+        tools.app = mock_firecrawl\n+        return tools\n+\n+\n+def test_init_with_env_vars():\n+    \"\"\"Test initialization with environment variables.\"\"\"\n+    with patch(\"agno.tools.firecrawl.FirecrawlApp\"):\n+        with patch.dict(\"os.environ\", {\"FIRECRAWL_API_KEY\": TEST_API_KEY}, clear=True):\n+            tools = FirecrawlTools()\n+            assert tools.api_key == TEST_API_KEY\n+            assert tools.formats is None\n+            assert tools.limit == 10\n+            assert tools.app is not None\n+\n+\n+def test_init_with_params():\n+    \"\"\"Test initialization with parameters.\"\"\"\n+    with patch(\"agno.tools.firecrawl.FirecrawlApp\"):\n+        tools = FirecrawlTools(api_key=\"param_api_key\", formats=[\"html\", \"text\"], limit=5, api_url=TEST_API_URL)\n+        assert tools.api_key == \"param_api_key\"\n+        assert tools.formats == [\"html\", \"text\"]\n+        assert tools.limit == 5\n+        assert tools.app is not None\n+\n+\n+def test_scrape_website(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test scrape_website method.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.model_dump.return_value = {\n+        \"url\": \"https://example.com\",\n+        \"content\": \"Test content\",\n+        \"status\": \"success\",\n+    }\n+    mock_firecrawl.scrape_url.return_value = mock_response\n+\n+    # Call the method\n+    result = firecrawl_tools.scrape_website(\"https://example.com\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"url\"] == \"https://example.com\"\n+    assert result_data[\"content\"] == \"Test content\"\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.scrape_url.assert_called_once_with(\"https://example.com\")\n+\n+\n+def test_scrape_website_with_formats(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test scrape_website method with formats.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.model_dump.return_value = {\n+        \"url\": \"https://example.com\",\n+        \"content\": \"Test content\",\n+        \"status\": \"success\",\n+    }\n+    mock_firecrawl.scrape_url.return_value = mock_response\n+\n+    # Set formats\n+    firecrawl_tools.formats = [\"html\", \"text\"]\n+\n+    # Call the method\n+    result = firecrawl_tools.scrape_website(\"https://example.com\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"url\"] == \"https://example.com\"\n+    assert result_data[\"content\"] == \"Test content\"\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.scrape_url.assert_called_once_with(\"https://example.com\", formats=[\"html\", \"text\"])\n+\n+\n+def test_crawl_website(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test crawl_website method.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.model_dump.return_value = {\n+        \"url\": \"https://example.com\",\n+        \"pages\": [\"page1\", \"page2\"],\n+        \"status\": \"success\",\n+    }\n+    mock_firecrawl.crawl_url.return_value = mock_response\n+\n+    # Call the method\n+    result = firecrawl_tools.crawl_website(\"https://example.com\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"url\"] == \"https://example.com\"\n+    assert result_data[\"pages\"] == [\"page1\", \"page2\"]\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.crawl_url.assert_called_once_with(\"https://example.com\", limit=10, poll_interval=30)\n+\n+\n+def test_crawl_website_with_custom_limit(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test crawl_website method with custom limit.\"\"\"\n+    # Reset the default limit\n+    firecrawl_tools.limit = None\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.model_dump.return_value = {\n+        \"url\": \"https://example.com\",\n+        \"pages\": [\"page1\", \"page2\"],\n+        \"status\": \"success\",\n+    }\n+    mock_firecrawl.crawl_url.return_value = mock_response\n+\n+    # Call the method with custom limit\n+    result = firecrawl_tools.crawl_website(\"https://example.com\", limit=5)\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"url\"] == \"https://example.com\"\n+    assert result_data[\"pages\"] == [\"page1\", \"page2\"]\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.crawl_url.assert_called_once_with(\"https://example.com\", limit=5, poll_interval=30)\n+\n+\n+def test_map_website(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test map_website method.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.model_dump.return_value = {\n+        \"url\": \"https://example.com\",\n+        \"sitemap\": {\"page1\": [\"link1\", \"link2\"]},\n+        \"status\": \"success\",\n+    }\n+    mock_firecrawl.map_url.return_value = mock_response\n+\n+    # Call the method\n+    result = firecrawl_tools.map_website(\"https://example.com\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"url\"] == \"https://example.com\"\n+    assert result_data[\"sitemap\"] == {\"page1\": [\"link1\", \"link2\"]}\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.map_url.assert_called_once_with(\"https://example.com\")\n+\n+\n+def test_search(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test search method.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.success = True\n+    mock_response.data = {\"query\": \"test query\", \"results\": [\"result1\", \"result2\"], \"status\": \"success\"}\n+    mock_firecrawl.search.return_value = mock_response\n+\n+    # Call the method\n+    result = firecrawl_tools.search(\"test query\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"query\"] == \"test query\"\n+    assert result_data[\"results\"] == [\"result1\", \"result2\"]\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.search.assert_called_once_with(\"test query\", limit=10)\n+\n+\n+def test_search_with_error(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test search method with error response.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.success = False\n+    mock_response.error = \"Search failed\"\n+    mock_firecrawl.search.return_value = mock_response\n+\n+    # Call the method\n+    result = firecrawl_tools.search(\"test query\")\n+\n+    # Verify results\n+    assert result == \"Error searching with the Firecrawl tool: Search failed\"\n+    mock_firecrawl.search.assert_called_once_with(\"test query\", limit=10)\n+\n+\n+def test_search_with_custom_params(firecrawl_tools, mock_firecrawl):\n+    \"\"\"Test search method with custom search parameters.\"\"\"\n+    # Setup mock response\n+    mock_response = Mock()\n+    mock_response.success = True\n+    mock_response.data = {\"query\": \"test query\", \"results\": [\"result1\", \"result2\"], \"status\": \"success\"}\n+    mock_firecrawl.search.return_value = mock_response\n+\n+    # Set custom search parameters\n+    firecrawl_tools.search_params = {\"language\": \"en\", \"region\": \"us\"}\n+\n+    # Call the method\n+    result = firecrawl_tools.search(\"test query\")\n+    result_data = json.loads(result)\n+\n+    # Verify results\n+    assert result_data[\"query\"] == \"test query\"\n+    assert result_data[\"results\"] == [\"result1\", \"result2\"]\n+    assert result_data[\"status\"] == \"success\"\n+    mock_firecrawl.search.assert_called_once_with(\"test query\", limit=10, language=\"en\", region=\"us\")\n"
        }
    ]
}