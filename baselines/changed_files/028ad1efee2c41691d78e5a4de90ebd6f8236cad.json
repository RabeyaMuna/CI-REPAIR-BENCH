{
    "sha_fail": "028ad1efee2c41691d78e5a4de90ebd6f8236cad",
    "changed_files": [
        {
            "commit": "028ad1efee2c41691d78e5a4de90ebd6f8236cad",
            "file_path": "src/accelerate/utils/__init__.py",
            "diff": "diff --git a/src/accelerate/utils/__init__.py b/src/accelerate/utils/__init__.py\nindex 4c9cd00..ddf794a 100644\n--- a/src/accelerate/utils/__init__.py\n+++ b/src/accelerate/utils/__init__.py\n@@ -59,6 +59,7 @@ from .imports import (\n     is_comet_ml_available,\n     is_cuda_available,\n     is_datasets_available,\n+    is_peft_available,\n     is_deepspeed_available,\n     is_dvclive_available,\n     is_fp8_available,\n@@ -80,6 +81,7 @@ from .imports import (\n     is_xpu_available,\n )\n from .modeling import (\n+    is_peft_model,\n     calculate_maximum_sizes,\n     check_device_map,\n     check_tied_parameters_in_config,\n"
        },
        {
            "commit": "028ad1efee2c41691d78e5a4de90ebd6f8236cad",
            "file_path": "src/accelerate/utils/fsdp_utils.py",
            "diff": "diff --git a/src/accelerate/utils/fsdp_utils.py b/src/accelerate/utils/fsdp_utils.py\nindex a638825..01bb54b 100644\n--- a/src/accelerate/utils/fsdp_utils.py\n+++ b/src/accelerate/utils/fsdp_utils.py\n@@ -17,8 +17,8 @@ import torch\n \n from ..logging import get_logger\n from .constants import FSDP_MODEL_NAME, FSDP_PYTORCH_VERSION, OPTIMIZER_NAME\n-from .imports import is_peft_available, is_torch_distributed_available\n-from .other import extract_model_from_parallel\n+from .imports import is_torch_distributed_available\n+from .modeling import is_peft_model\n from .versions import is_torch_version\n \n \n@@ -33,14 +33,8 @@ if is_torch_version(\">=\", FSDP_PYTORCH_VERSION) and is_torch_distributed_availab\n logger = get_logger(__name__)\n \n \n-def _is_peft_model(model):\n-    if is_peft_available():\n-        from peft import PeftModel\n-    return is_peft_available() and isinstance(extract_model_from_parallel(model), PeftModel)\n-\n-\n def _get_model_state_dict(model, adapter_only=False):\n-    if adapter_only and _is_peft_model(model):\n+    if adapter_only and is_peft_model(model):\n         from peft import get_peft_model_state_dict\n \n         return get_peft_model_state_dict(model, adapter_name=model.active_adapter)\n@@ -49,7 +43,7 @@ def _get_model_state_dict(model, adapter_only=False):\n \n \n def _set_model_state_dict(model, state_dict, adapter_only=False):\n-    if adapter_only and _is_peft_model(model):\n+    if adapter_only and is_peft_model(model):\n         from peft import set_peft_model_state_dict\n \n         return set_peft_model_state_dict(model, state_dict, adapter_name=model.active_adapter)\n"
        },
        {
            "commit": "028ad1efee2c41691d78e5a4de90ebd6f8236cad",
            "file_path": "src/accelerate/utils/modeling.py",
            "diff": "diff --git a/src/accelerate/utils/modeling.py b/src/accelerate/utils/modeling.py\nindex fb70d85..802b13c 100644\n--- a/src/accelerate/utils/modeling.py\n+++ b/src/accelerate/utils/modeling.py\n@@ -30,7 +30,7 @@ import torch.nn as nn\n from ..state import AcceleratorState\n from .constants import SAFE_WEIGHTS_NAME, WEIGHTS_NAME\n from .dataclasses import AutocastKwargs, CustomDtype, DistributedType\n-from .imports import is_mps_available, is_npu_available, is_xpu_available\n+from .imports import is_mps_available, is_npu_available, is_xpu_available, is_peft_available\n from .offload import load_offloaded_weight, offload_weight, save_offload_index\n from .tqdm import is_tqdm_available, tqdm\n \n@@ -47,6 +47,15 @@ WEIGHTS_INDEX_NAME = \"pytorch_model.bin.index.json\"\n logger = logging.getLogger(__name__)\n \n \n+def is_peft_model(model):\n+    from .other import extract_model_from_parallel\n+\n+    if is_peft_available():\n+        from peft import PeftModel\n+\n+    return is_peft_available() and isinstance(extract_model_from_parallel(model), PeftModel)\n+\n+\n def check_device_same(first_device, second_device):\n     \"\"\"\n     Utility method to check if two `torch` devices are similar. When dealing with CUDA devices, torch throws `False`\n"
        }
    ]
}