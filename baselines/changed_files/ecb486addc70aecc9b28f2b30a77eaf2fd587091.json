{
    "sha_fail": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
    "changed_files": [
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "ChangeLog",
            "diff": "diff --git a/ChangeLog b/ChangeLog\nindex a175ed7f..e0c06243 100644\n--- a/ChangeLog\n+++ b/ChangeLog\n@@ -1,3 +1,6 @@\n+23.4.1\n+ - fix: Handle systemctl commands when dbus not ready (#4681)\n+\n 23.4\n  - tests: datasourcenone use client.restart to block until done (#4635)\n  - tests: increase number of retries across reboot to 90 (#4651)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/cmd/devel/render.py",
            "diff": "diff --git a/cloudinit/cmd/devel/render.py b/cloudinit/cmd/devel/render.py\nindex 71d27552..99c24e1d 100755\n--- a/cloudinit/cmd/devel/render.py\n+++ b/cloudinit/cmd/devel/render.py\n@@ -12,6 +12,7 @@ import sys\n from cloudinit.cmd.devel import read_cfg_paths\n from cloudinit.handlers.jinja_template import (\n     JinjaLoadError,\n+    JinjaSyntaxParsingException,\n     NotJinjaError,\n     render_jinja_payload_from_file,\n )\n@@ -99,6 +100,13 @@ def render_template(user_data_path, instance_data_path=None, debug=False):\n             \"Cannot render from instance data due to exception: %s\", repr(e)\n         )\n         return 1\n+    except JinjaSyntaxParsingException as e:\n+        LOG.error(\n+            \"Failed to render templated user-data file '%s'. %s\",\n+            user_data_path,\n+            str(e),\n+        )\n+        return 1\n     if not rendered_payload:\n         LOG.error(\"Unable to render user-data file: %s\", user_data_path)\n         return 1\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/cmd/query.py",
            "diff": "diff --git a/cloudinit/cmd/query.py b/cloudinit/cmd/query.py\nindex a8178cf8..52153ff0 100644\n--- a/cloudinit/cmd/query.py\n+++ b/cloudinit/cmd/query.py\n@@ -29,6 +29,7 @@ from cloudinit.handlers.jinja_template import (\n     render_jinja_payload,\n )\n from cloudinit.sources import REDACT_SENSITIVE_VALUE\n+from cloudinit.templater import JinjaSyntaxParsingException\n \n NAME = \"query\"\n LOG = logging.getLogger(__name__)\n@@ -277,12 +278,19 @@ def handle_args(name, args):\n         return 1\n     if args.format:\n         payload = \"## template: jinja\\n{fmt}\".format(fmt=args.format)\n-        rendered_payload = render_jinja_payload(\n-            payload=payload,\n-            payload_fn=\"query commandline\",\n-            instance_data=instance_data,\n-            debug=True if args.debug else False,\n-        )\n+        try:\n+            rendered_payload = render_jinja_payload(\n+                payload=payload,\n+                payload_fn=\"query commandline\",\n+                instance_data=instance_data,\n+                debug=True if args.debug else False,\n+            )\n+        except JinjaSyntaxParsingException as e:\n+            LOG.error(\n+                \"Failed to render templated data. %s\",\n+                str(e),\n+            )\n+            return 1\n         if rendered_payload:\n             print(rendered_payload)\n             return 0\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/cmd/status.py",
            "diff": "diff --git a/cloudinit/cmd/status.py b/cloudinit/cmd/status.py\nindex f5ee9c11..249fc911 100644\n--- a/cloudinit/cmd/status.py\n+++ b/cloudinit/cmd/status.py\n@@ -137,7 +137,7 @@ def handle_status_args(name, args) -> int:\n     \"\"\"Handle calls to 'cloud-init status' as a subcommand.\"\"\"\n     # Read configured paths\n     paths = read_cfg_paths()\n-    details = get_status_details(paths)\n+    details = get_status_details(paths, args.wait)\n     if args.wait:\n         while details.status in (\n             UXAppStatus.NOT_RUN,\n@@ -147,7 +147,7 @@ def handle_status_args(name, args) -> int:\n             if args.format == \"tabular\":\n                 sys.stdout.write(\".\")\n                 sys.stdout.flush()\n-            details = get_status_details(paths)\n+            details = get_status_details(paths, args.wait)\n             sleep(0.25)\n     details_dict: Dict[str, Union[None, str, List[str], Dict[str, Any]]] = {\n         \"datasource\": details.datasource,\n@@ -272,12 +272,15 @@ def get_bootstatus(disable_file, paths) -> Tuple[UXAppBootStatusCode, str]:\n     return (bootstatus_code, reason)\n \n \n-def _get_systemd_status() -> Optional[UXAppStatus]:\n-    \"\"\"Get status from systemd.\n+def _get_error_or_running_from_systemd() -> Optional[UXAppStatus]:\n+    \"\"\"Get if systemd is in error or running state.\n \n     Using systemd, we can get more fine-grained status of the\n     individual unit. Determine if we're still\n-    running or if there's an error we haven't otherwise detected\n+    running or if there's an error we haven't otherwise detected.\n+\n+    If we don't detect error or running, return None as we don't want to\n+    report any other particular status based on systemd.\n     \"\"\"\n     for service in [\n         \"cloud-final.service\",\n@@ -324,7 +327,42 @@ def _get_systemd_status() -> Optional[UXAppStatus]:\n     return None\n \n \n-def get_status_details(paths: Optional[Paths] = None) -> StatusDetails:\n+def _get_error_or_running_from_systemd_with_retry(\n+    existing_status: UXAppStatus, *, wait: bool\n+) -> Optional[UXAppStatus]:\n+    \"\"\"Get systemd status and retry if dbus isn't ready.\n+\n+    If cloud-init has determined that we're still running, then we can\n+    ignore the status from systemd. However, if cloud-init has detected error,\n+    then we should retry on systemd status so we don't incorrectly report\n+    error state while cloud-init is still running.\n+    \"\"\"\n+    while True:\n+        try:\n+            return _get_error_or_running_from_systemd()\n+        except subp.ProcessExecutionError as e:\n+            last_exception = e\n+            if existing_status in (\n+                UXAppStatus.DEGRADED_RUNNING,\n+                UXAppStatus.RUNNING,\n+            ):\n+                return None\n+            if wait:\n+                sleep(0.25)\n+            else:\n+                break\n+    print(\n+        \"Failed to get status from systemd. \"\n+        \"Cloud-init status may be inaccurate. \",\n+        f\"Error from systemctl: {last_exception.stderr}\",\n+        file=sys.stderr,\n+    )\n+    return None\n+\n+\n+def get_status_details(\n+    paths: Optional[Paths] = None, wait: bool = False\n+) -> StatusDetails:\n     \"\"\"Return a dict with status, details and errors.\n \n     @param paths: An initialized cloudinit.helpers.paths object.\n@@ -395,7 +433,9 @@ def get_status_details(paths: Optional[Paths] = None) -> StatusDetails:\n         UXAppStatus.NOT_RUN,\n         UXAppStatus.DISABLED,\n     ):\n-        systemd_status = _get_systemd_status()\n+        systemd_status = _get_error_or_running_from_systemd_with_retry(\n+            status, wait=wait\n+        )\n         if systemd_status:\n             status = systemd_status\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/config/cc_apt_configure.py",
            "diff": "diff --git a/cloudinit/config/cc_apt_configure.py b/cloudinit/config/cc_apt_configure.py\nindex 6786a1d3..70c0de0a 100644\n--- a/cloudinit/config/cc_apt_configure.py\n+++ b/cloudinit/config/cc_apt_configure.py\n@@ -604,7 +604,6 @@ def get_apt_cfg() -> Dict[str, str]:\n             \"Dir::Etc::sourceparts\", DEFAULT_APT_CFG[\"Dir::Etc::sourceparts\"]\n         )\n     except ImportError:\n-\n         try:\n             apt_dump, _ = subp.subp([\"apt-config\", \"dump\"])\n         except subp.ProcessExecutionError:\n@@ -680,7 +679,20 @@ def generate_sources_list(cfg, release, mirrors, cloud):\n             )\n             aptsrc_file = apt_sources_list\n     disabled = disable_suites(cfg.get(\"disable_suites\"), rendered, release)\n+    disable_apt_sources_list = False\n+    if aptsrc_file == apt_sources_deb822 and os.path.exists(apt_sources_list):\n+        disable_apt_sources_list = True\n     util.write_file(aptsrc_file, disabled, mode=0o644)\n+    if disable_apt_sources_list:\n+        LOG.warning(\n+            \"Disabling %s to favor deb822 source format\", apt_sources_list\n+        )\n+        content = pathlib.Path(apt_sources_list).read_bytes()\n+        content = b\"# disabled by cloud-init\\n\" + content\n+        util.rename(apt_sources_list, f\"{apt_sources_list}.disabled\")\n+        util.write_file(\n+            f\"{apt_sources_list}.disabled\", content, preserve_mode=True\n+        )\n \n \n def add_apt_key_raw(key, file_name, hardened=False):\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/config/cc_final_message.py",
            "diff": "diff --git a/cloudinit/config/cc_final_message.py b/cloudinit/config/cc_final_message.py\nindex 73e7170b..5913d10a 100644\n--- a/cloudinit/config/cc_final_message.py\n+++ b/cloudinit/config/cc_final_message.py\n@@ -96,6 +96,10 @@ def handle(name: str, cfg: Config, cloud: Cloud, args: list) -> None:\n             stderr=True,\n             log=LOG,\n         )\n+    except templater.JinjaSyntaxParsingException as e:\n+        util.logexc(\n+            LOG, \"Failed to render templated final message: %s\", str(e)\n+        )\n     except Exception:\n         util.logexc(LOG, \"Failed to render final message template\")\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/config/cc_migrator.py",
            "diff": "diff --git a/cloudinit/config/cc_migrator.py b/cloudinit/config/cc_migrator.py\ndeleted file mode 100644\nindex 81791ba7..00000000\n--- a/cloudinit/config/cc_migrator.py\n+++ /dev/null\n@@ -1,102 +0,0 @@\n-# Copyright (C) 2012 Yahoo! Inc.\n-#\n-# Author: Joshua Harlow <harlowja@yahoo-inc.com>\n-#\n-# This file is part of cloud-init. See LICENSE file for license information.\n-\n-\"\"\"Migrator: Migrate old versions of cloud-init data to new\"\"\"\n-\n-import logging\n-import os\n-import shutil\n-\n-from cloudinit import helpers, util\n-from cloudinit.cloud import Cloud\n-from cloudinit.config import Config\n-from cloudinit.config.schema import MetaSchema, get_meta_doc\n-from cloudinit.settings import PER_ALWAYS\n-\n-MODULE_DESCRIPTION = \"\"\"\\\n-This module handles moving old versions of cloud-init data to newer ones.\n-Currently, it only handles renaming cloud-init's per-frequency semaphore files\n-to canonicalized name and renaming legacy semaphore names to newer ones. This\n-module is enabled by default, but can be disabled by specifying ``migrate:\n-false`` in config.\n-\"\"\"\n-\n-distros = [\"all\"]\n-frequency = PER_ALWAYS\n-\n-meta: MetaSchema = {\n-    \"id\": \"cc_migrator\",\n-    \"name\": \"Migrator\",\n-    \"title\": \"Migrate old versions of cloud-init data to new\",\n-    \"description\": MODULE_DESCRIPTION,\n-    \"distros\": distros,\n-    \"examples\": [\"# Do not migrate cloud-init semaphores\\nmigrate: false\\n\"],\n-    \"frequency\": frequency,\n-    \"activate_by_schema_keys\": [],\n-}\n-\n-__doc__ = get_meta_doc(meta)\n-LOG = logging.getLogger(__name__)\n-\n-\n-def _migrate_canon_sems(cloud):\n-    paths = (cloud.paths.get_ipath(\"sem\"), cloud.paths.get_cpath(\"sem\"))\n-    am_adjusted = 0\n-    for sem_path in paths:\n-        if not sem_path or not os.path.exists(sem_path):\n-            continue\n-        for p in os.listdir(sem_path):\n-            full_path = os.path.join(sem_path, p)\n-            if os.path.isfile(full_path):\n-                (name, ext) = os.path.splitext(p)\n-                canon_name = helpers.canon_sem_name(name)\n-                if canon_name != name:\n-                    new_path = os.path.join(sem_path, canon_name + ext)\n-                    shutil.move(full_path, new_path)\n-                    am_adjusted += 1\n-    return am_adjusted\n-\n-\n-def _migrate_legacy_sems(cloud):\n-    legacy_adjust = {\n-        \"apt-update-upgrade\": [\n-            \"apt_configure\",\n-            \"package_update_upgrade_install\",\n-        ],\n-    }\n-    paths = (cloud.paths.get_ipath(\"sem\"), cloud.paths.get_cpath(\"sem\"))\n-    for sem_path in paths:\n-        if not sem_path or not os.path.exists(sem_path):\n-            continue\n-        sem_helper = helpers.FileSemaphores(sem_path)\n-        for (mod_name, migrate_to) in legacy_adjust.items():\n-            possibles = [mod_name, helpers.canon_sem_name(mod_name)]\n-            old_exists = []\n-            for p in os.listdir(sem_path):\n-                (name, _ext) = os.path.splitext(p)\n-                if name in possibles and os.path.isfile(p):\n-                    old_exists.append(p)\n-            for p in old_exists:\n-                util.del_file(os.path.join(sem_path, p))\n-                (_name, freq) = os.path.splitext(p)\n-                for m in migrate_to:\n-                    LOG.debug(\n-                        \"Migrating %s => %s with the same frequency\", p, m\n-                    )\n-                    with sem_helper.lock(m, freq):\n-                        pass\n-\n-\n-def handle(name: str, cfg: Config, cloud: Cloud, args: list) -> None:\n-    do_migrate = util.get_cfg_option_str(cfg, \"migrate\", True)\n-    if not util.translate_bool(do_migrate):\n-        LOG.debug(\"Skipping module named %s, migration disabled\", name)\n-        return\n-    sems_moved = _migrate_canon_sems(cloud)\n-    LOG.debug(\n-        \"Migrated %s semaphore files to there canonicalized names\", sems_moved\n-    )\n-    _migrate_legacy_sems(cloud)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/config/modules.py",
            "diff": "diff --git a/cloudinit/config/modules.py b/cloudinit/config/modules.py\nindex 15571738..3605d46f 100644\n--- a/cloudinit/config/modules.py\n+++ b/cloudinit/config/modules.py\n@@ -27,6 +27,13 @@ LOG = logging.getLogger(__name__)\n # name in the lookup path...\n MOD_PREFIX = \"cc_\"\n \n+# List of modules that have removed upstream. This prevents every downstream\n+# from having to create upgrade scripts to avoid warnings about missing\n+# modules.\n+REMOVED_MODULES = [\n+    \"cc_migrator\",  # Removed in 24.1\n+]\n+\n \n class ModuleDetails(NamedTuple):\n     module: ModuleType\n@@ -194,11 +201,18 @@ class Modules:\n                 mod_name, [\"\", type_utils.obj_name(config)], [\"handle\"]\n             )\n             if not mod_locs:\n-                LOG.warning(\n-                    \"Could not find module named %s (searched %s)\",\n-                    mod_name,\n-                    looked_locs,\n-                )\n+                if mod_name in REMOVED_MODULES:\n+                    LOG.info(\n+                        \"Module `%s` has been removed from cloud-init. \"\n+                        \"It may be removed from `/etc/cloud/cloud.cfg`.\",\n+                        mod_name[3:],  # [3:] to remove 'cc_'\n+                    )\n+                else:\n+                    LOG.warning(\n+                        \"Could not find module named %s (searched %s)\",\n+                        mod_name,\n+                        looked_locs,\n+                    )\n                 continue\n             mod = importer.import_module(mod_locs[0])\n             validate_module(mod, raw_name)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/config/schema.py",
            "diff": "diff --git a/cloudinit/config/schema.py b/cloudinit/config/schema.py\nindex 89966d70..70823c11 100644\n--- a/cloudinit/config/schema.py\n+++ b/cloudinit/config/schema.py\n@@ -9,7 +9,9 @@ import sys\n import textwrap\n from collections import defaultdict\n from collections.abc import Iterable\n+from contextlib import suppress\n from copy import deepcopy\n+from enum import Enum\n from errno import EACCES\n from functools import partial\n from itertools import chain\n@@ -19,6 +21,7 @@ from typing import (\n     List,\n     NamedTuple,\n     Optional,\n+    Tuple,\n     Type,\n     Union,\n     cast,\n@@ -29,6 +32,7 @@ import yaml\n from cloudinit import importer, safeyaml\n from cloudinit.cmd.devel import read_cfg_paths\n from cloudinit.handlers import INCLUSION_TYPES_MAP, type_from_starts_with\n+from cloudinit.helpers import Paths\n from cloudinit.sources import DataSourceNotFoundException\n from cloudinit.util import error, get_modules_from_dir, load_file\n \n@@ -56,15 +60,6 @@ VERSIONED_USERDATA_SCHEMA_FILE = \"versions.schema.cloud-config.json\"\n USERDATA_SCHEMA_FILE = \"schema-cloud-config-v1.json\"\n NETWORK_CONFIG_V1_SCHEMA_FILE = \"schema-network-config-v1.json\"\n \n-SCHEMA_FILES_BY_TYPE = {\n-    \"cloud-config\": {\n-        \"latest\": USERDATA_SCHEMA_FILE,\n-    },\n-    \"network-config\": {\n-        \"latest\": NETWORK_CONFIG_V1_SCHEMA_FILE,\n-    },\n-}\n-\n _YAML_MAP = {True: \"true\", False: \"false\", None: \"null\"}\n SCHEMA_DOC_TMPL = \"\"\"\n {name}\n@@ -148,6 +143,49 @@ class SchemaProblem(NamedTuple):\n SchemaProblems = List[SchemaProblem]\n \n \n+class SchemaType(Enum):\n+    \"\"\"Supported schema types are etiher cloud-config or network-config.\n+\n+    Vendordata and Vendordata2 format adheres to cloud-config schema type.\n+    Cloud Metadata is unique schema to each cloud platform and likely will not\n+    be represented in this enum.\n+    \"\"\"\n+\n+    CLOUD_CONFIG = \"cloud-config\"\n+    NETWORK_CONFIG = \"network-config\"\n+\n+\n+# Placeholders for versioned schema and schema file locations.\n+# The \"latest\" key is used in absence of a requested specific version.\n+SCHEMA_FILES_BY_TYPE = {\n+    SchemaType.CLOUD_CONFIG: {\n+        \"latest\": USERDATA_SCHEMA_FILE,\n+    },\n+    SchemaType.NETWORK_CONFIG: {\n+        \"latest\": NETWORK_CONFIG_V1_SCHEMA_FILE,\n+    },\n+}\n+\n+\n+class InstanceDataType(Enum):\n+    \"\"\"Types of instance data provided to cloud-init\"\"\"\n+\n+    USERDATA = \"user-data\"\n+    NETWORK_CONFIG = \"network-config\"\n+    VENDORDATA = \"vendor-data\"\n+    VENDOR2DATA = \"vendor2-data\"\n+    # METADATA = \"metadata\"\n+\n+    def __str__(self):  # pylint: disable=invalid-str-returned\n+        return self.value\n+\n+\n+class InstanceDataPart(NamedTuple):\n+    config_type: InstanceDataType\n+    schema_type: SchemaType\n+    config_path: str\n+\n+\n class UserDataTypeAndDecodedContent(NamedTuple):\n     userdata_type: str\n     content: str\n@@ -206,6 +244,10 @@ class SchemaValidationError(ValueError):\n         return bool(self.schema_errors)\n \n \n+class SchemaValidationInvalidHeaderError(SchemaValidationError):\n+    \"\"\"Raised when no valid header is declared in the user-data file.\"\"\"\n+\n+\n def is_schema_byte_string(checker, instance):\n     \"\"\"TYPE_CHECKER override allowing bytes for string type\n \n@@ -535,7 +577,7 @@ def validate_cloudconfig_metaschema(validator, schema: dict, throw=True):\n def validate_cloudconfig_schema(\n     config: dict,\n     schema: Optional[dict] = None,\n-    schema_type: str = \"cloud-config\",\n+    schema_type: SchemaType = SchemaType.CLOUD_CONFIG,\n     strict: bool = False,\n     strict_metaschema: bool = False,\n     log_details: bool = True,\n@@ -548,8 +590,9 @@ def validate_cloudconfig_schema(\n     @param schema: jsonschema dict describing the supported schema definition\n        for the cloud config module (config.cc_*). If None, validate against\n        global schema.\n-    @param schema_type: Optional string. One of: cloud-config, network-config\n-       Default: cloud-config.\n+    @param schema_type: Optional SchemaType.\n+       One of: SchemaType.CLOUD_CONFIG or  SchemaType.NETWORK_CONFIG.\n+       Default: SchemaType.CLOUD_CONFIG\n     @param strict: Boolean, when True raise SchemaValidationErrors instead of\n        logging warnings.\n     @param strict_metaschema: Boolean, when True validates schema using strict\n@@ -562,8 +605,8 @@ def validate_cloudconfig_schema(\n     @raises: SchemaValidationError when provided config does not validate\n         against the provided schema.\n     @raises: RuntimeError when provided config sourced from YAML is not a dict.\n-    @raises: ValueError on invalid schema_type not in cloud-config or\n-        network_config\n+    @raises: ValueError on invalid schema_type not in CLOUD_CONFIG or\n+        NETWORK_CONFIG\n     \"\"\"\n     if schema is None:\n         schema = get_schema(schema_type)\n@@ -619,12 +662,12 @@ def validate_cloudconfig_schema(\n         if log_details:\n             details = _format_schema_problems(\n                 errors,\n-                prefix=f\"Invalid {schema_type} provided:\\n\",\n+                prefix=f\"Invalid {schema_type.value} provided:\\n\",\n                 separator=\"\\n\",\n             )\n         else:\n             details = (\n-                f\"Invalid {schema_type} provided: \"\n+                f\"Invalid {schema_type.value} provided: \"\n                 \"Please run 'sudo cloud-init schema --system' to \"\n                 \"see the schema errors.\"\n             )\n@@ -816,9 +859,12 @@ def _get_config_type_and_rendered_userdata(\n     :return: UserDataTypeAndDecodedContent\n     :raises: SchemaValidationError when non-jinja content found but\n         header declared ## template: jinja.\n+    :raises JinjaSyntaxParsingException when jinja syntax error found.\n+    :raises JinjaLoadError when jinja template fails to load.\n     \"\"\"\n     from cloudinit.handlers.jinja_template import (\n         JinjaLoadError,\n+        JinjaSyntaxParsingException,\n         NotJinjaError,\n         render_jinja_payload_from_file,\n     )\n@@ -840,13 +886,18 @@ def _get_config_type_and_rendered_userdata(\n                     )\n                 ]\n             ) from e\n+        except JinjaSyntaxParsingException as e:\n+            error(\n+                \"Failed to render templated user-data. \" + str(e),\n+                sys_exit=True,\n+            )\n         except JinjaLoadError as e:\n             error(str(e), sys_exit=True)\n         schema_position = \"format-l2.c1\"\n         user_data_type = type_from_starts_with(content)\n     if not user_data_type:  # Neither jinja2 nor #cloud-config\n         header_line, _, _ = content.partition(\"\\n\")\n-        raise SchemaValidationError(\n+        raise SchemaValidationInvalidHeaderError(\n             [\n                 SchemaProblem(\n                     schema_position,\n@@ -867,7 +918,7 @@ def _get_config_type_and_rendered_userdata(\n def validate_cloudconfig_file(\n     config_path: str,\n     schema: dict,\n-    schema_type: str = \"cloud-config\",\n+    schema_type: SchemaType = SchemaType.CLOUD_CONFIG,\n     annotate: bool = False,\n     instance_data_path: str = None,\n ) -> bool:\n@@ -876,7 +927,7 @@ def validate_cloudconfig_file(\n     @param config_path: Path to the yaml cloud-config file to parse, or None\n         to default to system userdata from Paths object.\n     @param schema: Dict describing a valid jsonschema to validate against.\n-    @param schema_type: One of network-config or cloud-config.\n+    @param schema_type: One of SchemaType.NETWORK_CONFIG or CLOUD_CONFIG\n     @param annotate: Boolean set True to print original config file with error\n         annotations on the offending lines.\n     @param instance_data_path: Path to instance_data JSON, used for text/jinja\n@@ -890,13 +941,13 @@ def validate_cloudconfig_file(\n     if not decoded_content:\n         print(\n             \"Empty '%s' found at %s. Nothing to validate.\"\n-            % (schema_type, config_path)\n+            % (schema_type.value, config_path)\n         )\n         return False\n \n-    if schema_type in (\"network-config\",):\n+    if schema_type in (SchemaType.NETWORK_CONFIG,):\n         decoded_config = UserDataTypeAndDecodedContent(\n-            schema_type, decoded_content\n+            schema_type.value, decoded_content\n         )\n     else:\n         decoded_config = _get_config_type_and_rendered_userdata(\n@@ -943,9 +994,9 @@ def validate_cloudconfig_file(\n         # Return a meaningful message on empty cloud-config\n         if not annotate:\n             raise RuntimeError(\n-                f\"{schema_type} {config_path} is not a YAML dict.\"\n+                f\"{schema_type.value} {config_path} is not a YAML dict.\"\n             )\n-    if schema_type == \"network-config\":\n+    if schema_type == SchemaType.NETWORK_CONFIG:\n         # Pop optional top-level \"network\" key when present\n         netcfg = cloudconfig.get(\"network\", cloudconfig)\n         if not netcfg:\n@@ -963,7 +1014,7 @@ def validate_cloudconfig_file(\n             cloudconfig, schema, strict=True, log_deprecations=False\n         ):\n             print(\n-                f\"Skipping {schema_type} schema validation.\"\n+                f\"Skipping {schema_type.value} schema validation.\"\n                 \" Jsonschema dependency missing.\"\n             )\n             return False\n@@ -1280,7 +1331,7 @@ def get_meta_doc(meta: MetaSchema, schema: Optional[dict] = None) -> str:\n     \"\"\"\n \n     if schema is None:\n-        schema = get_schema(schema_type=\"cloud-config\")\n+        schema = get_schema()\n     if not meta or not schema:\n         raise ValueError(\"Expected non-empty meta and schema\")\n     keys = set(meta.keys())\n@@ -1381,7 +1432,7 @@ def get_schema_dir() -> str:\n     return os.path.join(os.path.dirname(os.path.abspath(__file__)), \"schemas\")\n \n \n-def get_schema(schema_type: str = \"cloud-config\") -> dict:\n+def get_schema(schema_type: SchemaType = SchemaType.CLOUD_CONFIG) -> dict:\n     \"\"\"Return jsonschema for a specific type.\n \n     Return empty schema when no specific schema file exists.\n@@ -1395,7 +1446,7 @@ def get_schema(schema_type: str = \"cloud-config\") -> dict:\n     except (IOError, OSError):\n         LOG.warning(\n             \"Skipping %s schema valiation. No JSON schema file found %s.\",\n-            schema_type,\n+            schema_type.value,\n             schema_file,\n         )\n         return {}\n@@ -1424,10 +1475,13 @@ def get_parser(parser=None):\n         \"-t\",\n         \"--schema-type\",\n         type=str,\n-        choices=[\"cloud-config\", \"network-config\"],\n+        choices=[\n+            SchemaType.CLOUD_CONFIG.value,\n+            SchemaType.NETWORK_CONFIG.value,\n+        ],\n         help=(\n             \"When providing --config-file, the schema type to validate config\"\n-            \" against. Default: cloud-config\"\n+            f\" against. Default: {SchemaType.CLOUD_CONFIG}\"\n         ),\n     )\n     parser.add_argument(\n@@ -1467,8 +1521,8 @@ def get_parser(parser=None):\n     return parser\n \n \n-def handle_schema_args(name, args):\n-    \"\"\"Handle provided schema args and perform the appropriate actions.\"\"\"\n+def _assert_exclusive_args(args):\n+    \"\"\"Error or warn on invalid exclusive parameter combinations.\"\"\"\n     exclusive_args = [args.config_file, args.docs, args.system]\n     if len([arg for arg in exclusive_args if arg]) != 1:\n         error(\n@@ -1485,10 +1539,48 @@ def handle_schema_args(name, args):\n             \"Invalid flag combination. Cannot use --annotate with --docs\",\n             sys_exit=True,\n         )\n-    full_schema = get_schema(schema_type=\"cloud-config\")\n-    if args.docs:\n-        print(load_doc(args.docs))\n-        return\n+\n+\n+def get_config_paths_from_args(\n+    args,\n+) -> Tuple[str, List[InstanceDataPart]]:\n+    \"\"\"Return appropiate instance-data.json and instance data parts\n+\n+    Based on commandline args, and user permissions, determine the\n+    appropriate instance-data.json to source for jinja templates and\n+    a list of applicable InstanceDataParts such as user-data, vendor-data\n+    and network-config for which to validate schema. Avoid returning any\n+    InstanceDataParts when the expected config_path does not exist.\n+\n+    :return: A tuple of the instance-data.json path and a list of\n+        viable InstanceDataParts present on the system.\n+    \"\"\"\n+\n+    def get_processed_or_fallback_path(\n+        paths: Paths,\n+        primary_path_key: str,\n+        raw_fallback_path_key: str,\n+    ) -> str:\n+        \"\"\"Get processed data path when non-empty of fallback to raw data path.\n+\n+        - When primary path and raw path exist and are empty, prefer primary\n+          path.\n+        - When primary path is empty but the raw fallback path is non-empty,\n+          this indicates an invalid and ignored raw user-data was provided and\n+          cloud-init emitted a warning and did not process unknown raw\n+          user-data.\n+          In the case of invalid raw user-data header, prefer\n+          raw_fallback_path_key so actionable sensible warnings can be\n+          reported ot the user about the raw unparseable user-data.\n+        \"\"\"\n+        primary_datapath = paths.get_ipath(primary_path_key) or \"\"\n+        with suppress(FileNotFoundError):\n+            if not os.stat(primary_datapath).st_size:\n+                raw_path = paths.get_ipath(raw_fallback_path_key) or \"\"\n+                if os.stat(raw_path).st_size:\n+                    return raw_path\n+        return primary_datapath\n+\n     try:\n         paths = read_cfg_paths(fetch_existing_datasource=\"trust\")\n     except (IOError, OSError) as e:\n@@ -1511,8 +1603,19 @@ def handle_schema_args(name, args):\n         instance_data_path = paths.get_runpath(\"instance_data\")\n     else:\n         instance_data_path = paths.get_runpath(\"instance_data_sensitive\")\n+    config_files: List[InstanceDataPart] = []\n     if args.config_file:\n-        config_files = ((args.schema_type, args.config_file),)\n+        if args.schema_type:\n+            schema_type = SchemaType(args.schema_type)\n+        else:\n+            schema_type = SchemaType.CLOUD_CONFIG\n+        config_files.append(\n+            InstanceDataPart(\n+                InstanceDataType.USERDATA,\n+                schema_type,\n+                args.config_file,\n+            )\n+        )\n     else:\n         if os.getuid() != 0:\n             error(\n@@ -1520,92 +1623,111 @@ def handle_schema_args(name, args):\n                 \" user. Try using sudo.\",\n                 sys_exit=True,\n             )\n-        userdata_file = paths.get_ipath(\"cloud_config\")\n-        if not userdata_file:\n-            error(\n-                \"Unable to obtain user data file. No instance data available\",\n-                sys_exit=True,\n+        userdata_file = get_processed_or_fallback_path(\n+            paths, \"cloud_config\", \"userdata_raw\"\n+        )\n+        config_files.append(\n+            InstanceDataPart(\n+                InstanceDataType.USERDATA,\n+                SchemaType.CLOUD_CONFIG,\n+                userdata_file,\n             )\n-            return  # Helps typing\n-\n-        # Prefer raw user-data.txt when processed cloud-config is empty and\n-        # raw user-data.txt is not because processed cloud-config.txt will\n-        # not be written in cases where user-data header is not supported.\n-        try:\n-            if os.stat(userdata_file).st_size == 0:\n-                raw_userdata_file = paths.get_ipath(\"userdata_raw\")\n-                if os.stat(raw_userdata_file).st_size:\n-                    userdata_file = raw_userdata_file\n-        except FileNotFoundError:\n-            # Error handling on absent userdata_file below\n-            pass\n-\n-        config_files = ((\"user-data\", userdata_file),)\n-        supplemental_config_files = (\n-            (\"vendor-data\", paths.get_ipath(\"vendor_cloud_config\")),\n-            (\"vendor2-data\", paths.get_ipath(\"vendor2_cloud_config\")),\n-            (\"network-config\", paths.get_ipath(\"network_config\")),\n         )\n-        for cfg_type, cfg_file in supplemental_config_files:\n-            if cfg_file and os.path.exists(cfg_file):\n-                config_files += ((cfg_type, cfg_file),)\n-    if not os.path.exists(config_files[0][1]):\n+        supplemental_config_files: List[InstanceDataPart] = [\n+            InstanceDataPart(\n+                InstanceDataType.VENDORDATA,\n+                SchemaType.CLOUD_CONFIG,\n+                get_processed_or_fallback_path(\n+                    paths, \"vendor_cloud_config\", \"vendordata_raw\"\n+                ),\n+            ),\n+            InstanceDataPart(\n+                InstanceDataType.VENDOR2DATA,\n+                SchemaType.CLOUD_CONFIG,\n+                get_processed_or_fallback_path(\n+                    paths, \"vendor2_cloud_config\", \"vendordata2_raw\"\n+                ),\n+            ),\n+            InstanceDataPart(\n+                InstanceDataType.NETWORK_CONFIG,\n+                SchemaType.NETWORK_CONFIG,\n+                paths.get_ipath(\"network_config\") or \"\",\n+            ),\n+        ]\n+        for data_part in supplemental_config_files:\n+            if data_part.config_path and os.path.exists(data_part.config_path):\n+                config_files.append(data_part)\n+    if not os.path.exists(config_files[0].config_path):\n         error(\n-            f\"Config file {config_files[0][1]} does not exist\",\n+            f\"Config file {config_files[0].config_path} does not exist\",\n             fmt=\"Error: {}\",\n             sys_exit=True,\n         )\n+    return instance_data_path, config_files\n+\n+\n+def handle_schema_args(name, args):\n+    \"\"\"Handle provided schema args and perform the appropriate actions.\"\"\"\n+    _assert_exclusive_args(args)\n+    full_schema = get_schema()\n+    if args.docs:\n+        print(load_doc(args.docs))\n+        return\n+    instance_data_path, config_files = get_config_paths_from_args(args)\n \n     nested_output_prefix = \"\"\n     multi_config_output = bool(len(config_files) > 1)\n     if multi_config_output:\n         print(\n             \"Found cloud-config data types: %s\"\n-            % \", \".join(cfg_type for cfg_type, _ in config_files)\n+            % \", \".join(str(cfg_part.config_type) for cfg_part in config_files)\n         )\n         nested_output_prefix = \"  \"\n \n     error_types = []\n-    for idx, (cfg_type, cfg_file) in enumerate(config_files, 1):\n+    for idx, cfg_part in enumerate(config_files, 1):\n         performed_schema_validation = False\n         if multi_config_output:\n-            print(f\"\\n{idx}. {cfg_type} at {cfg_file}:\")\n-        if cfg_type == \"network-config\":\n-            cfg_schema = get_schema(cfg_type)\n-            schema_type = cfg_type\n+            print(\n+                f\"\\n{idx}. {cfg_part.config_type} at {cfg_part.config_path}:\"\n+            )\n+        if cfg_part.schema_type == SchemaType.NETWORK_CONFIG:\n+            cfg_schema = get_schema(cfg_part.schema_type)\n         else:\n             cfg_schema = full_schema\n-            cfg_type = \"user-data\" if cfg_type == \"cloud-config\" else cfg_type\n-            schema_type = \"cloud-config\"\n         try:\n             performed_schema_validation = validate_cloudconfig_file(\n-                cfg_file,\n+                cfg_part.config_path,\n                 cfg_schema,\n-                schema_type,\n+                cfg_part.schema_type,\n                 args.annotate,\n                 instance_data_path,\n             )\n         except SchemaValidationError as e:\n-            if not cfg_type:\n-                cfg_type = \"UNKNOWN_CONFIG_HEADER\"\n             if not args.annotate:\n-                print(f\"{nested_output_prefix}Invalid {cfg_type} {cfg_file}\")\n+                print(\n+                    f\"{nested_output_prefix}Invalid\"\n+                    f\" {cfg_part.config_type} {cfg_part.config_path}\"\n+                )\n                 error(\n                     str(e),\n                     fmt=nested_output_prefix + \"Error: {}\\n\",\n                 )\n-                error_types.append(cfg_type)\n+            error_types.append(cfg_part.config_type)\n         except RuntimeError as e:\n-            print(f\"{nested_output_prefix}Invalid {cfg_type}\")\n+            print(f\"{nested_output_prefix}Invalid {cfg_part.config_type!s}\")\n             error(str(e), fmt=nested_output_prefix + \"Error: {}\\n\")\n-            error_types.append(cfg_type)\n+            error_types.append(cfg_part.config_type)\n         else:\n             if performed_schema_validation:\n-                cfg = cfg_file if args.config_file else cfg_type\n-                print(f\"{nested_output_prefix}Valid schema {cfg}\")\n+                if args.config_file:\n+                    cfg = cfg_part.config_path\n+                else:\n+                    cfg = cfg_part.config_type\n+                print(f\"{nested_output_prefix}Valid schema {cfg!s}\")\n     if error_types:\n         error(\n-            \", \".join(error_type for error_type in error_types),\n+            \", \".join(str(error_type) for error_type in error_types),\n             fmt=\"Error: Invalid schema: {}\\n\",\n             sys_exit=True,\n         )\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/alpine.py",
            "diff": "diff --git a/cloudinit/distros/alpine.py b/cloudinit/distros/alpine.py\nindex 4aa8dd2c..2c779809 100644\n--- a/cloudinit/distros/alpine.py\n+++ b/cloudinit/distros/alpine.py\n@@ -86,6 +86,9 @@ class Distro(distros.Distro):\n             if create_hostname_file:\n                 pass\n             else:\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname file not created\"\n+                )\n                 return\n         if not conf:\n             conf = HostnameConf(\"\")\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/arch.py",
            "diff": "diff --git a/cloudinit/distros/arch.py b/cloudinit/distros/arch.py\nindex 6d7ec209..81b3d1a6 100644\n--- a/cloudinit/distros/arch.py\n+++ b/cloudinit/distros/arch.py\n@@ -124,6 +124,9 @@ class Distro(distros.Distro):\n             if create_hostname_file:\n                 pass\n             else:\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname file not created\"\n+                )\n                 return\n         if not conf:\n             conf = HostnameConf(\"\")\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/debian.py",
            "diff": "diff --git a/cloudinit/distros/debian.py b/cloudinit/distros/debian.py\nindex 553f48ed..ee28bb71 100644\n--- a/cloudinit/distros/debian.py\n+++ b/cloudinit/distros/debian.py\n@@ -140,6 +140,9 @@ class Distro(distros.Distro):\n             if create_hostname_file:\n                 pass\n             else:\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname file not created\"\n+                )\n                 return\n         if not conf:\n             conf = HostnameConf(\"\")\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/gentoo.py",
            "diff": "diff --git a/cloudinit/distros/gentoo.py b/cloudinit/distros/gentoo.py\nindex 0d21989f..dac6dc4f 100644\n--- a/cloudinit/distros/gentoo.py\n+++ b/cloudinit/distros/gentoo.py\n@@ -189,6 +189,9 @@ class Distro(distros.Distro):\n             if create_hostname_file:\n                 pass\n             else:\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname file not created\"\n+                )\n                 return\n         if not conf:\n             conf = HostnameConf(\"\")\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/opensuse.py",
            "diff": "diff --git a/cloudinit/distros/opensuse.py b/cloudinit/distros/opensuse.py\nindex 1c2f9caf..66cec625 100644\n--- a/cloudinit/distros/opensuse.py\n+++ b/cloudinit/distros/opensuse.py\n@@ -248,6 +248,10 @@ class Distro(distros.Distro):\n                 if create_hostname_file:\n                     pass\n                 else:\n+                    LOG.info(\n+                        \"create_hostname_file is False; hostname file not\"\n+                        \"created\"\n+                    )\n                     return\n             if not conf:\n                 conf = HostnameConf(\"\")\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/photon.py",
            "diff": "diff --git a/cloudinit/distros/photon.py b/cloudinit/distros/photon.py\nindex 0d9c34fa..4060edb9 100644\n--- a/cloudinit/distros/photon.py\n+++ b/cloudinit/distros/photon.py\n@@ -108,6 +108,9 @@ class Distro(distros.Distro):\n                         str(hostname),\n                     ]\n                 )\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname set transiently\"\n+                )\n             if ret:\n                 LOG.warning(\n                     (\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/distros/rhel.py",
            "diff": "diff --git a/cloudinit/distros/rhel.py b/cloudinit/distros/rhel.py\nindex 47455909..9def35e3 100644\n--- a/cloudinit/distros/rhel.py\n+++ b/cloudinit/distros/rhel.py\n@@ -127,6 +127,9 @@ class Distro(distros.Distro):\n                         str(hostname),\n                     ]\n                 )\n+                LOG.info(\n+                    \"create_hostname_file is False; hostname set transiently\"\n+                )\n         else:\n             host_cfg = {\n                 \"HOSTNAME\": hostname,\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/handlers/jinja_template.py",
            "diff": "diff --git a/cloudinit/handlers/jinja_template.py b/cloudinit/handlers/jinja_template.py\nindex 31223d44..7f908e61 100644\n--- a/cloudinit/handlers/jinja_template.py\n+++ b/cloudinit/handlers/jinja_template.py\n@@ -13,6 +13,7 @@ from cloudinit.helpers import Paths\n from cloudinit.settings import PER_ALWAYS\n from cloudinit.templater import (\n     MISSING_JINJA_PREFIX,\n+    JinjaSyntaxParsingException,\n     detect_template,\n     render_string,\n )\n@@ -54,9 +55,19 @@ class JinjaTemplatePartHandler(handlers.Handler):\n         if ctype in handlers.CONTENT_SIGNALS:\n             return\n         jinja_json_file = self.paths.get_runpath(\"instance_data_sensitive\")\n-        rendered_payload = render_jinja_payload_from_file(\n-            payload, filename, jinja_json_file\n-        )\n+        try:\n+            rendered_payload = render_jinja_payload_from_file(\n+                payload, filename, jinja_json_file\n+            )\n+        except JinjaSyntaxParsingException as e:\n+            LOG.warning(\n+                \"Ignoring jinja template for %s. \"\n+                \"Failed to render template. %s\",\n+                filename,\n+                str(e),\n+            )\n+            return\n+\n         if not rendered_payload:\n             return\n         subtype = handlers.type_from_starts_with(rendered_payload)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/helpers.py",
            "diff": "diff --git a/cloudinit/helpers.py b/cloudinit/helpers.py\nindex e00045ef..9eefafa1 100644\n--- a/cloudinit/helpers.py\n+++ b/cloudinit/helpers.py\n@@ -104,23 +104,7 @@ class FileSemaphores:\n         sem_file = self._get_path(cname, freq)\n         # This isn't really a good atomic check\n         # but it suffices for where and when cloudinit runs\n-        if os.path.exists(sem_file):\n-            return True\n-\n-        # this case could happen if the migrator module hadn't run yet\n-        # but the item had run before we did canon_sem_name.\n-        if cname != name and os.path.exists(self._get_path(name, freq)):\n-            LOG.warning(\n-                \"%s has run without canonicalized name [%s].\\n\"\n-                \"likely the migrator has not yet run. \"\n-                \"It will run next boot.\\n\"\n-                \"run manually with: cloud-init single --name=migrator\",\n-                name,\n-                cname,\n-            )\n-            return True\n-\n-        return False\n+        return os.path.exists(sem_file)\n \n     def _get_path(self, name, freq):\n         sem_path = self.sem_path\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/log.py",
            "diff": "diff --git a/cloudinit/log.py b/cloudinit/log.py\nindex fcfc5ef8..fa450e79 100644\n--- a/cloudinit/log.py\n+++ b/cloudinit/log.py\n@@ -166,6 +166,18 @@ def setup_backup_logging():\n     logging.Handler.handleError = handleError\n \n \n+class CloudInitLogRecord(logging.LogRecord):\n+    \"\"\"reporting the filename as __init__.py isn't very useful in logs\n+\n+    if the filename is __init__.py, use the parent directory as the filename\n+    \"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        if \"__init__.py\" == self.filename:\n+            self.filename = os.path.basename(os.path.dirname(self.pathname))\n+\n+\n def configure_root_logger():\n     \"\"\"Customize the root logger for cloud-init\"\"\"\n \n@@ -179,3 +191,6 @@ def configure_root_logger():\n     handler = LogExporter()\n     handler.setLevel(logging.WARN)\n     logging.getLogger().addHandler(handler)\n+\n+    # LogRecord allows us to report more useful information than __init__.py\n+    logging.setLogRecordFactory(CloudInitLogRecord)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/net/__init__.py",
            "diff": "diff --git a/cloudinit/net/__init__.py b/cloudinit/net/__init__.py\nindex c0888f52..65e7ff33 100644\n--- a/cloudinit/net/__init__.py\n+++ b/cloudinit/net/__init__.py\n@@ -1287,6 +1287,8 @@ def subnet_is_ipv6(subnet) -> bool:\n     \"\"\"Common helper for checking network_state subnets for ipv6.\"\"\"\n     # 'static6', 'dhcp6', 'ipv6_dhcpv6-stateful', 'ipv6_dhcpv6-stateless' or\n     # 'ipv6_slaac'\n+    # This function is inappropriate for v2-based routes as routes defined\n+    # under v2 subnets can contain ipv4 and ipv6 simultaneously\n     if subnet[\"type\"].endswith(\"6\") or subnet[\"type\"] in IPV6_DYNAMIC_TYPES:\n         # This is a request either static6 type or DHCPv6.\n         return True\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/net/dhcp.py",
            "diff": "diff --git a/cloudinit/net/dhcp.py b/cloudinit/net/dhcp.py\nindex 58b4bc56..06b40071 100644\n--- a/cloudinit/net/dhcp.py\n+++ b/cloudinit/net/dhcp.py\n@@ -5,15 +5,15 @@\n # This file is part of cloud-init. See LICENSE file for license information.\n \n import abc\n-import contextlib\n import glob\n import logging\n import os\n import re\n import signal\n import time\n+from contextlib import suppress\n from io import StringIO\n-from typing import Any, Dict, List\n+from typing import Any, Dict, List, Optional\n \n import configobj\n \n@@ -268,7 +268,7 @@ class IscDhclient(DhcpClient):\n \n         # this function waits for these files to exist, clean previous runs\n         # to avoid false positive in wait_for_files\n-        with contextlib.suppress(FileNotFoundError):\n+        with suppress(FileNotFoundError):\n             os.remove(pid_file)\n             os.remove(lease_file)\n \n@@ -486,9 +486,15 @@ class IscDhclient(DhcpClient):\n         return latest_file\n \n     @staticmethod\n-    def parse_dhcp_server_from_lease_file(lease_file):\n-        with open(lease_file, \"r\") as fd:\n-            for line in fd:\n+    def parse_dhcp_server_from_lease_file(lease_file) -> Optional[str]:\n+        \"\"\"Parse a lease file for the dhcp server address\n+\n+        @param lease_file: Name of a file to be parsed\n+        @return: An address if found, or None\n+        \"\"\"\n+        latest_address = None\n+        with suppress(FileNotFoundError), open(lease_file, \"r\") as file:\n+            for line in file:\n                 if \"dhcp-server-identifier\" in line:\n                     words = line.strip(\" ;\\r\\n\").split(\" \")\n                     if len(words) > 2:\n@@ -533,7 +539,7 @@ class Udhcpc(DhcpClient):\n \n         tmp_dir = temp_utils.get_tmp_ancestor(needs_exe=True)\n         lease_file = os.path.join(tmp_dir, interface + \".lease.json\")\n-        with contextlib.suppress(FileNotFoundError):\n+        with suppress(FileNotFoundError):\n             os.remove(lease_file)\n \n         # udhcpc needs the interface up to send initial discovery packets\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/net/network_manager.py",
            "diff": "diff --git a/cloudinit/net/network_manager.py b/cloudinit/net/network_manager.py\nindex 76a0ac15..bd6e6d75 100644\n--- a/cloudinit/net/network_manager.py\n+++ b/cloudinit/net/network_manager.py\n@@ -12,10 +12,15 @@ import itertools\n import logging\n import os\n import uuid\n-from typing import Optional\n+from typing import List, Optional\n \n from cloudinit import subp, util\n-from cloudinit.net import is_ipv6_address, renderer, subnet_is_ipv6\n+from cloudinit.net import (\n+    is_ipv6_address,\n+    is_ipv6_network,\n+    renderer,\n+    subnet_is_ipv6,\n+)\n from cloudinit.net.network_state import NetworkState\n from cloudinit.net.sysconfig import available_nm_ifcfg_rh\n \n@@ -158,11 +163,11 @@ class NMConnection:\n         if self.config[family][\"method\"] == \"auto\" and method == \"manual\":\n             return\n \n-        if (\n-            subnet_type == \"ipv6_dhcpv6-stateful\"\n-            or subnet_type == \"ipv6_dhcpv6-stateless\"\n-            or subnet_type == \"ipv6_slaac\"\n-        ):\n+        if subnet_type in [\n+            \"ipv6_dhcpv6-stateful\",\n+            \"ipv6_dhcpv6-stateless\",\n+            \"ipv6_slaac\",\n+        ]:\n             # set ipv4 method to 'disabled' to align with sysconfig renderer.\n             self._set_default(\"ipv4\", \"method\", \"disabled\")\n \n@@ -174,7 +179,8 @@ class NMConnection:\n         Adds a numbered property, such as address<n> or route<n>, ensuring\n         the appropriate value gets used for <n>.\n         \"\"\"\n-\n+        if not self.config.has_section(section):\n+            self.config[section] = {}\n         for index in itertools.count(1):\n             key = f\"{key_prefix}{index}\"\n             if not self.config.has_option(section, key):\n@@ -189,40 +195,37 @@ class NMConnection:\n         value = subnet[\"address\"] + \"/\" + str(subnet[\"prefix\"])\n         self._add_numbered(family, \"address\", value)\n \n-    def _add_route(self, family, route):\n-        \"\"\"\n-        Adds a ipv[46].route<n> property.\n-        \"\"\"\n-\n+    def _add_route(self, route):\n+        \"\"\"Adds a ipv[46].route<n> property.\"\"\"\n+        # Because network v2 route definitions can have mixed v4 and v6\n+        # routes, determine the family per route based on the gateway\n+        family = \"ipv6\" if is_ipv6_network(route[\"gateway\"]) else \"ipv4\"\n         value = route[\"network\"] + \"/\" + str(route[\"prefix\"])\n         if \"gateway\" in route:\n             value = value + \",\" + route[\"gateway\"]\n         self._add_numbered(family, \"route\", value)\n \n-    def _add_nameserver(self, dns):\n+    def _add_nameserver(self, dns: str) -> None:\n         \"\"\"\n         Extends the ipv[46].dns property with a name server.\n         \"\"\"\n-\n-        # FIXME: the subnet contains IPv4 and IPv6 name server mixed\n-        # together. We might be getting an IPv6 name server while\n-        # we're dealing with an IPv4 subnet. Sort this out by figuring\n-        # out the correct family and making sure a valid section exist.\n         family = \"ipv6\" if is_ipv6_address(dns) else \"ipv4\"\n-        self._set_default(family, \"method\", \"disabled\")\n-\n-        self._set_default(family, \"dns\", \"\")\n-        self.config[family][\"dns\"] = self.config[family][\"dns\"] + dns + \";\"\n+        if self.config.has_section(family):\n+            self._set_default(family, \"dns\", \"\")\n+            self.config[family][\"dns\"] = self.config[family][\"dns\"] + dns + \";\"\n \n-    def _add_dns_search(self, family, dns_search):\n+    def _add_dns_search(self, dns_search: List[str]) -> None:\n         \"\"\"\n         Extends the ipv[46].dns-search property with a name server.\n         \"\"\"\n-\n-        self._set_default(family, \"dns-search\", \"\")\n-        self.config[family][\"dns-search\"] = (\n-            self.config[family][\"dns-search\"] + \";\".join(dns_search) + \";\"\n-        )\n+        for family in [\"ipv4\", \"ipv6\"]:\n+            if self.config.has_section(family):\n+                self._set_default(family, \"dns-search\", \"\")\n+                self.config[family][\"dns-search\"] = (\n+                    self.config[family][\"dns-search\"]\n+                    + \";\".join(dns_search)\n+                    + \";\"\n+                )\n \n     def con_uuid(self):\n         \"\"\"\n@@ -304,8 +307,11 @@ class NMConnection:\n \n         device_mtu = iface[\"mtu\"]\n         ipv4_mtu = None\n+        found_nameservers = []\n+        found_dns_search = []\n \n         # Deal with Layer 3 configuration\n+        use_top_level_dns = \"dns\" in iface\n         for subnet in iface[\"subnets\"]:\n             family = \"ipv6\" if subnet_is_ipv6(subnet) else \"ipv4\"\n \n@@ -315,15 +321,28 @@ class NMConnection:\n             if \"gateway\" in subnet:\n                 self.config[family][\"gateway\"] = subnet[\"gateway\"]\n             for route in subnet[\"routes\"]:\n-                self._add_route(family, route)\n-            if \"dns_nameservers\" in subnet:\n+                self._add_route(route)\n+            if not use_top_level_dns and \"dns_nameservers\" in subnet:\n                 for nameserver in subnet[\"dns_nameservers\"]:\n-                    self._add_nameserver(nameserver)\n-            if \"dns_search\" in subnet:\n-                self._add_dns_search(family, subnet[\"dns_search\"])\n+                    found_nameservers.append(nameserver)\n+            if not use_top_level_dns and \"dns_search\" in subnet:\n+                found_dns_search.append(subnet[\"dns_search\"])\n             if family == \"ipv4\" and \"mtu\" in subnet:\n                 ipv4_mtu = subnet[\"mtu\"]\n \n+        # Now add our DNS search domains. We add them later because we\n+        # only want them if an IP family has already been defined\n+        if use_top_level_dns:\n+            for nameserver in iface[\"dns\"][\"nameservers\"]:\n+                self._add_nameserver(nameserver)\n+            if iface[\"dns\"][\"search\"]:\n+                self._add_dns_search(iface[\"dns\"][\"search\"])\n+        else:\n+            for nameserver in found_nameservers:\n+                self._add_nameserver(nameserver)\n+            for dns_search in found_dns_search:\n+                self._add_dns_search(dns_search)\n+\n         # we do not want to set may-fail to false for both ipv4 and ipv6 dhcp\n         # at the at the same time. This will make the network configuration\n         # work only when both ipv4 and ipv6 dhcp succeeds. This may not be\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/sources/azure/imds.py",
            "diff": "diff --git a/cloudinit/sources/azure/imds.py b/cloudinit/sources/azure/imds.py\nindex a9b2c455..a876f840 100644\n--- a/cloudinit/sources/azure/imds.py\n+++ b/cloudinit/sources/azure/imds.py\n@@ -104,7 +104,7 @@ class ReadUrlRetryHandler:\n             report_diagnostic_event(\n                 \"Polling IMDS failed attempt %d with exception: %r\"\n                 % (self._request_count, exception),\n-                logger_func=LOG.info,\n+                logger_func=LOG.warning,\n             )\n         return retry\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/stages.py",
            "diff": "diff --git a/cloudinit/stages.py b/cloudinit/stages.py\nindex 2cfd738a..18ecc01b 100644\n--- a/cloudinit/stages.py\n+++ b/cloudinit/stages.py\n@@ -969,7 +969,10 @@ class Init:\n         Find the config, determine whether to apply it, apply it via\n         the distro, and optionally bring it up\n         \"\"\"\n-        from cloudinit.config.schema import validate_cloudconfig_schema\n+        from cloudinit.config.schema import (\n+            SchemaType,\n+            validate_cloudconfig_schema,\n+        )\n \n         netcfg, src = self._find_networking_config()\n         if netcfg is None:\n@@ -1011,7 +1014,7 @@ class Init:\n         if netcfg and netcfg.get(\"version\") == 1:\n             validate_cloudconfig_schema(\n                 config=netcfg,\n-                schema_type=\"network-config\",\n+                schema_type=SchemaType.NETWORK_CONFIG,\n                 strict=False,\n                 log_details=True,\n                 log_deprecations=True,\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/templater.py",
            "diff": "diff --git a/cloudinit/templater.py b/cloudinit/templater.py\nindex c2dec80d..2e9217e9 100644\n--- a/cloudinit/templater.py\n+++ b/cloudinit/templater.py\n@@ -18,6 +18,8 @@ import re\n import sys\n from typing import Any\n \n+from jinja2 import TemplateSyntaxError\n+\n from cloudinit import type_utils as tu\n from cloudinit import util\n from cloudinit.atomic_helper import write_file\n@@ -42,6 +44,47 @@ BASIC_MATCHER = re.compile(r\"\\$\\{([A-Za-z0-9_.]+)\\}|\\$([A-Za-z0-9_.]+)\")\n MISSING_JINJA_PREFIX = \"CI_MISSING_JINJA_VAR/\"\n \n \n+class JinjaSyntaxParsingException(TemplateSyntaxError):\n+    def __init__(\n+        self,\n+        error: TemplateSyntaxError,\n+    ) -> None:\n+        super().__init__(\n+            error.message or \"unknown syntax error\",\n+            error.lineno,\n+            error.name,\n+            error.filename,\n+        )\n+        self.source = error.source\n+\n+    def __str__(self):\n+        \"\"\"Avoid jinja2.TemplateSyntaxErrror multi-line __str__ format.\"\"\"\n+        return self.format_error_message(\n+            syntax_error=self.message,\n+            line_number=self.lineno,\n+            line_content=self.source.splitlines()[self.lineno - 2].strip(),\n+        )\n+\n+    @staticmethod\n+    def format_error_message(\n+        syntax_error: str,\n+        line_number: str,\n+        line_content: str = \"\",\n+    ) -> str:\n+        \"\"\"Avoid jinja2.TemplateSyntaxErrror multi-line __str__ format.\"\"\"\n+        line_content = f\": {line_content}\" if line_content else \"\"\n+        return JinjaSyntaxParsingException.message_template.format(\n+            syntax_error=syntax_error,\n+            line_number=line_number,\n+            line_content=line_content,\n+        )\n+\n+    message_template = (\n+        \"Unable to parse Jinja template due to syntax error: \"\n+        \"{syntax_error} on line {line_number}{line_content}\"\n+    )\n+\n+\n # Mypy, and the PEP 484 ecosystem in general, does not support creating\n # classes with dynamic base types: https://stackoverflow.com/a/59636248\n class UndefinedJinjaVariable(JUndefined):\n@@ -102,18 +145,26 @@ def detect_template(text):\n     def jinja_render(content, params):\n         # keep_trailing_newline is in jinja2 2.7+, not 2.6\n         add = \"\\n\" if content.endswith(\"\\n\") else \"\"\n-        return (\n-            JTemplate(\n-                content,\n-                undefined=UndefinedJinjaVariable,\n-                trim_blocks=True,\n-                extensions=[\"jinja2.ext.do\"],\n-            ).render(**params)\n-            + add\n-        )\n+        try:\n+            return (\n+                JTemplate(\n+                    content,\n+                    undefined=UndefinedJinjaVariable,\n+                    trim_blocks=True,\n+                    extensions=[\"jinja2.ext.do\"],\n+                ).render(**params)\n+                + add\n+            )\n+        except TemplateSyntaxError as template_syntax_error:\n+            template_syntax_error.lineno += 1\n+            raise JinjaSyntaxParsingException(\n+                error=template_syntax_error,\n+            ) from template_syntax_error\n+        except Exception as unknown_error:\n+            raise unknown_error from unknown_error\n \n     if text.find(\"\\n\") != -1:\n-        ident, rest = text.split(\"\\n\", 1)\n+        ident, rest = text.split(\"\\n\", 1)  # remove the first line\n     else:\n         ident = text\n         rest = \"\"\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/util.py",
            "diff": "diff --git a/cloudinit/util.py b/cloudinit/util.py\nindex 2143f44f..6401a196 100644\n--- a/cloudinit/util.py\n+++ b/cloudinit/util.py\n@@ -303,6 +303,7 @@ def read_conf(fname, *, instance_data_file=None) -> Dict:\n     # Avoid circular import\n     from cloudinit.handlers.jinja_template import (\n         JinjaLoadError,\n+        JinjaSyntaxParsingException,\n         NotJinjaError,\n         render_jinja_payload_from_file,\n     )\n@@ -328,6 +329,12 @@ def read_conf(fname, *, instance_data_file=None) -> Dict:\n                 instance_data_file,\n                 fname,\n             )\n+        except JinjaSyntaxParsingException as e:\n+            LOG.warning(\n+                \"Failed to render templated yaml config file '%s'. %s\",\n+                fname,\n+                e,\n+            )\n         except NotJinjaError:\n             # A log isn't appropriate here as we generally expect most\n             # cloud.cfgs to not be templated. The other path is logged\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "cloudinit/version.py",
            "diff": "diff --git a/cloudinit/version.py b/cloudinit/version.py\nindex 2a789e24..b0efaed0 100644\n--- a/cloudinit/version.py\n+++ b/cloudinit/version.py\n@@ -4,7 +4,7 @@\n #\n # This file is part of cloud-init. See LICENSE file for license information.\n \n-__VERSION__ = \"23.4\"\n+__VERSION__ = \"23.4.1\"\n _PACKAGED_VERSION = \"@@PACKAGED_VERSION@@\"\n \n FEATURES = [\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "config/cloud.cfg.tmpl",
            "diff": "diff --git a/config/cloud.cfg.tmpl b/config/cloud.cfg.tmpl\nindex de0bf7bb..45838754 100644\n--- a/config/cloud.cfg.tmpl\n+++ b/config/cloud.cfg.tmpl\n@@ -111,7 +111,6 @@ disable_vmware_customization: false\n \n # The modules that run in the 'init' stage\n cloud_init_modules:\n-  - migrator\n {% if variant not in [\"netbsd\"] %}\n   - seed_random\n {% endif %}\n@@ -327,6 +326,9 @@ system_info:\n   paths:\n     cloud_dir: /var/lib/cloud/\n     templates_dir: /etc/cloud/templates/\n+{% elif is_bsd %}\n+  paths:\n+    run_dir: /var/run/\n {% endif %}\n {% if variant == \"debian\" %}\n   package_mirrors:\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "conftest.py",
            "diff": "diff --git a/conftest.py b/conftest.py\nindex bcf5a670..ca4743e2 100644\n--- a/conftest.py\n+++ b/conftest.py\n@@ -79,6 +79,14 @@ class _FixtureUtils:\n         return result[0]\n \n \n+class UnexpectedSubpError(BaseException):\n+    \"\"\"Error thrown when subp.subp is unexpectedly used.\n+\n+    We inherit from BaseException so it doesn't get silently swallowed\n+    by other error handlers.\n+    \"\"\"\n+\n+\n @pytest.fixture(autouse=True)\n def disable_subp_usage(request, fixture_utils):\n     \"\"\"\n@@ -142,12 +150,12 @@ def disable_subp_usage(request, fixture_utils):\n     if allow_all_subp is None and allow_subp_for is None:\n         # No marks, default behaviour; disallow all subp.subp usage\n         def side_effect(args, *other_args, **kwargs):\n-            raise AssertionError(\"Unexpectedly used subp.subp\")\n+            raise UnexpectedSubpError(\"Unexpectedly used subp.subp\")\n \n     elif allow_all_subp is not None and allow_subp_for is not None:\n         # Both marks, ambiguous request; raise an exception on all subp usage\n         def side_effect(args, *other_args, **kwargs):\n-            raise AssertionError(\n+            raise UnexpectedSubpError(\n                 \"Test marked both allow_all_subp and allow_subp_for: resolve\"\n                 \" this either by modifying your test code, or by modifying\"\n                 \" disable_subp_usage to handle precedence.\"\n@@ -161,7 +169,7 @@ def disable_subp_usage(request, fixture_utils):\n         def side_effect(args, *other_args, **kwargs):\n             cmd = args[0]\n             if cmd not in allow_subp_for:\n-                raise AssertionError(\n+                raise UnexpectedSubpError(\n                     \"Unexpectedly used subp.subp to call {} (allowed:\"\n                     \" {})\".format(cmd, \",\".join(allow_subp_for))\n                 )\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/conf.py",
            "diff": "diff --git a/doc/rtd/conf.py b/doc/rtd/conf.py\nindex bb2dc3d9..f8786950 100644\n--- a/doc/rtd/conf.py\n+++ b/doc/rtd/conf.py\n@@ -137,6 +137,10 @@ linkcheck_ignore = [\n ]\n \n linkcheck_anchors_ignore_for_url = (\n+    # Ignore github anchors in rst or md files\n+    r\"https://github.com/.*\\.rst\",\n+    r\"https://github.com/.*\\.md\",\n+    # Ignore github line number anchors in cloud-init and ubuntu-pro-client\n     r\"https://github.com/canonical/cloud-init.*\",\n     r\"https://github.com/canonical/ubuntu-pro-client.*\",\n )\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/development/contribute_docs.rst",
            "diff": "diff --git a/doc/rtd/development/contribute_docs.rst b/doc/rtd/development/contribute_docs.rst\nindex 6ba12179..a32dc38a 100644\n--- a/doc/rtd/development/contribute_docs.rst\n+++ b/doc/rtd/development/contribute_docs.rst\n@@ -10,8 +10,9 @@ Contribute to our docs\n     Style guide <style_docs.rst>\n     Directory layout <docs_layout.rst>\n \n-The documentation for cloud-init is hosted in GitHub and rendered on\n-`Read the Docs`_. It is mostly written in reStructuredText.\n+The documentation for cloud-init is hosted in the\n+`cloud-init GitHub repository`_ and rendered on `Read the Docs`_. It is mostly\n+written in reStructuredText.\n \n The process for contributing to the docs is largely the same as for code,\n except that for cosmetic changes to the documentation (spelling, grammar, etc)\n@@ -65,6 +66,7 @@ reviewer.\n \n .. LINKS\n .. include:: ../links.txt\n+.. _cloud-init GitHub repository: https://github.com/canonical/cloud-init/tree/main/doc/rtd\n .. _Read the Docs: https://readthedocs.com/\n .. _tools/.github-cla-signers: https://github.com/canonical/cloud-init/blob/main/tools/.github-cla-signers\n .. _tagging s-makin: https://github.com/s-makin\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/development/datasource_creation.rst",
            "diff": "diff --git a/doc/rtd/development/datasource_creation.rst b/doc/rtd/development/datasource_creation.rst\nindex 4b6bda4c..98f9f884 100644\n--- a/doc/rtd/development/datasource_creation.rst\n+++ b/doc/rtd/development/datasource_creation.rst\n@@ -1,7 +1,86 @@\n .. _datasource_creation:\n \n-Datasource creation\n-*******************\n+Supporting your cloud or platform\n+*********************************\n+\n+The upstream cloud-init project regularly accepts code contributions for new\n+platforms that wish to support cloud-init.\n+\n+Ways to add platform support\n+============================\n+\n+To add cloud-init support for a new platform, there are two possible\n+approaches:\n+\n+1. Provide platform compatibility with one of the existing datasource\n+   definitions, such as `nocloud`_ via `DatasourceNoCloud.py`_. Several\n+   platforms, including `Libvirt`_ and `Proxmox`_ use this approach.\n+2. Add a new datasource definition to upstream cloud-init. This provides\n+   tighter integration, a better debugging experience, and more control\n+   and flexibility of cloud-init's interaction with the datasource. This\n+   option is more sensible for clouds that have a unique architecture.\n+\n+Platform requirements\n+=====================\n+\n+There are some technical and logistical prerequisites that must be met for\n+cloud-init support.\n+\n+Technical requirements\n+----------------------\n+\n+A cloud needs to be able to identify itself to cloud-init at runtime, and that\n+the cloud be able to provide configuration to the instance.\n+\n+A mechanism for self-identification\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+Each cloud platform must positively identify itself to the guest. This allows\n+the guest to make educated decisions based on the platform on which it is\n+running. On the x86 and arm64 architectures, many clouds identify themselves\n+through `DMI`_ data. For example, Oracle's public cloud provides the string\n+``'OracleCloud.com'`` in the DMI chassis-asset field.\n+\n+``Cloud-init``-enabled images produce a log file with details about the\n+platform. Reading through this log in :file:`/run/cloud-init/ds-identify.log`\n+may provide the information needed to uniquely identify the platform.\n+If the log is not present, one can generate the log by running ``ds-identify``\n+manually.\n+\n+The mechanism used to identify the platform will be required for\n+``ds-identify`` and the datasource module sections below.\n+\n+A mechanism for cloud-init to retrieve configuration\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n+\n+There are different methods that cloud-init can use to retrieve\n+cloud-configuration for configuring the instance. The most common method is a\n+webserver providing configuration over a link-local network.\n+\n+Logistical requirements\n+-----------------------\n+\n+As with any open source project, multiple logistal requirements exist.\n+\n+Testing access\n+^^^^^^^^^^^^^^\n+\n+A platform that isn't available for testing cannot be independently validated.\n+You will need to provide some means for community members and upstream\n+developers to test and verify this platform. Code that cannot be used cannot be\n+supported.\n+\n+Maintainer support\n+^^^^^^^^^^^^^^^^^^\n+\n+A point of contact is required who can answer questions and occasionally\n+provide testing or maintenance support. Maintainership is relatively informal,\n+but there is an expectation that from time to time upstream may need to contact\n+a the maintainer with inquiries. Datasources that appear to be unmaintained\n+and/or unused may be considered for eventual removal.\n+\n+Adding cloud-init support\n+=========================\n \n There are multiple ways to provide `user data`, `metadata`, and\n `vendor data`, and each cloud solution prefers its own way. A datasource\n@@ -13,34 +92,14 @@ to see this class.\n If you are interested in adding a new datasource for your cloud platform you\n will need to do all of the following:\n \n-Identify a mechanism for positive identification of the platform\n-================================================================\n-\n-It is good practice for a cloud platform to positively identify itself to\n-the guest. This allows the guest to make educated decisions based on the\n-platform on which it is running. On the x86 and arm64 architectures, many\n-clouds identify themselves through `DMI`_ data. For example, Oracle's public\n-cloud provides the string ``'OracleCloud.com'`` in the DMI chassis-asset\n-field.\n-\n-``Cloud-init``-enabled images produce a log file with details about the\n-platform. Reading through this log in :file:`/run/cloud-init/ds-identify.log`\n-may provide the information needed to uniquely identify the platform.\n-If the log is not present, you can generate it by running from source\n-:file:`./tools/ds-identify` or the installed location\n-:file:`/usr/lib/cloud-init/ds-identify`.\n-\n-The mechanism used to identify the platform will be required for the\n-``ds-identify`` and datasource module sections below.\n-\n Add datasource module cloudinit/sources/DataSource<CloudPlatform>.py\n-====================================================================\n+--------------------------------------------------------------------\n \n We suggest you start by copying one of the simpler datasources\n such as ``DataSourceHetzner``.\n \n Re-run datasource detection\n----------------------------\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^\n \n While developing a new datasource it may be helpful to manually run datasource\n detection without rebooting the system.\n@@ -56,53 +115,65 @@ re-run, then clean up any logs, and finally, re-run ``cloud-init``:\n    sudo cloud-init init\n \n Add tests for datasource module\n-===============================\n+-------------------------------\n \n Add a new file with some tests for the module to\n :file:`cloudinit/sources/test_<yourplatform>.py`. For example, see\n :file:`cloudinit/sources/tests/test_oracle.py`\n \n Update ``ds-identify``\n-======================\n+----------------------\n \n In ``systemd`` systems, ``ds-identify`` is used to detect which datasource\n should be enabled, or if ``cloud-init`` should run at all. You'll need to\n make changes to :file:`tools/ds-identify`.\n \n Add tests for ``ds-identify``\n-=============================\n+-----------------------------\n \n Add relevant tests in a new class to\n :file:`tests/unittests/test_ds_identify.py`. You can use ``TestOracle`` as\n an example.\n \n Add your datasource name to the built-in list of datasources\n-============================================================\n+------------------------------------------------------------\n \n Add your datasource module name to the end of the ``datasource_list``\n entry in :file:`cloudinit/settings.py`.\n \n Add your cloud platform to apport collection prompts\n-====================================================\n+----------------------------------------------------\n \n Update the list of cloud platforms in :file:`cloudinit/apport.py`. This list\n will be provided to the user who invokes :command:`ubuntu-bug cloud-init`.\n \n Enable datasource by default in Ubuntu packaging branches\n-=========================================================\n+---------------------------------------------------------\n \n Ubuntu packaging branches contain a template file,\n-:file:`debian/cloud-init.templates`, which ultimately sets the default\n-``datasource_list`` when installed via package. This file needs updating when\n-the commit gets into a package.\n+:file:`config/cloud.cfg.tmpl`, which ultimately sets the default\n+``datasource_list`` that is installed by distros that use the upstream\n+packaging configuration.\n \n Add documentation for your datasource\n-=====================================\n+-------------------------------------\n \n You should add a new file in\n :file:`doc/rtd/reference/datasources/<cloudplatform>.rst`\n and reference it in\n :file:`doc/rtd/reference/datasources.rst`\n \n+Benefits of including your datasource in upstream cloud-init\n+============================================================\n+\n+Datasources included in upstream cloud-init benefit from ongoing maintenance,\n+compatibility with the rest of the codebase, and security fixes by the upstream\n+development team.\n+\n+\n .. _make-mime: https://cloudinit.readthedocs.io/en/latest/explanation/instancedata.html#storage-locations\n .. _DMI: https://www.dmtf.org/sites/default/files/standards/documents/DSP0005.pdf\n+.. _Libvirt: https://github.com/virt-manager/virt-manager/blob/main/man/virt-install.rst#--cloud-init\n+.. _Proxmox: https://pve.proxmox.com/wiki/Cloud-Init_Support\n+.. _DatasourceNoCloud.py: https://github.com/canonical/cloud-init/blob/main/cloudinit/sources/DataSourceNoCloud.py\n+.. _nocloud: https://cloudinit.readthedocs.io/en/latest/reference/datasources/nocloud.html\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/explanation/analyze.rst",
            "diff": "diff --git a/doc/rtd/explanation/analyze.rst b/doc/rtd/explanation/analyze.rst\nindex 10f41608..5f26e8a4 100644\n--- a/doc/rtd/explanation/analyze.rst\n+++ b/doc/rtd/explanation/analyze.rst\n@@ -92,7 +92,6 @@ Example output:\n         00.00100s (modules-config/config-apt_pipelining)\n         00.00100s (init-network/config-write_files)\n         00.00100s (init-network/config-seed_random)\n-        00.00100s (init-network/config-migrator)\n         00.00000s (modules-final/config-ubuntu_drivers)\n         00.00000s (modules-final/config-scripts_user)\n         00.00000s (modules-final/config-scripts_per_instance)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/explanation/format.rst",
            "diff": "diff --git a/doc/rtd/explanation/format.rst b/doc/rtd/explanation/format.rst\nindex 3de09c3e..26bfe665 100644\n--- a/doc/rtd/explanation/format.rst\n+++ b/doc/rtd/explanation/format.rst\n@@ -33,9 +33,8 @@ Begins with: ``#cloud-config`` or ``Content-Type: text/cloud-config`` when\n using a MIME archive.\n \n .. note::\n-   New in ``cloud-init`` v. 18.4: Cloud config data can also render cloud\n-   instance metadata variables using jinja templating. See\n-   :ref:`instance_metadata` for more information.\n+   Cloud config data can also render cloud instance metadata variables using\n+   jinja templating. See :ref:`instance_metadata` for more information.\n \n .. _user_data_script:\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/explanation/instancedata.rst",
            "diff": "diff --git a/doc/rtd/explanation/instancedata.rst b/doc/rtd/explanation/instancedata.rst\nindex ee3699eb..5024e179 100644\n--- a/doc/rtd/explanation/instancedata.rst\n+++ b/doc/rtd/explanation/instancedata.rst\n@@ -475,7 +475,6 @@ EC2 instance:\n      \"power_state_change\"\n     ],\n     \"cloud_init_modules\": [\n-     \"migrator\",\n      \"seed_random\",\n      \"bootcmd\",\n      \"write_files\",\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/howto/status.rst",
            "diff": "diff --git a/doc/rtd/howto/status.rst b/doc/rtd/howto/status.rst\nindex 01079f54..51ca02c3 100644\n--- a/doc/rtd/howto/status.rst\n+++ b/doc/rtd/howto/status.rst\n@@ -58,5 +58,29 @@ See the list of all possible reported statuses:\n     \"degraded running\"\n     \"disabled\"\n \n+Cloud-init enablement status\n+----------------------------\n+\n+Separately from the current running status described above, cloud-init can also\n+report how it was disabled or enabled. This can be viewed by checking\n+the `boot_status_code` in ``cloud-init status --long``, which may\n+contain any of the following states:\n+\n+- ``'unknown'``: ``ds-identify`` has not run yet to determine if cloud-init\n+  should be run during this boot\n+- ``'disabled-by-marker-file'``: :file:`/etc/cloud/cloud-init.disabled` exists\n+  which prevents cloud-init from ever running\n+- ``'disabled-by-generator'``: ``ds-identify`` determined no applicable\n+  cloud-init datasources\n+- ``'disabled-by-kernel-cmdline'``: kernel command line contained\n+  cloud-init=disabled\n+- ``'disabled-by-environment-variable'``: environment variable\n+  ``KERNEL_CMDLINE`` contained ``cloud-init=disabled``\n+- ``'enabled-by-kernel-cmdline'``: kernel command line contained\n+  cloud-init=enabled\n+- ``'enabled-by-generator'``: ``ds-identify`` detected possible cloud-init\n+  datasources\n+- ``'enabled-by-sysvinit'``: enabled by default in SysV init environment\n+\n See :ref:`our explanation of failure states<failure_states>` for more\n information.\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/reference/base_config_reference.rst",
            "diff": "diff --git a/doc/rtd/reference/base_config_reference.rst b/doc/rtd/reference/base_config_reference.rst\nindex 85a474f5..09bab932 100644\n--- a/doc/rtd/reference/base_config_reference.rst\n+++ b/doc/rtd/reference/base_config_reference.rst\n@@ -298,7 +298,6 @@ On an Ubuntu system, :file:`/etc/cloud/cloud.cfg` should look similar to:\n \n     # The modules that run in the 'init' stage\n     cloud_init_modules:\n-    - migrator\n     - seed_random\n     - bootcmd\n     - write_files\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/reference/merging.rst",
            "diff": "diff --git a/doc/rtd/reference/merging.rst b/doc/rtd/reference/merging.rst\nindex 62efffdb..7f1fc022 100644\n--- a/doc/rtd/reference/merging.rst\n+++ b/doc/rtd/reference/merging.rst\n@@ -3,19 +3,12 @@\n Merging user data sections\n **************************\n \n-The ability to merge user data sections is a feature that was implemented by\n-popular request. It was identified that there should be a way to specify how\n+The ability to merge user data sections allows a way to specify how\n cloud-config YAML \"dictionaries\" provided as user data are handled when there\n are multiple YAML files to be merged together (e.g., when performing an\n #include).\n \n-The previous merging algorithm was very simple and would only overwrite\n-(and not append). So, it was decided to create a new and improved way to merge\n-dictionaries (and their contained objects) together in a customisable way,\n-thus allowing users who provide cloud-config user data to determine exactly\n-how their objects will be merged.\n-\n-For example:\n+For example merging these two configurations:\n \n .. code-block:: yaml\n \n@@ -29,17 +22,7 @@ For example:\n      - bash3\n      - bash4\n \n-The previous way of merging the two objects above would result in a final\n-cloud-config object that contains the following:\n-\n-.. code-block:: yaml\n-\n-   #cloud-config (merged)\n-   runcmd:\n-     - bash3\n-     - bash4\n-\n-Typically this is not what users want - instead they would prefer:\n+Yields the following merged config:\n \n .. code-block:: yaml\n \n@@ -50,10 +33,6 @@ Typically this is not what users want - instead they would prefer:\n      - bash3\n      - bash4\n \n-This change makes it easier to combine the various cloud-config objects you\n-have into a more useful list. In this way, we reduce the duplication necessary\n-to accomplish the same result with the previous method.\n-\n Built-in mergers\n ================\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/reference/modules.rst",
            "diff": "diff --git a/doc/rtd/reference/modules.rst b/doc/rtd/reference/modules.rst\nindex 28f4cd64..0d069048 100644\n--- a/doc/rtd/reference/modules.rst\n+++ b/doc/rtd/reference/modules.rst\n@@ -41,7 +41,6 @@ date. A 5 year timeline may also be expected for changed keys.\n .. automodule:: cloudinit.config.cc_locale\n .. automodule:: cloudinit.config.cc_lxd\n .. automodule:: cloudinit.config.cc_mcollective\n-.. automodule:: cloudinit.config.cc_migrator\n .. automodule:: cloudinit.config.cc_mounts\n \n .. _mod-ntp:\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "doc/rtd/spelling_word_list.txt",
            "diff": "diff --git a/doc/rtd/spelling_word_list.txt b/doc/rtd/spelling_word_list.txt\nindex c51b946b..5dca6171 100644\n--- a/doc/rtd/spelling_word_list.txt\n+++ b/doc/rtd/spelling_word_list.txt\n@@ -35,7 +35,6 @@ cleanup\n cloudinit\n cloudlinux\n cloudplatform\n-commandline\n conf\n config\n configdrive\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "setup.py",
            "diff": "diff --git a/setup.py b/setup.py\nindex e40d730e..0d42774f 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -178,7 +178,7 @@ USR = \"usr\"\n ETC = \"etc\"\n USR_LIB_EXEC = \"usr/lib\"\n LIB = \"lib\"\n-if os.uname()[0] in [\"FreeBSD\", \"DragonFly\"]:\n+if os.uname()[0] in [\"FreeBSD\", \"DragonFly\", \"OpenBSD\"]:\n     USR = \"usr/local\"\n     USR_LIB_EXEC = \"usr/local/lib\"\n elif os.path.isfile(\"/etc/redhat-release\"):\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "systemd/cloud-final.service.tmpl",
            "diff": "diff --git a/systemd/cloud-final.service.tmpl b/systemd/cloud-final.service.tmpl\nindex bcf8b009..ab3daed0 100644\n--- a/systemd/cloud-final.service.tmpl\n+++ b/systemd/cloud-final.service.tmpl\n@@ -1,7 +1,7 @@\n ## template:jinja\n [Unit]\n Description=Execute cloud user/final scripts\n-After=network-online.target cloud-config.service rc-local.service\n+After=network-online.target time-sync.target cloud-config.service rc-local.service\n {% if variant in [\"ubuntu\", \"unknown\", \"debian\"] %}\n After=multi-user.target\n Before=apt-daily.service\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/freebsd/cloudinitlocal.tmpl",
            "diff": "diff --git a/sysvinit/freebsd/cloudinitlocal.tmpl b/sysvinit/freebsd/cloudinitlocal.tmpl\nindex ec9b1fb8..acf8c20a 100755\n--- a/sysvinit/freebsd/cloudinitlocal.tmpl\n+++ b/sysvinit/freebsd/cloudinitlocal.tmpl\n@@ -4,7 +4,7 @@\n # PROVIDE: cloudinitlocal\n {#\n ``cloudinitlocal`` purposefully does not depend on ``dsidentify``.\n-That makes it easy for image builders to create images without ``dsidentify``.\n+That makes it easy for image builders to disable ``dsidentify``.\n #}\n # REQUIRE: ldconfig mountcritlocal\n # BEFORE:  NETWORKING cloudinit cloudconfig cloudfinal\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/netbsd/cloudconfig.tmpl",
            "diff": "diff --git a/sysvinit/netbsd/cloudconfig.tmpl b/sysvinit/netbsd/cloudconfig.tmpl\nindex b78356ca..f299d7c1 100755\n--- a/sysvinit/netbsd/cloudconfig.tmpl\n+++ b/sysvinit/netbsd/cloudconfig.tmpl\n@@ -11,9 +11,10 @@ name=\"cloudinit\"\n start_cmd=\"start_cloud_init\"\n start_cloud_init()\n {\n-    test -e {{prefix}}/etc/cloud/cloud-init.disabled \\\n-      && warn \"cloud-init disabled by cloud-init.disabled file\" \\\n-      && exit 0\n+    if test -e {{prefix}}/etc/cloud/cloud-init.disabled ; then\n+       warn \"cloud-init disabled by cloud-init.disabled file\"\n+       exit 0\n+    fi\n     {{prefix}}/bin/cloud-init modules --mode config\n }\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/netbsd/cloudfinal.tmpl",
            "diff": "diff --git a/sysvinit/netbsd/cloudfinal.tmpl b/sysvinit/netbsd/cloudfinal.tmpl\nindex 3117d07c..fa092c88 100755\n--- a/sysvinit/netbsd/cloudfinal.tmpl\n+++ b/sysvinit/netbsd/cloudfinal.tmpl\n@@ -10,9 +10,10 @@ name=\"cloudinit\"\n start_cmd=\"start_cloud_init\"\n start_cloud_init()\n {\n-    test -e {{prefix}}/etc/cloud/cloud-init.disabled \\\n-      && warn \"cloud-init disabled by cloud-init.disabled file\" \\\n-      && exit 0\n+    if test -e {{prefix}}/etc/cloud/cloud-init.disabled ; then\n+       warn \"cloud-init disabled by cloud-init.disabled file\"\n+       exit 0\n+    fi\n     {{prefix}}/bin/cloud-init modules --mode final\n }\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/netbsd/cloudinit.tmpl",
            "diff": "diff --git a/sysvinit/netbsd/cloudinit.tmpl b/sysvinit/netbsd/cloudinit.tmpl\nindex a8e926c1..5a814989 100755\n--- a/sysvinit/netbsd/cloudinit.tmpl\n+++ b/sysvinit/netbsd/cloudinit.tmpl\n@@ -10,9 +10,10 @@ name=\"cloudinit\"\n start_cmd=\"start_cloud_init\"\n start_cloud_init()\n {\n-    test -e {{prefix}}/etc/cloud/cloud-init.disabled \\\n-      && warn \"cloud-init disabled by cloud-init.disabled file\" \\\n-      && exit 0\n+    if test -e {{prefix}}/etc/cloud/cloud-init.disabled ; then\n+       warn \"cloud-init disabled by cloud-init.disabled file\"\n+       exit 0\n+    fi\n     {{prefix}}/bin/cloud-init init\n }\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/netbsd/cloudinitlocal.tmpl",
            "diff": "diff --git a/sysvinit/netbsd/cloudinitlocal.tmpl b/sysvinit/netbsd/cloudinitlocal.tmpl\nindex ba840ab4..79e78aee 100755\n--- a/sysvinit/netbsd/cloudinitlocal.tmpl\n+++ b/sysvinit/netbsd/cloudinitlocal.tmpl\n@@ -16,9 +16,10 @@ name=\"cloudinitlocal\"\n start_cmd=\"start_cloud_init_local\"\n start_cloud_init_local()\n {\n-    test -e {{prefix}}/etc/cloud/cloud-init.disabled \\\n-      && warn \"cloud-init disabled by cloud-init.disabled file\" \\\n-      && exit 0\n+    if test -e {{prefix}}/etc/cloud/cloud-init.disabled; then\n+       warn \"cloud-init disabled by cloud-init.disabled file\"\n+       exit 0\n+    fi\n     {{prefix}}/bin/cloud-init init -l\n }\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "sysvinit/netbsd/dsidentify.tmpl",
            "diff": "diff --git a/sysvinit/netbsd/dsidentify.tmpl b/sysvinit/netbsd/dsidentify.tmpl\nindex 4ce7e067..cc536198 100755\n--- a/sysvinit/netbsd/dsidentify.tmpl\n+++ b/sysvinit/netbsd/dsidentify.tmpl\n@@ -11,9 +11,10 @@ name=\"dsidentify\"\n start_cmd=\"start_dsidentify\"\n start_dsidentify()\n {\n-    test -e {{prefix}}/etc/cloud/cloud-init.disabled \\\n-      && warn \"cloud-init disabled by cloud-init.disabled file\" \\\n-      && exit 0\n+    if test -e {{prefix}}/etc/cloud/cloud-init.disabled ; then\n+      warn \"cloud-init disabled by cloud-init.disabled file\"\n+      exit 0\n+    fi\n     {{prefix}}/lib/cloud-init/ds-identify\n }\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/integration_tests/cmd/test_clean.py",
            "diff": "diff --git a/tests/integration_tests/cmd/test_clean.py b/tests/integration_tests/cmd/test_clean.py\nindex 78600516..7a3278c1 100644\n--- a/tests/integration_tests/cmd/test_clean.py\n+++ b/tests/integration_tests/cmd/test_clean.py\n@@ -4,6 +4,7 @@ import re\n import pytest\n \n from tests.integration_tests.instances import IntegrationInstance\n+from tests.integration_tests.releases import CURRENT_RELEASE\n \n USER_DATA = \"\"\"\\\n #cloud-config\n@@ -32,7 +33,15 @@ write_files:\n class TestCleanCommand:\n     def test_clean_by_param(self, class_client: IntegrationInstance):\n         \"\"\"Clean with various params alters expected files without error\"\"\"\n-        assert class_client.execute(\"cloud-init status --wait\").ok\n+        result = class_client.execute(\"cloud-init status --wait --long\")\n+\n+        # Expect warning exit code 2 on Ubuntu Noble due to cloud-init\n+        # disabling /etc/apt/sources.list build artifact in favor of deb822\n+        return_code = 2 if CURRENT_RELEASE.series == \"noble\" else 0\n+        assert return_code == result.return_code, (\n+            f\"Unexpected cloud-init status exit code {result.return_code}\\n\"\n+            f\"Output:\\n{result}\"\n+        )\n         result = class_client.execute(\"cloud-init clean\")\n         assert (\n             result.ok\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/integration_tests/modules/test_apt_functionality.py",
            "diff": "diff --git a/tests/integration_tests/modules/test_apt_functionality.py b/tests/integration_tests/modules/test_apt_functionality.py\nindex e7ca6ed9..1882e270 100644\n--- a/tests/integration_tests/modules/test_apt_functionality.py\n+++ b/tests/integration_tests/modules/test_apt_functionality.py\n@@ -336,6 +336,21 @@ class TestDefaults:\n             assert 3 == sources_list.count(sec_deb_line)\n             assert 3 == sources_list.count(sec_src_deb_line)\n \n+    def test_no_duplicate_apt_sources(self, class_client: IntegrationInstance):\n+        r = class_client.execute(\"apt-get update\", use_sudo=True)\n+        assert not re.match(\n+            r\"^W: Target Packages .+ is configured multiple times in\", r.stderr\n+        )\n+\n+    def test_disabled_apt_sources(self, class_client: IntegrationInstance):\n+        feature_deb822 = is_true(\n+            get_feature_flag_value(class_client, \"APT_DEB822_SOURCE_LIST_FILE\")\n+        )\n+        if feature_deb822:\n+            assert class_client.execute(\n+                f\"test -f {ORIG_SOURCES_FILE}\"\n+            ).failed, f\"Found unexpected {ORIG_SOURCES_FILE}\"\n+\n \n DEFAULT_DATA_WITH_URI = _DEFAULT_DATA.format(\n     uri='uri: \"http://something.random.invalid/ubuntu\"'\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/integration_tests/modules/test_cli.py",
            "diff": "diff --git a/tests/integration_tests/modules/test_cli.py b/tests/integration_tests/modules/test_cli.py\nindex 8d7aff66..2d4eea3d 100644\n--- a/tests/integration_tests/modules/test_cli.py\n+++ b/tests/integration_tests/modules/test_cli.py\n@@ -7,6 +7,7 @@ import pytest\n \n from tests.integration_tests.instances import IntegrationInstance\n from tests.integration_tests.integration_settings import PLATFORM\n+from tests.integration_tests.releases import CURRENT_RELEASE\n \n VALID_USER_DATA = \"\"\"\\\n #cloud-config\n@@ -44,10 +45,13 @@ def test_valid_userdata(client: IntegrationInstance):\n     assert result.ok\n     assert \"Valid schema user-data\" in result.stdout.strip()\n     result = client.execute(\"cloud-init status --long\")\n-    if not result.ok:\n-        raise AssertionError(\n-            f\"Unexpected error from cloud-init status: {result}\"\n-        )\n+    # Ubuntu Noble will exit 2 for status due to cloud-init's warning about\n+    # disabling /etc/apt/sources.list in favor of deb822 sources\n+    return_code = 2 if CURRENT_RELEASE.series == \"noble\" else 0\n+    assert return_code == result.return_code, (\n+        f\"Unexpected exit {result.return_code} from cloud-init status:\"\n+        f\" {result}\"\n+    )\n \n \n @pytest.mark.skipif(\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/integration_tests/reporting/test_webhook_reporting.py",
            "diff": "diff --git a/tests/integration_tests/reporting/test_webhook_reporting.py b/tests/integration_tests/reporting/test_webhook_reporting.py\nindex 3fcda11c..fc842190 100644\n--- a/tests/integration_tests/reporting/test_webhook_reporting.py\n+++ b/tests/integration_tests/reporting/test_webhook_reporting.py\n@@ -54,7 +54,7 @@ def test_webhook_reporting(client: IntegrationInstance):\n     events = [json.loads(line) for line in server_output]\n \n     # Only time this should be less is if we remove modules\n-    assert len(events) > 56, events\n+    assert len(events) > 54, events\n \n     # Assert our first and last expected messages exist\n     ds_events = [\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/integration_tests/util.py",
            "diff": "diff --git a/tests/integration_tests/util.py b/tests/integration_tests/util.py\nindex 0a15203c..519c670c 100644\n--- a/tests/integration_tests/util.py\n+++ b/tests/integration_tests/util.py\n@@ -67,6 +67,9 @@ def verify_clean_log(log: str, ignore_deprecations: bool = True):\n         # Ubuntu lxd storage\n         \"thinpool by default on Ubuntu due to LP #1982780\",\n         \"WARNING]: Could not match supplied host pattern, ignoring:\",\n+        # Old Ubuntu cloud-images contain /etc/apt/sources.list\n+        \"WARNING]: Disabling /etc/apt/sources.list to favor deb822 source\"\n+        \" format\",\n     ]\n     traceback_texts = []\n     if \"install canonical-livepatch\" in log:\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/analyze/test_boot.py",
            "diff": "diff --git a/tests/unittests/analyze/test_boot.py b/tests/unittests/analyze/test_boot.py\nindex d54b9fac..bd99d361 100644\n--- a/tests/unittests/analyze/test_boot.py\n+++ b/tests/unittests/analyze/test_boot.py\n@@ -28,17 +28,12 @@ class TestDistroChecker(CiTestCase):\n \n \n class TestSystemCtlReader:\n-    @pytest.mark.parametrize(\n-        \"args\",\n-        [\n-            pytest.param([\"dummyProperty\"], id=\"invalid_property\"),\n-            pytest.param(\n-                [\"dummyProperty\", \"dummyParameter\"], id=\"invalid_parameter\"\n-            ),\n-        ],\n-    )\n-    def test_systemctl_invalid(self, args):\n-        reader = SystemctlReader(*args)\n+    def test_systemctl_invalid(self, mocker):\n+        mocker.patch(\n+            \"cloudinit.analyze.show.subp.subp\",\n+            return_value=(\"\", \"something_invalid\"),\n+        )\n+        reader = SystemctlReader(\"dont\", \"care\")\n         with pytest.raises(RuntimeError):\n             reader.parse_epoch_as_float()\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/cmd/devel/test_logs.py",
            "diff": "diff --git a/tests/unittests/cmd/devel/test_logs.py b/tests/unittests/cmd/devel/test_logs.py\nindex a40d53c6..af77717c 100644\n--- a/tests/unittests/cmd/devel/test_logs.py\n+++ b/tests/unittests/cmd/devel/test_logs.py\n@@ -231,15 +231,14 @@ class TestCollectLogs:\n                 \"cloud-init? more like cloud-innit!\\n\",\n             ),\n             (\n-                [\"ls\", \"/nonexistent-directory\"],\n+                [\"sh\", \"-c\", \"echo test 1>&2; exit 42\"],\n                 (\n                     \"Unexpected error while running command.\\n\"\n-                    \"Command: ['ls', '/nonexistent-directory']\\n\"\n-                    \"Exit code: 2\\n\"\n+                    \"Command: ['sh', '-c', 'echo test 1>&2; exit 42']\\n\"\n+                    \"Exit code: 42\\n\"\n                     \"Reason: -\\n\"\n                     \"Stdout: \\n\"\n-                    \"Stderr: ls: cannot access '/nonexistent-directory': \"\n-                    \"No such file or directory\"\n+                    \"Stderr: test\"\n                 ),\n                 None,\n             ),\n@@ -270,13 +269,7 @@ class TestCollectLogs:\n         \"cmd, expected_file_contents\",\n         [\n             ([\"echo\", \"cloud-init, shmoud-init\"], \"cloud-init, shmoud-init\\n\"),\n-            (\n-                [\"ls\", \"/nonexistent-directory\"],\n-                (\n-                    \"ls: cannot access '/nonexistent-directory': \"\n-                    \"No such file or directory\\n\"\n-                ),\n-            ),\n+            ([\"sh\", \"-c\", \"echo test 1>&2; exit 42\"], \"test\\n\"),\n         ],\n     )\n     def test_stream_command_output_to_file(\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/cmd/devel/test_render.py",
            "diff": "diff --git a/tests/unittests/cmd/devel/test_render.py b/tests/unittests/cmd/devel/test_render.py\nindex d179f474..1e26643c 100644\n--- a/tests/unittests/cmd/devel/test_render.py\n+++ b/tests/unittests/cmd/devel/test_render.py\n@@ -6,6 +6,7 @@ import pytest\n \n from cloudinit.cmd.devel import render\n from cloudinit.helpers import Paths\n+from cloudinit.templater import JinjaSyntaxParsingException\n from cloudinit.util import ensure_dir, write_file\n from tests.unittests.helpers import mock, skipUnlessJinja\n \n@@ -148,3 +149,19 @@ class TestRender:\n         write_file(instance_data, '{\"my-var\": \"jinja worked\"}')\n         render.render_template(user_data, instance_data, False)\n         assert \"Unable to render user-data file\" in caplog.text\n+\n+    @skipUnlessJinja()\n+    def test_invalid_jinja_syntax(self, caplog, tmpdir):\n+        user_data = tmpdir.join(\"user-data\")\n+        write_file(user_data, \"##template: jinja\\nrendering: {{ my_var } }\")\n+        instance_data = tmpdir.join(\"instance-data\")\n+        write_file(instance_data, '{\"my-var\": \"jinja worked\"}')\n+        assert render.render_template(user_data, instance_data, True) == 1\n+        assert (\n+            JinjaSyntaxParsingException.format_error_message(\n+                syntax_error=\"unexpected '}'\",\n+                line_number=2,\n+                line_content=\"rendering: {{ my_var } }\",\n+            )\n+            in caplog.text\n+        )\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/cmd/test_query.py",
            "diff": "diff --git a/tests/unittests/cmd/test_query.py b/tests/unittests/cmd/test_query.py\nindex 0a5efe7f..86e60f5c 100644\n--- a/tests/unittests/cmd/test_query.py\n+++ b/tests/unittests/cmd/test_query.py\n@@ -15,6 +15,7 @@ from cloudinit.atomic_helper import b64e\n from cloudinit.cmd import query\n from cloudinit.helpers import Paths\n from cloudinit.sources import REDACT_SENSITIVE_VALUE\n+from cloudinit.templater import JinjaSyntaxParsingException\n from cloudinit.util import write_file\n from tests.unittests.helpers import mock\n \n@@ -567,3 +568,67 @@ class TestQuery:\n             m_getuid.return_value = 100\n             assert 1 == query.handle_args(\"anyname\", args)\n         assert expected_error in caplog.text\n+\n+    @pytest.mark.parametrize(\n+        \"header_included\",\n+        [True, False],\n+    )\n+    def test_handle_args_formats_jinja_successfully(\n+        self, caplog, tmpdir, capsys, header_included\n+    ):\n+        \"\"\"Test that rendering a jinja template works as expected.\"\"\"\n+        instance_data = tmpdir.join(\"instance-data\")\n+        instance_data.write(\n+            '{\"v1\": {\"v1_1\": \"val1.1\", \"v1_2\": \"val1.2\"}, \"v2\": '\n+            '{\"v2_2\": \"val2.2\"}, \"top\": \"gun\"}'\n+        )\n+        header = \"## template: jinja\\n\" if header_included else \"\"\n+        format = header + \"v1_1: {{ v1.v1_1 }}\"\n+        expected = header + \"v1_1: val1.1\\n\"\n+\n+        args = self.Args(\n+            debug=False,\n+            dump_all=False,\n+            format=format,\n+            instance_data=instance_data.strpath,\n+            list_keys=False,\n+            user_data=\"ud\",\n+            vendor_data=\"vd\",\n+            varname=None,\n+        )\n+        with mock.patch(\"os.getuid\") as m_getuid:\n+            m_getuid.return_value = 100\n+            assert 0 == query.handle_args(\"anyname\", args)\n+        out, _err = capsys.readouterr()\n+        assert expected == out\n+\n+    def test_handle_args_invalid_jinja_exception(self, caplog, tmpdir, capsys):\n+        \"\"\"Raise an error when a jinja syntax error is encountered.\"\"\"\n+        instance_data = tmpdir.join(\"instance-data\")\n+        instance_data.write(\n+            '{\"v1\": {\"v1_1\": \"val1.1\", \"v1_2\": \"val1.2\"}, \"v2\": '\n+            '{\"v2_2\": \"val2.2\"}, \"top\": \"gun\"}'\n+        )\n+        format = \"v1_1: {{ v1.v1_1 } }\"\n+        expected_error = (\n+            \"Failed to render templated data. \"\n+            + JinjaSyntaxParsingException.format_error_message(\n+                syntax_error=\"unexpected '}'\",\n+                line_number=2,\n+                line_content=\"v1_1: {{ v1.v1_1 } }\",\n+            )\n+        )\n+        args = self.Args(\n+            debug=False,\n+            dump_all=False,\n+            format=format,\n+            instance_data=instance_data.strpath,\n+            list_keys=False,\n+            user_data=\"ud\",\n+            vendor_data=\"vd\",\n+            varname=None,\n+        )\n+        with mock.patch(\"os.getuid\") as m_getuid:\n+            m_getuid.return_value = 100\n+            assert 1 == query.handle_args(\"anyname\", args)\n+        assert expected_error in caplog.text\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/cmd/test_status.py",
            "diff": "diff --git a/tests/unittests/cmd/test_status.py b/tests/unittests/cmd/test_status.py\nindex 6c85a59a..6e4eac4b 100644\n--- a/tests/unittests/cmd/test_status.py\n+++ b/tests/unittests/cmd/test_status.py\n@@ -9,9 +9,14 @@ from unittest import mock\n \n import pytest\n \n+from cloudinit import subp\n from cloudinit.atomic_helper import write_json\n from cloudinit.cmd import status\n-from cloudinit.cmd.status import UXAppStatus, _get_systemd_status\n+from cloudinit.cmd.status import (\n+    UXAppStatus,\n+    _get_error_or_running_from_systemd,\n+    _get_error_or_running_from_systemd_with_retry,\n+)\n from cloudinit.subp import SubpResult\n from cloudinit.util import ensure_file\n from tests.unittests.helpers import wrap_and_call\n@@ -59,7 +64,10 @@ class TestStatus:\n             \"Cloud-init enabled by systemd cloud-init-generator\",\n         ),\n     )\n-    @mock.patch(f\"{M_PATH}_get_systemd_status\", return_value=None)\n+    @mock.patch(\n+        f\"{M_PATH}_get_error_or_running_from_systemd_with_retry\",\n+        return_value=None,\n+    )\n     def test_get_status_details_ds_none(\n         self,\n         m_get_systemd_status,\n@@ -704,7 +712,10 @@ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\n         ],\n     )\n     @mock.patch(M_PATH + \"read_cfg_paths\")\n-    @mock.patch(f\"{M_PATH}_get_systemd_status\", return_value=None)\n+    @mock.patch(\n+        f\"{M_PATH}_get_error_or_running_from_systemd_with_retry\",\n+        return_value=None,\n+    )\n     def test_status_output(\n         self,\n         m_get_systemd_status,\n@@ -745,7 +756,10 @@ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\n             assert out == expected_status\n \n     @mock.patch(M_PATH + \"read_cfg_paths\")\n-    @mock.patch(f\"{M_PATH}_get_systemd_status\", return_value=None)\n+    @mock.patch(\n+        f\"{M_PATH}_get_error_or_running_from_systemd_with_retry\",\n+        return_value=None,\n+    )\n     def test_status_wait_blocks_until_done(\n         self, m_get_systemd_status, m_read_cfg_paths, config: Config, capsys\n     ):\n@@ -796,7 +810,10 @@ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\n         assert out == \"....\\nstatus: done\\n\"\n \n     @mock.patch(M_PATH + \"read_cfg_paths\")\n-    @mock.patch(f\"{M_PATH}_get_systemd_status\", return_value=None)\n+    @mock.patch(\n+        f\"{M_PATH}_get_error_or_running_from_systemd_with_retry\",\n+        return_value=None,\n+    )\n     def test_status_wait_blocks_until_error(\n         self, m_get_systemd_status, m_read_cfg_paths, config: Config, capsys\n     ):\n@@ -849,7 +866,10 @@ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\n         assert out == \"....\\nstatus: error\\n\"\n \n     @mock.patch(M_PATH + \"read_cfg_paths\")\n-    @mock.patch(f\"{M_PATH}_get_systemd_status\", return_value=None)\n+    @mock.patch(\n+        f\"{M_PATH}_get_error_or_running_from_systemd_with_retry\",\n+        return_value=None,\n+    )\n     def test_status_main(\n         self, m_get_systemd_status, m_read_cfg_paths, config: Config, capsys\n     ):\n@@ -873,7 +893,12 @@ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\n         assert out == \"status: running\\n\"\n \n \n-class TestSystemdStatusDetails:\n+class TestGetErrorOrRunningFromSystemd:\n+    @pytest.fixture(autouse=True)\n+    def common_mocks(self, mocker):\n+        mocker.patch(\"cloudinit.cmd.status.sleep\")\n+        yield\n+\n     @pytest.mark.parametrize(\n         [\"active_state\", \"unit_file_state\", \"sub_state\", \"main_pid\", \"status\"],\n         [\n@@ -881,7 +906,7 @@ class TestSystemdStatusDetails:\n             # enabled, enabled-runtime, and static into an \"enabled\" state\n             # and everything else functionally disabled.\n             # Additionally, SubStates are undocumented and may mean something\n-            # different depending on the ActiveState they are mapped too.\n+            # different depending on the ActiveState they are mapped to.\n             # Because of this I'm only testing SubState combinations seen\n             # in real-world testing (or using \"any\" string if we dont care).\n             (\"activating\", \"enabled\", \"start\", \"123\", UXAppStatus.RUNNING),\n@@ -910,7 +935,7 @@ class TestSystemdStatusDetails:\n             (\"failed\", \"invalid\", \"failed\", \"0\", UXAppStatus.ERROR),\n         ],\n     )\n-    def test_get_systemd_status(\n+    def test_get_error_or_running_from_systemd(\n         self, active_state, unit_file_state, sub_state, main_pid, status\n     ):\n         with mock.patch(\n@@ -923,4 +948,70 @@ class TestSystemdStatusDetails:\n                 stderr=None,\n             ),\n         ):\n-            assert _get_systemd_status() == status\n+            assert _get_error_or_running_from_systemd() == status\n+\n+    def test_exception_while_running(self, mocker, capsys):\n+        m_subp = mocker.patch(\n+            f\"{M_PATH}subp.subp\",\n+            side_effect=subp.ProcessExecutionError(\n+                \"Message recipient disconnected from message bus without\"\n+                \" replying\"\n+            ),\n+        )\n+        assert (\n+            _get_error_or_running_from_systemd_with_retry(\n+                UXAppStatus.RUNNING, wait=True\n+            )\n+            is None\n+        )\n+        assert 1 == m_subp.call_count\n+        assert \"Failed to get status\" not in capsys.readouterr().err\n+\n+    def test_retry(self, mocker, capsys):\n+        m_subp = mocker.patch(\n+            f\"{M_PATH}subp.subp\",\n+            side_effect=[\n+                subp.ProcessExecutionError(\n+                    \"Message recipient disconnected from message bus without\"\n+                    \" replying\"\n+                ),\n+                subp.ProcessExecutionError(\n+                    \"Message recipient disconnected from message bus without\"\n+                    \" replying\"\n+                ),\n+                SubpResult(\n+                    \"ActiveState=activating\\nUnitFileState=enabled\\n\"\n+                    \"SubState=start\\nMainPID=123\\n\",\n+                    stderr=None,\n+                ),\n+            ],\n+        )\n+        assert (\n+            _get_error_or_running_from_systemd_with_retry(\n+                UXAppStatus.ERROR, wait=True\n+            )\n+            is UXAppStatus.RUNNING\n+        )\n+        assert 3 == m_subp.call_count\n+        assert \"Failed to get status\" not in capsys.readouterr().err\n+\n+    def test_retry_no_wait(self, mocker, capsys):\n+        m_subp = mocker.patch(\n+            f\"{M_PATH}subp.subp\",\n+            side_effect=subp.ProcessExecutionError(\n+                \"Message recipient disconnected from message bus without\"\n+                \" replying\"\n+            ),\n+        )\n+        mocker.patch(\"time.time\", side_effect=[1, 2, 50])\n+        assert (\n+            _get_error_or_running_from_systemd_with_retry(\n+                UXAppStatus.ERROR, wait=False\n+            )\n+            is None\n+        )\n+        assert 1 == m_subp.call_count\n+        assert (\n+            \"Failed to get status from systemd. \"\n+            \"Cloud-init status may be inaccurate.\"\n+        ) in capsys.readouterr().err\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/config/test_cc_apt_configure.py",
            "diff": "diff --git a/tests/unittests/config/test_cc_apt_configure.py b/tests/unittests/config/test_cc_apt_configure.py\nindex 18e66630..64b9d46c 100644\n--- a/tests/unittests/config/test_cc_apt_configure.py\n+++ b/tests/unittests/config/test_cc_apt_configure.py\n@@ -3,9 +3,12 @@\n \"\"\" Tests for cc_apt_configure module \"\"\"\n \n import re\n+from pathlib import Path\n+from unittest import mock\n \n import pytest\n \n+from cloudinit import features\n from cloudinit.config import cc_apt_configure\n from cloudinit.config.schema import (\n     SchemaValidationError,\n@@ -15,6 +18,8 @@ from cloudinit.config.schema import (\n from tests.unittests.helpers import skipUnlessJsonSchema\n from tests.unittests.util import get_cloud\n \n+M_PATH = \"cloudinit.config.cc_apt_configure.\"\n+\n \n class TestAPTConfigureSchema:\n     @pytest.mark.parametrize(\n@@ -266,3 +271,33 @@ class TestEnsureDependencies:\n             install_packages.assert_called_once_with(expected_install)\n         else:\n             install_packages.assert_not_called()\n+\n+\n+class TestAptConfigure:\n+    @mock.patch(M_PATH + \"get_apt_cfg\")\n+    def test_disable_source(self, m_get_apt_cfg, tmpdir):\n+        m_get_apt_cfg.return_value = {\n+            \"sourcelist\": f\"{tmpdir}/etc/apt/sources.list\",\n+            \"sourceparts\": f\"{tmpdir}/etc/apt/sources.list.d/\",\n+        }\n+        cloud = get_cloud(\"ubuntu\")\n+        features.APT_DEB822_SOURCE_LIST_FILE = True\n+        sources_file = tmpdir.join(\"/etc/apt/sources.list\")\n+        Path(sources_file).parent.mkdir(parents=True, exist_ok=True)\n+        with open(sources_file, \"w\") as f:\n+            f.write(\"content\")\n+\n+        cfg = {\n+            \"sources_list\": \"\"\"\\\n+Types: deb\n+URIs: {{mirror}}\n+Suites: {{codename}} {{codename}}-updates {{codename}}-backports\n+Components: main restricted universe multiverse\n+Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg\"\"\"\n+        }\n+        cc_apt_configure.generate_sources_list(cfg, \"noble\", {}, cloud)\n+        assert not Path(f\"{tmpdir}/etc/apt/sources.list\").exists()\n+        assert (\n+            Path(f\"{tmpdir}/etc/apt/sources.list.disabled\").read_text()\n+            == \"# disabled by cloud-init\\ncontent\"\n+        )\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/config/test_schema.py",
            "diff": "diff --git a/tests/unittests/config/test_schema.py b/tests/unittests/config/test_schema.py\nindex 28f0b39d..0ea45357 100644\n--- a/tests/unittests/config/test_schema.py\n+++ b/tests/unittests/config/test_schema.py\n@@ -23,6 +23,7 @@ from cloudinit.config.schema import (\n     VERSIONED_USERDATA_SCHEMA_FILE,\n     MetaSchema,\n     SchemaProblem,\n+    SchemaType,\n     SchemaValidationError,\n     annotated_cloudconfig_file,\n     get_jsonschema_validator,\n@@ -40,6 +41,7 @@ from cloudinit.distros import OSFAMILIES\n from cloudinit.safeyaml import load, load_with_marks\n from cloudinit.settings import FREQUENCIES\n from cloudinit.sources import DataSourceNotFoundException\n+from cloudinit.templater import JinjaSyntaxParsingException\n from cloudinit.util import load_file, write_file\n from tests.hypothesis import given\n from tests.hypothesis_jsonschema import from_schema\n@@ -245,7 +247,6 @@ class TestGetSchema:\n             {\"$ref\": \"#/$defs/cc_locale\"},\n             {\"$ref\": \"#/$defs/cc_lxd\"},\n             {\"$ref\": \"#/$defs/cc_mcollective\"},\n-            {\"$ref\": \"#/$defs/cc_migrator\"},\n             {\"$ref\": \"#/$defs/cc_mounts\"},\n             {\"$ref\": \"#/$defs/cc_ntp\"},\n             {\"$ref\": \"#/$defs/cc_package_update_upgrade_install\"},\n@@ -826,6 +827,41 @@ class TestValidateCloudConfigFile:\n             \" Nothing to validate\" in out\n         )\n \n+    @pytest.mark.parametrize(\"annotate\", (True, False))\n+    def test_validateconfig_file_raises_jinja_syntax_error(\n+        self, annotate, tmpdir, mocker, capsys\n+    ):\n+        \"\"\" \"\"\"\n+        # will throw error because of space between last two }'s\n+        invalid_jinja_template = \"## template: jinja\\na:b\\nc:{{ d } }\"\n+        mocker.patch(\"os.path.exists\", return_value=True)\n+        mocker.patch(\n+            \"cloudinit.util.load_file\",\n+            return_value=invalid_jinja_template,\n+        )\n+        mocker.patch(\n+            \"cloudinit.handlers.jinja_template.load_file\",\n+            return_value='{\"c\": \"d\"}',\n+        )\n+        config_file = tmpdir.join(\"my.yaml\")\n+        config_file.write(invalid_jinja_template)\n+        with pytest.raises(SystemExit) as context_manager:\n+            validate_cloudconfig_file(config_file.strpath, {}, annotate)\n+        assert 1 == context_manager.value.code\n+\n+        _out, err = capsys.readouterr()\n+        expected = (\n+            \"Error:\\n\"\n+            \"Failed to render templated user-data. \"\n+            + JinjaSyntaxParsingException.format_error_message(\n+                syntax_error=\"unexpected '}'\",\n+                line_number=3,\n+                line_content=\"c:{{ d } }\",\n+            )\n+            + \"\\n\"\n+        )\n+        assert expected == err\n+\n \n class TestSchemaDocMarkdown:\n     \"\"\"Tests for get_meta_doc.\"\"\"\n@@ -1761,6 +1797,110 @@ class TestMain:\n         out, _err = capsys.readouterr()\n         assert f\"Valid schema {myyaml}\\n\" == out\n \n+    @pytest.mark.parametrize(\n+        \"update_path_content_by_key, expected_keys\",\n+        (\n+            pytest.param(\n+                {},\n+                {\n+                    \"ud_key\": \"cloud_config\",\n+                    \"vd_key\": \"vendor_cloud_config\",\n+                    \"vd2_key\": \"vendor2_cloud_config\",\n+                    \"net_key\": \"network_config\",\n+                },\n+                id=\"prefer_processed_data_when_present_and_non_empty\",\n+            ),\n+            pytest.param(\n+                {\n+                    \"cloud_config\": \"\",\n+                    \"vendor_cloud_config\": \"\",\n+                    \"vendor2_cloud_config\": \"\",\n+                },\n+                {\n+                    \"ud_key\": \"userdata_raw\",\n+                    \"vd_key\": \"vendordata_raw\",\n+                    \"vd2_key\": \"vendordata2_raw\",\n+                    \"net_key\": \"network_config\",\n+                },\n+                id=\"prefer_raw_data_when_processed_is_empty\",\n+            ),\n+            pytest.param(\n+                {\"cloud_config\": \"\", \"userdata_raw\": \"\"},\n+                {\n+                    \"ud_key\": \"cloud_config\",\n+                    \"vd_key\": \"vendor_cloud_config\",\n+                    \"vd2_key\": \"vendor2_cloud_config\",\n+                    \"net_key\": \"network_config\",\n+                },\n+                id=\"prefer_processed_vd_file_path_when_raw_and_processed_empty\",\n+            ),\n+        ),\n+    )\n+    @mock.patch(M_PATH + \"read_cfg_paths\")\n+    @mock.patch(M_PATH + \"os.getuid\", return_value=0)\n+    def test_main_processed_data_preference_over_raw_data(\n+        self,\n+        _read_cfg_paths,\n+        _getuid,\n+        read_cfg_paths,\n+        update_path_content_by_key,\n+        expected_keys,\n+        paths,\n+        capsys,\n+    ):\n+        \"\"\"\"\"\"\n+        paths.get_ipath = paths.get_ipath_cur\n+        read_cfg_paths.return_value = paths\n+        path_content_by_key = {\n+            \"cloud_config\": \"#cloud-config\\n{}\",\n+            \"vendor_cloud_config\": \"#cloud-config\\n{}\",\n+            \"vendor2_cloud_config\": \"#cloud-config\\n{}\",\n+            \"vendordata_raw\": \"#cloud-config\\n{}\",\n+            \"vendordata2_raw\": \"#cloud-config\\n{}\",\n+            \"network_config\": \"{version: 1, config: []}\",\n+            \"userdata_raw\": \"#cloud-config\\n{}\",\n+        }\n+        expected_paths = dict(\n+            (key, paths.get_ipath_cur(expected_keys[key]))\n+            for key in expected_keys\n+        )\n+        path_content_by_key.update(update_path_content_by_key)\n+        for path_key, path_content in path_content_by_key.items():\n+            write_file(paths.get_ipath_cur(path_key), path_content)\n+        data_types = \"user-data, vendor-data, vendor2-data, network-config\"\n+        ud_msg = \"  Valid schema user-data\"\n+        if (\n+            not path_content_by_key[\"cloud_config\"]\n+            and not path_content_by_key[\"userdata_raw\"]\n+        ):\n+            ud_msg = (\n+                f\"Empty 'cloud-config' found at {expected_paths['ud_key']}.\"\n+                \" Nothing to validate.\"\n+            )\n+\n+        expected = dedent(\n+            f\"\"\"\\\n+        Found cloud-config data types: {data_types}\n+\n+        1. user-data at {expected_paths[\"ud_key\"]}:\n+        {ud_msg}\n+\n+        2. vendor-data at {expected_paths['vd_key']}:\n+          Valid schema vendor-data\n+\n+        3. vendor2-data at {expected_paths['vd2_key']}:\n+          Valid schema vendor2-data\n+\n+        4. network-config at {expected_paths['net_key']}:\n+          Valid schema network-config\n+        \"\"\"\n+        )\n+        myargs = [\"mycmd\", \"--system\"]\n+        with mock.patch(\"sys.argv\", myargs):\n+            main()\n+        out, _err = capsys.readouterr()\n+        assert expected == out\n+\n     @pytest.mark.parametrize(\n         \"net_config,net_output,error_raised\",\n         (\n@@ -1880,7 +2020,7 @@ def _get_meta_doc_examples(file_glob=\"cloud-config*.txt\"):\n \n class TestSchemaDocExamples:\n     schema = get_schema()\n-    net_schema = get_schema(schema_type=\"network-config\")\n+    net_schema = get_schema(schema_type=SchemaType.NETWORK_CONFIG)\n \n     @pytest.mark.parametrize(\"example_path\", _get_meta_doc_examples())\n     @skipUnlessJsonSchema()\n@@ -1953,7 +2093,7 @@ VALID_BOND_CONFIG = {\n \n @skipUnlessJsonSchema()\n class TestNetworkSchema:\n-    net_schema = get_schema(schema_type=\"network-config\")\n+    net_schema = get_schema(schema_type=SchemaType.NETWORK_CONFIG)\n \n     @pytest.mark.parametrize(\n         \"src_config, expectation\",\n@@ -2323,9 +2463,9 @@ apt_reboot_if_required: Default: ``false``. Deprecated in version 22.2.\\\n \n                     \"\"\"  # noqa: E501\n                 ),\n-                \"\",\n-                does_not_raise(),\n-                id=\"root_annotate_unique_errors_no_exception\",\n+                \"\"\"Error: Invalid schema: user-data\\n\\n\"\"\",\n+                pytest.raises(SystemExit),\n+                id=\"root_annotate_errors_with_exception\",\n             ),\n             pytest.param(\n                 0,\n@@ -2414,7 +2554,7 @@ apt_reboot_if_required: Default: ``false``. Deprecated in version 22.2.\\\n                 False,\n                 dedent(\n                     \"\"\"\\\n-                    Invalid UNKNOWN_CONFIG_HEADER {cfg_file}\n+                    Invalid user-data {cfg_file}\n                     \"\"\"  # noqa: E501\n                 ),\n                 dedent(\n@@ -2422,7 +2562,7 @@ apt_reboot_if_required: Default: ``false``. Deprecated in version 22.2.\\\n                     Error: Cloud config schema errors: format-l1.c1: Unrecognized user-data header in {cfg_file}: \"#bogus-config\".\n                     Expected first line to be one of: #!, ## template: jinja, #cloud-boothook, #cloud-config, #cloud-config-archive, #cloud-config-jsonp, #include, #include-once, #part-handler\n \n-                    Error: Invalid schema: UNKNOWN_CONFIG_HEADER\n+                    Error: Invalid schema: user-data\n \n                     \"\"\"  # noqa: E501\n                 ),\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/net/test_dhcp.py",
            "diff": "diff --git a/tests/unittests/net/test_dhcp.py b/tests/unittests/net/test_dhcp.py\nindex 09393c13..6895c8e5 100644\n--- a/tests/unittests/net/test_dhcp.py\n+++ b/tests/unittests/net/test_dhcp.py\n@@ -33,6 +33,46 @@ LEASE_F = \"/run/dhclient.lease\"\n DHCLIENT = \"/sbin/dhclient\"\n \n \n+@pytest.mark.parametrize(\n+    \"server_address,lease_file_content\",\n+    (\n+        pytest.param(None, None, id=\"no_server_addr_on_absent_lease_file\"),\n+        pytest.param(None, \"\", id=\"no_server_addr_on_empty_lease_file\"),\n+        pytest.param(\n+            None,\n+            \"lease {\\n  fixed-address: 10.1.2.3;\\n}\\n\",\n+            id=\"no_server_addr_when_no_server_ident\",\n+        ),\n+        pytest.param(\n+            \"10.4.5.6\",\n+            \"lease {\\n fixed-address: 10.1.2.3;\\n\"\n+            \"  option dhcp-server-identifier 10.4.5.6;\\n\"\n+            \"  option dhcp-renewal-time 1800;\\n}\\n\",\n+            id=\"server_addr_found_when_server_ident_present\",\n+        ),\n+    ),\n+)\n+class TestParseDHCPServerFromLeaseFile:\n+    def test_find_server_address_when_present(\n+        self, server_address, lease_file_content, tmp_path\n+    ):\n+        \"\"\"Test that we return None in the case of no file or file contains no\n+        server address, otherwise return the address.\n+        \"\"\"\n+        lease_file = tmp_path / \"dhcp.leases\"\n+        if server_address:\n+            if lease_file_content:\n+                lease_file.write_text(lease_file_content)\n+            assert (\n+                server_address\n+                == IscDhclient.parse_dhcp_server_from_lease_file(lease_file)\n+            )\n+        else:\n+            assert not IscDhclient.parse_dhcp_server_from_lease_file(\n+                lease_file\n+            )\n+\n+\n class TestParseDHCPLeasesFile(CiTestCase):\n     def test_parse_empty_lease_file_errors(self):\n         \"\"\"parse_dhcp_lease_file errors when file content is empty.\"\"\"\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/sources/azure/test_errors.py",
            "diff": "diff --git a/tests/unittests/sources/azure/test_errors.py b/tests/unittests/sources/azure/test_errors.py\nindex f310be72..03e53ca8 100644\n--- a/tests/unittests/sources/azure/test_errors.py\n+++ b/tests/unittests/sources/azure/test_errors.py\n@@ -121,7 +121,10 @@ def test_reportable_errors(\n     assert error.as_encoded_report() == \"|\".join(data)\n \n \n-def test_dhcp_lease():\n+def test_dhcp_lease(mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n     error = errors.ReportableErrorDhcpLease(duration=5.6, interface=\"foo\")\n \n     assert error.reason == \"failure to obtain DHCP lease\"\n@@ -129,7 +132,10 @@ def test_dhcp_lease():\n     assert error.supporting_data[\"interface\"] == \"foo\"\n \n \n-def test_dhcp_interface_not_found():\n+def test_dhcp_interface_not_found(mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n     error = errors.ReportableErrorDhcpInterfaceNotFound(duration=5.6)\n \n     assert error.reason == \"failure to find DHCP interface\"\n@@ -180,7 +186,10 @@ def test_dhcp_interface_not_found():\n         ),\n     ],\n )\n-def test_imds_url_error(exception, reason):\n+def test_imds_url_error(exception, reason, mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n     duration = 123.4\n     fake_url = \"fake://url\"\n \n@@ -195,7 +204,11 @@ def test_imds_url_error(exception, reason):\n     assert error.supporting_data[\"url\"] == fake_url\n \n \n-def test_imds_metadata_parsing_exception():\n+def test_imds_metadata_parsing_exception(mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n+\n     exception = ValueError(\"foobar\")\n \n     error = errors.ReportableErrorImdsMetadataParsingException(\n@@ -206,7 +219,11 @@ def test_imds_metadata_parsing_exception():\n     assert error.supporting_data[\"exception\"] == repr(exception)\n \n \n-def test_unhandled_exception():\n+def test_unhandled_exception(mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n+\n     source_error = None\n     try:\n         raise ValueError(\"my value error\")\n@@ -227,7 +244,11 @@ def test_unhandled_exception():\n     assert f\"|{quoted_value}|\" in error.as_encoded_report()\n \n \n-def test_imds_invalid_metadata():\n+def test_imds_invalid_metadata(mocker):\n+    mocker.patch(\n+        \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+    )\n+\n     key = \"compute\"\n     value = \"Running\"\n     error = errors.ReportableErrorImdsInvalidMetadata(key=key, value=value)\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/sources/azure/test_imds.py",
            "diff": "diff --git a/tests/unittests/sources/azure/test_imds.py b/tests/unittests/sources/azure/test_imds.py\nindex 1fe44b48..45185449 100644\n--- a/tests/unittests/sources/azure/test_imds.py\n+++ b/tests/unittests/sources/azure/test_imds.py\n@@ -236,7 +236,7 @@ class TestFetchMetadataWithApiFallback:\n             ),\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\"Polling IMDS failed attempt 1 with.*400.*\"),\n             ),\n             (\n@@ -314,7 +314,7 @@ class TestFetchMetadataWithApiFallback:\n             ),\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\n                     \"Polling IMDS failed attempt 1 with exception: \"\n                     f\"{error_regex}\"\n@@ -377,7 +377,7 @@ class TestFetchMetadataWithApiFallback:\n             ),\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\n                     \"Polling IMDS failed attempt 1 with exception:.*400.*\"\n                 ),\n@@ -401,7 +401,7 @@ class TestFetchMetadataWithApiFallback:\n             ),\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\n                     \"Polling IMDS failed attempt 1 with exception:.*429.*\"\n                 ),\n@@ -479,7 +479,7 @@ class TestFetchMetadataWithApiFallback:\n         assert logs == [\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\n                     f\"Polling IMDS failed attempt {i} with exception:\"\n                     f\"{error_regex}\"\n@@ -535,7 +535,7 @@ class TestFetchMetadataWithApiFallback:\n             ),\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 StringMatch(\n                     \"Polling IMDS failed attempt 1 with exception:\"\n                     f\".*{error_regex}\"\n@@ -722,7 +722,7 @@ class TestFetchReprovisionData:\n         backoff_logs = [\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 f\"Polling IMDS failed attempt {i} with exception: \"\n                 f\"{wrapped_error!r}\",\n             )\n@@ -789,7 +789,7 @@ class TestFetchReprovisionData:\n         backoff_logs = [\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 f\"Polling IMDS failed attempt {i} with exception: \"\n                 f\"{wrapped_error!r}\",\n             )\n@@ -799,7 +799,7 @@ class TestFetchReprovisionData:\n         assert caplog.record_tuples == backoff_logs + [\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 f\"Polling IMDS failed attempt {failures+1} with exception: \"\n                 f\"{exc_info.value!r}\",\n             ),\n@@ -835,7 +835,7 @@ class TestFetchReprovisionData:\n         assert caplog.record_tuples == [\n             (\n                 LOG_PATH,\n-                logging.INFO,\n+                logging.WARNING,\n                 \"Polling IMDS failed attempt 1 with exception: \"\n                 f\"{exc_info.value!r}\",\n             ),\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/sources/azure/test_kvp.py",
            "diff": "diff --git a/tests/unittests/sources/azure/test_kvp.py b/tests/unittests/sources/azure/test_kvp.py\nindex f0f4a999..ad6cd83d 100644\n--- a/tests/unittests/sources/azure/test_kvp.py\n+++ b/tests/unittests/sources/azure/test_kvp.py\n@@ -39,7 +39,10 @@ def telemetry_reporter(tmp_path):\n \n \n class TestReportFailureToHost:\n-    def test_report_failure_to_host(self, caplog, telemetry_reporter):\n+    def test_report_failure_to_host(self, caplog, telemetry_reporter, mocker):\n+        mocker.patch(\n+            \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+        )\n         error = errors.ReportableError(reason=\"test\")\n         assert kvp.report_failure_to_host(error) is True\n         assert (\n@@ -52,7 +55,10 @@ class TestReportFailureToHost:\n         }\n         assert report in list(telemetry_reporter._iterate_kvps(0))\n \n-    def test_report_skipped_without_telemetry(self, caplog):\n+    def test_report_skipped_without_telemetry(self, caplog, mocker):\n+        mocker.patch(\n+            \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+        )\n         error = errors.ReportableError(reason=\"test\")\n \n         assert kvp.report_failure_to_host(error) is False\n@@ -83,6 +89,9 @@ class TestReportSuccessToHost:\n         }\n         assert report in list(telemetry_reporter._iterate_kvps(0))\n \n-    def test_report_skipped_without_telemetry(self, caplog):\n+    def test_report_skipped_without_telemetry(self, caplog, mocker):\n+        mocker.patch(\n+            \"cloudinit.sources.azure.identity.query_vm_id\", return_value=\"foo\"\n+        )\n         assert kvp.report_success_to_host() is False\n         assert \"KVP handler not enabled, skipping host report.\" in caplog.text\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_cli.py",
            "diff": "diff --git a/tests/unittests/test_cli.py b/tests/unittests/test_cli.py\nindex 1713d986..099fb5c9 100644\n--- a/tests/unittests/test_cli.py\n+++ b/tests/unittests/test_cli.py\n@@ -2,6 +2,7 @@\n \n import contextlib\n import io\n+import logging\n import os\n from collections import namedtuple\n \n@@ -172,6 +173,45 @@ class TestCLI:\n         for subcommand in expected_subcommands:\n             assert subcommand in err\n \n+    @pytest.mark.parametrize(\n+        \"subcommand,log_to_stderr,mocks\",\n+        (\n+            (\"init\", False, [mock.patch(\"cloudinit.cmd.main.status_wrapper\")]),\n+            (\n+                \"modules\",\n+                False,\n+                [mock.patch(\"cloudinit.cmd.main.status_wrapper\")],\n+            ),\n+            (\n+                \"schema\",\n+                True,\n+                [\n+                    mock.patch(\n+                        \"cloudinit.stages.Init._read_cfg\", return_value={}\n+                    ),\n+                    mock.patch(\"cloudinit.config.schema.handle_schema_args\"),\n+                ],\n+            ),\n+        ),\n+    )\n+    @mock.patch(\"cloudinit.cmd.main.setup_basic_logging\")\n+    def test_subcommands_log_to_stderr_via_setup_basic_logging(\n+        self, setup_basic_logging, subcommand, log_to_stderr, mocks\n+    ):\n+        \"\"\"setup_basic_logging is called for modules to use stderr\n+\n+        Subcommands with exception of 'init'  and 'modules' use\n+        setup_basic_logging to direct logged errors to stderr.\n+        \"\"\"\n+        with contextlib.ExitStack() as mockstack:\n+            for mymock in mocks:\n+                mockstack.enter_context(mymock)\n+            self._call_main([\"cloud-init\", subcommand])\n+        if log_to_stderr:\n+            setup_basic_logging.assert_called_once_with(logging.WARNING)\n+        else:\n+            setup_basic_logging.assert_not_called()\n+\n     @pytest.mark.parametrize(\"subcommand\", [\"init\", \"modules\"])\n     @mock.patch(\"cloudinit.cmd.main.status_wrapper\")\n     def test_modules_subcommand_parser(self, m_status_wrapper, subcommand):\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_conftest.py",
            "diff": "diff --git a/tests/unittests/test_conftest.py b/tests/unittests/test_conftest.py\nindex 68903430..e9f7a432 100644\n--- a/tests/unittests/test_conftest.py\n+++ b/tests/unittests/test_conftest.py\n@@ -1,6 +1,7 @@\n import pytest\n \n from cloudinit import subp\n+from conftest import UnexpectedSubpError\n from tests.unittests.helpers import CiTestCase\n \n \n@@ -8,7 +9,7 @@ class TestDisableSubpUsage:\n     \"\"\"Test that the disable_subp_usage fixture behaves as expected.\"\"\"\n \n     def test_using_subp_raises_assertion_error(self):\n-        with pytest.raises(AssertionError):\n+        with pytest.raises(UnexpectedSubpError):\n             subp.subp([\"some\", \"args\"])\n \n     def test_typeerrors_on_incorrect_usage(self):\n@@ -17,6 +18,13 @@ class TestDisableSubpUsage:\n             #  pylint: disable=no-value-for-parameter\n             subp.subp()\n \n+    def test_subp_exception_escapes_exception_handling(self):\n+        with pytest.raises(UnexpectedSubpError):\n+            try:\n+                subp.subp([\"some\", \"args\"])\n+            except Exception:\n+                pytest.fail(\"Unexpected exception raised\")\n+\n     @pytest.mark.allow_all_subp\n     def test_subp_usage_can_be_reenabled(self):\n         subp.subp([\"whoami\"])\n@@ -25,14 +33,14 @@ class TestDisableSubpUsage:\n     def test_subp_usage_can_be_conditionally_reenabled(self):\n         # The two parameters test each potential invocation with a single\n         # argument\n-        with pytest.raises(AssertionError) as excinfo:\n+        with pytest.raises(UnexpectedSubpError) as excinfo:\n             subp.subp([\"some\", \"args\"])\n         assert \"allowed: whoami\" in str(excinfo.value)\n         subp.subp([\"whoami\"])\n \n     @pytest.mark.allow_subp_for(\"whoami\", \"bash\")\n     def test_subp_usage_can_be_conditionally_reenabled_for_multiple_cmds(self):\n-        with pytest.raises(AssertionError) as excinfo:\n+        with pytest.raises(UnexpectedSubpError) as excinfo:\n             subp.subp([\"some\", \"args\"])\n         assert \"allowed: whoami,bash\" in str(excinfo.value)\n         subp.subp([\"bash\", \"-c\", \"true\"])\n@@ -41,7 +49,7 @@ class TestDisableSubpUsage:\n     @pytest.mark.allow_all_subp\n     @pytest.mark.allow_subp_for(\"bash\")\n     def test_both_marks_raise_an_error(self):\n-        with pytest.raises(AssertionError, match=\"marked both\"):\n+        with pytest.raises(UnexpectedSubpError, match=\"marked both\"):\n             subp.subp([\"bash\"])\n \n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_ds_identify.py",
            "diff": "diff --git a/tests/unittests/test_ds_identify.py b/tests/unittests/test_ds_identify.py\nindex a871943c..749705bd 100644\n--- a/tests/unittests/test_ds_identify.py\n+++ b/tests/unittests/test_ds_identify.py\n@@ -18,16 +18,14 @@ from tests.unittests.helpers import (\n     populate_dir_with_ts,\n )\n \n-UNAME_MYSYS = (\n-    \"Linux 4.4.0-62-generic #83-Ubuntu SMP Wed Jan 18 14:10:15 UTC 2017 x86_64\"\n-)\n+UNAME_MYSYS = \"Linux #83-Ubuntu SMP Wed Jan 18 14:10:15 UTC 2017 x86_64\"\n UNAME_PPC64EL = (\n-    \"Linux 4.4.0-83-generic #106-Ubuntu SMP \"\n-    \"Mon Jun 26 17:53:54 UTC 2017 \"\n+    \"Linux #106-Ubuntu SMP mon Jun 26 17:53:54 UTC 2017 \"\n     \"ppc64le ppc64le ppc64le\"\n )\n UNAME_FREEBSD = (\n-    \"FreeBSD 12.1-RELEASE-p10 FreeBSD 12.1-RELEASE-p10 GENERIC  amd64\"\n+    \"FreeBSD FreeBSD 14.0-RELEASE-p3 releng/14.0-n265398-20fae1e1699\"\n+    \"GENERIC-MMCCAM amd64\"\n )\n UNAME_OPENBSD = \"OpenBSD GENERIC.MP#1397 amd64\"\n \n@@ -84,7 +82,6 @@ preserve_hostname: false\n \n # The modules that run in the 'init' stage\n cloud_init_modules:\n- - migrator\n  - seed_random\n  - bootcmd\n  - write-files\n@@ -341,7 +338,17 @@ class DsIdentifyBase(CiTestCase):\n             },\n         ]\n \n-        written = [d[\"name\"] for d in mocks]\n+        uname = \"Linux\"\n+        runpath = \"run\"\n+        written = []\n+        for d in mocks:\n+            written.append(d[\"name\"])\n+            if d[\"name\"] == \"uname\":\n+                uname = d[\"out\"].split(\" \")[0]\n+        # set runpath so that BSDs use /var/run rather than /run\n+        if uname != \"Linux\":\n+            runpath = \"var/run\"\n+\n         for data in mocks:\n             mocklines.append(write_mock(data))\n         for d in default_mocks:\n@@ -364,7 +371,7 @@ class DsIdentifyBase(CiTestCase):\n             err = e.stderr\n \n         cfg = None\n-        cfg_out = os.path.join(rootd, \"run/cloud-init/cloud.cfg\")\n+        cfg_out = os.path.join(rootd, runpath, \"cloud-init/cloud.cfg\")\n         if os.path.exists(cfg_out):\n             contents = util.load_file(cfg_out)\n             try:\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_net.py",
            "diff": "diff --git a/tests/unittests/test_net.py b/tests/unittests/test_net.py\nindex 9f85e333..742982dc 100644\n--- a/tests/unittests/test_net.py\n+++ b/tests/unittests/test_net.py\n@@ -2962,9 +2962,9 @@ pre-down route del -net 10.0.0.0/8 gw 11.0.0.1 metric 3 || true\n                 may-fail=false\n                 address1=192.168.0.2/24\n                 gateway=192.168.0.1\n+                address2=192.168.2.10/24\n                 dns=192.168.0.10;10.23.23.134;\n                 dns-search=barley.maas;sacchromyces.maas;brettanomyces.maas;\n-                address2=192.168.2.10/24\n \n                 \"\"\"\n             ),\n@@ -4154,6 +4154,148 @@ iface bond0 inet6 static\n             \"\"\"\n         ),\n     },\n+    \"v2-mixed-routes\": {\n+        \"expected_network_manager\": {\n+            \"cloud-init-eth0.nmconnection\": textwrap.dedent(\n+                \"\"\"\\\n+                # Generated by cloud-init. Changes will be lost.\n+\n+                [connection]\n+                id=cloud-init eth0\n+                uuid=1dd9a779-d327-56e1-8454-c65e2556c12c\n+                autoconnect-priority=120\n+                type=ethernet\n+                interface-name=eth0\n+\n+                [user]\n+                org.freedesktop.NetworkManager.origin=cloud-init\n+\n+                [ethernet]\n+\n+                [ipv4]\n+                method=auto\n+                may-fail=true\n+                route1=169.254.42.42/32,62.210.0.1\n+                route2=169.254.42.43/32,62.210.0.2\n+                address1=192.168.1.20/16\n+                dns=8.8.8.8;\n+                dns-search=lab;home;\n+\n+                [ipv6]\n+                route1=::/0,fe80::dc00:ff:fe20:186\n+                route2=fe80::dc00:ff:fe20:188/64,fe80::dc00:ff:fe20:187\n+                method=auto\n+                may-fail=true\n+                address1=2001:bc8:1210:232:dc00:ff:fe20:185/64\n+                dns=FEDC::1;\n+                dns-search=lab;home;\n+\n+            \"\"\"\n+            )\n+        },\n+        \"yaml\": textwrap.dedent(\n+            \"\"\"\\\n+            version: 2\n+            ethernets:\n+              eth0:\n+                dhcp4: true\n+                dhcp6: true\n+                nameservers:\n+                  search: [lab, home]\n+                  addresses: [8.8.8.8, \"FEDC::1\"]\n+                routes:\n+                  - to: 169.254.42.42/32\n+                    via: 62.210.0.1\n+                  - via: fe80::dc00:ff:fe20:186\n+                    to: ::/0\n+                  - to: 169.254.42.43/32\n+                    via: 62.210.0.2\n+                  - via: fe80::dc00:ff:fe20:187\n+                    to: fe80::dc00:ff:fe20:188\n+                addresses:\n+                  - 192.168.1.20/16\n+                  - 2001:bc8:1210:232:dc00:ff:fe20:185/64\n+        \"\"\"\n+        ),\n+    },\n+    \"v2-dns-no-if-ips\": {\n+        \"expected_network_manager\": {\n+            \"cloud-init-eth0.nmconnection\": textwrap.dedent(\n+                \"\"\"\\\n+                # Generated by cloud-init. Changes will be lost.\n+\n+                [connection]\n+                id=cloud-init eth0\n+                uuid=1dd9a779-d327-56e1-8454-c65e2556c12c\n+                autoconnect-priority=120\n+                type=ethernet\n+                interface-name=eth0\n+\n+                [user]\n+                org.freedesktop.NetworkManager.origin=cloud-init\n+\n+                [ethernet]\n+\n+                [ipv4]\n+                method=auto\n+                may-fail=true\n+                dns=8.8.8.8;\n+                dns-search=lab;home;\n+\n+                [ipv6]\n+                method=auto\n+                may-fail=true\n+                dns=FEDC::1;\n+                dns-search=lab;home;\n+\n+            \"\"\"\n+            )\n+        },\n+        \"yaml\": textwrap.dedent(\n+            \"\"\"\\\n+            version: 2\n+            ethernets:\n+              eth0:\n+                dhcp4: true\n+                dhcp6: true\n+                nameservers:\n+                  search: [lab, home]\n+                  addresses: [8.8.8.8, \"FEDC::1\"]\n+        \"\"\"\n+        ),\n+    },\n+    \"v2-dns-no-dhcp\": {\n+        \"expected_network_manager\": {\n+            \"cloud-init-eth0.nmconnection\": textwrap.dedent(\n+                \"\"\"\\\n+                # Generated by cloud-init. Changes will be lost.\n+\n+                [connection]\n+                id=cloud-init eth0\n+                uuid=1dd9a779-d327-56e1-8454-c65e2556c12c\n+                autoconnect-priority=120\n+                type=ethernet\n+                interface-name=eth0\n+\n+                [user]\n+                org.freedesktop.NetworkManager.origin=cloud-init\n+\n+                [ethernet]\n+\n+            \"\"\"\n+            )\n+        },\n+        \"yaml\": textwrap.dedent(\n+            \"\"\"\\\n+            version: 2\n+            ethernets:\n+              eth0:\n+                nameservers:\n+                  search: [lab, home]\n+                  addresses: [8.8.8.8, \"FEDC::1\"]\n+        \"\"\"\n+        ),\n+    },\n }\n \n \n@@ -6267,6 +6409,27 @@ class TestNetworkManagerRendering(CiTestCase):\n             entry[self.expected_name], self.expected_conf_d, found\n         )\n \n+    def test_v2_mixed_routes(self):\n+        entry = NETWORK_CONFIGS[\"v2-mixed-routes\"]\n+        found = self._render_and_read(network_config=yaml.load(entry[\"yaml\"]))\n+        self._compare_files_to_expected(\n+            entry[self.expected_name], self.expected_conf_d, found\n+        )\n+\n+    def test_v2_dns_no_ips(self):\n+        entry = NETWORK_CONFIGS[\"v2-dns-no-if-ips\"]\n+        found = self._render_and_read(network_config=yaml.load(entry[\"yaml\"]))\n+        self._compare_files_to_expected(\n+            entry[self.expected_name], self.expected_conf_d, found\n+        )\n+\n+    def test_v2_dns_no_dhcp(self):\n+        entry = NETWORK_CONFIGS[\"v2-dns-no-dhcp\"]\n+        found = self._render_and_read(network_config=yaml.load(entry[\"yaml\"]))\n+        self._compare_files_to_expected(\n+            entry[self.expected_name], self.expected_conf_d, found\n+        )\n+\n \n @mock.patch(\n     \"cloudinit.net.is_openvswitch_internal_interface\",\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_templating.py",
            "diff": "diff --git a/tests/unittests/test_templating.py b/tests/unittests/test_templating.py\nindex 4113d1bc..36821c19 100644\n--- a/tests/unittests/test_templating.py\n+++ b/tests/unittests/test_templating.py\n@@ -6,7 +6,10 @@\n \n import textwrap\n \n+import pytest\n+\n from cloudinit import templater\n+from cloudinit.templater import JinjaSyntaxParsingException\n from cloudinit.util import load_file, write_file\n from tests.unittests import helpers as test_helpers\n \n@@ -167,3 +170,136 @@ class TestTemplates(test_helpers.CiTestCase):\n             ).strip(),\n             expected_result,\n         )\n+\n+\n+class TestJinjaSyntaxParsingException:\n+    def test_jinja_syntax_parsing_exception_message(self):\n+        \"\"\"\n+        Test that the message of the JinjaSyntaxParsingException is written and\n+        formatted as expected, and that the template is filled in correctly.\n+        \"\"\"\n+        jinja_template = (\n+            \"## template: jinja\\n\"\n+            \"#cloud-config\\n\"\n+            \"runcmd:\\n\"\n+            \"{% if 1 == 1 % }\\n\"\n+            '  - echo \"1 is equal to 1\"\\n'\n+            \"{% endif %}\\n\"\n+        )\n+        expected_error_msg = (\n+            \"Unable to parse Jinja template due to syntax error: \"\n+            \"unexpected '}' on line 4: {% if 1 == 1 % }\"\n+        )\n+        with pytest.raises(JinjaSyntaxParsingException) as excinfo:\n+            templater.render_string(jinja_template, {})\n+        assert str(excinfo.value) == expected_error_msg\n+\n+    @pytest.mark.parametrize(\n+        \"line_no,replace_tuple,syntax_error\",\n+        (\n+            (\n+                4,\n+                (\"%}\", \"% }\"),\n+                \"unexpected '}'\",\n+            ),\n+            (\n+                6,\n+                (\"%}\", \"% }\"),\n+                \"expected token 'end of statement block', got '%'\",\n+            ),\n+            (\n+                8,\n+                (\"%}\", \"% }\"),\n+                \"expected token 'end of statement block', got '%'\",\n+            ),\n+            (\n+                4,\n+                (\"%}\", \"}}\"),\n+                \"unexpected '}'\",\n+            ),\n+            (\n+                6,\n+                (\"%}\", \"}}\"),\n+                \"unexpected '}'\",\n+            ),\n+            (\n+                8,\n+                (\"%}\", \"}}\"),\n+                \"unexpected '}'\",\n+            ),\n+            (\n+                4,\n+                (\"==\", \"=\"),\n+                \"expected token 'end of statement block', got '='\",\n+            ),\n+            (\n+                7,\n+                (\"}}\", \"} }\"),\n+                \"unexpected '}'\",\n+            ),\n+        ),\n+    )\n+    def test_functionality_for_various_syntax_errors(\n+        self, line_no, replace_tuple, syntax_error\n+    ):\n+        \"\"\"\n+        Test a variety of jinja syntax errors and make sure the exceptions\n+        are raised with the correct syntax error, line number, and line content\n+        as expected.\n+        \"\"\"\n+        jinja_template = (\n+            \"## template: jinja\\n\"\n+            \"#cloud-config\\n\"\n+            \"runcmd:\\n\"\n+            '{% if v1.cloud_name == \"unknown\" %}\\n'\n+            '  - echo \"Cloud name is unknown\"\\n'\n+            \"{% else %}\\n\"\n+            '  - echo \"Cloud name is known: {{ v1.cloud_name }}\"\\n'\n+            \"{% endif %}\\n\"\n+        )\n+        # replace \"%}\" in line_no with \"% }\"\n+        jinja_template = jinja_template.replace(\n+            jinja_template.split(\"\\n\")[line_no - 1],\n+            jinja_template.split(\"\\n\")[line_no - 1].replace(*replace_tuple),\n+        )\n+\n+        with pytest.raises(JinjaSyntaxParsingException) as excinfo:\n+            templater.render_string(jinja_template, {})\n+        error: JinjaSyntaxParsingException = excinfo.value\n+        assert error.lineno == line_no\n+        assert error.message == syntax_error\n+        assert (\n+            error.source.splitlines()[line_no - 2]  # -2 because of header\n+            == jinja_template.splitlines()[line_no - 1]\n+        )\n+\n+    def test_format_error_message_with_content_line(self):\n+        expected_error_msg = (\n+            \"Unable to parse Jinja template due to syntax error: \"\n+            \"unexpected '}' on line 4: {% if 1 == 1 % }\"\n+        )\n+        error_msg = JinjaSyntaxParsingException.format_error_message(\n+            syntax_error=\"unexpected '}'\",\n+            line_number=4,\n+            line_content=\"{% if 1 == 1 % }\",\n+        )\n+        assert error_msg == expected_error_msg\n+\n+    @pytest.mark.parametrize(\n+        \"line_content\",\n+        (\n+            \"\",\n+            None,\n+        ),\n+    )\n+    def test_format_error_message_without_content_line(self, line_content):\n+        expected_error_msg = (\n+            \"Unable to parse Jinja template due to syntax error: \"\n+            \"unexpected '}' on line 4\"\n+        )\n+        error_msg = JinjaSyntaxParsingException.format_error_message(\n+            syntax_error=\"unexpected '}'\",\n+            line_number=4,\n+            line_content=line_content,\n+        )\n+        assert error_msg == expected_error_msg\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tests/unittests/test_util.py",
            "diff": "diff --git a/tests/unittests/test_util.py b/tests/unittests/test_util.py\nindex 519ef63c..7186780b 100644\n--- a/tests/unittests/test_util.py\n+++ b/tests/unittests/test_util.py\n@@ -466,7 +466,7 @@ class TestUtil:\n         ) in caplog.text\n \n     @skipUnlessJinja()\n-    def test_read_conf_with_failed_template(self, mocker, caplog):\n+    def test_read_conf_with_failed_config_json(self, mocker, caplog):\n         mocker.patch(\"os.path.exists\", return_value=True)\n         mocker.patch(\n             \"cloudinit.util.load_file\",\n@@ -481,7 +481,7 @@ class TestUtil:\n         assert conf == {}\n \n     @skipUnlessJinja()\n-    def test_read_conf_with_failed_vars(self, mocker, caplog):\n+    def test_read_conf_with_failed_instance_data_json(self, mocker, caplog):\n         mocker.patch(\"os.path.exists\", return_value=True)\n         mocker.patch(\n             \"cloudinit.util.load_file\",\n@@ -495,6 +495,34 @@ class TestUtil:\n         assert \"Could not apply Jinja template\" in caplog.text\n         assert conf == {\"a\": \"{{c}}\"}\n \n+    @pytest.mark.parametrize(\n+        \"template\",\n+        [\n+            '{\"a\": \"{{c} } }\"',\n+            '{\"a\": \"{{c} } \"',\n+            \"{% if c %} C is present {% else % } C is NOT present {% endif %}\",\n+        ],\n+    )\n+    @skipUnlessJinja()\n+    def test_read_conf_with_config_invalid_jinja_syntax(\n+        self, mocker, caplog, template\n+    ):\n+        mocker.patch(\"os.path.exists\", return_value=True)\n+        mocker.patch(\n+            \"cloudinit.util.load_file\",\n+            return_value=\"## template: jinja\\n\" + template,\n+        )\n+        mocker.patch(\n+            \"cloudinit.handlers.jinja_template.load_file\",\n+            return_value='{\"c\": \"d\"}',\n+        )\n+        conf = util.read_conf(\"cfg_path\", instance_data_file=\"vars_path\")\n+        assert (\n+            \"Failed to render templated yaml config file 'cfg_path'\"\n+            in caplog.text\n+        )\n+        assert conf == {}\n+\n     @mock.patch(\n         M_PATH + \"read_conf\",\n         side_effect=(OSError(errno.EACCES, \"Not allowed\"), {\"0\": \"0\"}),\n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tools/build-on-openbsd",
            "diff": "diff --git a/tools/build-on-openbsd b/tools/build-on-openbsd\nindex 611353da..bc551c0d 100755\n--- a/tools/build-on-openbsd\n+++ b/tools/build-on-openbsd\n@@ -44,7 +44,7 @@ else\n     RC_LOCAL=\"/etc/rc.local\"\n     RC_LOCAL_CONTENT=\"\n \n-/usr/lib/cloud-init/ds-identify\n+/usr/local/lib/cloud-init/ds-identify\n \n cloud-init init --local\n \n"
        },
        {
            "commit": "ecb486addc70aecc9b28f2b30a77eaf2fd587091",
            "file_path": "tools/ds-identify",
            "diff": "diff --git a/tools/ds-identify b/tools/ds-identify\nindex 7a051935..085ea3e1 100755\n--- a/tools/ds-identify\n+++ b/tools/ds-identify\n@@ -68,7 +68,6 @@ DI_DISABLED=\"disabled\"\n DI_DEBUG_LEVEL=\"${DEBUG_LEVEL:-1}\"\n \n PATH_ROOT=${PATH_ROOT:-\"\"}\n-PATH_RUN=${PATH_RUN:-\"${PATH_ROOT}/run\"}\n PATH_SYS_CLASS_DMI_ID=${PATH_SYS_CLASS_DMI_ID:-${PATH_ROOT}/sys/class/dmi/id}\n PATH_SYS_HYPERVISOR=${PATH_SYS_HYPERVISOR:-${PATH_ROOT}/sys/hypervisor}\n PATH_SYS_CLASS_BLOCK=${PATH_SYS_CLASS_BLOCK:-${PATH_ROOT}/sys/class/block}\n@@ -82,11 +81,17 @@ PATH_PROC_UPTIME=${PATH_PROC_UPTIME:-${PATH_ROOT}/proc/uptime}\n PATH_ETC_CLOUD=\"${PATH_ETC_CLOUD:-${PATH_ROOT}/etc/cloud}\"\n PATH_ETC_CI_CFG=\"${PATH_ETC_CI_CFG:-${PATH_ETC_CLOUD}/cloud.cfg}\"\n PATH_ETC_CI_CFG_D=\"${PATH_ETC_CI_CFG_D:-${PATH_ETC_CI_CFG}.d}\"\n-PATH_RUN_CI=\"${PATH_RUN_CI:-${PATH_RUN}/cloud-init}\"\n-PATH_RUN_CI_CFG=${PATH_RUN_CI_CFG:-${PATH_RUN_CI}/cloud.cfg}\n-PATH_RUN_DI_RESULT=${PATH_RUN_DI_RESULT:-${PATH_RUN_CI}/.ds-identify.result}\n \n-DI_LOG=\"${DI_LOG:-${PATH_RUN_CI}/ds-identify.log}\"\n+# Declare global here, so they can be overwritten from the outside.\n+# if not overwritten from the outside, we'll populate them with system default\n+# paths, once we have determined the system we're running on.\n+# This is done in set_run_path(), which must run after read_uname_info().\n+PATH_RUN=\"${PATH_RUN:-}\"\n+PATH_RUN_CI=\"${PATH_RUN_CI:-}\"\n+PATH_RUN_CI_CFG=\"${PATH_RUN_CI_CFG:-}\"\n+PATH_RUN_DI_RESULT=\"${PATH_RUN_DI_RESULT:-}\"\n+\n+DI_LOG=\"${DI_LOG:-}\"\n _DI_LOGGED=\"\"\n \n # set DI_MAIN='noop' in environment to source this file with no main called.\n@@ -154,6 +159,8 @@ debug() {\n     shift\n     [ \"$lvl\" -gt \"${DI_DEBUG_LEVEL}\" ] && return\n \n+    [ \"$DI_LOG\" = \"\" ] && DI_LOG=\"stderr\"\n+\n     if [ \"$_DI_LOGGED\" != \"$DI_LOG\" ]; then\n         # first time here, open file descriptor for append\n         case \"$DI_LOG\" in\n@@ -1579,6 +1586,7 @@ collect_info() {\n }\n \n print_info() {\n+    read_uname_info\n     collect_info\n     _print_info\n }\n@@ -1835,12 +1843,25 @@ read_uptime() {\n     return\n }\n \n+set_run_path() {\n+    if [ \"$DI_UNAME_KERNEL_NAME\" != \"Linux\" ]; then\n+        PATH_RUN=${PATH_RUN:-\"${PATH_ROOT}/var/run\"}\n+    else\n+        PATH_RUN=${PATH_RUN:-\"${PATH_ROOT}/run\"}\n+    fi\n+\n+    PATH_RUN_CI=\"${PATH_RUN_CI:-${PATH_RUN}/cloud-init}\"\n+    PATH_RUN_CI_CFG=${PATH_RUN_CI_CFG:-${PATH_RUN_CI}/cloud.cfg}\n+    PATH_RUN_DI_RESULT=${PATH_RUN_DI_RESULT:-${PATH_RUN_CI}/.ds-identify.result}\n+\n+    DI_LOG=\"${DI_LOG:-${PATH_RUN_CI}/ds-identify.log}\"\n+}\n+\n _main() {\n     local dscheck_fn=\"\" ret_dis=1 ret_en=0\n \n     read_uptime\n     debug 1 \"[up ${_RET}s]\" \"ds-identify $*\"\n-    read_uname_info\n     read_virt\n     read_kernel_cmdline\n     if is_disabled; then\n@@ -1963,11 +1984,14 @@ _main() {\n main() {\n     local ret=\"\"\n     ensure_sane_path\n+    read_uname_info\n+    set_run_path\n+\n     [ -d \"$PATH_RUN_CI\" ] || mkdir -p \"$PATH_RUN_CI\"\n     if [ \"${1:+$1}\" != \"--force\" ] && [ -f \"$PATH_RUN_CI_CFG\" ] &&\n         [ -f \"$PATH_RUN_DI_RESULT\" ]; then\n         if read ret < \"$PATH_RUN_DI_RESULT\"; then\n-            if [ \"$ret\" = \"0\" ] || [ \"$ret\" = \"1\" ]; then\n+            if [ \"$ret\" = \"0\" ] || [ \"$ret\" = \"1\" ] || [ \"$ret\" = \"2\" ]; then\n                 debug 2 \"used cached result $ret. pass --force to re-run.\"\n                 return \"$ret\";\n             fi\n"
        }
    ]
}